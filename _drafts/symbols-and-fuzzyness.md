# Symbols and the Fuzzyness of Reality

In this article I want to talk about the Dreyfus' citicism of AI since I think it points out our confusion between the symbolic-driven machine and the thinking mind.
Furthermore, it shows that philosophy is a source for creative ideas to overcome obstacles in the area of AI.

In my opinion Dreyfus (and the philosophers he studied) was ahead of his time with respect to the material reality in the field of AI.
And he was right in pointing out that workers in the field of AI should study some philosophy.
I argue that today we can observe developments in the field of *machine learning* that were already (indirectly) proposed by Dreyfus around 1986.

## Dreyfus

Hubert L. Dreyfus (1929 - 2017) was a philosopher heavily influenced and interested in phenomenology and existentialism.
For example, he studied, Martin Heiddegger, Edmund Husserl, Soren Kierkegaard, Maurice Merleau-Ponty, Jean-Paul Sartre, and Dostoevsky.
He was also a professor at MIT and later at the University of California, Berkeley.
Dreyfus was an aggressive critic of AI in the 60s to the 80s which got him in trouble at MIT; he almost lost his job and he was personally attacked by the AI community.
His publication of *Alchemy and AI* in 1965 caused major controversy.

In his book *What Computers Can't Do* published in 1972 which is basically a long version of the publication, Dreyfus elaborates on the inherent inabilty of disembodied machines to mimic higher mental functions and in his follow up book *What Computers Still Can't Do: A Critieu of Artificial Reason* he added a lengthy new introduction outlining new develpments in the field of AI and assessing the paradigms of connectionism and neural networks that have transformed the field.
In the end, he was right and maybe wrong at the same time.
At a time when researchers were proposing grand plans for general problem solvers and automatic translation machines, Dreyfus predicted that they would fail because their conception of mental functioning was naive.
He suggested that they would do well to acquaint themselves with modern philosophical approaches to human being.
He was right that perception and cognition does not work symbolically but he is maybe also wrong, since it seems that symbol manipulation can simulate the fuzzyness of perception.

The harsh critic Dreyfus had to live with harsh criticism of his work.
He noted that 

>my colleagues working in AI dared not be seen having lunch with me.

The famous author of *ELIZA*, the first chat bot that was able to simulate human-like conversations, was an outspoken critic of Dreyfus' position but he took it professional.

>I became the only member of the AI community to be seen eating lunch with Dreyfus. And I deliberately made it plain that theirs was not the way to treat a human being.

Seymoure Papert arranged a chess match between Dreyfus and Mac Hack (a program) which Dreyfus lost, much to Paper's satisfaction.
By the early 1990 several of Dreyfus' radical opinions had become mainstream.
Oeverall the AI community still ignored Dreyfus since the gap between their principles and phenomenolgy was to huge.
Furthermore, Dreyfus was not willing to tackle the problems he saw but to give an absolut answer: it will never happen.
If one does not search for new ways by scientific observation, one can not find solutions.
The philosophy of Heidegger, on the other hand, suggests limits to the scientific method that we can not overcome.
He famously claimed that

>Science does not think.

By which he means science can not understand the being-in-the-world, which might be the reason for Dreyfus's neglaction.

## Thinking in Symbols?

On the one hand, computers can only do symbolic manipulations, i.e., they compute (in a discrete world).
They change zeros to ones and vice verca but they are not aware of what they do.
If you ask ChatGPT: Are you sad?
It will clarify that it is unable to be in any mood; it only pretends to be sad.
It simulates the communcation of a person that is in a bad mood.

On the other hand, achievements in the area of machine learning suggest that they large networks preceive in a similar way than humans.
These networks do not measure the length of the edges to decide wether an image depicts a chair or a desk.
Instead they *learn* a model of their underlying reality, all its fuzzyness, and then "just know" that the picture depicts a chair.

But let us start from the beginning.
For this we have to go back to a time of pioneers of AI, a time before the rise of *machine learning*.
At that time, many thought that human-like intelligence can be thought of the ability of playing chess, i.e., they belied in *computationalism* (the mind operates like a Turing machine).
If we ignore the chessboard and only care about the moves of chessplayers, then chess is a purely symbolic game.
There are countable many chess games, therefore, in theory, a computer can compute the best next move at any stage of a game.
This leads to the conclusion that thought is explicitly symbolic which is supported by Descartes *mind-body dualism* (mental phenomena are non-physical).
In that case, we just need the correct mathematical formula or some algorithm and a symbol processing machine to reproduce human thinking.
Cognition is the manipulation of internal (explicit) symbols by internal rules thus human behaviour is, to a large extent, context free.
In other words: we just have to look inside the box (the human brain) to fully understand the actions of a person.
Dreyfus' critique of AI concerns this assumption that the brain is analogoues to computer hardware and the mind is analogoues to computer software and that the mind works by performing discrete computations (in the form of algorithmic rules) on discrete representations or symbols.

Dreyfus uses Heidegger's understanding of being that reverses this assumption.
Heidegger argues that our being is in fact highly context-bound.
We are a form of being-in-the-world that is aware of its and other's being-in-the-world.
A person and its world can not be seperated the subject-object distinction is fuzzy.
For example, if I leave a note at a desk, then this physical note is an extension of myself.
Parts of my memory lies on the desk at home.
Furthermore, it is a huge leap from choosing to see reality as consisting of indivisible atoms to state that because we want to or can see things in this way that it is therefore an objective fact that they are the case.
He aggressivly stated that any research program that assumes that such "facts" are real facts will quickly run into prfound theoretical and practical problems.
To think like humans, a machines would require to being-in-the-world like humans are.
Therefore, they would need the awareness of their own and other's being-in-the-workd which leads to the concept of not-being, i.e., death.