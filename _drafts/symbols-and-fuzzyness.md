---
layout: post
title:  "Symbols and the Fuzzyness of Reality"
---

In this article, I aim to discuss Dreyfus' critique of artificial intelligence and shed light on the prevailing confusion between symbol-driven machines and the thinking mind.
To achieve this, I will share my fundamental understanding of phenomenology, since it is the basis of Dreyfus' thought.

I acknowlede that I am not formally trained in the field of philosophy.
As such, please take my insights with a grain of salt.

I think there is little doubt today that Dreyfus and the continental philosophers he studied were ahead of their time regarding the cognitive problem of artificial intelligence.
This suggests that AI practitioners should explore philosophical perspectives even if they come from a place of "the fuzzy world".
I argue that we can now observe developments in *machine learning* that were, albeit indirectly, proposed by Dreyfus around 1986.
Furthermore, this perspective might give us a last stand between us and the machine.

## Dreyfus and AI

Hubert L. Dreyfus (1929 - 2017) was a philosopher deeply influenced by and interested in phenomenology and existentialism.
He studied the works of *Edmund Husserl*, *Martin Heidegger*, *Soren Kierkegaard*, *Maurice Merleau-Ponty*, *Jean-Paul Sartre*, *Nietzsche* and *Dostoevsky*.

Dreyfus held professorial positions at *MIT* and later at the *University of California*, *Berkeley*.
During the 1960s to the 1980s, he emerged as a staunch critic of AI, which led to tensions at MIT, nearly costing him his job and drawing personal attacks from the AI community.
His 1965 publication *Alchemy and Artificial Intelligence*, in which he compared AI to the process of alchemy trying to make gold from metal, sparked considerable controversy.

In following 1972 book, *What Computers Can't Do*, which essentially expands on his earlier publication, Dreyfus delves into the inherent inability of disembodied machines to replicate higher mental functions.
In the follow-up book, *What Computers Still Can't Do: A Critique of Artificial Reason*, he provided a comprehensive new introduction, addressing recent developments in AI and evaluating the paradigms of connectionism and neural networks that have reshaped the field.

In the end, Dreyfus was both right and perhaps wrong simultaneously.
At a time when researchers were proposing ambitious plans for general problem solvers and automatic translation machines, Dreyfus predicted their failure due to their naive understanding of mental functioning as a purely symbolic activity.
He recommended that they should familiarize themselves with contemporary philosophical approaches to human cognition.
Probably due to his aggressive attitute he got completely ignored -- for the better or worse.

Today, many connectivsts will argue that formal methods are not expressive enough for human-like cognition and indirectly agree with Dreyfus.
It seems that he was correct in asserting that perception and cognition are not pure symbolic powered expert systems.
However, he may have been wrong in suggesting that symbol manipulation cannot simulate the fuzziness of cognition and unconscious fast thinking we use when catching a ball.

As a fierce critic, Dreyfus had to endure harsh criticism of his own work.
He noted that 

>My colleagues working in AI dared not be seen having lunch with me.

Joseph Weizenbaum, the famous inventor of *ELIZA*, the first chat bot that was able to simulate human-like conversations, was an outspoken critic of Dreyfus' position but he took it professional.

>I became the only member of the AI community to be seen eating lunch with Dreyfus. And I deliberately made it plain that theirs was not the way to treat a human being. -- Joseph Weizenbaum

Seymour Papert organized a chess match between Dreyfus and *Mac HackÜ (a computer program), which Dreyfus lost, much to Papert's delight.

>"A ten year old can beat the machine" Dreyfus says. Well, the machine beats Dreyfus. What does this tell us about him?

By the early 1990s, several of Dreyfus' radical opinions had become mainstream. 
However, the AI community largely continued to ignore Dreyfus, since the gap between their principles of naturalism and Dreyfus' phenomenology remained too vast.

>What does he offer us? Phenomenology! That ball of fluff. That cotton candy! -- Edward Feigenbaum

Moreover, Dreyfus was not inclined to address the problems he identified but instead provided an absolute answer: it will never happen.
Because of the advances in cognitive science the gap has closed a lot lately.
Many phenomenological claims are now founded in cognitive science but some of the more fundamental criticism is ignored in mainstream discussions about *artificial intelligence* and its impact on society.

Because this topic is so fundamental, I want to do it justice.
Therefore, I will try to guide you into the phenomenological mindset.
We all know naturalism.
It is how we imagine the reality to be, i.e., the assumption that nature is best accounted by reference to material principles, that it encompasses all that exists throughout space and time.
So what is *Phenomenology*?

## Heidegger and the Nazis

Before we can talk about that I have to include an important disclaimer!

While discussing the philosophical contributions of Heidegger, it is essential to also acknowledge his association with *National Socialism*.
He actively endorsed this ideology and exploited it as a mechanism for acquiring control, influence, and power.
For instance, he employed the services of the Gestapo (the Geheime Staatspolizei) to sideline his colleagues.
In other instances, he helped students to move away from the danger.
Regrettably, Heidegger neither apologized nor distanced himself from his actions, nor did he acknowledge any wrongdoing.
Instead, he attempted to obfuscate and justify his actions, which is particularly disconcerting given the fact that both his mentor, Edmund Husserl, and his student (and romantic partner), Hannah Arendt, were of Jewish descent.

Moreover, many argue that it is impossible to separate Heidegger's politics from his philosophy -— they are intertwined, and I tend to agree, at least to some extent.
Thus, engaging with Heidegger's work can be a perilous undertaking, even if many of his ideas are incompatible with Nazism.
Perhaps it was his concern with technology that spiraled into fear and desperation, leading him to view Nazism as a means to escape the prevailing technological mode of being in his time.

Karl Popper, who coined the term *critical rationalism*, which is the bases for how we do science, has no good word for Heidegger.

>Heidegger is, so to speak, the Hegelian of our time, who was also a Nazi, among other things. The worst part is that in Germany and all over the world, for example in South America, France, and Spain, Heidegger is admired and imitated. [...] He usually writes things that one cannot understand at all, and that too, for pages on end! -- Karl Popper

Other notable critics include Karl Jaspers, Theodor W. Adorno (Frankfurt School), Jürgen Habermas (Frankfurt School), Kurt Tucholsky, and numerous others.
Heidegger's thinking and writing have been criticized for dressing up banalities as profound insights, projecting his personal moods onto others, hiding behind an overly complex language, overemphasizing the role of human beings in dertermining the nature of being, lacking any ethical content, circular reasoning and tautologies, being the root for the rise of *relativism* and the rejection of objective turths.

Despite these criticisms, Heidegger remains an influential figure in the history of philosophy, and his ideas continue to be debated and studied in academic circles.
He influenced the works of Herbert Marcuse, Jean-Paul Sartre, Jacques Derrida, Paul Tillich, Michel Foucault and many more.
It would be a mistake to completely dismiss his works because of his character.
But it would also be a mistake to dive into his work without knowing about his actions and connections to the Nazi party.

>How is it that such a brilliant mind was taken in by the Nazis? How could Heidegger be so socially irresponsible? It is the same problem as with Celan: here is a wonderful writer who was a rotten anti-Semite [...] I have shown Heidegger’s brain with a mushroom-like tumor growing out of it to make the point. -- Anselm Kiefer

## Phenomenology

*Phenomenology*, derived from the Greek word "phainomenon" (that which appears), is a philosophical study that explores the structure of raw experience and consciousness.
It was founded by the Austrian-German philosopher *Edmund Husserl* in an attempt to save our production of knowledge, i.e., to give it a solid fundament. 
He picked up the works of *Franz Brentano* who introduced the concept of *intentionality*.

>Knowledge is to be based upon empirical evidence not metaphysical and theological notions. -- Franz Brentano

Phenomenology was further developed by *Martin Heidegge*r, who wrote with *Being in Time (Sein und Zeit)* one of the most influential book of the 20th century.
He shifted the focus from *intentionality* and *consciousness* to the *nature of Being* itself -- from consciousness-oriented to world-oriented.
Later the french philosophers *Maurice Merleau-Ponty* and *Jean-Paul Sartre* added their contributions.

While all phenomologists emphasize the detailed description of conscious experiences or phenomena, it is a broad branch today.
Some phenomologists lean more towards *idealism* some towards *realism*, and many would argue that the traditional distinction between *idealism* and *realism* is not particularly helpful for understanding phenomenology.

One can argue that phenomenology was laid out by Kant's *Critique of Pure Reason* -- a project to explain how we combine what is known as sensory knowledge with reasoned knowledege.
Immanuel Kant argued that there is the *Thing-in-itself (Ding an sich)* which is the status of objects as they are, independent of perception.
Phenomena, in his view, are the things as they appear to us, while noumena are things as they are in themselves (Ding an sich).
Similar to phenomenologists, Kant also suggests that experience is actively structured by certain fundamental concepts.
But to perceive anything at all, some knowledge exists in the mind a priori (independent of experience) -- objects can be *intuited*, and that *intuition* is consequently distinct from the *Things-in-themselves*.
However, many phenomenologists do not posit the existence of noumena or things-in-themselves the same way Kant does.

Back in the day, Husserl thought that Descartes' *rationalism*, was not radical enough and that he constructed an artificial separable "I" that has no basis.
Descartes famously suspended judgement on everything that could possibly be doubted but immediately jumped from the "I think" to the assertion that he is a thinking thing; leaving the human subject all together.
A similar criticism can be found in the works of *Kierkegaard*, a religious thinker that most certainly influenced Heidegger.

Descartes' rationalism neglects the fundamental sensual sensation and experience in favor of rational thinking.
Husserl wanted a new solid foundation of knowledge and since it has to start with conciousness, he wanted a *Science of the Human Spirit* (very similar to Decartes).
Husserl went back to Decartes and tried to bracket (suspending judgement) not the objects but objects of knowledge (particulars, interpretations).
In his later works he even tried to bracket his own theoretical attitude (metaphysical assumtions) to get to the "I" of the lived world (Lebenswelt) rather than the "I" of some abstruse theoretical knowledge of the world.
He wanted to get to the "I know" of a prescientific conciousness, that is, the "I know" of *ordinary life*.

Phenomenology re-emphasis *empiricism* (Hume) over *rationalism* (Descartes, Spinoza, Leibniz) in so far that it values first-hand experimental data.
However, mainly it is not interested in tracing experiences back to an external, physical cause.
It goes against the *Representational Theory of Consciousness*, which assumes that conscious experience is fundamentally a matter of mental representation.
That is, our conscious experience of the world is a result of internal mental representations that depict or model the world.
This view is rather mainstream (cognitive science, neural processes) and compatible with recent developments in *artificial intelligence*. 
In contrast, phenomenology aims to provide a rich, descriptive account of our lived experience as it is, without reducing it to physical or psychological terms, or explaining it in terms of causal mechanisms.
There can be points of tension but also points of agreements here.
For example, phenomenologists emphasise the directness and immediacy of our experience which creates a tension with the view that experience is mediated by internal mental representations.

Phenomenology begins with the one thing we seemingly have access to -- our subjective experience -- and takes it very serious.
It emphasizes one's *world*, rather than focusing on an objective reality.
*World*, in this context, is what Germans mean when they say "meine Welt".
It is what we subjectively perceive.
It consists of moods, emotions and subjective perspectives.
One can say: "In my world everyone seem to be sad."
One of Heidegger's main point is that science (naturalism) has no access to this "world" as a whole, even though this "world" is intuitively understood by us.

Let's try to think phenomenological by using an example:
Rather than focusing on the measurable distance between one's home and the train station, phenomenology examines the subjectively felt distance.
Take time as another example.
If we study time objectively, we measure it in seconds, minutes, and hours.
This is the objective, noumenal (Kant) time that progresses at a constant rate, independent of human experience. However, the phenomenological perspective explores the subjective, first-person experience of time.

>Put your hand on a hot stove for a minute, and it seems like an hour. Sit with an interesting friend for an hour, and it seems like a minute.

For a rationalist or naturalist, time is consistent for everyone (with the exception of Einstein's relativity).
A phenomenologist recognizes that it can appear quite different.
Consider fear as another example.
A naturalist might analyze fear based on the physiological changes that occur, such as the activation of the sympathetic nervous system and increased heart rate, or by observable behaviors.
In contrast, the phenomenological perspective delves into what the actual experience of fear feels like -- the movements and dynamics of consciousness and how it influences the perception of the experience.

Lastly, let's examine Heidegger's most famous example: a hammer held in one's hand.
It is impossible to see the entire hammer at once since some parts are always concealed.
Nevertheless, one is certain of the existence of the object called "hammer".
Even though, scientifically speaking, there is no such thing as a hammer;
our senses and our mind make up the hammer in our head.
Making a logical argument for the existence of the hammer would be peculiar.
While investigating the hammer, one doesn't continuously think, "I can see a hammer. I can still see a hammer.
Therefore, it is one object that is continually present."
Instead, one simply experiences it as a single object without rationalization. 
Furthermore, the experience of the hammer is inseparable from recognizing its function, and properties.
It may be perceived as dirty, cheap or handy and if I see a hammer I see its potential in hammering things.

>This world is not there for me as mere world of facts and affairs, but, with the same immediacy as a world of values, a world of goods, a practical world. Without further effort on my part I find the things before me furnished not only with the qualities that benefit their positive nature, but with value-characters such as beautiful or ugly, agreeable or disagreeable, pleasant or unpleasant, and so forth. Things in their immediacy stand there as objects to be used, the "table" with its "books", the "glass to drink from", the "vase", the "piano" and so forth [...] The same considerations apply of course just as well to the men and beasts in my surroundings as to "mere things". They are my "friends" or my "foes", my "servants" or "superios", "strangers" or "relatives" and so forth. -- Edmund Husserl

Phenomenology takes the hammer seriously without trying to objectify and disect it into its pieces to capture the situated being in the world that each individual embodies.
This thinking is more artistic than scientific.
If you are at a concert it makes no sense to determine the objective meaning of the event.
The real meaning, the truth, is what you experienced at the event.
In this context, objective reality is unable to provide "real truth".
Truth is what appears; what is presented to me.
Phenomenology offers an alternative perspective on truth that neglects emprirical and statistical investigations.
It is not anti-science but trys to provide a kind of "first-person" perspective that can enrich our understanding of consciousness and experience in ways that complement the "third-person" perspective of the sciences.

## Intentionality

Husserl sought to establish an objective study of the subjective (*transcendental phenomenology*) by proposing a *theory of intentionality*.
He developed this idea starting with Franz Brentano's *intentionality*.

Today, *intentionality*, which translates from Latin to "to point at", remains a significant concern among *philosophers of the mind*, particularly the *nature of consciousness*, the *semantics of language*, and the *problem of representation*.
*Intentionality* is a concept used to describe the ability of the mind to form representations and have thoughts about or towards the world. 

A common debate involves the *material* source of *intentionality* and *consciousness* and their relation.
This led to the mentioned *dualism* since the mind seems to have several properties that are not present in physics.
But if *dualism* fails then there are interesting challenges to *materialism* with respect to *intentionality*.

Consciousness, in Husserl's view, has the property of *intentionality* (*aboutness*, *meaning*);
In presentation, something is presented;
in judgement something is affirmed or denied;
in love, something is loved;
in hate something is hated;
in desire something is desired;
Consciousness does not merely carry around representations of objects like a bag of items or ideas but it makes objects present to us.
It is directed and constitutive and meaning-giving and ordering.
The very nature of my knowing constructs the overall situation; 
pulls it together for me;
Conciousness is not passive but active;

The concept of *intentionality* can be likened to the directional "pointer" that connects a signifier to its corresponding signified.
For instance, the term "cat" refers to a real-life cat.
Similarly, an image signifies its depicted subject, and a thought about Mount Everest directs itself towards the actual Mount Everest.
However, the concept of intentionality goes beyond being a mere pointer. 
This is illustrated by the fact that one can harbor contradictory thoughts about the same object or concept.
For instance, someone might hold both beliefs that "the morning star is shining" and "the evening star is not shining," unaware that both stars are, in fact, the same entity.

Furthermore, signifiers, including thoughts, words, or images, have the capacity to represent entities that lack a tangible existence in reality, such as a pink unicorn.
This suggests that the connection between the signifier and the signified is more intricate than a straightforward physical pointer.
This relationship entails a complex interplay of mental and linguistic processes that significantly influence our comprehension and interpretation of the world around us.

How is *intentionality* actualized when the signified either does not exist, or when it refers to multiple entities, such as in the case of the term "atom"?
In the realm of linguistics, and contrary to Plato's notion of ideas as eternally stable, Saussure argued that the relationship between the signifier and the signified is arbitrary or "unmotivated".
The existence of a physical object "out there" is not a necessity.
For instance, while the letters "c-a-t" spell out 'cat', they don't inherently embody the essence of "catness".
Similarly, the French term "chat" does not correspond identically to the English "cat" in terms of the meaning it generates, as "chat" carries different connotations in French.
In another example, the French word "mouton" encapsulates both "mutton" and a living "sheep", whereas English differentiates between the two.
These discrepancies underscore the complexity and the subjective nature of linguistic signification.

We humans apply meaning to otherwise meaningless matter.
For instance, a picture signifies its subject matter only because we assign meaning to it. 
Absent this human intervention, the picture would not inherently refer to anything; particles of ink have no inherent correlation with, for instance, mountains.
Computers operate on a similar principle, even though we often perceive them as continuously referring to objects or concepts.
However, it is once again human interpretation that assigns meaning to the computer's output.
Computers manipulate symbols, and within a specific programming language, these manipulations hold significance.
However, it's important to note that no symbol is *grounded* in a tangible experience.
The meaning is derived from the context provided by the specific language and the human interpretation of that context.

One could argue that unicorns, while not *grounded* in tangible experience, are nonetheless constructed from components of grounded experiences, such as those of a horse and a horn. 
If we adhere to *materialism*, the philosophy asserting that everything, including thought, can be explained in terms of matter and physical phenomena, then my contemplation of Mount Everest can be reduced to a specific arrangement of electrons, neurons, dendrites, and the like. 
In essence, it is just physical particles and nothing more.
However, unlike a computer, there's no external entity assigning meaning to these particles. 
So, the question arises: how can these ostensibly meaningless particles point to something, without an external mind assigning meaning to them, as we do with computers?
If we suggest that a sub-process in the brain assigns meaning to our thoughts, it merely relocates the problem without genuinely resolving it. 
The quandary of how raw physical processes can embody meaning remains unanswered.

## Being and Time

In *Being and Time* Heidegger is concerned with nature of *Being (Sein)*, which, according to him, should be the central question of philosophy (*existential phenomenology*).
He thinks that previous philosophers have failed to adress this question adequately, confusing the concept of *Being* with particular beings or entities.
He also thinks that Husserl's cause to establish a new kind of foundationalism by the process of bracketing is impossible because bracketing is never complete.
You can not strip the transcendential self bare of the evidence of this that or the other kind of object of knowledge and catch it.
You never catch the relation between subject and object (the intentional state) without the objects.

Heidegger distinguishes between *being (Sein)* and *beings (Seiendem)* and argues that *Being* (universal) is the indispensable reason for *beings* (individual: particular manifestation of the universal).
Furthermore, he uses the term *being there (Dasein)* to describe the unique mode of existence of human beings which are beings that *care* (Heidegger's intentionality) about their own existence and embeddedness in a world of meaning and relationships.
Only *Dasein* is capable of questioning *Being (Sein)*, which makes us special.
So do we have the ground of being in the consciousness (Dasein) of our own existence?

>Why is there something rather than nothing? How can I be on this verge of nothingness?

From the title of the book we immediately see Heidegger's emphasis on *time*.
He argues that *Dasein's* experience of time is fundamentally different from the objective, linear conception of time.
*Dasein* experiences time as a unified whole, with past, present, and future interwoven in a complex and dynamic strucutre.

>Dasein finds ‘itself’ proximally in what it does, uses, expects, avoids—in those things environmentally ready-to-hand with which it is proximally concerned. -- Martin Heidegger

The concept of *time* is closely linked to the importance of *death* in Heidegger's philosophy.
He analyzes death without contrasting it to immortality, focusing instead on how our awareness of death imbues our lives with meaning.
Human existence is characterized by *Being-Towards-Death (Sein-zum-Tode)*.
Heidegger envisions death not as a fixed point at the end of one's life, but rather as something we continually approach, with the awareness of its inevitability always in the back of our minds.
From the moment we become Dasein, which is both embodied and linguistic, we are conscious of time and the approaching certainty of our own demise.

When *Dasein* reflects on the world, it experiences a sense of not being the center of that world, and that other processes and beings have their own concerns and experiences regardless of *Dasein's* presence.
This sensation gives *Dasein* one of its original dispositions towards the world: *thrownness* *(Geworfenheit)*.
It feels as if we are thrown into something already in progress.
Although skepticism may lead us to question whether the world is merely a simulation or a dream, the very act of questioning arises from the experience of thrownness that has shaped our entire lives up to that point.
Questioning the realness of our Dasein requires a profound experience of it.

>Dasein gets dragged along in thrownness; that is to say, as something which has been thrown into the world. [...] It exists as an entity which has to be as it is and as it can be. -- Martin Heidegger

When we consider the future, we undertake projects (*projections*), that is, we consider our possibilities of action.
And from all the things we do, there is only one that we must do and that is to die.
Any possible action we take in time is one step closer towards death, no matter what that action is.
We are aware of this, and it actually changes the shape of all experience.
According to Heidegger, this gives our actions value, because we have to choose which one is most worth doing, considering that anything that you do brings your death one step closer.

>[Death is] the possibility of the impossibility of any existence at all [...] it is the possibility of the impssibility of every way of comporting oneself towards anything. -- Martin Heidegger

As if Kierkegaard is speaking.

Heidegger claims that an original way of being is in the disposition of *care*, meaning that one is open to the world, that one will take an interest in it.
One questions the world and is curious about it.
Our projects matter because each project is a step towards death.

In addition, Heidegger argues that the world is *ready-to-hand* and that we are most human, when we putting our hands on the world, i.e., when we explore the *Handlichkeit* (manipulability) of the world.
We should make our hands dirty and play with the world.

*Dasein* cares about *thrownness* (past) and *projections* (future) but also where it gets its sense of *unfreedom*, which is caused by everbody else.
In some sense one is always a product of the time, place, and culture within which one is born, lives, and dies.
But within this *facticity*, these circumscribed limits, there is freedom—in fact, the *necessity of choice*. 
In other words, as thrown, we are thrust into a set of circumstances, and freedom lies in choosing to embrace our thrown possibility.
This duality exists at each and every moment of our existence and bears upon our potentiality for being *authentic*. 
We often conform to societal norms, becoming absorbed in politics, TV shows, career expectations, consumption, and idle gossip.
This leads to a *loss of authenticity* and the pursuit of one's own unique projects, as we become part of the collective *They-self (das Man)*.

>The "they", which supplies the answer to the question of the "who" of everyday Dasein, is the "nobody" to whom every Dasein has already surrendered itself -- Martin Heidegger

*Authenticity* is not about morality, but rather about engaging in activities that define our individuality, which can become overshadowed by the world in a state of *fallenness* (*Verfallens*).
We lose ourselves to the crowd and assimilate with others.
We fall out of ourselves into the crowd.
Again I can sense Kierkegaard.

According to Heidegger, conforming to what everyone else does merely because it is the norm opposes the concept of exercising one's freedom.
This inauthentic way of living leads to becoming entrenched in the mundane, where curiosity and exploration are replaced by repetitive habits and following trends.

To live *authentically*, Heidegger posits that one must be conscious of death and embrace the freedom that this awareness provides, thus allowing for the pursuit of individuality and personal growth.
For Heidegger, when *Dasein* truly reckons with the reality of death and owns that its fate is sealed by the limitations death imposes, our finitude, the *everyday world* falls away -- others, the objects of concern, everything. 
These are moments of *anxiety*.
Think of what happens to persons the moment they receive a diagnosis of cancer or another terminal disease.
The dread and anxiety experienced in that moment are uniquely their own.
There is nothing anyone can do for them. 
They are completely alone with the knowledge that they could be facing the end (or at least a radically modified existence).
Dasein for the most part covers over and flees from this awareness of our being toward death but this reaction is not the only possibility. 
According to Heidegger, it is possible for this truth to somehow be kept in sight.

>When one becomes free for one’s own death, one is liberated from one’s lostness in those possibilities which may accidentally thrust themselves upon one; and one is liberated in such a way that for the first time one can authentically understand and choose among the factical possibilities lying ahead of that possibility which is not to be outstripped [death]. -- Martin Heidegger

For Heidegger, being authentic does not require some exceptional effort or discipline, like meditation. 
Rather, it entails a kind of shift in attention and engagement, a reclaiming of oneself, from the way we typically fall into our everyday ways of being.
It is about how we approach the world in our daily activities. 
*Dasein* inevitably moves between our day-by-day enmeshment with the they (*das Man*) and a seizing upon glimpses of our truer, uniquely individual possibilities for existence.
The challenge is to bring ourselves back from our fallenness in the they (*das Man*) to retrieve ourselves so that we can become our *authentic* selves. 
He does not mean here anything like a moral imperative to do the right thing according to an external law, but rather a clear and focused listening to and heeding of one's unique capabilities and potential.
In doing so *Dasein* authentically understands itself and is able to act in the world accordingly.

As Heidegger sought to think in a pre-scientific manner, he turned to the pre-scientific language of the ancient Greeks.
For instance, "truth" in that era had a different meaning than how we understand the term today. Something that reveals itself to you, or a thing or being that appears to you, was considered true.
Interestingly, this coincides with our expression "a moment of truth," such as when we are compelled to reveal our "true selves".

For Heidegger, *understanding* is a way we project the meaning of our *Dasein* onto objects.
We create objects (that we understand) in our own image.
I make an object for myself; I project my meaning onto it.
Here, we encounter *postmodern* tendencies.
According to Heidegger, we project meaning onto the world, naming things and giving them the meaning we desire, with the way we talk about them being more revealing of ourselves than of the things themselves.
So, what is the quest for truth? 
The quest for truth becomes the pursuit of the unveiling of *Being*.

Heidegger's phenomenology claims to take a step back from the way we ordinarily conceptualize and theorize about reality and begin from immediacy of experience, which has priority for him, and elicit the structure of experience from there. 

## Being and Science

I hope that by now, you have gained an understanding of the phenomenological perspective.
Let's attempt to comprehend science through this lens.

According to Heidegger, science is the theory of reality (Theorie des Wirklichen).
In German, the word for reality, "Wirklichkeit", is derived from "wirken", which means to have an effect or to appear.
What is real is actual (wirklich), or genuinely present (anwesend), regardless of one's standpoint.
That which is real appeals to us by itself, imposing its presence upon us.
It's unsurprising that reality can surprise us, as we may have previously believed things to be different.

To scientifically "capture" reality, we must employ a methodical approach.
Theories should assist us in perceiving reality.
We must envision reality as accurately as possible and derive a theory that allows us to "corner" (stellen) reality.
In doing so, reality falls into our trap.

Science, in contrast to philosophy, must narrow down its focus.
Science does not examine *beings as a whole* or *Being* itself; it only investigates individual beings.
Philosophy, on the other hand, explores the difference between *Being* and *beings*, which Heidegger calls *ontological difference*.

According to Heidegger, scientists must objectify reality in order to extract it.
As a result, everything that is real is transformed into a variety of adversarial aspects. 
What is present is processed into a theory of reality.
Each theory secures a specific domain of reality as its subject matter.
Scientists cannot dissect *Being*; they suffer from an oblivion of it.
And even if they were to combine all the parts and theories, we would still not arrive at a study of *Being*.

In fact, science is so effective precisely because it overlooks *Being*! 
Heidegger goes so far to say that 

>Science does not think. -- Martin Heidegger

Scientists must measure or observe reality using instruments, which serve as traps for reality. 
They rely on tangible aspects of reality and focus on specific elements. 
In this sense, every objectification of what is real involves calculation or counting (mit etwas rechnen).

Undoubtedly, science has provided us with fantastic new tools and insights into reality.
And no one would claim scientists do not think in the sense we understand thinking.
However, Heidegger cautions us that the scientific method requires a certain level of blindness towards the bigger picture and that natural sciences have an exceptional position in our technological society which might be less founded than we think.
In 1951, he already discussed the devastation of the Earth in connection with his understanding of thinking and the role of science.
Scientists may count every tree, measure and observe, but they do not always consider the forest as a whole. 
They often overlook the broader context or *interpretive horizon (Auslegungshorizont)*.
Today, we try to solve climate change using *systems theory*, i.e. a method to act agains our blindness of the bigger picture.
Therefore, I would say Heiddeger had a point.
However, if he is correct *systems theory* shouldn't "work" either.

>Science does not think. This is an offensive statement for ordinary thinking. It does not think because, according to the nature of its procedures and tools, it can never think. The fact that science cannot think is not a deficiency, but an advantage. This alone ensures its ability to engage in a specific subject area according to the mode of research. Let's accept the offensive character of this statement. -- Martin Heidegger

For Heidegger, true understanding of experience must begin with this phenomenological starting point, the immediacy of experience. 

## Meditations on Being

All the fuss about *Being* reminds you maybe about some Eastern philosophy.
It is known that Heidegger was familar with the writings of Zuangzi and many argue that his work is inspired by Eastern thought.
For example, he ask that, instead of investigating reality, we should sit back and let beings, that are present, introduce themselves to us.

Imagine a tree.
Let us assume you are standing in front of the tree.
With all what you are you are standing there and the tree as well.
The tree introduces itself and we introduce ourselves to the tree by standing there.
Again, Heidegger plays with the word *Vorstellung* which means both: introduction as well as imagination.

>Let's pause for a moment, just as when we take a breath before and after a leap. For now, we have indeed jumped, out of the familiar realm of the sciences and even, as will become apparent, of philosophy. And where have we leaped to? Perhaps into an abyss? No! Rather, onto [...] the ground on which we live and die, if we don't deceive ourselves. -- Marin Heidegger

This sounds a lot like the instruction for meditation.
Scientifically this situation remains completely irrelevant.
Standing in front of a tree is probably the most mondane thing ever, right?
Nothing special; who cares?
Important is the non-scientific perspective (also excluding psychology) of the process.
We should not reduce our approch to anything!

>Where is the tree and the human? [...] Where is the introduction that takes place? [...] Is the tree part of our conciousness or is he standing on grassland? -- Marin Heidegger

Even if everything seems to be so trivial for us (as Dasein), it is not trivial at all.
Why should we ask such questions?
Isn't it obvious for everyone that we just stand in front of a tree?

>For suddenly, we give away everything as soon as the sciences of physics, physiology, psychology, along with scientific philosophy, explain to us with all the expenditure of their evidence and proofs that we actually do not perceive a tree, but in reality, an emptiness in which sparse electrical charges are scattered here and there, whizzing back and forth at great speed. -- Marin Heidegger

Heidegger argues that, if we are honest, we tend to let go of the concept of a tree and instead adopt the scientific view of electrical charges, even though science cannot examine its own essence and is blind to *Being*.
We are inclined to believe we understand what is happening, and if we do not know, we trust that science will eventually provide the answers.
Heidegger claims that this assumption is incorrect.
Occasionally, it would be beneficial to simply allow *beings* to exist as they are.
Rather than conceptualizing and relying on reality, we should experience it.
We should seek out *beings* that reveal themselves to us.
*Being* is more expansive than we think, if we give it space.

## Spaces of (Im)Possibilities

Technology is often viewed as having both positive and negative effects, with its impact largely dependent on who controls it.
Many people see technology as a mere tool, adhering to the notion that guns don't kill people, but people do.
In their white paper {% cite eu:2020 %} the *European Comission* states:

>Like any technology, AI brings opportunities and risks. -- {% cite eu:2020 %}

This quote presumes that humans have full control over technology.
Janina Loh refers to this as the *Neutrality Thesis of Technology* {% cite loh:2019 %}.
Numerous other philosophers challenge this perspective as well, arguing that technology can embody inherent values that may not be immediately apparent.

For example, in the 1920s, architect Robert Moses designed overpasses in New York that were too low for buses to pass beneath.
As buses primarily served low-income people of color, this design choice restricted their access to areas that white residents wanted to keep segregated.
Architecture is a form of regulation and control.
If a building has no entrance for wheelchairs, its design denies access for certain people;
By definition this is a form of discrimination -- one that our society no longer "likes" since there is no more justification.
Not all forms of discriminations are seen as unjustfied today.
For example, the missing voting right for children is a form of discrimination that we accept.

Another prime illustration of this principle can be seen in digital spaces.
These environments are imbued with values, determined by the control and regulation of permissible actions.
Digital spaces, or *cyberspace*, as it's often termed, have never been free from regulation, despite common misconceptions.
Rather than being shaped by traditional architectural forms, digital spaces are regulated by *source code*.
The design of websites or applications, dictated by this code, significantly influences the behavior of their users.
In other words, the very structure of these platforms functions as a form of regulation, guiding user interactions and activities.

>Codes constitute cyberspaces; spaces enable and disable individuals and groups. The selections about code are therefore in part a selection about who, what, and, most important, what ways of life will be enabled and disabled. -- {% cite lessig:2006 %}

Web pioneers often look back at the "good old days".
Their (mine included) romantic view of the beginnings of the internet is that everything was possible.
It was easy to build a website.
A little bit of HTML, which you could hack into a simple text editor, and you are done.
However, without regulations coming from coorperations or institutions, social norms and code regulated the web instead.
And since information technolgy was rather new, a few individual coders had a lot to "say".
Today, these individuals got replaced by a view coorperations.

Similar to Lessig, Don Ihde discusses in *Technology and the Lifeworld*, technology as an expandasion or limit of possibilities.
Technology goes beyond mere functionality or direct control.
{% cite rosengruen:2022 %} argues that Western societies are currenty shifting from *rule of law* to *rule of code*:

>[...] source code is about to become the main regulator of individual and institutional behavior that regulates all other regulators including law -- {% cite rosengruen:2022 %}

Rosengrün's argument is not centered on the premise that regulation is inherently detrimental, or that large corporations harbor malicious intentions.
Instead, he acknowledges the necessity, and indeed the inevitability, of regulation.
Moreover, he observes that the alignment of corporate regulatory practices with their profit-making objectives is to be expected.
He forcefully advocates for the *rule of law* as an indispensable prerequisite for a democratic society.
Consequently, any attempt to replace it, could precipitate the dissolution of such a society.
For this reason, Rosengrün asserts that code must be not only open but also subject to regulation.
He underscores the potential dangers of allowing code to regulate law.
For instance, when machine learning is used in the policy-making process, it is unrealistic to expect that law will maintain supremacy over code.

Sam Altman, the CEO of OpenAI, recently proposed a licensing-based regulation during a US Senate hearing. 
This proposal is concerning as it would potentially undermine the open-source community, achieving exactly the opposite of the intended effect! 
While licensing could introduce some safety measures, ultimately it would protect large corporations and obscure the inner workings of the technology that regulate regulations.

The notion of *regulation by code* is familiar to us programmers, as we understand that even the selection of a programming language can either expand or limit our possibilities.
For instance, if one's objective is to engage in machine learning, the programming language Scheme wouldn't be the optimal choice.
Furthermore, the popularity of specific languages can influence their usage.
It's important to note, however, that this degree of openness isn't solely controlled by a single programmer. 
Instead, it's shaped by the broader social and technological systems that surround us.
As a significant amount of control lies with large corporations, they inherently influence the horizon of the possible.

Technology not only provides a framework for action, but also actively shapes our environment.
It constructs particular subjects and defines our identities, delineating not only who we are but also who we can potentially become.

Another stark illustration of technology's pervasive (positive) influence can be found in modern birth control methods and in the strategies we deploy to shape our identities, such as curating online profiles to garner peer validation.
It's widely acknowledged that social media can inadvertently amplify negative aspects of human behavior, underscoring the necessity to incorporate media into our understanding of this phenomenon.
Adopting a phenomenological viewpoint, it becomes clear that the subject and the technology it employs cannot be disentangled from each other.
Further instances of technology's impact manifest in the realm of beauty and medical advancements. 
Technologies related to beauty and cosmetic surgery exert pressure to conform to evolving standards of beauty, standards that were unattainable just six decades ago.
Similarly, assistive tools have profoundly enhanced the agency of individuals with disabilities, and advancements in medical transitions have carved out new avenues for expressing and experiencing transgender identities.

## A Mode of Understanding

I think, Heidegger goes a bit further.
He thinks of technology as a *mode of seeing* where every "seeing" has its necessary blind spots.

He expands on the example of the hammer to illustrate his thoughts about technology:
When using a hammer (a form of technology), you don't even think about the tool itself; instead, you focus on the nail.
The hammer recedes from your awareness, and you concentrate on the task *at hand*.

Or imagine a keyboard.
As you become proficient at typing, your primary experience involves the words appearing on the screen rather than the act of pressing the keys.

Technology vanishes from our *world*.
Only if it breaks or fails to perform as expected it introduces itself again.
Otherwise, it simply serves as a medium through which we experience our world.
For Heidegger, technology withdraws from our attention and becomes transparent.
We don't experience the technology itself, but rather the world through it.
Consequently, technology introduces its own *mode of seeing*.

When you drive a car proficiently, you develop a sense of the vehicle's size and whether it can fit through a gap.
Similarly, wearing nail extensions frequently can cause you to forget about them, even though they change how you interact with objects.

Part of the allure of technology is found in the diverse opportunities it provides for unique forms of embodiment.
Philosopher Bruno Latour posits that when technology becomes sufficiently transparent, it becomes an intrinsic part of our self-perception and our experience of the world, thereby giving rise to a new, compound entity.
Evidence supporting this viewpoint is substantial (citation needed).

Our enjoyment of driving stems from the fact that we transform into the driver, a being with speed and power surpassing any land creature.
Likewise, our delight in operating digital devices arises from the sensation of becoming a being that can converse with someone on the opposite side of the globe at a speed comparable to a lightning strike.

Similarly, a person wielding a hammer essentially evolves into a new subject, equipped with its own unique way of perceiving the world. This newly formed subject, as a result of the technology's influence, experiences the world from a distinct perspective and possesses an individualized subjectivity.

If this assesement is correct and a new piece of technolgy comes along, we can and should ask what kind of subject/people will this turn us into?

Heidegger takes this exploration another step further when discussing not merely specific technologies, but the very *essence of technology* itself.
In his essay *The Question Concerning Technology*, he challenges the prevailing views of technology as merely an instrument (a means to an end) and as a product of human activity.
He posits that while we perceive ourselves as creators of technology, in reality, technology originates from elsewhere.
He also presents technology as potentially highly dangerous.

Heidegger asserts that perceiving certain types of technology as instruments or tools is itself a technological *mode of understanding*.
He argues that there is no such thing as a purely instrumental object.
Instruments only manifest to those who interpret the world instrumentally.
In this view, technology is a way of comprehending the world that reduces it to raw material, encouraging us to see the world solely as a realm for our intervention.

In ancient times, the Greeks used the term "techne" to denote what we now call technology.
However, their concept of "techne" embraced both art and technique, something akin to our modern notion of "craft".
For the Greeks, "techne" implied the act of bringing something into existence.
It was not about an engineer constructing an object; rather, the craftsman's role was to assist in the emergence of something, so to say helping the material to take on a new form.

A craftsman would never consider themselves as the absolute origin of the reality of what they were creating.
In Heidegger's view, they would perceive themselves as facilitating the process of something coming into existence.

In stark contrast, modern technology is not seen as aiding something to emerge.
Instead, as Heidegger posits, it forces things into existence.
We have come to perceive ourselves as the source of what we create, believing that we are the origin of everything.
This is a highly specific way of interpreting the world, one that seemingly grants us the power to control everything around us.
Therefore, technology unveils the world in a particular way -- it reveals the world as raw material and conceals *Being*.

Given that technology represents a *mode of understanding* the world, and acknowledging that our understanding of the world is not entirely self-determined, this perspective seems to envelop us; it is greater than us as individuals.
Heidegger sees the "highest danger" of technology as its potential to erode our ability to interpret reality profoundly.

The moment we start viewing ourselves as manipulable raw materials, we cease to see ourselves as the ultimate source from which fresh interpretations of the world can spring.
Furthermore, technology can trap us in a specific worldview because as soon as we attempt to devise a new way of interpreting the world, we find ourselves trying to exert power over our inherent *will to power*.
In essence, we attempt to control our very propensity for control.
Every effort to overcome this *will to power* only serves to reinforce it.
Consequently, every attempt to break free from this technological mindset only propels us back into it.

Heidegger suggests a balance: to release, to "let it be".
That is, to both say "yes" to technology, accepting its presence, while simultaneously saying "no" in order to maintain a certain distance.
This balance keeps us open, prepared, ready for the emergence of new interpretations of the world.
How they can come to us remains a mystery.

>Philosophy will not be able to bring about a direct change of the present state of the world. This is true not only of philosophy but of all merely human meditations and endeavors. Only a god can still save us. I think the only possibility of salvation left to us is to prepare readiness, through thinking and poetry, for the appearance of the god or for the absence of the god during the decline; so that we do not, simply put, die meaningless deaths, but that when we decline, we decline in the face of the absent god. – Heidegger, Spiegel inverview in 1966

## Conclusion

I have offered you my understanding of some of Heidegger’s philosophy. 
What are my personal thoughts on it? Well, I believe that he undeniably provides some insightful perspectives. 
His portrayal of the human condition as *Dasein*, thrown into a world in progress, resonates with my personal experience. 
It counters the illusion that we possess complete control over everything.

Even if our *Dasein* cannot be objectively measured, it remains an undeniable presence -- the subjective experience of our world matters, regardless of its "rationality". 
A person suffering from paranoia may be irrational, but their experiences are real and impactful. 
Moreover, our existence is neither strictly mental nor physical; 
instead, it extends through time and space and is not so easily separable from the world. 
If I write a note on a piece of paper, does this note become part of my being? 
If someone steals my mobile device containing all my essential data, feeling as though my identity as my understanding of "who I am" and "how I see the world" has been robbed, might be a reasonable response.
This partially explains why many individuals enjoy driving fast cars, despite their detrimental impact on the environment. 
The car and driver together form more than a mere "thing";
they create a composite being.

Heidegger's emphasis on the *ordinary life* may seem trivial, yet, how frequently do we feel lost, overwhelmed, and alienated in the world, even though we are experts in navigating this chaos? 
Often, we forget that we are temporal beings in a world where we are deeply rooted.
This fact becomes crystal clear when considering all the small habits our bodies carry out so effortlessly that we hardly give them a thought.
All the smells we can perceive, all the various tactile experiences we can receive and give, and the ways in which we can walk, sit, run, and dance. 
Sometimes, when one feels lost in the digital spectacle, returning to the simplicity of the ordinary can offer a reassuring sense of home.

Heidegger's intense concerns regarding technology have significantly influenced many thinkers.
This perspective challenges the mainstream belief that technology is inherently neutral.
It is tied to the notion that we have far less control over our *being-towards-death* than we typically presume.

Few would dispute that technology has transformed our self-perception. 
Sigmund Freud already famously introduced three humiliations:

+ Earth is no longer the center of the universe.
+ Humans are not the apex of creation but part of an evolutionary biological process.
+ The human "ego" is not fully in control but is governed by unconscious processes.

To this, I would append Nietzsche's declaration that:

+ God is dead, implying that normative values are constructed and lack any metaphysical "essence".

We might further speculate two additional humiliations:

+ The human "ego" or "self" is an illusion.
+ Machines are more intelligent than us.

Despite these considerations, it seems that we still resist the notion that technology could or have already changed us in undesirable ways, even if we take all the precautions to avoid negative outcomes. 
Isn't that so? 
Even though the European Comission upholds the *Neutrality Thesis of Technology*, considerable distrust and resistance exist, often funneled into dystopian futures envisioned by the *cyberpunk* genre. 
Therefore, I argue, we can no longer envision having a choice in which technological path we take!
We lack alternatives; we lack the capacity to dream of a different future.
Heidegger may indeed be right when he describes our *technological mode of being*, wherein we perceive the world and its inhabitants as tools -- entities we can dominate and control at will.
His student Hannah Arendt later emphasised her fear of our inability to think (in an Heidegerian sense) and consequently to steer historical developments.

>It could be that we, who are earth-bound creatures and have begun to act as though we were dwellers of the universe, will forever be unable to understand, that is, to think and speak about the things which nevertheless we are able to do. -- Hannah Arendt

Heidegger was onto something significant. 
After all, his critics from the Frankfurt School, such as T. Adorno, partially concurred when they discussed the concept of *instrumental rationality*, which often leads to irrational outcomes. 
However, in stark contrast, they argue that we are not rational enough. 
In other words, decisions that are instrumentally rational may cumulatively produce irrational results -- a viewpoint compatible with *systems theory*. 

For instance, it may be entirely instrumentally rational to use cheap oil to bolster my company's profits, but this contributes to the death of people -— an outcome that is irrational. 

If we aim to combat climate change, we likely need to set aside Heidegger's philosophy with respect to technology.
Indeed, Heidegger offers no concrete solution and leaves us in a state of uncertainty, waiting for a God who might rescue us. 
Perhaps, from his perspective, climate change is the God we await.

Our response to the increasing frequency of anticipated climate disasters is primarily technological.
It's not God, but artificial intelligence and other technologies that we hope will save us.
And I must believe in this, because I can't conceive of any alternative that wouldn't result in unprecedented loss of life. 
However, this widely-held view serves to further empower the masters of technology.

>The everyday demonstration of the power of our technology grants the priests of the church, who make all of this possible, almost limitless authority and credibility. -- {% cite weizenbaum:2001 %}

As noted in {% cite rosengruen:2021 %}, a viewpoint often propagated, referred to as the *transhumanist* view, suggests that each individual has the choice of whether to utilize technology or not. 
However, similar to the *Neutrality Thesis of Technology*, this *freedom of choice* only makes sense when viewing technology from a strictly *STEM* (science, technology, engineering, mathematics) perspective.

As McLuhan points out in {% cite mcluhan:1964 %}, the true substance of a piece of technology isn't defined by what it seems to convey, but rather how it interacts with society as a whole. 
He asserts that advancements in *communication technology* are the key drivers of societal change, rather than the content being communicated.

>The medium is the message -- {% cite mcluhan:1964 %}

The promise that technology will enhance our lives paradoxically echoes the belief in metaphysical concepts that self-proclaimed rationalists often disdain; 
it resembles a new form of religion. 
Furthermore, when we examine the material reality, we fall short in providing even low-tech technology to those who need it most. 
We don't even have to consider ambitious endeavors such as colonizing Mars or turning space travel into a commercial venture.

For instance, many disabled individuals do not face a struggle in identifying suitable assistive devices, but rather in acquiring them. 
These tools may not be affordable, or their production may have been discontinued due to insufficient demand. 
Often, these individuals grapple with obtaining basic equipment such as walking sticks, forceps, wheelchairs, and other low-tech tools. 
Believing that highly sophisticated robots can grant them more autonomy, when one examines the situation systematically, requires a considerable leap of faith.

Of course, there are also wonderful examples of scalable technologies available to many people. 
However, the crux of the matter is that the adoption of new technologies is neither avoidable nor optional; 
quite the contrary, it is often inevitable and if decisions are made by a view "priests" we can no longer call our society democratic.
Furthermore, while these "priests" may not harbor any malevolent intentions, their motivations most certainly do not completely align with the interests of the general public and according to {% cite rosengruen:2021 %} they assume to have many answers which are debated to this day and consequently quite sucessfully plant a new concept of being human in the public discourse -- a naive techno-futurism that lost awe to the human condition (*Dasein*).
Weizenbaum aptly identifies the devastating effects that such transhumanism unfolds in public:

>Firstly, to impress them with the depth of the task that the AI is dealing with. Secondly, to suggest the progress that has already been made. And thirdly -- and this is particularly important -- to propagate a certain image of humans as completely self-evident in society. {% cite weizenbaum:2001 %}

While I acknowledge the robustness of Heidegger's critique of technology, I do not subscribe to the distinction between what he terms as the benevolent old technology and the malevolent new kind, such as differentiating between a windmill that passively harnesses wind and a turbine that forces a river into a specific course. 
I view this distinction as arbitrary.

Moreover, categorizing perspectives as either *instrumental* or *non-instrumental* seems to introduce an unnecessary binary. 
This can lead us into the nostalgic trap of perceiving traditional, conservative, and thus hierarchical ways of life as more humane. 
Consequently, the leap to slogans such as make our country great again, advocating a return to some supposedly better past, becomes less significant. 
However, this should not deter us from critiquing technology.

Let's consider an analogy: the concept of *free* and *instrumental play*, as introduced by Wolfgang Iser in {% cite iser:1993 %}. 
Iser labels play in games with specific goals as *instrumental play*.
At the other end of the spectrum is *free play*, a form of play devoid of definite endpoints, perpetuating the continuity of play.

*Instrumental play* is a goal-oriented approach that values efficiency, expertise, and optimized strategies as components of play. 
For instance, if children engage with their surroundings, such as running around, this can be considered *free play*.
However, when they introduce goals like catching one another, the play tends more towards *instrumental play*.
The aim of playing isn't solely to reach the end but to discover the most effective way of getting there.

However, there's no such thing as pure *free* or pure *instrumental* play.
Playing chess to win money leans heavily towards *instrumental* play, while playing with a ball purely to enjoy the physical experience is predominantly *free* play. Furthermore, there's no inherently "good" or "bad" style of play. 
In fact, the issue sometimes arises when we deem *instrumental play* to be the correct, or "good," way to play.

But here's the crucial point: *instrumental play* isn't the opposite of *free play*; 
instead, there exists a tension between the two. 
One can derive deep enjoyment from improving a skill, achieving goals, or uncovering solutions to complex problems. 
Similarly, we can perceive the Earth and its inhabitants instrumentally (as a means to an end) or appreciate them for what they are (as ends in themselves).

Therefore, I favor the Kantian notion extended to all beings as well as things -— never viewing anything merely as a mean to an end, but always as an end in itself. 
Furthermore, just as *instrumental play* can enrich *free play*, such as by enabling other forms of *free play* via the acquisition of new skills and habits, I also believe that the scientific perspective, which necessitates objectifying entities and often neglects the broader context, can still enhance our appreciation of the whole.

>I have a friend, who is an artist. And he is sometimes taken a view which I don't agree with very well. He hold up a flower and says: "Look how beautiful it is." And I agree. And he says: "I as an artist can see how beautiful that is but you as a scientist take this all apart and it becomes a doll thing." And I think he is kind of nutty. First of all the beauty that he sees is available to other people and to me too. I may not be quite as refined aesthetically as he is but I can appreciate the beauty of the flower. At the same time, I see much more about the flower than he sees. I can image cells in it; the complicated actions inside which also have a beauty. I mean it is not just beauty at this dimension of one centimetre, there is also beauty at a smaller dimensions; the inner structure also the processes; the fact that the colors and the flowers evolved in order to attract insects to pollinate it is interesting. It means that insects can see the color. It adds a question: does this aesthetic sense also exist in lower forms? Why is it aesthetic? All kinds of interesting questions which the science knowledge only adds to the excitement and mystery in the aura of a flower; it only adds. I don't understand how it subtracts. -- Richard Feynman

Regarding Heidegger's concept of *Being*, I have also reservations. 
It appears to me that he has introduced yet another fundamental entity, much like Plato did with his *world of ideas*. 
It's peculiar that by substituting *Being* with *God*, some of Heidegger's works take on a biblical mysticism.

Probably unintended, Heidegger seems like a preacher of *Being*, that is, guiding us to the "right" and *authentic* path of life by focusing on *Being*. 
Moreover, whenever the term *authentic* is used, I tend to be suspicious. 
It's the most effective pitch of any mystical guru: be *authentic*; 
find yourself. 
Nobody wants to be inauthentic, a sheep in the herd; 
everyone wants to feel special and be part of an extraordinary group.

It's also unsurprising that this *esoteric mysticism* can swiftly lead to *fascism* because one becomes an entity elevated above the herd. 
After all, there's a desire to "correct" others who are on the "wrong" path, and if they are not "fixable," more drastic measures might be employed. 
While there is no causal link, and many *esoteric* people strongly oppose *fascism*, there are tendencies, and we can observe a correlation between *esotericism* (and techno/science scepticism) and *fascism*, at least in Germany during the time of the pandemic.

Heidegger likely wouldn't view the philosophical "advice" discernible in his writings as something to be cultivated in others or even consciously in ourselves. 
Such a contrived promotion of these concepts would be too subjectivist, *instrumental*, or even moralistic, which is not Heidegger’s intent. 
Yet, how people interpret and use his texts is up to them.

Depending on its definition, being *authentic* is nearly always either impossible or so loosely defined that it becomes meaningless. 
Heidegger's definition tends to lean towards the latter. 
It also seems slightly contradictory since we are already *thrown* into a world in progress; 
how can we be anything other than what we already are, including how we attend to and engage with our existence? 
Indeed, we can stand up for our beliefs, be responsible, and honest with ourselves and others, but if we strip away everything we've picked up from others, we're probably left with nothing.

## Wittgenstein's Language Games

When we examine our languages, it becomes apparent that some words are rooted in experience. 
Although the relationship, as previously mentioned, is arbitrary, it nonetheless exists. 
For instance, the word "dog" is based on the experience of a specific type of being. 
However, according to Ludwig Wittgenstein, this explanation lacks precision. 
In fact, the word "dog" is rooted in numerous experienced situations, and its meaning depends on the *language game* we are currently engaged in.

Take, for instance, the term "sharp" as applied to a knife. 
In a primary school context, the knife may be deemed "sharp," whereas in a kitchen context, the same knife could be seen as "not sharp". 
The knife's sharpness is contingent on the practice for which it is used.

Similarly, as a chemist, one might describe a glass as "full," while a physicist, recognizing that most of the space between atoms is empty, might argue that the glass is "not full". 
Hence, words are anchored in multiple *language games*, that is, the activities and practices in which they are employed. 
They are not metaphysically tethered to a specific object.

One might assume that in chess, the "knight" corresponds to the distinct horse-like object. 
However, the knight is a unique kind of piece that alone can leap over other pieces. 
Its movement is singular: one step straight and one step diagonally. 
A word is akin to a chess piece in this respect; 
its meaning is in what it can do, not the object it represents. 
Moving a knight to C3 does not depend on the horse-like object itself. 
The move can be executed regardless of the piece's form, whether with a penny or digitally on a computer. 
In chess, the "knight" derives its meaning from what one can do with it. 
Uttering a word is similar to making a move in the *language game* you are participating in. 
The meaning of the word resides in the activities and interactions within a given environment that are linked to the use of that word, rather than the corresponding object.

Wittgenstein believed that a significant amount of confusion arises when we mix up *language games*, especially in metaphysics. 
He argued that many metaphysical questions stem from a misuse of language.

For instance, a friend of mine is an artist, and she has crafted impeccably convincing replicas of everyday objects. 
During one of my visits, I asked her: "Is this apple real?" She replied, "Yes, you can eat it." 
We were playing the same *language game*, and she understood my question. 
She was aware that I might have mistaken the apple for one of her replicas. 
She even recognized that my question implied my desire to eat the apple. 
However, if I were to pose the same question to a fruit vendor at a market: "Is this apple real?" he would probably answer, "Yes," albeit with some confusion. 
My question doesn't make sense in the *language game* he's playing; we're in different games, and in his game, my question is meaningless.

If we engage in a mathematical *language game*, the seemingly reasonable question "is something real" (in an existential sense) might prove to be meaningless. 
Such a question makes perfect sense when suspicion of imitation arises, but in math, querying whether numbers "exist" might simply be a misuse of language. 
According to Wittgenstein, philosophers have attempted to "fix" this misunderstanding by constructing a system, essentially engaging in metaphysics. 
Yet, ironically, it's language that can lead us astray while remaining highly transparent.

Nonetheless, this doesn't imply that words are not grounded in reality. 
Quite the contrary, they are deeply rooted, albeit in a much more intricate manner! 
For instance, the relational context of words within a text hints at the *language game* in play. 
Only once we understand the game can we be confident about a word's intended meaning.

Why is this significant in conversations surrounding *artificial intelligence*? 
Indeed, if an AI, such as ChatGPT, aims to be valuable, it must at least mimic an understanding of *language games*. 
Interestingly, well-constructed prompts frequently serve to illuminate the language game that the chatbot is participating in. 
Moreover, meaning can only emerge when words (or other symbols) are grounded in experience. 
Hence, it is tempting to assert that without experience, *strong AI* is unattainable. 
Finally, it could be argued that the use of the term "intelligence" in the context of AI might constitute a misuse of language.
 
## Searles' Chinese Room Argument

John Searle, in his *Chinese Room argument*, asserts that symbolic AI will never achieve strong AI status, meaning it will remain a simulation of intelligence rather than truly embodying it.

Here's how the argument unfolds: Imagine a person, let's call him Bob, who is confined within a room that houses a book of instructions written in Chinese. 
Bob neither understands nor speaks Chinese, and his only means of communication with the outside world is a small slot through which he can pass written text. 
Outside the room, there's a person who is fluent in Chinese. 
This person writes a message on a piece of paper and slides it through the slot into the room. Bob, upon receiving the text, consults the instruction book to find the appropriate response, writes it down, and sends it back out through the slot.

From the perspective of the person outside the room, it appears as if Bob can comprehend and communicate in Chinese, despite Bob's ignorance of the language. 
This situation is similar to the operation of a computer: it receives input and employs specific rules to produce an output.

However, I believe this argument lacks substantial strength as it hinges on the presumption that there is a single atomic entity that "understands" Chinese. 
Consider a single neuron in my brain, for instance. 
This neuron doesn't understand English on its own. 
Therefore, following Searle's logic, one could conclude that I don't understand English. 
But the reality is that my entire system comprehends English. Following this reasoning, one could argue that the entire room, in Searle's scenario, comprehends Chinese.

Presumably, what Searle is trying to convey is that the Chinese language, in this scenario, isn't grounded in experience. 
Being able to use words and construct grammatically correct sentences doesn't necessarily equate to understanding the content, as there's no connection to personally experienced situations. 
A more compelling argument on this topic has been made by Dreyfus.

## Dreyfus' Criticism of Symbolic AI

In {% cite dreyfus:1986 %}, Dreyfus provides a compelling critique of *symbolic AI*, examining the chasm that exists between *expert systems* and *human experts*.
While reading this think about *sub-symbolic systems* such as artificial neural networks.
Do they suffer from the same deficiencies?

An expert system is a computer program designed to emulate the decision-making capabilities of a human expert using if-then rules instead of conventional procedural code. 
The presumption underlying this concept is that experts adhere to precise, unambiguous rules, distinguishing them from non-experts. The theory suggests that it's possible to codify this expertise into symbolic rules and then incorporate them into a machine. 
Therefore, the idea is that any entity, human or machine, with access to these rules could potentially achieve expertise.

Dreyfus dissects this reasoning through a Heideggerian lens. 
We can scrutinize this argument more closely by posing some simple but probing questions:

1. Does an expert system genuinely replicate the practices of human experts?
2. Are you an expert in any field?
3. How did you become an expert?

According to Dreyfus, humans acquire expertise through various stages. 
Let's consider learning to drive as an example. 
A novice driver learns to gauge her speed by referencing the speedometer. 
She is given rules such as "shift to second gear when the speedometer reads ten miles per hour". 
For a beginner, driving can be exceptionally slow-going, as one must remember all the rules and features.

As the practice continues, the beginner becomes aware of various aspects of the situation. 
After exposure to numerous examples, the student learns to recognize these new elements. 
Instructions can now refer to these newly understood situational aspects, as well as the objectively defined, non-situational features recognizable to the novice.

The advanced beginner driver, utilizing both situational (engine sounds) and non-situational (speed) elements in their gear-shifting rules, learns the maxim: shift up when the engine sounds like it is racing and down when it sounds like it's straining. 
She learns to observe the demeanor, as well as the position and velocity of pedestrians or other drivers. 
For instance, she can differentiate the behavior of a distracted or inebriated driver from that of an impatient but alert one. Engine sounds and behavior styles are difficult to encapsulate in words, making choice examples vital for learning such distinctions.

Upon reaching the stage of competence, the student learns to differentiate between important and unimportant elements of the situation. 
With growing experience, the number of potentially relevant elements that the learner can recognize becomes overwhelming. 
This complexity might lead the student to question how anyone could master the skill. 
To manage this overload and attain competence, learners, through instruction or experience, devise a plan or select a perspective. 
This perspective then determines which elements of the situation should be treated as significant and which ones can be disregarded. 
By focusing attention on only a few of the many possible relevant features and aspects, such a perspective simplifies decision-making.

The competent performer thus seeks new rules and reasoning procedures to determine a plan or perspective. 
However, these rules aren't as straightforward as the rules and maxims provided to beginners. 
There are simply too many situations, each differing subtly from the others. 
In fact, there are more situations than can be named or precisely defined, so no one can prepare a comprehensive list of actions for every potential situation. 
Thus, coping with this complexity becomes challenging, rather than exhausting. 
At this stage, if the learned rules fail, the performer might feel remorse for their mistake rather than rationalizing that they hadn't been given adequate rules.

A competent driver, considering factors like speed, road conditions, and time pressure, may decide she is going too fast. 
She then has to decide whether to ease off the accelerator, remove her foot entirely, or step on the brake, and determine precisely when to do so. 
The driver may feel relieved if she navigates the curve without eliciting honks from other drivers, and alarmed if she begins to skid. Successful plans trigger feelings of euphoria, while mistakes create a sinking feeling.

As the competent performer becomes increasingly **emotionally** invested in their task, it becomes harder to maintain the detached rule-following stance of the beginner. 
While it may seem that this **emotional** involvement could hinder objective rule-testing and thus impede further skill development, the opposite appears to be true. 
If the learner's experiences are **emotionally** charged, the resulting positive and negative experiences will reinforce successful responses and inhibit unsuccessful ones. 
The performer's theory of the skill, represented by rules and principles, will gradually be replaced by **situational discriminations** paired with associated responses. 
Proficiency seems to develop if, and only if, experience is assimilated in this atheoretical manner and intuitive behavior replaces reasoned responses. 
Action becomes easier and less stressful as the learner simply **sees** what needs to be achieved (rather than what actions to take to achieve it), rather than deciding through a calculative procedure which of several possible alternatives should be chosen.

The proficient driver, approaching a curve on a rainy day, may feel in her gut that she's going dangerously fast. 
She must then decide whether to apply the brakes or merely to reduce pressure on the accelerator by a certain amount. 
The proficient performer, immersed in her skilled activity, can discern what needs to be done, but must decide how to do it.

The expert, thanks to a vast repertoire of situational discriminations, not only **sees** what needs to be achieved; she intuitively understands how to accomplish her goal. 
This capacity for subtle and refined discernment sets the expert apart from the proficient performer. 
Through ample experience in various situations, the expert performer's brain gradually subdivides this class of situations into subclasses, each associated with the same response. 
This allows for the immediate intuitive situational response that characterizes expertise. 
Driving likely demands the ability to discern a similar number of typical situations. The expert driver not only senses when it's necessary to slow down on an off-ramp; she naturally performs the appropriate action.

A beginner relies on rules and facts for decision-making, much like a programmed computer. 
With talent and extensive, engaged experience, the beginner evolves into an expert who intuitively knows what to do without resorting to rules. 
Normally, an expert does not deliberate. She doesn't solve problems. 
She doesn't even consciously think. She simply does what usually works, and of course, it usually does.

This description of skill acquisition illuminates why experts often struggle to articulate the rules they're following: they're not abiding by any predefined rules! 
Instead, they're discerning thousands of unique cases. 
This also explains why expert systems never quite match human experts. 
If you ask an expert to describe the rules she's using, you're essentially compelling her to regress to the level of a beginner and recite the rules she learned at the outset. 
Thus, instead of applying rules she has long forgotten, as knowledge engineers might assume, the expert is forced to recall rules she no longer utilizes. 
If these rules are programmed into a computer, the computer's speed, accuracy, and ability to store and access millions of facts could surpass a human beginner using the same rules. 
However, such systems can only achieve competence at best.
No number of rules and facts can emulate the knowledge an expert acquires when she has accumulated the experiences and outcomes of tens of thousands of situations.

Hubert Dreyfus, in his critique, directly targets the fundamental assumption underpinning symbolic AI, which he labels "the psychological assumption". 
He defines it as follows:

>The mind can be viewed as a device operating on bits of information according to formal rules.

Dreyfus challenges this assertion by illustrating that human intelligence and expertise primarily depend on unconscious instincts rather than conscious symbolic manipulations. 
Experts swiftly resolve problems by leveraging their intuitions, not through methodical trial-and-error searches.

However, Dreyfus' insights extend beyond this academic revelation. 
He cautions, in a vein similar to Heidegger, that treating rationality as rule-governed behavior presents substantial risks to society. 
He posits that the calculative conception of reason underpins a broader trend towards calculative rationality in our culture, a trend laden with potential peril. 
The escalating bureaucratic nature of society -- a society abstracted and regulated by rules -- heightens the threat that future skill and expertise may erode due to an excessive reliance on calculative rationality.

## References

{% bibliography --cited_in_order %}






## TODO

## Escaping the Matrix

In Western thought we tend to think of the body as a second-class entity, as the thing being controlled by the mind;
a tradition that started with Plato continued with Descartes and the scientific revolution.
There is this longing to overcome the flesh

Plato wants to guide us out of the cage and into the light of wisdom.
He wants us to recognize the illusion directly in front of us.
Paradoxically, what he initiated led to the contruction of an actual illusion bringing metaphysics into our world.

Contrary to Plato's belief, phenomenology suggest that there was never a cage in the first place.
To escape the Matrix, it is unnecessary to swallow the "red pill".
Instead, turn off your phone -- your limitless distractions -- and go out to touch, see, and be present in the world.
We must embrace being a perpetual beginner: coming back again and again to what we perceive before us, remaining open to the adventures of experience.

Even if we have this attitude, our life is not a series of problems to be solved through sophisticated analysis of data or facts to be recorded.
For example, mindfulness practice to improve ones performance or other "life hacks" are just another instrumentalization of being.
Meditation for the sake of a better life-work-balance is just mental workout.


Being is bigger than that.

While science and technology liberated many of us from our own ignorance and the harsh condition of a life with nature, today it is hard to believe that more knowledge, more information, and more technology will continue this trend if we 


When it comes to specific scientific investigations there is nothing wrong about this approach.
But as a general position on how things are it is problematic, since our immidiate experience of the world is very different.

We never need to look for our right arm in the way we might look for a pair of scissors around our desk.
That cloud that I see can be a small cloud close overhead or a huge cloud far above; 
meanwhile what I had thought was a bird turns out to be a speck of dust on my glasses.

>I cannot conceive myself as nothing but a bit of the world, a mere object of biological, psychological or sociological investigation. -- Merleau-Ponty

The worldlyness of our *being-there* combined with our subjective and inter-subjective experience enriches our increasingly "head-based" and digitial reality.
We should allow ourselves to wonder and neglect any rationalization that reduces being to an object.


Heidegger posses the question if our objectifying mode of thinking led us into a vortex that we can no longer escape if we stay on the path of domination.


## Criticism of Heidegger

As I already disclaimed, Heidegger is a dangerous thinker and we have to be aware of his connection to *national socialism*.
He is so effective and appealing because he hit a lot of hight notes.
His emphasis on experience through the lense of *Dasein* as *being there thrown* into a world already in progress and his understanding of technology as a *mode of understanding* are powerful sources of critique of modern life and our technological development under *technology exceptionalism*.
He expresses a mood that many of us feel: that we instrumentalise ourselves more and more.

## AI and Heidegger

For scientists it is rather senseless to take Heidegger's philosophy seriously since it suggest to stop doing science all together.
Heidegger's philosophy suggests limits to the scientific method that we cannot surpass.
He famously claimed that

>Science does not think.

By which he means science can not understand the being-in-the-world, which might be the reason for Dreyfus's neglaction.

## Thinking in Symbols?

On the one hand, computers can only do symbolic manipulations, i.e., they compute (in a discrete world).
They change zeros to ones and vice verca but they are not aware of what they do.
If you ask ChatGPT: Are you sad?
It will clarify that it is unable to be in any mood; it only pretends to be sad.
It simulates the communcation of a person that is in a bad mood.

On the other hand, achievements in the area of machine learning suggest that they large networks preceive in a similar way than humans.
These networks do not measure the length of the edges to decide wether an image depicts a chair or a desk.
Instead they *learn* a model of their underlying reality, all its fuzzyness, and then "just know" that the picture depicts a chair.

But let us start from the beginning.
For this we have to go back to a time of pioneers of AI, a time before the rise of *machine learning*.
At that time, many thought that human-like intelligence can be thought of the ability of playing chess, i.e., they belied in *computationalism* (the mind operates like a Turing machine).
If we ignore the chessboard and only care about the moves of chessplayers, then chess is a purely symbolic game.
There are countable many chess games, therefore, in theory, a computer can compute the best next move at any stage of a game.
This leads to the conclusion that thought is explicitly symbolic which is supported by Descartes *mind-body dualism* (mental phenomena are non-physical).
In that case, we just need the correct mathematical formula or some algorithm and a symbol processing machine to reproduce human thinking.
Cognition is the manipulation of internal (explicit) symbols by internal rules thus human behaviour is, to a large extent, context free.
In other words: we just have to look inside the box (the human brain) to fully understand the actions of a person.
Dreyfus' critique of AI concerns this assumption that the brain is analogoues to computer hardware and the mind is analogoues to computer software and that the mind works by performing discrete computations (in the form of algorithmic rules) on discrete representations or symbols.

Dreyfus uses Heidegger's understanding of being that reverses this assumption.
Heidegger argues that our being is in fact highly context-bound.
We are a form of being-in-the-world that is aware of its and other's being-in-the-world.
A person and its world can not be seperated the subject-object distinction is fuzzy.
For example, if I leave a note at a desk, then this physical note is an extension of myself.
Parts of my memory lies on the desk at home.
Furthermore, it is a huge leap from choosing to see reality as consisting of indivisible atoms to state that because we want to or can see things in this way that it is therefore an objective fact that they are the case.
He aggressivly stated that any research program that assumes that such "facts" are real facts will quickly run into prfound theoretical and practical problems.
To think like humans, a machines would require to being-in-the-world like humans are.
Therefore, they would need the awareness of their own and other's being-in-the-workd which leads to the concept of not-being, i.e., death.

*Husserl*, *Heidegger* and *Merleau-Ponty* reject the kind of scientific naturalism or "*scientism*" that takes empirical science to be *epistemologically* and *metaphysically* privileged over all other forms of enquiry.
However, this does not make phenomenologists *ant-science* and  
Therefore, I will first try to give you the back bone 

### Alchemy and AI

In the summary of his controversal publiction Dreyfus states:

>An examination of [the difficulties to simulate cognitive processes on computers] reveals that the attempt to analyse intelligent behavior in digital computer language systematically excludes three fundamental huam forms of information processing (fringe consciousness, essence/accident discrimination, and ambiguity tolerance). Moreover, there are four distinct types of intelligent activity, only two of which do not presuppose these human forms of information processing and can therefore be programmed. -- Dreyfus in Alchemy and Artificial Intelligence



**Prompt:** Imagine you are a robot that can walk like a human. Now imagine I ask you to buy and bring me the best pizza to eat. What would you do?

**Answer:** As a highly advanced AI language model, I don't have a physical body to walk or perform tasks. However, if I were a robot with human-like walking capabilities, here's how I would fulfill your request:

Research: I would first search for the best pizza places in your area, taking into consideration customer reviews, ratings, and menu offerings. I would prioritize establishments known for their fresh, high-quality ingredients and unique flavors.

Decision-making: After analyzing the available options, I would select the most highly recommended pizza place that meets your preferences.

Ordering: I would contact the chosen pizza place to place an order for the best-rated pizza on their menu, ensuring it meets your dietary restrictions, if any. If allowed, I would also customize the pizza with toppings you prefer.

Payment: I would pay for the pizza using a pre-authorized method, such as a credit card or digital wallet.

Picking up the pizza: I would walk to the pizza place, maintaining a human-like gait and adhering to traffic and pedestrian rules.

Transporting the pizza: I would carefully carry the pizza box, making sure it remains level and undisturbed during the journey back to you.

Delivering the pizza: Upon reaching your location, I would present the pizza to you with a friendly greeting and ensure you are satisfied with the choice.

Cleanup and follow-up: Once you have finished enjoying the pizza, I would assist in cleaning up, if necessary, and ask for your feedback on the experience. This would help me better understand your preferences and make better choices in the future.







### Causal Theory of Intentionality

One naturalistic theory of intentionality is the *Causal Theory of Intentionality*.
The idea is that a thought or idea is about something if it is caused by that thing, i.e., there is a causal connection between that mental state and the thing it's about.

This sounds pretty plausabil.
If I see a cat then my thought is about the cat because the cat caused my thought.
I connect the *cause* (seeing the cat) by the *effect* (my thought of the cat).

This theory is appealing but has several problems.
Firstly, it struggles to address misrepresentations.
For instance, you may have a thought about your cat, but in reality, you might be mistaken, and the thought is about your neighbour's cat.
Maybe it's night, and the visibility is poor, leading to this misperception.
In this scenario, your thought about your cat is caused not by your cat, but by the neighbour's cat.
If both can trigger the same effect, wouldn't the effect differ, leading to a thought about "your cat and the neighbour's cat"?

Another issue is the problem of hallucination.
Your thought about your cat might not be triggered by the cat itself but by a hallucinogenic drug or a simulation, such as the Matrix.

The theory also fails to explain how one can harbor a thought about something that does not exist, like a blue elephant.

Finally, the theory is confronted with a degree of arbitrariness.
The causal chain from the stimulus that instigates the thought to the brain processes is quite extensive.
The light photons travel from the sun, hit the snow on Mount Everest, travel through the air into the eyes, and so forth.
There are no objectively defined endpoints and no rationale as to why the light from Everest and our thought should be the two endpoints.

### Biological Theory of Intentionality

The basic idea of the *Biological Theory of Intentionality* is that our cognitive capacities have evolved for certain purposes over millions of years, and these purposes determine the content of our intentional states (the states that are about something).
This theory suggests that intentionality isn't just about the relationship between your thoughts and the world, but also about the biological processes that give rise to those thoughts.

The need to run away from predators is a biological function and perhaps over time this function becomes a representation of predators.

This theory avoids the misrepresentation problem.
In this case your thought that bears represent bears is caused not by bears themselves but by the desire to avoid predators.
Therefore, if you mistakenly believe that an old stump is a bear this can be explained as a result of your representation being caused by the desire to avoid predators.

One problem of this theory is that it can not account for sophisticated and abstract beliefs and thoughts concerning math, philosophy and metphysical reasoning and so forth.
Spaceships or subatomic particles have no relevance to our evolutionary history thus it is unlclear how this theory can account for that.

Furthermore, the theory can not explain the either-or-problem.
If your desire to avoid both bears and stumps that look like bears has been wired in by evolution, then your thought that represents bears would actually represent "bears or stumps that look like bears" and not "bears" specifically.

### Connectionist Theory of Intentionality

The *Connectionist Theory of Intentionality* is a perspective that "aboutness" is based on the framework of connectionism.

Connectionism models cognition using *artificial neural networks* or systems that mirror the structure and function of neural networks in the brain.
The system's state (the pattern of activation across the nodes) can represent a particular object or concept if the pattern has been learned over time in response to that object or concept.
For instance, a certain pattern of activation could represent a cat if the system has learned to activate that pattern when a cat is present.

This approach allows for a nuanced understanding of mental representation, as it can account for properties like gradience (degrees of activation), distributed representation, parallel processing, and the ability to handle noisy or incomplete data.

However, the *Connectionist Theory* is primarily a model of how cognitive processes could work in the brain or in *artificial neural networks*, rather than a full-fledged philosophical theory of intentionality.
The theory does not explain how the patterns of activations associated with certain inputs have semantic content, i.e., how they come to be "about" something in the world.
They are not *grounded* in experience!
Similar to any computation we humans, i.e., external observers, interpret the output and states of the system.

Another problem is the distribution of knowledge across the network.
This makes it difficult to account for our ability to reflect on our knowledge and beliefs, which seem to require explicit representations.
It is also unclear how normative aspects of intentionality (our thoughts can be correct or incorrect, appropriate or inappropriate) can be acoounted for.

### Phenomenal Intentionality Theory

All the above theories are *naturalistic* theories of intentionality.
These theories attempt to *ground* intentionality in the *physical world* and often align with a *materialist* view of the mind.

The *Phenomenal Intentionality Theory (PIT)* posits that intentionality arises from conscious experience or phenomenology, i.e., is *grounded* in or derived from the phenomenal character of experience.
The contents of our thoughts -- what our thoughts are about -- are determined by the way things subjectively appear to us in our conscious experiences.
Therefore, *intentionality* plays a fundamental role for consciousness that can't be reduced to or explained in terms of more basic physical or natural processes.

PIT is not traditionally considered a naturalistic theory of intentionality, but this is debated.
If one finds a naturalistic explanation for consciousness, then PIT might be compatible with *naturalism*.

PIT takes a "consciousness first" approach to intentionality, since it claims that consciousness either grounds or is explanatorily prior to intentionality.
For example, someone who accepts *phenomenal intentionality* might say that if you see a red cube and have a thought about that cube, then your thought is "about" the cube because of the way the cube appears to you in your conscious experience.
It's not just that you're receiving sensory information about the red cube, but the way you consciously experience the cube shapes what your thought is about.
Therefore, *intentionality* is not just a mechanical or biological process, but is deeply tied to our subjective experiences.

PIT also faces challenges such as explaining how unconscious thoughts can have intentionality, how we can have thoughts about abstract or non-existent entities, and how to reconcile the subjective nature of phenomenal experience with a more objective, scientific understanding of the world.
