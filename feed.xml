<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://bzoennchen.github.io/Pages/feed.xml" rel="self" type="application/atom+xml" /><link href="https://bzoennchen.github.io/Pages/" rel="alternate" type="text/html" /><updated>2024-02-15T08:57:34+01:00</updated><id>https://bzoennchen.github.io/Pages/feed.xml</id><title type="html">Bene’s Blog</title><subtitle>A blog dedicated to computer science, education, music, philosophy and technology</subtitle><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><entry><title type="html">Musical Interrogation IV - Transformer</title><link href="https://bzoennchen.github.io/Pages/2024/02/03/musical-interrogation-IV.html" rel="alternate" type="text/html" title="Musical Interrogation IV - Transformer" /><published>2024-02-03T00:00:00+01:00</published><updated>2024-02-03T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2024/02/03/musical-interrogation-IV</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2024/02/03/musical-interrogation-IV.html"><![CDATA[<blockquote>
  <p>Recurrent models trained in practice are effectively feed-forward.
This could happen either because truncated backpropagation through time cannot learn patterns significantly longer than k steps, or, more provocatively, because models trainable by gradient descent cannot have long-term memory. – John Miller</p>
</blockquote>

<p>This time in the series we use the most famous model architecture for generative purposes: the <strong>transformer</strong> <a class="citation" href="#vaswani:2017">(Vaswani et al., 2017)</a>.
Transformers were initially targeted at natural language processing (NLP) problems, where the network input is a series of high-dimensional embeddings representing words or word fragments.
Transformers were introduced in 2017 by the authors of <em>Attention Is All You Need</em> <a class="citation" href="#vaswani:2017">(Vaswani et al., 2017)</a> to basically replace <em>recurrency</em> with <em>attention</em>.</p>

<p>One of the problems with RNNs is that they can forget information that is further back in the sequence.
While more sophisticated architectures, such as LSTMs <a class="citation" href="#hochreiter:1997">(Hochreiter &amp; Schmidhuber, 1997)</a> and <em>gated recurrent units</em> (GRUs) <a class="citation" href="#chung2014">(Chung et al., 2014)</a> partially, addressed this problem, they still struggle with long term dependecies.
The idea that intermediate representations in the RNN should be exploited to produce the output led to the <em>attention mechanism</em> <a class="citation" href="#bahdanau:2014">(Bahdanau et al., 2014)</a> and, in the end, to the transformer architecture <a class="citation" href="#vaswani:2017">(Vaswani et al., 2017)</a>.
The transformer avoids the problem of vanishing or exploding gradients by avoiding recurrency, that is, by utilizing the whole sequence in parallel.</p>

<p>Today, all successful large language model (LLMs) utilize the transformer architecture.
It brought us ChatGPT (based on GPT-3 <a class="citation" href="#brown:2020">(Brown et al., 2020)</a> and GPT-4 <a class="citation" href="#openai:2023">(OpenAI, 2023; Bubeck et al., 2023)</a>), LLaMA <a class="citation" href="#touvron:2023">(Touvron et al., 2023)</a>, LLaMA 2 <a class="citation" href="#touvron:2023b">(Touvron et al., 2023)</a>, BERT <a class="citation" href="#devlin:2019">(Devlin et al., 2019)</a> and many fine-tuned derivates such as Codex <a class="citation" href="#chen:2021">(Chen et al., 2021)</a> .
In the domain of symbolic music, transformers where also employed.
Examples are the Music Transformer <a class="citation" href="#huang:2018">(Huang et al., 2018)</a>, the Pop Music Transformer <a class="citation" href="#huang:2020">(Huang &amp; Yang, 2020)</a>, multi-track music generation <a class="citation" href="#ens:2020">(Ens &amp; Pasquier, 2020)</a>, piano inpainting <a class="citation" href="#hadjeres:2021">(Hadjeres &amp; Crestel, 2021)</a>, Theme Transformer <a class="citation" href="#shih:2022">(Shih et al., 2022)</a> and more.
Furthermore there are transformers, such as MusicGen <a class="citation" href="#copet:2023">(Copet et al., 2023)</a> that generate audio output directly.</p>

<p>While there is an intuitive explanation of the attention mechanism, it is still unclear why exaclty the transformer is so effective—there is no rigorous mathematical proof.
It is well-known how their components work and what mathematical operations are performed, but it is very hard to interpret the seemingly emerging power when all the small parts work together.
One source of their effectiveness is that they relate tokens to other tokens more directly (without a hidden state which washes away the information) and the independence of multiple execution paths make them especially suitable for the exploitation of multicore processors such as GPUs and TPUs.
However, looking at the whole sequence at once comes at a cost: computation and memory complexity!
Therefore, to train transformers you require GPUs with a lot of memory which is concerning for artists who might want to utilize transformers independently from proprietary cloud services.</p>

<p>Original transformers where introduced for natural language processing.
However, since language datasets share some of the characteristics of musical notations, transformers achieve good results in learning the structure of symbolic pieces.
In music as well as in language the number of input variables can be very large, and the statistics are similar at every position; it’s not sensible to re-learn the meaning of the word <em>dog</em> at every possible position in a body of text.
Language datasets and music datasets have the complication that their sequences vary in length.</p>

<p>However, we also have to remember that there are also differences between the two domains.
The alphabet of musical notations has more than 26 symbols and there is a strong relation between certain symbols.
For example, there is a strong relation between the C’s of each octave or a whole and half note in the same pitch class.
Furthermore, shifting all the letters in a text changes the meaning of that text dramatically while in the case of music this is most often not the case.</p>

<h2 id="attention-in-encoder-decoder-rnns">Attention in Encoder-Decoder RNNs</h2>

<p>What is the idea behind the attention mechanism?
Attention was introduced to bidirectional recurrent neural networks (RNNs) in 2014 <a class="citation" href="#bahdanau:2014">(Bahdanau et al., 2014)</a> for language translation, that is, for an <em>encoder-decoder architecture</em>.
In this scenario we want to translate a sentence from e.g. English into e.g. German.
The attention mechanism helps the decoder part of the RNN to focus on different parts of the encoders ouput (representations of the English words) differently.
Therefore, it helps to preserve long term dependencies.</p>

<p>The <strong>encoder’s</strong> input is a sequence of tokens, let’s say words for simplicity, i.e. a sequence</p>

\[\mathbf{x}_{0}, \ldots \mathbf{x}_{n-1}.\]

<p>For each word \(\mathbf{x}_{i}\) it computes some output \(\mathbf{y}_{i}\).
The assumption is that the probability for \(\mathbf{x}_{i}\) depends on \(\mathbf{x}_{j}\).
Since we have the whole sentence given, we can use a <em>bidirectional RNN</em> and look into the future.
Thus, with respect to dependency, the probability for token \(i\) can depend on the probability for token \(j\) and vice versa.</p>

<p>The <strong>decoder’s</strong> input is the <strong>whole</strong> sequence computed by the <strong>encoder</strong> but as a weighted sum.
The output is a sequence of German words, let’s say</p>

\[\mathbf{y'}_{0}, \ldots \mathbf{y'}_{n-1}.\]

<p>This time however, the <strong>decoder</strong> RNN is unidirectional.
It can not look into the future and computes each German word strictly from left to right.
To compute the weights or attenion scores of \(\mathbf{y'}_{i}\), an <strong>alignment model</strong> receives the hidden state \(\mathbf{h'}_{i-1}\) and the outputs of the encode as input.
First a simple dot product is comuted:</p>

\[e_{i,j} = \mathbf{h'}_{i}^\top \mathbf{y}_{j} \quad \text{ for } j = 0, \ldots, i-1.\]

<p>Later it was suggested to us an additional linear transformation on the output:</p>

\[e_{i,j} = \mathbf{h'}_{i}^\top (\mathbf{W}\mathbf{y}_{j}) \quad \text{ for } j = 0, \ldots, i-1.\]

<p>where \(\mathbf{W}\) is learned.
All these scores are normalized by the softmax function giving us \(n\) weights:</p>

\[\alpha_{i,j} = \frac{\exp\left( e_{i,j} \right)}{\sum\limits_{k=0}^{n-1} \exp\left( e_{i, k}\right)}.\]

<p>Then the <strong>decoder’s</strong> ‘real’ input is computed by a weighted sum of the <strong>encoder’s</strong> output:</p>

\[\hat{\mathbf{h}}_i = \sum_j \alpha_{i,j} \mathbf{y}_j.\]

<p>The weights determine how “strong” the information of the input will be utilized, i.e., how much attention is spent on each previous output of the model.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:90%;" src="/Pages/assets/images/rnn-attention.png" alt="RNN with attention" />
<div style="display: table;margin: 0 auto;">Figure 1: RNN with self-attention.</div>
</div>
<p><br /></p>

<p>In case of a decoder, this results in a quadratic complexity of \(\mathcal{O}(n^2)\) because for each of the \(n\) tokens, we want to decode, we have \(n\) weights.</p>

<h2 id="the-transformer-architecture">The Transformer Architecture</h2>

<p>The original transformer was introduced for the task of machine translation thus it was an encoder-decoder architecture.
In Fig. 2 you see a slightly modified version where the addition (residual connections) and the layer norm are in front of the attention layer.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:90%;" src="/Pages/assets/images/transformer.png" alt="RNN with attention" />
<div style="display: table;margin: 0 auto;">Figure 2: The slightly modified transformer.</div>
</div>
<p><br /></p>

<p>Let’s consider a scenario in which we have an English sentence that we want to translate into French. 
In this process, the encoder plays a crucial role by transforming the English sentence into a highly compressed and information-rich representation.</p>

<p>Subsequently, the decoder comes into play, generating the French translation word by word. 
It relies on the previously computed French words to predict and produce the next one. 
It’s important to note that the input provided to the decoder is a partial translation, essentially a shifted version of what it is currently working on. 
This is because the decoder should lack the ability to see into the future; it only has access to the portion of the translation it has computed up to that point—otherwise it would cheat while training which would hurt the learning process.</p>

<p>To address this limitation, the decoder employs a masked version of the multi-head attention layer. 
This mechanism ensures that the decoder focuses on the relevant information without peeking ahead.</p>

<p>Furthermore, the utilization of residual connections and layer normalization over a mini-batch (layer norm) serves as a valuable tool to combat the issue of vanishing gradients in deep neural networks, ensuring the efficient training and optimization of the translation model.</p>

<p>In our case we do not acutally want to translate a sentence but we want to generate musical notes from a sequence of given notes.
Therfore, we have no encoded information and there is no encoding envolved.
We only need the decoder part.
Furthermore, I only use one (masked) multi-head attention layer in each block.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:40%;" src="/Pages/assets/images/decoder.png" alt="Decoder-only transformer" />
<div style="display: table;margin: 0 auto;">Figure 3: Our decoder-only transformer.</div>
</div>
<p><br /></p>

<p>Ok, but how does this really works?
What is going on here?
Well, the key to understand transformers is to understand the self-attention mechanism which I try to explain below.</p>

<h2 id="self-attention">Self-Attention</h2>

<p>The idea of the transformer is to just rely on (self-)attention thus remove recurrency.
This means that the model “sees” \(n\) tokens to generate the \((n+1)^\text{th}\) token.
Simple RNNs for predicting the next tokens only see the previous token and the hidden state which represents all the tokens before.
But, as I discussed in previous articles, the information of the hidden state gets washed away over time and without attention there seem to be little control over the importance of certain tokens of the sequence.</p>

<p>The fundamental operation of the transformer, i.e. the attention mechanism, is implemented in its <code class="language-plaintext highlighter-rouge">Head</code>.
Let \(\mathbf{x}_0, \ldots, \mathbf{x}_{n-1} \in \mathbb{R}^{D \times 1}\) be the \(n\) tokens of a sequence.
A standard neural network layer \(f(\cdot)\), takes a \(D \times 1\) input and applies a linear transformation followed by an activation function like a \(\text{ReLU}\):</p>

\[f(\mathbf{x}) = \text{ReLU}\left( \mathbf{W}\mathbf{x} + \mathbf{b }\right),\]

<p>where \(\mathbf{b}\) contains the biases, and \(\mathbf{W}\) contains the weights.</p>

<p>A self-attention \(\mathbf{sa}(\cdot)\) block takes all the \(n\) inputs, each of dimension \(D \times 1\), and returns \(n\) output vectors of the same size.
Note that in our case each input represents a musical note or event.
First, a set of <strong>values</strong> is computed for each input:</p>

\[\mathbf{v}_i = \mathbf{b}_v + \mathbf{W}_v \mathbf{x}_i, \quad \text{ (value)}\]

<p>where \(\mathbf{b}_v \in \mathbb{R}^D \text{ and } \mathbf{W}_v \in \mathbb{R}^{D \times D}\) represent biases and weights, respectively (<strong>for all inputs</strong>). 
The \(j^\text{th}\) output \(\mathbf{sa}_j(\mathbf{x}_0, \ldots, \mathbf{x}_{n-1})\) is a weighted sum of all the values \(\mathbf{v}_i, i = 0, \ldots n-1\) where the weight each weight depends on \(\mathbf{x}_j\):</p>

\[\mathbf{sa}_j(\mathbf{x}_0, \ldots, \mathbf{x}_{n-1}) = \sum_{i=0}^{n-1} \alpha(\mathbf{x}_i, \mathbf{x}_j) \mathbf{v}_i.\]

<p>The scalar weight \(\alpha(\mathbf{x}_i, \mathbf{x}_j)\) is the <strong>attention</strong> that the \(j^\text{th}\) output pays to the input \(\mathbf{x}_i\).
The \(n\) weights \(\alpha(\cdot, \mathbf{x}_j)\) are non-negative and sum to one.
Hence, self-attention can be thought of as <em>routing</em> the values in different proportions to create each output.</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:35%;" src="/Pages/assets/images/routing.png" alt="Routing principle" />
<div style="display: table;margin: 0 auto;">Figure 4: Routing principle.</div>
</div>
<p><br /></p>

<p>To compute the attention, we apply two more linear transformations to the inputs:</p>

\[\begin{aligned}
\mathbf{q}_j &amp;= \mathbf{b}_q + \mathbf{W}_q \mathbf{x}_j \quad \text{ (query)}\\
\mathbf{k}_i &amp;= \mathbf{b}_k + \mathbf{W}_k \mathbf{x}_i \quad \text{ (key).}
\end{aligned}\]

<p>The <strong>dot product</strong> of two vectors \(\mathbf{q}_j\), \(\mathbf{k}_i\) is a measurement of their similarity.
In the special case where both vectors are unit vectors, the dot product is the cosine of the angle between the two.
In general, this relationship is expressed by the following equation:</p>

\[\mathbf{q}_j \circ \mathbf{k}_i = \mathbf{q}_j^\top  \mathbf{k}_i = \Vert \mathbf{q}_j \Vert \cdot \Vert \mathbf{k}_i \Vert \cos(\beta),\]

<p>where \(\beta\) is the angle between the two verctors.
Computing the <em>dot product</em> between queries and keys gives us the similarities we desire.
To normalize, we then pass the result through a <em>softmax</em> function:</p>

\[\alpha(\mathbf{x}_i, \mathbf{x}_j) = \frac{\exp(\mathbf{q}_j^\top \mathbf{k}_i \sqrt{D_q})}{\sum\limits_{r=0}^{n-1} \exp(\mathbf{q}_j^\top \mathbf{k}_r \sqrt{D_q})},\]

<p>where \(D_q\) is the dimension of the queries and keys (i.e., the number of rows in \(\mathbf{W}_q\) and \(\mathbf{W}_k\), which must be the same).
You can think of the <em>key</em> of what is offered and the <em>query</em> of what is searched.
If \(\mathbf{X}\), \(\mathbf{K}\), \(\mathbf{Q}\), and \(\mathbf{V}\) contain all the inputs, keys, queries and values then we can compute the self-attention by</p>

\[\mathbf{Sa}(\mathbf{X}) = \mathbf{V} \cdot \text{Softmax}\left( \frac{\mathbf{K}^\top \mathbf{Q}}{\sqrt{D_q} }\right).\]

<p>The overall computation is illustrated in Figure 5.</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:90%;" src="/Pages/assets/images/self-attention.png" alt="Self-attention in matrix-form" />
<div style="display: table;margin: 0 auto;">Figure 5: Self-attention in matrix-form.</div>
</div>
<p><br /></p>

<h2 id="masking-attention-head">Masking Attention Head</h2>

<p>Since our transformer should not look into the future, because when we use it in the prediction mode it also can not look ahead of the token it predicts, we have to mask entries in</p>

\[\text{Softmax}\left(\frac{\mathbf{K}^\top \mathbf{Q}}{\sqrt{D}_q}\right).\]

<p>If you look into the code, I did this by setting the respective values in \(\mathbf{K}^\top \mathbf{Q}\) to negative infinite before computing the softmax.</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:60%;" src="/Pages/assets/images/transformer-head.png" alt="Transformer head" />
<div style="display: table;margin: 0 auto;">Figure 6: Transformer head for a sequence length equal to 5.</div>
</div>
<p><br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Head</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">""" one head of self-attention """</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>   <span class="c1"># key embedding
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># query embedding
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># value embedding
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s">'tril'</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">sequence_len</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">)))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span> <span class="c1"># to avoid overfitting
</span>        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">B</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">C</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># B, T, head_size, compute all keys
</span>        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># B, T, head_size, compute all queries
</span>        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">head_size</span> <span class="o">=</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span>
        
         <span class="c1"># B, T, head_size @ B, head_size, 
</span>        <span class="n">wei</span> <span class="o">=</span> <span class="n">q</span> <span class="o">@</span> <span class="n">k</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">head_size</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">))</span> <span class="c1"># T =&gt; B, T, T
</span>
        <span class="c1"># because we can not look into the future 
</span>        <span class="n">wei</span> <span class="o">=</span> <span class="n">wei</span><span class="p">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">tril</span><span class="p">[:</span><span class="n">T</span><span class="p">,</span> <span class="p">:</span><span class="n">T</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s">'-inf'</span><span class="p">))</span>
        <span class="n">wei</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">wei</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">wei</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">wei</span><span class="p">)</span>

        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># B, T, head_size
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">wei</span> <span class="o">@</span> <span class="n">v</span> <span class="c1"># T, T @ B, T, head_size =&gt; B, T, head_size
</span>        <span class="k">return</span> <span class="n">out</span>
<span class="p">...</span>
</code></pre></div></div>

<p>The multi-head attention layer consists of multiple heads.
Note that apart from <strong>masked</strong> <strong>self-attention</strong>, the head also applys a <strong>dropout</strong> which helps with regularization.</p>

<h2 id="stacked-multi-head-attention">Stacked Multi-Head Attention</h2>

<p>Instead of using only one <code class="language-plaintext highlighter-rouge">Head</code> it is usually a good idea to use multiple ones.
To do this we transform the input into a <code class="language-plaintext highlighter-rouge">head_size</code>-dimensional space.
Suppose we use 4 heads than <code class="language-plaintext highlighter-rouge">head_size * 4</code> should be equal to the rows of \(\mathbf{W}_0\) (compare Fig. 7) of the multi-head attention layer.
Since I add the input to the output of <code class="language-plaintext highlighter-rouge">MultiHeadAttention</code> (via residual connections), the columns of \(\mathbf{W}_0\) should be equal to the dimension of the input of the <code class="language-plaintext highlighter-rouge">MultiHeadAttention</code>.
In my case this is <code class="language-plaintext highlighter-rouge">n_embd</code>, i.e. the dimension of our embedded tokens.</p>

<p>\(\mathbf{W}_0\) transforms the concatenated results of the heads back to the dimension equal to <code class="language-plaintext highlighter-rouge">n_embd</code>. 
This is needed to stack <code class="language-plaintext highlighter-rouge">Block</code>s (each consisting of a <code class="language-plaintext highlighter-rouge">MultiHeadAttention</code>) on top of each other.
The output of <code class="language-plaintext highlighter-rouge">Block</code> \(i\) has to fit into block \(i+1\).</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:90%;" src="/Pages/assets/images/multi-head.png" alt="Multi-head attention" />
<div style="display: table;margin: 0 auto;">Figure 7: Multi-head attention.</div>
</div>
<p><br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">Head</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_heads</span><span class="p">)]</span>
        <span class="p">)</span>

        <span class="c1"># W_0
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">W0</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">head_size</span> <span class="o">*</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">)</span> 

        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># concatenation of the results of each head
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">head</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">heads</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> 

        <span class="c1"># Figure 7
</span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">W0</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
<span class="p">...</span>
</code></pre></div></div>

<p>The hope is that each <code class="language-plaintext highlighter-rouge">Head</code> concentrates on different parts of the structure we want to learn.</p>

<h2 id="transformer-block">Transformer Block</h2>

<p>A <code class="language-plaintext highlighter-rouge">Block</code> consists of a <code class="language-plaintext highlighter-rouge">MultiHeadAttention</code>-layer and a relatively simple FFN-layer followed by two <code class="language-plaintext highlighter-rouge">LayerNorm</code> which applies <em>layer normalization</em> over a mini-batch of inputs.
This helps the gradients to stay in a “good” range.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="c1"># head_size could be defined differently
</span>        <span class="n">head_size</span> <span class="o">=</span> <span class="n">n_embd</span> <span class="o">//</span> <span class="n">n_heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">sa</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ffwd</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ln1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">n_embd</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ln2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">n_embd</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">sa</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ln1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c1"># residual connection
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">ffwd</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ln2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c1"># residual connection
</span>        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">n_embd</span><span class="p">),</span> 
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="p">...</span>
</code></pre></div></div>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:40%;" src="/Pages/assets/images/block.png" alt="Transformer block" />
<div style="display: table;margin: 0 auto;">Figure 8: Our decoder transformer block with only one (masked) multi-head attention layer.</div>
</div>

<h2 id="positional-encoding">Positional Encoding</h2>

<p>The Transformer has no more hidden state.
Therefore, instead of processing token by token trying to memorize important information via the hidden state, it processes all \(n\) tokens at in parallel, which is good for parallel computation but increases the time and space complexity from \(\mathcal{O}(n)\) (LSTM) to \(\mathcal{O}(n^2)\).</p>

<p>Furthermore, we have to encode the position of the tokens into \(\mathbf{x}\) because we lost the implicit order of computation.
In the original paper <a class="citation" href="#vaswani:2017">(Vaswani et al., 2017)</a> the authors utilized a embdding that involved sine and cosine functions.
Their embedding is a very clever use of peridoic functions but I will not go into details here.
Instead of using a fixed embedding, I let the transformer learn the positional embedding.</p>

<p>Therefore, I transform the input <code class="language-plaintext highlighter-rouge">idx</code> into two vectors <strong>positional embedding</strong> and <strong>token embedding</strong>, which are <strong>added</strong> together.
Note that our input <code class="language-plaintext highlighter-rouge">idx</code> is an array of numbers each representing the id of the token.
Each number will be transformed into a specific vector (i.e. its embedding).
The embedding will be learned.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">n_blocks</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="c1"># vocab_size is the size of our alphabet
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">token_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">)</span>

        <span class="c1"># sequence_len is equal to n
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">position_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">sequence_len</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">Block</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_blocks</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">idx</span><span class="p">.</span><span class="n">shape</span>
        
        <span class="c1"># token embedding. B, T, n_embd
</span>        <span class="n">token_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">token_embedding_table</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> 

        <span class="c1"># positional embedding. T, n_embd 
</span>        <span class="n">pos_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">position_embedding_table</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span> 

        <span class="n">x</span> <span class="o">=</span> <span class="n">token_emb</span> <span class="o">+</span> <span class="n">pos_emb</span> <span class="c1"># B, T, n_embd + T, n_embd =&gt; B, T, n_embd
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># B, T, head_size
</span>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># B, T, vocab_size
</span>        <span class="k">return</span> <span class="n">logits</span>

<span class="p">...</span>
</code></pre></div></div>

<p>By increasing the dimension of the embedding, the sequence length, the number of heads within a block and the number of blocks we can drastically increase the size and power of our decoder-only transformer.
However, this will rapidly increase the memory requirements and training time.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:40%;" src="/Pages/assets/images/decoder.png" alt="Decoder-only transformer" />
<div style="display: table;margin: 0 auto;">Figure 9: Our simplified decoder-only transformer.</div>
</div>
<p><br /></p>

<p>Futhermore, it is very important to understand that what really matters is a <strong>high-quality training dataset</strong>!
Of course, your model achitecture matters too, but your model can not learn what is not there.
Additionally, the <strong>musical representation</strong> you feed into the transformer matters as well.
In our case this representation, using basically piano rolls, is very simple.
It does not contain any high level information such as the end of a bar, section, phrase or musical theme.
We just hope that the transformer will eventually learn all these concepts.
It is a active research question what impact a good musical representation has on the result the trained transformer generates.</p>

<h2 id="relative-positional-self-attention">Relative Positional Self-Attention</h2>

<p>So far our positional encoding was just a sequence of natural numbers \(0, 1, \ldots, n-1\) and we used an embbedding which was added to the input, that is, the embedding of \(i\) was added to the embedding of \(\mathbf{x}_i\) of the input sequence.
However, this encoding might not be optimal in the context of music where we tones, phrases, musical ideas and themes reapeat frequently.
A relative position representation to allow attention to be informed by how far two positions are apart in a sequence might be much more effective.</p>

<p>So, instead of learning the index of a token within a sequence we want the mode to learn relative distances between tokens.
In other words, instead of learning the attention spent by token with index \(j\) on \(i\), that is, \(\alpha(\mathbf{x}_i, \mathbf{x}_j)\) we want to compute an attention score based on the (directed) distance \(i-j\).
This concept was introduced by <a class="citation" href="#shaw:2018">(Shaw et al., 2018)</a>.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:60%;" src="/Pages/assets/images/relative-attention.png" alt="Relative positional encoding" />
<div style="display: table;margin: 0 auto;">Figure 10: Relative positional encoding.</div>
</div>
<p><br /></p>

<p>Note that if there are \(\mathcal{O}(n)\) absolute positions \(0, 1, \ldots, n-1\) then there are \(\mathcal{O}(n)\) relative positions \(-(n-1), \ldots, -1, 0, 1,\ldots, n-1\).
The authors also introduce a maximal distance \(k\) such that they only learn weights</p>

\[\mathbf{w}^{V}_{\text{clip}(i-j,k)} \text{ with } \text{clip}(x,k) = \max(-k, \min(k,x))\]

<p>Therefore, they learn relative position representations for the keys \(\mathbf{w}^K_{-k}, \ldots, \mathbf{w}^K_{k}\) and for the values \(\mathbf{w}^V_{-k}, \ldots, \mathbf{w}^V_{k}\).
They introduce the relative position between \(\mathbf{x}_i\) and \(\mathbf{x}_j\) to be</p>

\[\mathbf{a}_{ij} = \mathbf{w}_{\text{clip}(i-j,k)}\]

<p>Thus there are \(\mathcal{O}(n^2)\) different such vectors but many share the same value.
Of course, they drop the absolute positional encoding.
And they adapt the <strong>self-attention comuputation</strong> from</p>

\[\mathbf{sa}_j(\mathbf{x}_0, \ldots, \mathbf{x}_{n-1}) = \sum_{i=0}^{n-1} \alpha(\mathbf{x}_i, \mathbf{x}_j) \mathbf{v}_i.\]

<p>to</p>

\[\mathbf{sa}_j(\mathbf{x}_0, \ldots, \mathbf{x}_{n-1}) = \sum_{i=0}^{n-1} \alpha(\mathbf{x}_i, \mathbf{x}_j) (\mathbf{v}_i + \mathbf{a}^V_{ij}).\]

<p>and the computation of the similarity between <strong>query</strong> and <strong>key</strong> from</p>

\[\frac{(\mathbf{W}_q \mathbf{x}_i)^\top (\mathbf{W}_k \mathbf{x}_j)}{\sqrt{D_q}}\]

<p>to</p>

\[\frac{(\mathbf{W}_q \mathbf{x}_i)^\top (\mathbf{W}_k \mathbf{x}_j + \mathbf{a}^K_{ij})}{\sqrt{D_q}}.\]

<p>Computation-wise the first manipulation can be easily achieved by adding a matrx \(\mathbf{A}\) to \(\mathbf{V}\).
However, the second manipulation destroys parallelism, i.e. the possibility to compute everything by matrix-matrix multiplications.
This can be mitigated by splitting the computation into two parts:</p>

\[\frac{(\mathbf{W}_q \mathbf{x}_i)^\top (\mathbf{W}_k \mathbf{x}_j + \mathbf{a}^K_{ij})}{\sqrt{D_q}} = \frac{(\mathbf{W}_q \mathbf{x}_i)^\top (\mathbf{W}_k \mathbf{x}_j) + (\mathbf{W}_q \mathbf{x}_i)^\top \mathbf{a}^K_{ij}}{\sqrt{D_q}}\]

<p>Assuming that \(\mathbf{S}\) contains all the relative attention scores, that is,</p>

\[\mathbf{S}_{ij} = (\mathbf{W}_q \mathbf{x}_i)^\top \mathbf{a}^K_{ij},\]

<p>then we can go back to the matrix form which gives us</p>

\[\mathbf{Sa}(\mathbf{X}) = (\mathbf{V} + \mathbf{A}^V) \cdot \text{Softmax}\left( \frac{\mathbf{K}^\top \mathbf{Q} + \mathbf{S}}{\sqrt{D_q} }\right).\]

<p>To compute \(\mathbf{S}\) <a class="citation" href="#shaw:2018">(Shaw et al., 2018)</a> instantiate an intermediate tensor \(\mathbf{R} \in \mathbf{R}^{k \times k \times D_q},\) containing the embeddings that correspond to the relative distance between all keys and queries.
\(\mathbf{Q}\) is then reshaped to an \((k, 1, D_q)\) tensor, and \(\mathbf{S} = \mathbf{Q} \mathbf{R}^\top.\)
This incurs a total space complexity of \(\mathcal{O}(k^2 D_q)\).</p>

<h2 id="the-music-transformer">The Music Transformer</h2>

<p>The Music Transformer <a class="citation" href="#huang:2018">(Huang et al., 2018)</a> was one of the first transformer utilized to generate symbolic music.
Even if it was introduced five years ago (which is like a century in the AI-world) it is worth studying it.
In the paper you find two different datasets</p>

<ol>
  <li><a href="https://github.com/czhuang/JSB-Chorales-dataset">J.S. Bach chorales dataset</a></li>
  <li><a href="https://www.piano-e-competition.com/">Piano-e-Competition dataset</a></li>
</ol>

<p>and they used an impressive sequence length of <strong>2048-tokens</strong>!
They used GPUs for the training.
With such a large number of token, one question arises: How did they manage to put 2000-tokens and all the respective matrices in the GPUs’ memory?</p>

<p>The authors correctly identify the space complexity of \(\mathcal{O}(k^2 D_q)\) to be problematic for GPU computation and they reduce the complexity to \(\mathcal{O}(k D_q)\) by exchanging space for re-computation.
This is possible due to the structure of the tensor \(\mathbf{R}\) which contains many equal values.</p>

<p>To handly very long sequences, the authors use local attention <a class="citation" href="#liu:2018">(Liu et al., 2018)</a> by chunking the input sequence into non-overlapping blocks.
Each block then attends to itself and the one before.</p>

<h2 id="attention-free-transformer">Attention-Free Transformer</h2>

<p>Basically, the attention mechanism, regardless of the specifics, solves a routing problem, that it, which information is transported to the next layer of the neural network.
Thus, it has a quadratic time and space complexity of \(\mathcal{O}(n^2)\) where \(n\) is our sequence length.
Therefore, if you have limited ressources, it is hard to scale it to larger sequences.
As with the local attention and other techniques, like the Linformer <a class="citation" href="#wang:2020">(Wang et al., 2020)</a>, Longformer <a class="citation" href="#"></a>, Reformer <a class="citation" href="#kitaev:2020">(Kitaev et al., 2020)</a>, and Synthesizer <a class="citation" href="#tay:2021">(Tay et al., 2021)</a>, and Performer <a class="citation" href="#choromanski:2022">(Choromanski et al., 2022)</a> there are ways to improve this but in principle the complexity will bite us eventually.</p>

<p>Now we enter in an era in deep learning where we question if we actually need the attention layers in the transformer!
This was proposed in 2022.
Instead of computing attention, <em>FNet</em> <a class="citation" href="#leethorp:2022">(Lee-Thorp et al., 2022)</a> just mixes tokens according to the discrete Fourier transformation (DFT).
First, a 1D transformation is computed with respect to the embedding and then another with respect to time.
Amazingly even though there is no parameter to learn within the <code class="language-plaintext highlighter-rouge">Fourier</code>-layer (which replaces the <code class="language-plaintext highlighter-rouge">Head</code>) this strategy seems to work almost as good as the far more computational expensive task of learning all the required attention scores.</p>

<p>The Fourier transform decomposes a function (in our case a discrete signal) into its constituent frequencies.
Given a sequence \(x_0, \ldots, x_{N-1}\), the discrete Fourier transform (DFT) is defined by</p>

\[X_k = \sum\limits_{n=0}^{N-1} x_n \exp\left( - \frac{2\pi i}{N} nk \right), \quad 0 \leq k \leq N-1.\]

<p>\(X_k\) encodes the <strong>phase</strong> and <strong>power</strong> of frequency \(k\) within the signal.</p>

<p><em>FNet</em> consists of a Fourier <strong>mixing sublayer</strong> followed by a feed-forward sublayer.
Essentially, the self-attention sublayer of each transformer decoder layer is replaced with a <strong>Fourier sublayer</strong> which applies a 2D DFT to its</p>

\[(\text{sequence length} \times \text{hidden dimension})\]

<p>embedding input.
This can be achieved using two 1D DFTs—one 1D DFT along the sequence dimension, \(\mathcal{F}_\text{seq}\), and one 1D DFT along the hidden dimension, \(\mathcal{F}_\text{h}\):</p>

\[y = \text{Real}\left( \mathcal{F}_\text{seq} \left( \mathcal{F}_\text{h}(\mathbf{x}) \right) \right)\]

<p>The authors only consider the real part of the DFT.</p>

<p>Now, as emphasized by the title of their paper, the Fourier transform is probably not the important part.
It is just a special case of how you can mix tokens.
Important is the mixing itself which allows information to flow from one token to all the other tokens and the Fourier transform happens to be a nice why of mixing.
The paper indicate that it might not be so important to let the model learn how exaclty information flows around.
It might be just enough if information flows at all (to all tokens).
In other words, the exact routing might be less important than we thought.</p>

<p>Now, the results of the paper are not better than using a traditional transformer.
But one trades accuracy for resources thus longer sequence length and a faster computation.</p>

<p>To the best of my knowledge, I have not seen this tried out for symbolic music generation.
But when I have time, I play around with it.
Futhermore, one might think about a special mixing which is effective for our specific task.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="vaswani:2017">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017). attention is all you need. <i>CoRR</i>, <i>abs/1706.03762</i>. http://arxiv.org/abs/1706.03762</span></li>
<li><span id="hochreiter:1997">Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. <i>Neural Computation</i>, <i>9</i>(8), 1735–1780. https://doi.org/10.1162/neco.1997.9.8.1735</span></li>
<li><span id="chung2014">Chung, J., Gulcehre, C., Cho, K. H., &amp; Bengio, Y. (2014). <i>Empirical evaluation of gated recurrent neural networks on sequence modeling</i>.</span></li>
<li><span id="bahdanau:2014">Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. <i>CoRR</i>, <i>abs/1409.0473</i>.</span></li>
<li><span id="brown:2020">Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., … Amodei, D. (2020). <i>Language models are few-shot learners</i>.</span></li>
<li><span id="openai:2023">OpenAI. (2023). <i>GPT-4 rechnical report</i>.</span></li>
<li><span id="bubeck:2023">Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S., Nori, H., Palangi, H., Ribeiro, M. T., &amp; Zhang, Y. (2023). <i>Sparks of artificial general intelligence: Early experiments with GPT-4</i>.</span></li>
<li><span id="touvron:2023">Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., &amp; Lample, G. (2023). <i>LLaMA: Open and efficient foundation language models</i>.</span></li>
<li><span id="touvron:2023b">Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., … Scialom, T. (2023). <i>LlaMA 2: Open foundation and fine-tuned chat models</i>.</span></li>
<li><span id="devlin:2019">Devlin, J., Chang, M.-W., Lee, K., &amp; Toutanova, K. (2019). <i>BERT: Pre-training of deep bidirectional transformers for language understanding</i>.</span></li>
<li><span id="chen:2021">Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., … Zaremba, W. (2021). <i>Evaluating large language models trained on code</i>.</span></li>
<li><span id="huang:2018">Huang, C.-Z. A., Vaswani, A., Uszkoreit, J., Shazeer, N., Hawthorne, C., Dai, A. M., Hoffman, M. D., &amp; Eck, D. (2018). Music Transformer: Generating music with long-term structure. <i>ArXiv Preprint ArXiv:1809.04281</i>.</span></li>
<li><span id="huang:2020">Huang, Y.-S., &amp; Yang, Y.-H. (2020). <i>Pop Music Transformer: Beat-based modeling and generation of expressive pop piano compositions</i>.</span></li>
<li><span id="ens:2020">Ens, J., &amp; Pasquier, P. (2020). <i>MMM: Exploring conditional multi-track music generation with the transformer</i>.</span></li>
<li><span id="hadjeres:2021">Hadjeres, G., &amp; Crestel, L. (2021). <i>The piano inpainting application</i>.</span></li>
<li><span id="shih:2022">Shih, Y.-J., Wu, S.-L., Zalkow, F., Müller, M., &amp; Yang, Y.-H. (2022). <i>Theme Transformer: Symbolic music generation with theme-conditioned transformer</i>.</span></li>
<li><span id="copet:2023">Copet, J., Kreuk, F., Gat, I., Remez, T., Kant, D., Synnaeve, G., Adi, Y., &amp; Défossez, A. (2023). <i>Simple and controllable music generation</i>.</span></li>
<li><span id="shaw:2018">Shaw, P., Uszkoreit, J., &amp; Vaswani, A. (2018). Self-attention with relative position representations. <i>CoRR</i>, <i>abs/1803.02155</i>. http://arxiv.org/abs/1803.02155</span></li>
<li><span id="liu:2018">Liu, P. J., Saleh, M., Pot, E., Goodrich, B., Sepassi, R., Kaiser, L., &amp; Shazeer, N. (2018). Generating Wikipedia by summarizing long sequences. <i>International Conference on Learning Representations</i>. https://openreview.net/forum?id=Hyg0vbWC-</span></li>
<li><span id="wang:2020">Wang, S., Li, B. Z., Khabsa, M., Fang, H., &amp; Ma, H. (2020). <i>Linformer: Self-Attention with linear complexity</i>.</span></li>
<li><span id="kitaev:2020">Kitaev, N., Kaiser, Ł., &amp; Levskaya, A. (2020). <i>Reformer: The Efficient Transformer</i>.</span></li>
<li><span id="tay:2021">Tay, Y., Bahri, D., Metzler, D., Juan, D.-C., Zhao, Z., &amp; Zheng, C. (2021). <i>Synthesizer: Rethinking self-attention in transformer models</i>.</span></li>
<li><span id="choromanski:2022">Choromanski, K., Likhosherstov, V., Dohan, D., Song, X., Gane, A., Sarlos, T., Hawkins, P., Davis, J., Mohiuddin, A., Kaiser, L., Belanger, D., Colwell, L., &amp; Weller, A. (2022). <i>Rethinking Attention with Performers</i>. https://arxiv.org/abs/2009.14794</span></li>
<li><span id="leethorp:2022">Lee-Thorp, J., Ainslie, J., Eckstein, I., &amp; Ontanon, S. (2022). <i>FNet: Mixing tokens with Fourier transforms</i>.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Music" /><category term="ML" /><category term="Transformer" /><summary type="html"><![CDATA[Recurrent models trained in practice are effectively feed-forward. This could happen either because truncated backpropagation through time cannot learn patterns significantly longer than k steps, or, more provocatively, because models trainable by gradient descent cannot have long-term memory. – John Miller]]></summary></entry><entry><title type="html">Escaping the Reality of the Climate Crisis?</title><link href="https://bzoennchen.github.io/Pages/2024/01/02/conspiracy.html" rel="alternate" type="text/html" title="Escaping the Reality of the Climate Crisis?" /><published>2024-01-02T00:00:00+01:00</published><updated>2024-01-02T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2024/01/02/conspiracy</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2024/01/02/conspiracy.html"><![CDATA[<p>Diverging from my area of expertise is always a risky endeavor, but since this is a blog rather than a scientific journal, I’m giving myself the liberty to explore and have fun with different ideas (even if the topic is depressing). 
Often writing helps in transforming the mess into a structured and coherent concept. 
The process of rethinking and reflecting can be invaluable.</p>

<p>In this piece, I aim to explore various aspects by drawing connections myself, linking the movie <em>The Matrix</em>, Plato’s <em>Allegory of the Cave</em>, <em>myths</em>, and <em>conspiracy theories</em>. 
Additionally, I plan to delve into the understandable yet problematic skepticism surrounding <em>second-order observation</em>. 
I will relate this skepticism to the notions of <em>complexity</em>, <em>contingency</em> and <em>hyperreality</em>, and discuss why we rely on <em>second-order observation</em> to address the <em>climate crisis</em>. 
Through these connections, I hope to shed light on the interplay between our perception of reality, the challenges of understanding complex systems, and our responses to global issues.</p>

<p>To do this, I first need a definition for conspiracy theory and I think the one given by Joseph E. Uscinski fits well:</p>

<blockquote>
  <p>By conspiracy theory, I mean an explanation of historical, ongoing, or future events that cites as a main causal factor a group of powerful persons, the conspirators, acting in secret for their own benefit against the common good. – Joseph E. Uscinski</p>
</blockquote>

<h2 id="mythology-and-conspiracy-theories">Mythology and Conspiracy Theories</h2>

<p>The phenomena of conspiracy theories hunts me since the terror attacks of 9/11 happened back when I was a child.
I remember watching the <em>Zeitgeist</em> series, which linked various conspiracy theories involving religion, the September 11 attacks and the financial sector.
During that time, even German TV occasionally presented documentaries that portrayed certain events in a conspiratorial light.
The shock and uncertainty that the Western world experienced after these events, combined with a sense of lack of control, created a fertile ground for such theories. 
These ‘documentaries’ were not only entertaining, but they also sparked my interest in geopolitics, the history of religion, history in general, and even philosophy. 
They managed to make historical events captivating, and I often wished that my history classes were similarly engaging.
Fortunately, I never embraced the logic presented in these films; for me, they remained within the realm of entertainment but I could see how easy it is to fall for them on an emotional level.
Interestingly, years later, when a real plot unfolded to deceive the public (and other nations) into supporting the war against Iraq, there was no corresponding emergence of conspiracy theories like those seen previously.</p>

<p>During the pandemic, I observed a repetition of history in the form of similar documentaries emerging, and I became interested in how they were designed and how they relate to the conspiratorial ‘documentaries’ I encountered in my childhood. Indeed, they bore striking similarities.</p>

<p>Apart from the obvious parallels, such as misrepresentation and drawing connections between completely unrelated events, there were also more bizarre links.
For instance, these documentaries often incorporate some form of spiritual concept, promising a return to or discovery of a ‘true self’, an ‘inner peace’ or a ‘forgotten innocence’. 
For example, the <em>Zeitgeist</em> series uses a speech from the Indian philosopher Jiddu Krishnamurti (1895 – 1986) but only as an emotional device:</p>

<blockquote>
  <p>We will see how very important it is to bring about in the human mind the radical revolution.
The crisis is a crisis in consciousness, a crisis that cannot anymore accept the old norms, the old patterns, the ancient traditions.
And considering what the world is now with all the misery, conflict, destructive brutality, aggresion, and so on, man is still as he was, is still brutal, violent, aggressive, competitive and has built a society along these lines. – Jiddu Krishnamurti</p>
</blockquote>

<p>Consequently, it was no surprise to me that at the protests against COVID-19 restrictions and at QAnon gatherings, there was a peculiar blend of people, including everyone from right-wingers to faith healers.
This mix reflects the broad, albeit unusual, appeal of such conspiratorial narratives and the desire for an effective (postmodern) narrator, e.g. Donald Trump, who provides a myth that carries emotional weight rather than the difficulty and uncertainty of a complex world—a <em>myth</em> one can live by.
I think there was also reasonable protest and the situation is certainly much more complex than I am every able to understand.</p>

<p>It is far to easy to make fun of people believing in mythologies.
In an objective scientific sense, myths are eihter false or unfalsifiable.
However, socially they can be very useful and powerful.
They explain experience.
A myth is ment to answer questions and offer solutions to quell the anxieties of the present through stories.
They can serve a useful purpose, particularly in politics.
They create visions, unities and identities among groups such that they can work together towards a meaningful goal—a mission greater than oneself.
Here, spirituality plays an important role, be it in the form of <em>the light of God</em>, <em>Siegfried the dragonslayer</em>, <em>Achilleus the greatest of all the Greek warriors</em> or <em>Donald Trump the warrior King</em>.</p>

<p>I believe that spirituality is a significant aspect of life and is deeply intertwined with philosophy, a field that ideally should stand in stark contrast to conspiratorial thinking.
This raises an intersting question: where does the connection lie?
Why can spirituality lead to the descent into the rabbit hole of conspiracy theories?</p>

<p>First of all, there is a strong relation between philosphy, religion and spirituality, e.g. between Platonism and Christianity.
Furthermore, in my view, there are similarities between <em>metaphysics</em> and the construction of a grand conspiratorial theory (or myth) that attempts to explain everything. 
While philosophy seeks to understand the nature of reality and existence, conspiracy theories often attempt to provide all-encompassing explanations for complex events or phenomena. 
This similarity in seeking comprehensive understandings can blur the lines between philosophical inquiry and the development of overarching conspiratorial narratives.
The difference here seem to be that duo to their mythological structure, conspiracy theories provide a shortcut into our soul (psyche, mind, unconsciousness).</p>

<p>If one values reasoning, myths can be very dangerous.
They misconstrue associations, destroy nuances and advance subconscious theses without a required burden of evidence.
Instead of delivering arguments, they short-circuit the entire argumentative process.
Myths do not make logical claims but significations <a class="citation" href="#barthes:1973">(Barthes, 1973)</a>.
For example, calling someone <em>a snake</em> is not a logical conclusion but signifies deceptive behaviour.
Real snakes, of course, are not significantly more or less deceptive than any other animal.
But mythological snakes often are and calling someone a snake can be a powerful gesture in our culture.</p>

<blockquote>
  <p>Poetry feeds and waters the passions instead of drying them up; she lets them rule, although they ought to be controlled, if mankind are ever to increase in happiness and virtue. – Socrates</p>
</blockquote>

<p>If Trump speaks of <em>America</em> or our radical right-wingers speak of Germany, they do not mean literal countries.
They signify a mythological symbol.
To critique their definition as being racist, irrational, exclusive, inhumane, disastrous only demontrate to them that you are of ‘the them’; that you are jealous that they won.
An effective myth is a self-contained world of signs were everything has a marked position, making it very hard to signify otherwise with a believer.
Any contrary narrative is spun by false prophets which conspire against the ‘chosen ones’.</p>

<h2 id="the-matrix-and-the-cave">The Matrix and the Cave</h2>

<p><em>The Matrix</em> is one of my all-time favorite movies, which increased my interest in computer science and philosophy.
As a child, I fantasized about being <em>The One</em>, akin to the hacker Neo, who could hack the matrix. 
Interestingly, the movie is inspired by French philosopher and theorist of postmodern media and culture, Jean Baudrillard (1929 – 2007), especially by his book <em>Simulacra and Simulation</em> <a class="citation" href="#baudrillard:1983">(Baudrillard, 1983)</a>.
The book even makes an appearance (as an empty prop) at the beginning of the film when Neo gives a disc to his clients and the actors were reportedly required to read it.</p>

<p>Baudrillard—the prophet of post-truth—focused on analyzing what can be termed <em>postmodern media</em>, although postmodernity is challenging to define.
Thinkers in the field of postmodern theory frequently hold different opinions but there is one core agreement: there are no all encompassing meta-narratives.
For some, such as Niklas Luhmann (1927 – 1998), the concept of postmodernity itself is contentious, with Luhmann believing it never truly existed <a class="citation" href="#luhmann:2000">(Luhmann, 2000)</a>. 
But back to Baudrillard.</p>

<p>He was an interesting figure but not taken very seriously by the academic community.
His writing style is polemical and his worldview extremely cynical. 
Despite this, his texts are intriguing and thought-provoking, capturing a sentiment that resonates with many facets of our society today.
In many sense, he was ahead of his time and highly influencial in the media and culture he studied.</p>

<p>What particularly makes <em>The Matrix</em> fascinating in connection with Baudrillard is how the film embodies the type of pop-cultural phenomenon he often discussed in his philosophy.
The movie not only reflects his ideas but might be able to bring them to life in a way that is accessible to a broader audience.
Furthermore, Baudrillard was still alive when the movie hit the theatre.
So, did it succeed in bringing his theory to the big screen?</p>

<h3 id="the-simularcum-is-true">The Simularcum is True</h3>

<p>When we first meet Neo, his computer is active, processing something, with the screen reflecting on his face. 
He listens to music through headphones while lying on his desk, asleep. 
This scene introduces the difficulty of distinguishing between a dream and reality or more precisely, the problem of informational overload and sensory input that, according to Baudrillard, leads to passivity.
The abundance of disjointed information and excessive transparency makes it nearly impossible to organize the world and assign meaning to it.
Faces transform into screens or terminals that passively absorb.</p>

<p>In his early career, Baudrillard aimed to merge (post-)Marxism with (post-)structuralism but eventually abandoned the former.
He applied structuralism in his analysis of <em>The System of Objects</em> <a class="citation" href="#baudrillard:1968">(Baudrillard, 1968)</a>. 
Baudrillard theorized that the significance of commodities stems not primarily from their use or exchange value, but rather from their sign value. 
In structuralism, the meaning of elements, such as words, doesn’t derive from what they represent. 
For instance, teaching a child the word ‘tree’ isn’t as simple as pointing to one and stating, “Look, this is a tree!”
The child wouldn’t know if ‘tree’ refers to that specific tree, its leaves, or a category of trees. 
Understanding the word ‘tree’ requires knowledge of many other words and examining their relationships to ‘tree’—their difference.
Baudrillard argues that in a postmodern society, any cultural idea, image, sign, or symbol is apt to be pulled out of its social context and used to advertise and to place the individual in the position of a consumer.
As these signs are lifted out of the social, they lose all possibility of stable reference.
They may be used for anything, for any purpose.
All that remains is a yawning abyss of meaninglessness—a placeless surface that is incapable of holding personal identity, self, or society.</p>

<p>Baudrillard believed that in a postmodern society, the meaning and value of an object are primarily defined by its relationship to other objects. 
Apple products serve as a pertinent example. 
They appear overpriced when considering solely their use value.
However, their value arises from what they signify in relation to other objects which leads to the demishing of <em>symbolic values</em>.
For example, a pen given to you for your graduation, has probably a high symbolic value to you.
Symbolic values are a assigned by a subject in relation to another subject.
Sign value is an object’s value within a system of objects signifying, for example, social status.</p>

<p>Baudrillard, known for his cynical views, believed that objects have triumphed over subjects. 
He posited that just as money has become a universal medium that renders everything comparable and thus exchangeable, <em>the code</em> has made every sign integratable thus also exchangeable.
It is not that subjects or objects stand no longer for something ‘real’ but that the referent, that does not exist, disappeared.
For example, in the Renaissance people or objects appear to stand for a real referent that does not exist, for instance, royalty, nobility, holiness, etc.
According to Baudrillard, instead of disimulating something, now signs dissimulate that there is nothing.</p>

<blockquote>
  <p>The transition from signs which dissimulate something to signs which dissimulate that there is nothing, marks the decisive turning point. 
The first implies a theology of truth and secrecy (to which the notion of ideology still belongs). 
The second inaugurates an age of simulacra and simulation, in which there is no longer any God to recognize his own, nor any last judgment to separate truth from false, the real from its artificial resurrection, since everything is already dead and risen in advance. – Jean Baudrillard</p>
</blockquote>

<p>This leads to a kind of dissolution of the ‘real’ meaning behind objects.
Accroding to Baudrillard, in the postmodern world, simulacra (e.g. images) have replaced the reality they once represented.
In other words, our current reality is dominated by these simulacra—representations, images, and signs—that no longer have any connection to any real object or event they might have originally represented.
Importantly, the simulacrum is not just covering up the truth or reality; it’s not a mask over something real!
What we perceive as truth or reality is actually just a construct (the simulacrum) that conceals the fact that there is no underlying, original reality; we enter simulation.
In other words, what we consider ‘real’ is just a construct of our perceptions and societal argreements.
In our current postmodern state, the simulacrum has become the truth for us, because there is no other reality against which to measure it.</p>

<blockquote>
  <p>The simulacrum is never what hides the truth—it is the truth that hides the fact that there is none.
The simularcum is true. – Jean Baudrillard</p>
</blockquote>

<p>Following Baudrillard’s perspective, experiences such as a teenager’s first kiss are no longer real in a sense that they express true love;
instead, they are mere simulations of a Hollywood love story because these stories are the truth!
Life imitates advertisement.
This does not mean that there is no more love.
However, there is nothing behind the ‘Hollywood love story’—it is true itself.</p>

<p>We are compelled to reproduce these images and to participate, even if we know or suspect it is all a simulation.
Critically, the problem (if it is in fact one) is not a virtualized reality that hides the truth, but that the truth is simulation.
People are fake but they are turthfully fake because being fake is the truth.</p>

<blockquote>
  <p>[…] pretending […] leaves the principle of reality intact: the difference is always clear, it is simply masked, whereas simulation threatens the difference between the ‘true’ and the ‘false’, the ‘real’ and the ‘imaginary’. – Jean Baudrillard</p>
</blockquote>

<p>When more and more simulacra transform into simulation we enter the matrix.
Pictures of ourselves no longer represent us, or us pretending to be someone else, but they are a simulation of some specific and often stereotypical fantasy that has no reference to something real other than different parts of the code.
That is the depressing and cynical viewpoint of Baudrillard.</p>

<h3 id="back-to-plato">Back to Plato</h3>

<p>I love <em>The Matrix</em> but I have to assess that it did not succeed in capturing Baudrillard’s main themes.
The main problem is a clear line between simulation and reality; between the matrix and Zion.
The matrix clearly is not the truth but hides it.
Rather than exploring the new problem of simulation, the movie falls back on the <em>Allegory of the Cave</em> presented in Plato’s <em>Republic</em>.
Instead of investigating further questions, it postulates a true world behind the simulation by re-introducing religion.
Thus <em>The Matrix</em> brings us back where it all started but, according to Baudrillard, this is no longer possible.
In Baudrillard’s framework, the movie is itself the truth that hides the fact that there is none and therefore distracts the audience from acknowledging <em>hyperreality</em>.</p>

<p>The <em>Allegory of the Cave</em> is a metaphor for exploring the nature of knowledge and reality.
Plato imagined a group of people who lived their entire live chained inside a dark cave.
The only thing they can see are the shadows projected on the wall of the cave by objects passing in front of a fire behind them. 
These shadows are the only reality they know.
The cave dwellers believe the shadows to be the real objects, not knowing that these are mere reflections. 
Their knowledge and understanding of the world are based solely on this limited perspective.
One day, a prisoner breaks free. 
He struggles to adjust to the light outside the cave, but eventually, he sees and understands the true nature of reality. 
He realizes that the sun illuminates the world and that what he saw in the cave were just shadows of real objects.
The freed prisoner returns to the cave to enlighten the others. 
However, his eyes have adjusted to the sunlight, so the cave is now blindingly dark to him. 
The other prisoners, unable to understand his experiences and seeing his blindness in the dark, refuse to believe him. 
They cling to their old beliefs about the shadows being the real objects.</p>

<p>In Plato’s metaphysics, the form (true essence of things) are more real than their physical representations.
The shadows represent the physical world, while the objects outside the cave symbolize the forms.
Plato also emphasizes that education is not just a matter of transferring information, but a transformative experience that leads to understanding, or to the seeing of a different world that opens up.
Of course, it is the philosopher that seeks the truth (outside the cave) and then attempts to bring this knowledge back to the people (inside the cave).</p>

<p>We can draw a neat parallel between Plato’s <em>Allegory of the Cave</em> and the film <em>The Matrix</em> by replacing the <em>cave</em> with <em>the matrix</em> and the philosopher with the character Morpheus. 
In this parallel, Morpheus takes on the role of guiding Neo (and others) out of the matrix—similar to leading prisoners out of the cave. 
Neo learns to understand and manipulate the matrix on his terms, which parallels the ability to manipulate the shadows on the cave walls.</p>

<p>In <em>The Matrix</em>, Neo is confronted with a crucial binary decision, symbolized by the choice between a red and a blue pill. 
As revealed in the sequels, this choice is, in itself, a part of a predetermined simulation—a much more Baudrillardian take.
Morpheus presents Neo with this decision and advises him to trust his instinct that something is fundamentally wrong with the world. 
This guidance emphasizes the importance of an emotional rather than a logical conclusion, steering Neo to follow his feelings in making this pivotal choice.</p>

<p>Once Neo makes his choice, the distinction between the matrix and reality is clear to him; it is a clear binary: reality and simulation.
True love is still possible outside and even inside the matrix, even if it is predetermined.
According to Baudrillard reality is a simulation echoing Kant, who does not grant us the access to the thing in itself, and of course Nietzsche, who tells us that there are only constructed values.
Simualation is nothing bad or something to fear.
It was always already there but the simulacrum (e.g. cave paintings, images) changed towards its own gravity towards its own perfection.
What Baudrillard feared is a world akin to the movie <em>Minority Report</em>.
A world without reversability where everything is already decided in advance and there is no more place for ambiguity.
The perfect simulation gets rid of illusions and imaginations; it is too real; it is <em>hyperreal</em>;
Therefore, Baudrillard does not fear the loss of reality but an exzess of it which would lead to the destruction of illusions and imaginations like the technical perfection of sex, i.e. pornography, leads to the removal of sexuality and intimacy.
This is thematized in <em>Jon Don</em> where the main character imagines pornographic content during sex and needs to learn how to be intimate.</p>

<blockquote>
  <p>Reality and simulation aren’t opposed to one another. 
There are two sides of the same coin. – <a class="citation" href="#baudrillard:2008">(Baudrillard, 2008)</a></p>
</blockquote>

<p>With this in mind, if we reexamine <em>The Matrix</em> it becomes clear that Baudrillard would describe it to be a pretty good simulation of the matrix.
In a sense, the sign of simulation is re-integrated into the simulation itself.
This reinterpretation highlights the film’s exploration of reality, perception, and the nature of choice, themes that resonate with Plato’s allegory but not with <em>Simulacra and Simulation</em>.
Thus Baudrillard concludes:</p>

<blockquote>
  <p>The radical illusion of the world is a problem faced by all great cultures, which they have solved through art and symbolization.
What we have invented, in order to support this suffering, is a simulated real, which henceforth supplants the real and is its final solution, a virtual universe from which everything dangerous and negative has ben expelled.
And The Matrix is undeniably part of that.
Everything belonging to the order of dream, utopia and phantasm is given expression, ‘realized’.
We are in the uncut transparency.
The Matrix is surely the kind of film about the matrix that the matrix would have been albe to produce. – Jean Baudrillard</p>
</blockquote>

<h2 id="neo-a-conspiratorial-narcissist">Neo, a Conspiratorial Narcissist?</h2>

<p>Now, what has this to do with <em>conspiracy theories</em>?
Well, other than Baudrillard’s theory of a reality that is simulation, the <em>cave allegory</em> offers a theoretical justification for doubting established institutions, which are likened to the matrix.
One might discover that parts of reality, e.g. institutions, norms, moral judgements, ideologies, is constructed and that there has to be something real behind it.
This suspicion of a matrix is not unfounded, however, believing in some absolut point of view behind it opens the door to confusion.
We are in a cave but going outside might only lead to another cave.
This does not mean that any cave is as useful, functional or equally connected to some underlying reality.
Although not all interpretations of a text are equally meaningful, a good text offers numerous interesting and valuable interpretations and the same seems to be true of our <em>lifeworld</em>.</p>

<p>Doubting reality—a known or presented world—is the starting point of any conspiracy theory.
The perspective is compelling because it feeds the allure of knowing a secret, akin to Neo’s experience in the matrix.
Such knowledge is seen as something that sets an individual apart from ‘the herd’, giving them a sense of being special or enlightened.
It is similar to <em>New Age</em> beliefs in some sort of special knowledge about the universe presented in movies like <em>The Secret</em>.</p>

<p>Belief in conspiracy theories appears to be driven by motives that can be characterized as epistemic (understanding one’s environment), existential (being safe and in control of one’s environment), and social (maintaining a positive image of the self and the social group) <a class="citation" href="#douglas:2017">(Douglas et al., 2017)</a>.
One important facet of conspiracy theories that often goes without much notice is that they are notions about power: who has it and how are they using it?
Conspiracy theories accuse an implicitly powerful group of conspiring.
Usually that group is already powerful—even if that power is a fantasy—i.e., the president, a legislative body, industries or corporations, foreign countries, multinational groups, etc. 
Powerless groups are rarely accused of conspiring <a class="citation" href="#uscinski:2018">(Uscinski, 2018)</a>.
This also reflects the plot of <em>The Matrix</em> where agents of the matrix are much more powerful than ‘enlightened’ humans.</p>

<p>Studies show that some people are more prone to believing in conspiracy theories than others.
Some people will believe in any conspiracy theory even on light evidence while others, at the opposite end of the spectrum, are naive and will deny the existence of conspiracies even on accumulating evidence <a class="citation" href="#uscinski:2018">(Uscinski, 2018)</a>.
According to Jan-Willem Prooijen, conspiracy theories orginate through the same cognitive process that produce other types of belief (e.g. spirituality), they reflect a desire to protect one’s own group against a potentially hostile outgroup, and they are often grounded in strong ideologies.
They are a natural defensive reaction to feelings of uncertainty and fear <a class="citation" href="#prooijen:2018">(Prooijen, 2018)</a>.</p>

<p>Interestingly, in studies, individuals who perceive patterns in abstract paintings, random dots, or coin tosses were more inclined to believe in conspiracy theories, paranormal phenomena, and hold religious beliefs. 
Belief in conspiracies also tends to rise during natural disasters when people feel a lack of control. 
Due to their tendency to seek patterns, conspiracy theorists tend to categorize everything neatly into a framework of good versus evil.
Even though the world that is constructed is miserable, it is without uncertainty.</p>

<p>We are risk calculating creatures, always on the watch for new dangerous patterns.
This is evolutionary advantageous.</p>

<blockquote>
  <p>Conspiracy is a stubborn creed because humans are pattern-seeking animals.
Show us a sky full of stars, and we will arrange them into animals and giant spoons.
Show us a world full of random misery, and we will use the same trick to connect the dots into secret conspiracies. – Jonathan Kay <a class="citation" href="#kay:2011">(Kay, 2011)</a>.</p>
</blockquote>

<p>Perceiving patterns is the opposite of perceiving randomness, and randomness cannot be the basis for making sense. 
Of course, quite often, events occur randomly, without any discernible purpose or meaning. 
Sometimes, foolish mistakes simply happen unintentionally.</p>

<p>Research indicates that education reduces the likelihood of believing in conspiracy theories (with exceptions). 
This may initially appear counterintuitive because education encourages skepticism toward received wisdom. 
Shouldn’t skepticism lead one to think that there might be something hidden behind the scenes?
Well, skepticism is only one aspect of the equation. Education teaches individuals to scrutinize the evidence and seek primary sources, or more precisely, to consider <strong>all</strong> available evidence.
Under such scrutiny conspiracy theories fall apart.
Moreover, having a greater understanding tends to foster humility since individuals become increasingly aware of the vast expanse of knowledge that remains beyond their grasp.</p>

<p>Scrutiny is built into our institutions.
In the context of academic publishing, one must demonstrate a comprehensive understanding of the relevant literature and show how experiments can be reproduced to validate the published findings.
A peer review process by experts in the field checks for the soundness of the work and identifies possible errors. 
While this system is not flawless, makes mistakes, overemphasis the number instead of the value of publications, can be biased, and often favours the middle to upper class, it remains open to critique and has propelled us a long way.
Science is a discourse.
Theories are never absolute true but are seen as true as long as there is no evidence or proof that gives rise to different conclusions.
Mistakes have been made and will continue to be made in the future, but the system is self-correcting, self-preserving, and has advanced our knowledge considerably.</p>

<p>Conspiracy theories are also fueled by our cognitive biases. 
For instance, the <strong>proportionality bias</strong> tends to make us believe that a substantial effect must have a significant cause. 
Consider a scenario where either a neighbor or the President of the United States dies randomly; which one is more likely to trigger a conspiracy theory?
Studies have revealed that when people are informed about the assassination of a president, they are more inclined to believe in a conspiracy theory if it coincides with the outbreak of a subsequent civil war <a class="citation" href="#prooijen:2018">(Prooijen, 2018)</a>.
<strong>Tribalism</strong> encourages us to protect our own ingroup and establish a clear division between ‘us vs. them’, often framing it as a battle between good and evil.
The <strong>intentionality bias</strong> leads us to believe that negative consequences of our actions are unintentional, while attributing intentionality to others when they cause harm. 
For example, we may view bankers as evil, but perceive our own pension fund as a necessary institution.</p>

<p>Seeing patterns everywhere is the need for control <a class="citation" href="#shermer:2022">(Shermer, 2022)</a>.</p>

<blockquote>
  <p>The economy is not this crazy patchwork of supply and demand laws, market forces, interest rate changes, tax policies, business cycles, boom-and-bust fluctuations, recessions and upwings, bull and bear markets, and the like.
Instead, it is a conspiracy of a handful of powerful people variously identified as the Illuminati, the Bilderberger group, the Council on Foreign Relations, the Trilateral Commission, the Rockefellers and Rothshields.
[…] Conspiracists believe that the complex and messy world of politics, economics, and culture can all be explained by a single conspiracy and conspiratorial event that downplays chance and attributes everything to this final end of history. – Michael Shermer</p>
</blockquote>

<p><a class="citation" href="#landau:2015">(Landau et al., 2015)</a> show that people compensate for perceived loss of control by trying to restore control themselves by</p>

<blockquote>
  <p>bolstering personal agency, affiliating with external systems perceived to be acting on the self’s behalf, and affirming clear contingencies between actions and outcomes [… and] seeking out and preferring simple, clear, and consistent interpretations of the social and physical environments.</p>
</blockquote>

<p><strong>Narcissism</strong>, characterized by a belief in one’s superiority and the desire for special treatment, strongly correlates with a tendency to believe in conspiracy theories. 
Narcissists also exhibit heightened sensitivity to perceived threats <a class="citation" href="#cichocka:2022">(Cichocka et al., 2022)</a>.
Within the realm of narcissism, grandiose narcissists seek admiration by bolstering their egos through a sense of uniqueness, charm, and grandiose fantasies. 
It’s worth noting that narcissists often display naivety and are less likely to engage in <strong>cognitive reflection</strong>.
Surprisingly, studies have uncovered evidence suggesting that, contrary to expectations, education increases the likelihood of narcissists adopting conspiracy beliefs <a class="citation" href="#cosgrove:2023">(Cosgrove &amp; Murphy, 2023)</a>. 
This underscores the critical role of cognitive reflection as one of the most, if not the most, essential abilities to guard against narcissistic tendencies towards conspiracy beliefs.</p>

<blockquote>
  <p>[Conspiracy believers] are relatively untrusting, ideologically eccentric, concerned about personal safety, and prone to perceiving agency in action – <a class="citation" href="#hart:2015">(Hart &amp; Graether, 2015)</a></p>
</blockquote>

<p>Similar to the experience of emerging from the cave in Plato’s allegory, delving into a conspiracy theory is not merely a transfer of knowledge, but a transformative experience. 
It involves a world being shattered and a new one being constructed in its place.
This process signifies a profound shift in perception and understanding, where previously accepted realities are dismantled and replaced with an entirely different framework of belief and interpretation.</p>

<p>Like Morpheus’ emphasis on trusting one’s instincts in <em>The Matrix</em>, conspiracy theories often accurately capture the emotional aspects of a person’s situation. 
These theories provide compelling descriptions of emotional states but tend to offer simplistic and reactionary explanations for complex situations. 
Additionally, much like the concept of the matrix, they seek an all-encompassing explanation for everything.
Essentially, these theories represent a futile effort to eliminate contingency and the growing uncertainty about the future. 
They attempt to provide a sense of certainty and understanding in a world that is inherently open, unpredictable and complex. 
This desire for comprehensive explanations reflects a deep-seated human need for order and predictability in an increasingly uncertain world.</p>

<h2 id="escaping-the-matrix">Escaping the Matrix?</h2>

<p>The incorporation of expressions like ‘escaping the matrix’ and ‘being red-pilled’ into the vocabulary of conspiracy theory groups as metaphorical language is unsurprising.
These terms, which originated from <em>The Matrix</em>, are used metaphorically to describe the experience of awakening to a hidden or suppressed truth.
This desire might increase with the suspicion that there is none.
Specifically, ‘escaping the matrix’ denotes the recognition and liberation from a controlling system or an illusionary world, while ‘being red-pilled’ represents a moment of profound revelation or enlightenment, often regarding societal structures or purported conspiracies.
These metaphors have gained traction within certain groups as a way to express their beliefs in uncovering what they perceive as hidden truths within society.
They believe to be the philosophers of our age, teaching us how real man behave and how ‘the system’ keeps them weak and small.</p>

<p>Contrary to the common belief that ignorance fuels the acceptance of a matrix-like reality, it is curiosity that often propels this belief. 
People are attracted to the notion of discovering hidden truths and understanding the world in ways that differ from the majority’s perspective.
The group forms, in a manner reminiscent of a cult, and establishes easily comprehensible guidelines, resembling the revolutionaries from another pop-cultural and frequently misunderstood film—<em>Fight Club</em>.
The theme of ‘stepping out of the dark’ is central to Plato’s cave allegory, <em>The Matrix</em>, and various conspiracy theories. 
Such curiosity ignites a desire to investigate and question conventional narratives, leading some individuals to adopt alternative interpretations of reality.</p>

<p>Interestingly, critical thinking and intelligence do not necessarily prevent one from falling into this rabbit hole.
As described above, these attributes can sometimes drive narcissits deeper into exploring and accepting these alternate realities—the problem is a lack of reflection.
The quest for understanding and the allure of uncovering hidden knowledge can be so compelling that even the most critical and intelligent minds are susceptible to these alternate explanations.</p>

<p>Furthermore, it is a fact that people do engage in conspiracies. 
A brief examination of history reveals numerous instances of conspiracies, some of which have even led to wars between nations. 
However, in retrospect, these conspiracies can often be explained without assuming the involvement of thousands of people. 
The complexity and impact of these historical events do not necessarily require large-scale collusion; often, they can be understood through the actions and decisions of a relatively small number of individuals or groups and through a systemic rationality. 
This understanding helps differentiate between plausible historical conspiracies and the more elaborate, less credible theories that claim widespread secret collaboration.
If it exists, the matrix is not a planned construction of anybody but a Baudrillardian process beyond anyones control.</p>

<p>In addition, it’s important to recognize that the world is inherently unjust. 
Justice is a human concept, one that evolves over time as we make what we call progress. 
However, in the realm of nature, there is no concept of justice at least none I am aware of;
nature operates outside of morality.
Absolute justice remains elusive and if we seek an explanation for the world’s injustice, conspiracy theories provide a sense of comfort.</p>

<p>It appears to me that the belief in having escaped the matrix or emerged from the cave is a strong indication of someone having entrenched themselves deeply in their own perspective—failing to see that their perspective also relies on some sort of <em>second-order observation</em>; a following of the herd, or in Baudrillard’s viewpoint, the false assumption that there is something true behind the simulation.
This belief offers comfort by addressing various uncertainties and the realization of one’s own ignorance. 
No one desires to be ignorant and no one wants to rely on some sort of authority, yet in many ways, we all are.
In our complex world, this is an unavoidable reality. 
Conspiracy theories provide a sense of understanding and control in a world where complete knowledge is unattainable, helping individuals cope with the inherent limitations of human understanding.</p>

<p>Therefore, I believe that individuals who are particularly uncomfortable with uncertainty, who seek control over their lives, and who are actively aware of their lack of control, are more susceptible to falling into these rabbit holes of alternate realities. 
Additionally, a certain degree of narcissism may be necessary to believe in the premise that one possesses a superior ability to understand complex matters better than trained experts and to assume that the media consisting of hundred of thousand of journalists is a monolith.
This combination of a need for control, discomfort with uncertainty, and a self-perceived exceptional understanding can lead individuals to embrace alternative explanations that offer a sense of clarity and personal significance in a complex world.</p>

<p>If we contemplate the matrix envisioned by Baudrillard, then attempting to escape it through the immersion in an alternate version of reality, fostered by extensive consumption of social media and digital content, appears absurd. 
Perhaps a more appropriate approach to disengaging from the machinery of simulation and countering the sensation that reality seems increasingly tenuous is to simply disconnect from it all (from time to time).
When advertisements, repetitive media, individuals transformed into brands, and an incessant stream of content seize our attention, the signal overflow—the noise—overshadows a more tangible reality. 
In a scenario where there may be no external escape from the simulation, it could be valuable, from time to time, to focus on what is immediately before us: to experience, touch, smell, listen to our bodies, engage with physical sensations, concentrate, savor awareness, and relinquish the illusion of the “real.”</p>

<p>We are not superheroes; we are composed of the same fundamental elements as everything else. 
While it might feel like we inhabit a sort of matrix, it’s essential to acknowledge that this is a choice we make. 
From childhood, we develop self-conceptions and fantasies, but this doesn’t negate the existence of the world itself. 
Fantasies are constructs, and doubting the existence of the world presupposes a profound level of experience and knowledge of that world—a world where we learn to eat, walk, dance, and understand the nuances of correct and incorrect language usage.
We often employ our habits so routinely that we forget we are employing them, and in doing so, we forget that the world—our home—is still there. 
The central question here is what is more reasonable to doubt: the world you intimately grew up in or your doubts about doubting it?</p>

<h2 id="our-dependence-on-second-order-observation">Our Dependence on Second-order Observation</h2>

<p>Thinking critically and maintaining a sense of curiosity are attributes that I certainly hope everyone possesses.
It is crucial that institutions, including large media operations, research institutions, and particularly governments, are consistently challenged and kept under close scrutiny.
Conspiracy theories can serve as a force to encourage the prevention of corruption.
I would be quite suspicious if there were no conspiracy theories!</p>

<p>Simultaneously, these theories have the potential to divert attention from genuine issues. 
The public should advocate for accountability and transparency, cultivating a healthy and well-informed society in which decisions and policies undergo scrutiny and improvement through public discourse and critical examination.</p>

<p>However, as the current state of affairs stands, the notion that everyone can participate in the marketplace of ideas and engage in public discourse seems somewhat impractical. 
This dream may appear overly optimistic, excessively humanistic, and excessively individualistic. 
Instead, according to Luhmann, there exists an interdependent network of social systems that co-evolve together—not individual souls but interconnected systems.</p>

<p>Similarily we demand the media should try to be as objective as they can be but it is naive to think that they are able to present reality as it is.
Here I agree with Luhmann:</p>

<blockquote>
  <p>It is impossible to understand the reality of the mass media if you assume it is their job to provide correct information on the world and then assess how they fail, distort reality, and manipulate opinion—–as if they could do otherwise. – Niklas Luhmann</p>
</blockquote>

<p>If one anticipates that the primary purpose of the media is to deliver accurate information, they are likely to encounter inconsistencies that raise significant doubts about the credibility of the mass media apparatus. 
The media is inherently self-preserving and functions in a manner that constructs and sustains itself. 
While it is certainly beneficial for the media to provide accurate information, this is not its foremost objective.
Media irritates politics and the political system, economics and the scientific system irritate the media.</p>

<p>In my view, this mistaken perception of the media contributes to the proliferation of conspiracy theories, as it portrays the entire system as corrupt. 
Instead of recognizing the various shortcomings within the media (of which there are many), one tends to assume a broad conspiracy aimed at deliberately deceiving the public. 
This leads to a pervasive distrust, particularly directed towards well-established media outlets.
As a consequence, consumers may turn to ‘alternative’ media sources, even though these alternatives often inadvertently rely on established media institutions for their information. 
Reporting, conducting on-site investigations, collecting information, and managing extensive archives are expensive endeavors that only large institutions can effectively undertake. 
These institutions are essential if we are to have any hope of acquiring reliable information about the world.</p>

<p>The core issue lies in our reliance on what Niklas Luhmann refers to as <em>second-order observation</em> and is consequently a trust issue.
In modern society, directly observing reality is increasingly challenging. 
To stay informed about various aspects such as the state of the economy, job market trends, recent fashion styles, developments in one’s favorite sports league, or new scientific inventions and studies, it is impractical to personally verify these facets. 
Instead, we depend on the observations made by others and, of course, machines.
This means we have to engage with various forms of reporting and analysis: reading reports about the GDP, considering the opinions of fashion critics, watching sports programs, and reviewing scientific papers. 
This reliance on second-hand information shapes our understanding of the world, as we depend on external observers to provide us with insights and knowledge about various domains that we cannot directly experience or verify ourselves.</p>

<p>We frequently depend on multiple layers of <em>second-order observations</em> or various levels of abstraction.
Scientific papers serve as a prime example. 
These papers are typically not intended for a general audience but are meant for peers within the specific field of research. 
As a result, the average person often finds them inaccessible.
Consequently, we turn to science communicators and mass media to distill and present scientific information. 
These intermediaries play a crucial role in interpreting and translating complex scientific data and studies into ‘facts’ that are understandable and relevant to the general public. 
This reliance on filtered and simplified interpretations highlights our dependence on external sources to understand and engage with specialized knowledge areas.</p>

<p>At the core of our society is the notion of the individual as a subject capable of making their own decisions and drawing sound conclusions. 
However, it’s evident that our understanding of the numerous processes occurring around us is limited. 
The complexity of the modern world might only be manageable through <em>functional differentiation</em> and <em>second-order observation</em>. 
We are heavily dependent on specialists and experts, and our understanding is largely shaped by observing their observations.</p>

<p>Conspiracy theorists seemingly reject <em>second-order observation</em>, viewing it as a form of manipulation akin to the matrix. 
However, this rejection is a perilous illusion.
There is no position outside of second-order observation, no external vantage point from which to objectively assess ‘reality’ as it is, separate from the interpretations and understandings provided by others.
This perspective underscores the intricate and interconnected nature of knowledge and understanding in contemporary society.</p>

<p>Philosophers ranging from Plato, Fichte, and Kierkegaard to Russell, Kant, and Heidegger have provided insights that prompt us to question the application of second-order observation.
These philosophical teachings encourage us to contemplate whether we should exercise independent thinking and challenge the prevailing mainstream narrative.
This concept is epitomized in Heidegger’s notion of avoiding assimilation into <em>das Man</em> (the they), Kierkegaard’s emphasis on distancing oneself from the public, or Fichte’s focus on the ego. 
The stories goes like this: There exists an inner truth within us, and we should search within our <em>authentic</em> selves to discover it. 
As sovereign individuals in a libertarian society, we should not solely rely on the opinions, or observations, of others. 
As Kant famously articulated, we should have the courage to employ our own intellect (Verstand). 
I align with Kant with a caveat: we should also have the courage to acknowledge our own ignorance and cultivate the ability to rectify it.
By utilizing second-order observation wisely, we can develop a <em>cultural intelligence</em> more akin to Hegel’s concept of the world spirit than Kant’s emphasis on the individual.</p>

<h2 id="conviction-under-constructivism">Conviction under Constructivism</h2>

<p>Biologists Humberto Maturana, Francisco Varela, Samy Frenk, and Gabriela Uribe made a significant discovery regarding our understanding of color perception.
Rather than focusing solely on the correlation between the physical source of color and the retina’s response, they emphasized another more important correlation: the one between the retina and subjective color perception. 
In this context, the external source of color functions as a trigger, not the sole determinant.</p>

<p>This structure of subjective color perception effectively maintains the perception of colors under various objective conditions, even when there are substantial discrepancies between the perceived and ‘emitted’ color, as seen in deception experiments. 
Maturana and Varela extended this insight to introduce the concept of autopoesis, integral to the biological theory of cognition <a class="citation" href="#maturana:1987">(Maturana &amp; Varela, 1987)</a>.</p>

<p>In line with their constructivist theory, every individual constructs their own cognition and, by extension, their reality.
Maturana theory seems not far from Kant’s and to an extend Fichte’s understanding of cognition.
Constructivism does not imply an absence of a single reality or a state of complete subjectivity, but rather, it leads to some noteworthy conclusions:</p>

<ol>
  <li>An absolute system of values and knowledge cannot exist because personal experience forms an unshakable foundation.</li>
  <li>Convincing someone can only succeed when they develop their own system of conviction.</li>
  <li>Humans, capable of observing their cognitive actions and recognizing the relativity of their seemingly valid knowledge, face the responsibility of choosing and adhering to their own value system.</li>
</ol>

<p>These conclusions have significant relevance to our current discussion. 
Maturana’s framework explains the challenge of debunking conspiracy theories and how individuals can inhabit vastly different realities. 
It also underscores our responsibility to acknowledge our inherently constructed perspective on reality and the value system we embrace.</p>

<p>Now, I should mention that there are numerous critics of constructivism, including Markus Gabriel, who advocates for what he refers to as <em>new realism</em>.
In his book <em>Der Sinn des Denkens</em> (English: <em>The Sense of Thinking</em>) <a class="citation" href="#gabriel:2018">(Gabriel, 2018)</a>, he writes:</p>

<blockquote>
  <p>Constructivism is incorrect. New realism asserts that we can perceive reality as it is, without there being precisely one world or reality that encompasses all objects or facts that exist. – Markus Gabriel</p>
</blockquote>

<p>I read his book with the expectation of finding a plausible justification for why this should be the case, but I couldn’t find any consistent argument. 
Admittedly, this might be unfair as the book is a popular science book and doesn’t aim to provide a rigorous theory. 
Nevertheless, Gabriel often labels assertions as obvious without offering a reasonable explanation. 
Based on what I’ve encountered and also observed in my own life, I lean toward believing in constructivism.</p>

<p>Certainly, this form of relativism raises several pressing issues. 
For instance, how can we justify the actions of individuals whose worldviews may vastly differ from our own?
Additionally, how can international bodies like the United Nations apply pressure on nations that violate human rights if their value systems diverge significantly from a Western dominated notion of values?
Richard Rorty has an intreresting take on that question.
If we want universal acceptance of and respect for human rights, we shouldn’t try to argue about it. 
We shouldn’t attempt to work out rational justifications of human rights, or arguments that will convince people that human rights are a good thing. 
Instead, according to Rorty, we would achieve better results if we try to influence people’s feelings instead of their minds—philosophy as poetry <a class="citation" href="#rorty:2016">(Rorty, 2016)</a>!
This approach to human rights doesn’t justifying human rights in an abstract and philosophical way—something which according to Rorty isn’t possible anyway.
In a sense, Rorty suggest that, instead of arguing rationally against mythologies, we should imagine, construct and present better ones.
He does not believe in a second enlightenment—in which logic and rationality will triumph over evil.
It is worth noting that similar challenges and questions arise when we consider the concept of <em>free will</em>, which is itself a highly contentious notion, compare for example <a class="citation" href="#sapolsky:2023">(Sapolsky, 2023)</a>.</p>

<p>In a world with no singular perspective there are multiple viewpoints coexisting and each has its inherent blind spots. 
According to Luhmann, this principle applies to any observing system, whether it’s a psychological system, like the human mind, or a social system. 
The diversity of perspectives inherently limits each view, preventing it from fully encompassing all facets of a situation or concept. 
This inherent limitation in observation highlights the intricate and multifaceted nature of comprehending and interpreting the world around us.</p>

<p>The diversity of perspectives among individuals often complicates accurate communication because each of us essentially speaks a slightly different language. Communication, in itself, can be seen as improbable. 
Nevertheless, it remains a crucial element as it plays a central role in stabilizing the chaos and connecting psychic and social systems. Interestingly, it can be effective even when we don’t fully comprehend each other. 
A prime example of this is ChatGPT, which may not understand as humans do but still manages to communicate effectively.</p>

<p>So, can we embrace and navigate this diversity of perspectives? Can or should we tolerate the uncanny sensation of numerous distinct realities coexisting? 
Is it possible for us to, to some extent, accept that others may inhabit a differently constructed world while simultaneously acknowledging the existence of something that persists, even if we cease to believe in it—namely, the measureable physical <em>reality</em>?</p>

<h2 id="the-reality-of-the-climate-crisis">The Reality of the Climate Crisis</h2>

<p>The COVID-19 pandemic had a measurable positive effect on pollution levels—which did not last for long.
However, one could argue that it also had a negative impact on trust levels in institutions, especially scientific ones.
This erosion of trust may ultimately hinder efforts to address the climate crisis.
The ongoing debate regarding climate change’s origins and the necessity of curbing CO2 and equivalent gas emissions continues to persist even if the scientific community is clear on the matter—a conviction I have established via <em>second-order observation</em>.</p>

<p>It appears to me that COVID, combined with the rapid and highly polarizing consumption of “news” on social media, has fractured our social discourse. 
The culture of dialogue has suffered, forcing individuals to align with one of two extreme sides. 
It now seems impossible to critique one party without facing accusations of working for the other.
The language we employ has become more moralizing. 
Instead of characterizing people as simply incompetent, misled, misguided, or influenced by flawed incentives within a system, they are often labeled as evil. 
This focus on the individual impedes progress in reforming social systems, which are in need of change to provide alternative incentives that prioritize social, ecological, and economic measures for all inhabitants of the planet.
Part of the reality of the climate crisis is that we need trusted institutions that need to be aligned in a way that dealing with the crisis becomes possible.</p>

<p>Emissions are not the only problems on our hand.
Many ecological systems are on the bringe of collapse.
Our agriculture is under threat.
Water shortages are on the horizon.
Increased carbon dioxide absorption by oceans leads to ocean acidification, which can harm marine life, especially coral reefs and shellfish.
Climate change can exacerbate health issues by increasing the spread of diseases, heat-related illnesses, and air quality problems due to wildfires and increased pollen levels.
Changing weather patterns and more frequent extreme events can disrupt agriculture and water supplies, potentially leading to food shortages and conflicts over resources.
As climate impacts worsen, there will be never-seen increased migration and displacement of populations, both within and across borders, as people seek refuge from areas affected by climate-related hazards.
Climate change is very likely to intensify extreme weather events such as hurricanes, droughts, heatwaves, and heavy rainfall. 
These events can lead to increased property damage, displacement of populations, and economic losses.
Sea levels are expected to continue rising, posing a threat to coastal communities, infrastructure, and ecosystems. 
Flooding and saltwater intrusion into freshwater sources may become more common.
I imagine that, at some point, borders of certain countries will be closed, dividing the world in a <em>real</em> and a <em>hyperreal</em> one.</p>

<p>Considering all the points I discussed, the resistance to transitioning away from fossil fuels is expected, given the various parties involved. 
It would be a relief if we were in a simulated reality, where everything could be dismissed as a bad dream.
However, we are faced with the pressing need to convince everyone that climate change is a real problem that demands immediate action.
And that it is worth to sacrifice for the unknown other.
Individuals who have limited information may be persuaded through sound arguments and credible sources. 
However, those who actively reject the mainstream narrative may ultimately question the legitimacy of <em>second-order observation</em>.</p>

<p>An example of this dynamic in action was during a BBC News panel where Brian Cox (physics professor and science communicator) clashed with skeptic Malcolm Roberts (politician). 
Roberts insisted on <em>empirical evidence</em> and rejected <em>appeals to authority</em>. 
All seemed well and logical, but when Cox presented a graph as evidence, Roberts dismissed it, alleging that the data had been corrupted by NASA.
At this juncture, a discussion is no longer possible because there are no external empirical evidence available beyond that produced by scientific institutions.</p>

<p>Undeniable empirical evidence, including temperature records, ice melt data, and rising sea levels, serves as a compelling testament to the tangible effects of climate change. 
To promote a more informed perspective, it is advisable to encourage individuals to explore and critically evaluate reputable, peer-reviewed scientific sources, rather than relying on fringe or biased information.
So, let’s delve into a tiny selection of influential contributions from the scientific community that have shaped our understanding of climate change.
Note that this is only a tiny selection from the whole corpus:</p>

<p>As early as 1896, Svante Arrhenius published a groundbreaking paper on the greenhouse effect, demonstrating how rising concentrations of greenhouse gases lead to an increase in global average surface temperatures <a class="citation" href="#arrhenius:1896">(Arrhenius, 1896)</a>.
Another significant milestone occurred in 1967 when Manabe and Wetherald published the first paper that incorporated the fundamental elements of Earth’s climate into a computer model, exploring the implications of doubling carbon dioxide levels for global temperatures <a class="citation" href="#manabe:1967">(Manabe &amp; Wetherald, 1967)</a>. 
Remarkably, the results of their work remain valid today, according to Prof. Forster.
In 1976, Charles D. Keeling and his team documented a pivotal moment by revealing the sharp rise in carbon dioxide levels at the Mauna Loa observatory in Hawaii <a class="citation" href="#keeling:1976">(Keeling et al., 1976)</a>. 
This paper highlighted the observable increase in atmospheric CO2 resulting from the combustion of carbon, petroleum, and natural gas.
Fast-forwarding to 2006, Held and Soden advanced the concept known as <em>wet-get-wetter, dry-get-drier</em> precipitation in the context of global warming <a class="citation" href="#held:2006">(Held &amp; Soden, 2006)</a>. 
This idea, though occasionally misunderstood and misapplied, remains the first and perhaps the only systematic conclusion regarding regional precipitation and global warming based on a robust physical understanding of the atmosphere.
Additionally, the <em>Intergovernmental Panel on Climate Change</em> (IPCC) reports have played an integral role in consolidating and disseminating crucial climate science findings, further enhancing our collective comprehension of climate change.
If one is convinced that there may be some shadiness going on, I encourage the reader to delve into the extensive history of climate change science, for example <em>The Discovery of Global Warming</em> <a class="citation" href="#weart:2009">(Weart, 2008)</a>.</p>

<p>Additional, one can highlight the overwhelming consensus among climate scientists and scientific organizations that climate change is real and largely caused by human activities, compare <a class="citation" href="#myers:2021">(Myers et al., 2021; Lynas et al., 2021; Cook et al., 2016; Cook et al., 2013; Doran &amp; Zimmerman, 2009)</a>.
Of course, if we only rely on those papers we have to trust an even <em>higher-order observation</em>!
In addition, one can argue that there is no plausible alternative theory apart from the effects humans caused by polluting the planet.</p>

<p>But if an individual has lost trust in institutions all these efforts will be fruitless.
Therefore, it is so deeply important that our scientific institutions as well as the media defend and improve their reputation.
Without the trust in <em>the other</em>, I see great danger on the horizon, especially if things become increasingly difficult.
The challenge lies in persuading individuals who harbor skepticism, particularly toward what climate change deniers label as <em>mainstream science</em>.</p>

<p>According to Maturana, convincing someone can only happen when they develop their own system of conviction. 
This aspect is especially crucial to consider. 
Therefore, engagement must be respectful. 
It’s essential to take the worries, fears, and arguments of deniers seriously, even when they appear unreasonable.
However, it’s important to remember that while we encourage others to develop their convictions, we should also acknowledge our own unique and potentially flawed convictions and remain true to them if we are not convinced otherwise.</p>

<blockquote>
  <p>I think I do it always through stories, never through direct confrontation.
Because if you directly confront somebody who’s thinking polar opposite to you, they don’t really listen.
They are thinking of arguments to refute to. […]
The first thing is to listen to them because maybe they’ve got a point, maybe they’re doing something you never thought about.
But if you still feel that you’re right, then you must have the courage of your conviction. – Jane Goodall</p>
</blockquote>

<p>There may be another reason for the denial of climate change: it provides an opportunity to oppose intellectual elites, who are perceived as hypocritical and arrogant. 
To elaborate, in his book <em>Bullshit Jobs</em> <a class="citation" href="#graeber:2018">(Graeber, 2018)</a>, David Graeber presents a hypothesis explaining why the political right in the US supports the military while criticizing teachers and other social workers. 
This occurs despite both groups—unlike hedge fund managers—doing ‘real’ work that positively impacts society.</p>

<p>Graeber argues that in our system, jobs with a tangible positive societal impact are often undervalued and poorly compensated, partly because these roles already offer the intrinsic reward of doing something meaningful. 
Conversely, <em>bullshit jobs</em>, which achieve little or are outright useless, are often better compensated.
These jobs typically involve managing other managers and offer little in terms of societal contribution. 
Graeber supports his argument with qualitative reports from individuals who themselves believe their jobs serve no meaningful purpose. 
This discrepancy leads to a situation where the pain of feeling useless is offset by a higher salary, while workers in more impactful roles are deprived of fair benefits.</p>

<p>From his perspective, the intellectual elite are not only well-compensated but also engage in work that is perceived as both  interesting and meaningful, akin to being paid for a hobby. 
This perceived privilege, coupled with the tendency of some intellectuals to look down on blue-collar workers, breeds strong resentment against them, including the scientific community. 
Furthermore, for someone growing up in a working-class family, the perceived impossibility of breaking into this elite exacerbates the resentment, possibly even more than the resentment towards billionaires. 
The notion is that, theoretically, anyone could become rich, but entering the intellectual elite seems far less attainable.</p>

<p>Additionally, there is an entire industry centered around climate denial. 
Our society has fostered an army of lobbyists whose primary aim is to actively sabotage progress in addressing climate issues. 
In contrast to these ‘knowledgable’ deniers, scientists are required to rigorously justify every aspect of their research repeatedly and tend to be cautious about offering concrete advice. 
Conversely, climate deniers merely need to sow seeds of doubt; their strategy revolves around raising questions rather than providing evidence-based answers. 
This asymmetry in approach creates a challenging environment for advancing scientific understanding and consensus on climate change.</p>

<h2 id="conclusion">Conclusion</h2>

<p>What I wanted to emphasize is the idea that we are constantly existing within a blurred world of reality and simulation, relying on second-order observation. 
The root cause of descending into the rabbit hole may not be a detachment from reality but rather an <em>attachment to certainty</em>. 
Perhaps Baudrillard is correct in asserting that we are entering a hyperreality that is no longer contradictory and dissolves all illusions, imaginations, and mysteries.
According to him, we cannot ceanse ourselfs from simulation.
What we are trying to do is to purge the world of all mysteries, illusions and imaginations.
But certainty exists only in a pure form of simulation. 
In a constructivist sense, we cannot access the absolute true reality (the thing in itself) because it is always already mediated.
If we cannot accept this fundamental ambiguity of our reality (by which Baudrillard does not mean physical reality but that which is intelligible via signs), we run the risk of constructing the one and only reality, i.e., hegemony.
Since this realm does not allow contradictions, it tends to integrate everything, including disasters, into it.</p>

<p>Contradictions form the very foundation of our environment. 
We perceive the reality of nature when it manifests as a non-human force of destruction, such as a natural disaster or a pandemic. 
What occurs is incomprehensible. 
In hyperreality, nature ceases to be a conflicting force and becomes merely an element within the simulation—a floating sign. 
Destruction transforms into a calculated event.
For example, repeatedly displaying graphs of death tolls gives us the illusion of control.
It can be seen as an attempt to reintegrate death (arguably the greatest contradiction of all) into the simulation.
The negative, along with contradictions, is either integrated or discriminated against.
Wars, natural disasters, and pandemics metamorphose into a spectacle on the television screen, a tourist attraction for our theme park, and are more disastrous than the disaster, more natural than nature—in short, a perfect simulation that surpasses and supplants reality.</p>

<p>In a postmodern society, the absence of any central value system and firm, objective evaluative guides tends to create a demand for substitutes. 
These substitutes are symbolically created rather than being actual or socially produced. 
The need for these symbolic group tokens results in tribal politics and defines self-constructing practices that are collectivized but not socially produced. 
These neo-tribes function solely as imagined communities and, unlike their premodern namesake, exist only in symbolic form through the commitment of individual ‘members’ to the idea of an identity. 
They exist as imagined communities through a multitude of agent acts of self-identification and endure solely because people use them as vehicles of self-definition.</p>

<p>Therefore, I have no intention of passing moral judgment on conspiracy theorists.
One might even argue that they perceive cracks in the simulation but mistakenly believe in a way out of it, which, and this misinterprets <em>The Matrix</em> as well, serves as the perfect cover-up for our reality as always partly simulated.
Baudrillard famously argued that Disneyland does not hide the fact that it is a simulation, but rather conceals the fact that America is a simulation too. 
Disneyland is more real than America.
Conspiracy theories operate similarly; they are pure simulations and, in this regard, true. 
The outsider is convinced of his or her reality, and the contradictory nature of these theories is not contradictory for him or her. 
Instead, (obvious) contradictions are necessary to make the theory hyperreal. 
The suspicion of the theorists is not unreasonable, but their conclusion is fatal—they demand a simple metanarrative and cannot see that this can only be another far more harmful simulation.
We should also not forget that conspiracy theorists often risk a significant amount of social capital, leading to alienation from their relatives and friends. Being a conspiracy theorist is generally not an enjoyable experience</p>

<p>Several factors contribute to the prevalence of conspiracy theories, including information overload, the perception of a reality that is becoming ‘less real’, the sensation of living in a quasi-simulated reality, natural disasters, ongoing conflicts, and the rapid pace of our society. 
Our modern world is so complex that it is virtually impossible for any single individual to comprehensively make sense of all that occurs.
As a result, we heavily rely on the concept of second-order observation, and there is no shame in acknowledging this fact.
Turning to experts and authorities, provided that their authority is derived from genuine competence, is necessary. 
However, it’s crucial to subject these authorities to scrutiny and verification and to be aware that their observation has always a blind spot.</p>

<p>Nothing in what I’ve stated here should be misconstrued as a defense of the political system. 
Lobbyism, which is sometimes indistinguishable from outright corruption, represents a significant issue. 
The consistent failure to fulfill promises, whether they be pledges for a transaction tax, the cessation of subsidies that actively contribute to global warming, or the numerous ‘conferences’ like COP that, at this point, are merely part of a <em>hope economy</em>—offering a false and pacifying sense of hope—that fuels the distrust in institutions.</p>

<p>COP28 proved to be a disaster for the majority of the world’s population. 
There was essentially no consensus on even the most basic measures. 
No accord on phasing out fossil fuels, and not even a genuine commitment to promoting renewable energy. 
The decision to have COP led by one of the world’s largest oil and gas companies is, at this point, satirical if it were not true.
In an assessment by journalist Jonathan Watts in The Guardian, the winners of the conference were identified as the oil and gas industry, the United States, China, COP28 President Sultan Al Jaber, the green energy sector, and lobbyists. Conversely, the losers encompassed the climate, small island nations, climate justice, future generations, other species, and scientists.</p>

<p>Nothing in what I’ve said here should be interpreted as a defense of the media for its issues, nor should it downplay the problem of increasing wealth inequality or any other ecological, social, or economic problems.
Both mass media and the scientific system have their problems, but this doesn’t negate their incredible value.
Moreover, independent media outlets play a crucial role, but we must be under no illusion that the verification of information is becoming increasingly challenging. 
Social media platforms present us with an overwhelming array of viewpoints, claims, and video content. With the ascent of generative artificial intelligence, the task of verifying this deluge of information becomes even more daunting.
The power of the image is indeed huge. 
The blurred line between hyperreality and lower forms of simulations makes it difficult to navigate through the mass of information. In contrast, conspiracy theorists do not bear the burden of a demanding verification process. 
They can simply draw upon fringe and unvalidated stories, presenting them in an entertaining, sensational style akin to news pornography. 
They can use the power of high-order simulacra which are disconnected from the real.</p>

<p>Believing in a conspiracy theory is akin to being the prisoner in Plato’s cave, presuming that everyone else is, in fact, in prison. 
It is the belief in something outside of simulation.
The most effective remedy is to harbor doubts about our own competence, to be skeptical of ourselves, to maintain self-awareness at a metacognitive level, and to be able to live in a contradictory world and recognize those contradictions.
These contradictions live on the borders of hyperreality—in slums, cobalt mines, the streets of New York City, the border of Mexico, the fortress of the European sea, refugee camps, and the ‘ugly’ parts of the world.</p>

<p>Now, I am not sure if I can agree with the cynical viewpoint of Baudrillard. 
His overly dramatic and playful writings are interesting but also contradictory, probably by design.
He would probably be horrified at our attempt to <a href="https://blogs.nvidia.com/blog/earth-2-supercomputer/">simulate the whole earth</a> to predict and control our future. 
But how else can we deal with an open, unpredictable future other than the pursuit of more and more accurate predictions? Esposito asks if this future will still be open <a class="citation" href="#esposito:2024">(Esposito, 2024; Esposito et al., 2023)</a>.</p>

<p>It appears to me that logical reasoning alone is not sufficiently compelling.
Maybe Rorty is right about the importance of empathic stories.
But where are these stories in the mainstream?
Are we already too cynical, too ironic?
We need storytellers and artists to craft more persuasive mythologies, narratives, and stories that resonate on an emotional level.
But I believe this can only be possible if we do not filter out the negative and the ugly part of society.
I want a serious vision which is shamelessly emphatic towards all forms of life.
This anti-Socratic approach, while potentially controversial, could prove more effective in influencing beliefs and behaviors and, in the end, matter more than any rational argument could be.</p>

<p>We have reached an alarming point at which millions of people can no longer discriminate between reality and hyperreality. 
That which cannot be simulated seems to disappear. 
There is a confusion between truth claims grounded in evidence and sound logic and alternative facts inspired by ludicrous, unsubstantiated conspiracy theories due to proliferation.
In the case of the climate crisis, there is no room for alternative truths.
Sooner or later the reality of the crisis will eventually bleed into hyperreality.
Will we be able to give it symbolic meaning, or will it be re-integrated into the simulation?</p>

<p>Even if we construct our own perspective on the world, the physical reality of the climate crisis will not disappear if we stop believing in it.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="barthes:1973">Barthes, R. (1973). <i>Mythologies</i>. Hill &amp; Wang Pub.</span></li>
<li><span id="baudrillard:1983">Baudrillard, J. (1983). <i>Simulacra and Simulation</i>. Semiotext(e).</span></li>
<li><span id="luhmann:2000">Luhmann, N. (2000). Why does society describe itself as postmodern. In W. Rasch &amp; C. Wolfe (Eds.), <i>Observing complexity: Systems theory and postmodernity</i> (pp. 35–49). University of Minnesota.</span></li>
<li><span id="baudrillard:1968">Baudrillard, J. (1968). <i>System of Objects</i>.</span></li>
<li><span id="baudrillard:2008">Baudrillard, J. (2008). <i>The Perfect Crime</i>. Verso.</span></li>
<li><span id="douglas:2017">Douglas, K. M., Sutton, R. M., &amp; Cichocka, A. (2017). The psychology of conspiracy theories. <i>Current Directions in Psychological Science</i>, <i>26</i>(6), 538–542. https://doi.org/10.1177/0963721417718261</span></li>
<li><span id="uscinski:2018">Uscinski, J. E. (2018). The study of conspiracy theories. <i>Argumenta</i>, 233–245. https://doi.org/10.23811/53.arg2017.usc</span></li>
<li><span id="prooijen:2018">Prooijen, J.-W. (2018). <i>The Psychology of Conspiracy Theories</i>. Taylor &amp; Francis Group. https://doi.org/10.4324/9781315525419</span></li>
<li><span id="kay:2011">Kay, J. (2011). <i>Among the Truthers: A Journey Through America’s Growing Conspiracist Underground</i>. Harper.</span></li>
<li><span id="shermer:2022">Shermer, M. (2022). <i>Conspiracy: Why the Rational Believe the Irrational</i>. Johns Hopkins University Press.</span></li>
<li><span id="landau:2015">Landau, M. J., Kay, A. C., &amp; Whitson, J. A. (2015). Compensatory control and the appeal of a structured world. <i>Psychol Bull</i>. https://doi.org/10.1037/a0038703</span></li>
<li><span id="cichocka:2022">Cichocka, A., Marchlewska, M., &amp; Biddlestone, M. (2022). Why do narcissists find conspiracy theories so appealing? <i>Curr Opin Psychol</i>. https://doi.org/10.1016/j.copsyc.2022.101386</span></li>
<li><span id="cosgrove:2023">Cosgrove, T. J., &amp; Murphy, C. P. (2023). Narcissistic susceptibility to conspiracy beliefs exaggerated by education, reduced by cognitive reflection. <i>Front Psychol</i>. https://doi.org/10.3389/fpsyg.2023.1164725</span></li>
<li><span id="hart:2015">Hart, J., &amp; Graether, M. (2015). Something’s going on here: Psychological predictors of belief in conspiracy theories. <i>Journal of Individual Differences</i>.</span></li>
<li><span id="maturana:1987">Maturana, H. R., &amp; Varela, F. J. (1987). <i>The Tree of Knowledge</i>. Shambhala.</span></li>
<li><span id="gabriel:2018">Gabriel, M. (2018). <i>Der Sinn des Denkens</i>. Ullstein Buchverlag.</span></li>
<li><span id="rorty:2016">Rorty, R. (2016). <i>Philosophy as Poetry</i>. University of Virginia Press.</span></li>
<li><span id="sapolsky:2023">Sapolsky, R. M. (2023). <i>Determined</i>. Bodley Head.</span></li>
<li><span id="arrhenius:1896">Arrhenius, S. (1896). XXXI. On the influence of carbonic acid in the air upon the temperature of the ground . <i>The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</i>, <i>41</i>(251), 237–276. https://doi.org/10.1080/14786449608620846</span></li>
<li><span id="manabe:1967">Manabe, S., &amp; Wetherald, R. T. (1967). Thermal equilibrium of the atmosphere with a given distribution of relative humidity. <i>Journal of Atmospheric Sciences</i>, <i>24</i>(3), 241–259. https://doi.org/10.1175/1520-0469(1967)024&lt;0241:TEOTAW&gt;2.0.CO;2</span></li>
<li><span id="keeling:1976">Keeling, C. D., Bacastow, R. B., Bainbridge, A. E., Ekdahl Jr., C. A., Guenther, P. R., Waterman, L. S., &amp; Chin, J. F. S. (1976). Atmospheric carbon dioxide variations at Mauna Loa Observatory, Hawaii. <i>Tellus</i>, <i>28</i>(6), 538–551. https://doi.org/10.1111/j.2153-3490.1976.tb00701.x</span></li>
<li><span id="held:2006">Held, I. M., &amp; Soden, B. J. (2006). Robust responses of the hydrological cycle to global warming. <i>Journal of Climate</i>, <i>19</i>(21), 5686–5699. https://doi.org/10.1175/JCLI3990.1</span></li>
<li><span id="weart:2009">Weart, S. R. (2008). <i>The Discovery of Global Warming</i>. Harvard University Press.</span></li>
<li><span id="myers:2021">Myers, K. F., Doran, P. T., Cook, J., Kotcher, J. E., &amp; Myers, T. A. (2021). Consensus revisited: quantifying scientific agreement on climate change and climate expertise among Earth scientists 10 years later. <i>Environmental Research Letters</i>, <i>16</i>(10), 104030. https://doi.org/10.1088/1748-9326/ac2774</span></li>
<li><span id="lynas:2021">Lynas, M., Houlton, B. Z., &amp; Perry, S. (2021). Greater than 99% consensus on human caused climate change in the peer-reviewed scientific literature. <i>Environmental Research Letters</i>, <i>16</i>(11), 114005. https://doi.org/10.1088/1748-9326/ac2966</span></li>
<li><span id="cook:2016">Cook, J., Oreskes, N., Doran, P. T., Anderegg, W. R. L., Verheggen, B., Maibach, E. W., Carlton, J. S., Lewandowsky, S., Skuce, A. G., Green, S. A., Nuccitelli, D., Jacobs, P., Richardson, M., Winkler, B., Painting, R., &amp; Rice, K. (2016). Consensus on consensus: a synthesis of consensus estimates on human-caused global warming. <i>Environmental Research Letters</i>, <i>11</i>(4), 048002. https://doi.org/10.1088/1748-9326/11/4/048002</span></li>
<li><span id="cook:2013">Cook, J., Nuccitelli, D., Green, S. A., Richardson, M., Winkler, B., Painting, R., Way, R., Jacobs, P., &amp; Skuce, A. (2013). Quantifying the consensus on anthropogenic global warming in the scientific literature. <i>Environmental Research Letters</i>, <i>8</i>(2), 024024. https://doi.org/10.1088/1748-9326/8/2/024024</span></li>
<li><span id="doran:2009">Doran, P. T., &amp; Zimmerman, M. K. (2009). Examining the scientific consensus on climate change. <i>Eos, Transactions American Geophysical Union</i>, <i>90</i>(3), 22–23. https://doi.org/https://doi.org/10.1029/2009EO030002</span></li>
<li><span id="graeber:2018">Graeber, D. (2018). <i>Bullshit Jobs</i>. Simon &amp; Schuster.</span></li>
<li><span id="esposito:2024">Esposito, E. (2024). Can we use the open future? Preparedness and innovation in times of self-generated uncertainty. <i>European Journal of Social Theory</i>, <i>0</i>(0). https://doi.org/10.1177/13684310231224546</span></li>
<li><span id="esposito:2023">Esposito, E., Hofmann, D., &amp; Coloni, C. (2023). Can a predicted future still be an open future? Algorithmic forcasts and actionability in the precision medicine. <i>History and Theory</i>. https://doi.org/10.1111/hith.12327</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Opinion" /><category term="Social Systems Theory" /><category term="Conspiracy Theories" /><summary type="html"><![CDATA[Diverging from my area of expertise is always a risky endeavor, but since this is a blog rather than a scientific journal, I’m giving myself the liberty to explore and have fun with different ideas (even if the topic is depressing). Often writing helps in transforming the mess into a structured and coherent concept. The process of rethinking and reflecting can be invaluable.]]></summary></entry><entry><title type="html">Laws of Form</title><link href="https://bzoennchen.github.io/Pages/2023/11/19/laws-of-form.html" rel="alternate" type="text/html" title="Laws of Form" /><published>2023-11-19T00:00:00+01:00</published><updated>2023-11-19T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2023/11/19/laws-of-form</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/11/19/laws-of-form.html"><![CDATA[<p>In my last blog <a href="/Pages/2023/10/07/system-theory-and-ai.html">post</a>, I discussed Niklas Luhmann’s Social Systems Theory and I emphasized that his theory is based on differentiation and seemingly paradox relations.
My general understanding of Luhmann’s radical constructivism in the most reductive sense is that there are no unified and independent objects—there are only differences.
What an observer can identify as an object is a differentiation of a system and its environment, a foreground and its background, an interior and the external.
However, any observer is itself a distinction between system and environment.
I want to further investigate this idea by looking into Luhmann’s inspiration—his muse so to say.
So let me examine the logic of Georg Spencer-Brown presented in his work <em>Laws of Form</em> <a class="citation" href="#brown:1969">(Spence-Brown, 1969)</a>.</p>

<h2 id="the-principle-of-differentiation">The Principle of Differentiation</h2>

<p>As mentioned, Luhmann’s theory is based on paradoxes such as</p>

<blockquote>
  <p>This statement is wrong.</p>
</blockquote>

<p>The statement is logically problematic because it is self-referential. 
If the statement is false, it states that it is in fact true and if the statement is true, it states that it is false.
Another famous paradox is Russell’s antinomy of the naïve set theory:</p>

\[R := \left\{ x \ | \ x \not\in x \right\}.\]

<p>\(R\) is the set of all sets that do not contain themselves which seems to be a well-defined mathematical object.
However, if we introduce the self-referential relation, we run into a paradox:</p>

<p>\begin{equation} 
R \in R \iff R \not\in R
\end{equation}</p>

<p>This paradox is related to the barber that shaves everyone that does not shave themselves.
If that is the case, does the barber shave themselves?</p>

<p>Another example involves the the proof of the <a href="/Pages/2021/06/08/Informatics-a-love-letter.html">Halting Problem</a>.
To prove it, one can establish a self-referential relation between a machine that presumable solves the Halting Problem.
The machine does not halt if the machine it checks halts, and it halts if the machine it checks does not halt.
Via the self-referential relation, that is, by letting the machine check itself, we get a contradiction.</p>

<p>The idea of Spencer-Brown is to resolve these paradoxes over time.
\(R \in R\) holds at one moment in time and \(R \not\in R\) holds at the next moment.
Note however that he does not resolve Russell’s antinomy <a class="citation" href="#cull:1979">(Cull &amp; Frank, 1979)</a>.
His idea of resolving paradoxes over time is reminiscent of the Hegelian dialectic—a process of self-creation.
The self-referential relation is a paradox if we ignore time and it becomes a generator if we consider time and place.</p>

<p>This led the biologists Huberto R. Maturana and Francisco J. Varela to the concept of <em>autopoiesis</em> <a class="citation" href="#maturana:1987">(Maturana &amp; Varela, 1987)</a>.
Furthermore, the importance of differentiation is inspired by the logic of Spencer-Brown and his work <em>Laws of Form</em> <a class="citation" href="#brown:1969">(Spence-Brown, 1969)</a>.
He resolves the paradox by a similar idea that gave us imaginary numbers, that is, by using what he calls <em>Re-entry</em> which (re-)introduces a system into itself.</p>

<p>Luhmann integrated this idea into his social systems theory.
For example, the media can observe and reintroduce itself into itself. 
It can use its systemic operations on itself, i.e. it can report on itself.</p>

<p>Spencer-Brown begins his work by a quote from Lao-Tse (a stand-in for many different authors) thus begins by philosophical considerations:</p>

<blockquote>
  <p>Wu ming tain di zhi shi. – Loa-Tse</p>
</blockquote>

<p>The sentence has mainly two different meanings.
One is:</p>

<blockquote>
  <p>The beginning of heaven and earth is without a name.</p>
</blockquote>

<p>The other one is:</p>

<blockquote>
  <p>‘Nothing’ is the name of the beginning of heaven and earth.</p>
</blockquote>

<p>A paradox arises: How can Nothing be nothing if we can call it ‘Nothing’?
Furthermore, the quote points to a distinction between heaven and earth.
Can there be heaven without earth—a <em>calling</em> or <em>indication</em> without a <em>distinction</em>?
Spencer-Brown begins by the assumption that there is no such thing:</p>

<blockquote>
  <p>We take the idea of distinction and the idea of indication and that we cannot make an indication without making a distinction as given.
Therefore, we take the form of distinction as the form itself. – Georg Spencer-Brown</p>
</blockquote>

<p>In other words, what we normally identify as object (the form / system) is for Spencer-Brown equal to the distinction (system-environment differentiation).
There is no clear separation between the object or the result of distinction and the process of distinguishing.
Therefore, the process must be integrated into Spencer-Brown’s logic and as we will see, there is no clear separation between objects and operations in Spencer-Browns calculus.
Spencer-Brown thinks that differentiation is a proto-operation that is more fundamental than performing calculations or writing text because to do these activities we have to differentiate beforehand.
I cannot calculate 1 + 1 = 2 without distinguishing between the different symbols and a symbol and ‘nothing’ or the void.</p>

<p>Spencer-Brown uses the mark or cross (result) which at the same time marks (process).
The mark is, calls, and makes a difference.</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/mark.png" alt="The mark." /></div>
<p><br /></p>

<p>There is an interior of the mark and not the interior—the system and its environment.
I can make a distinction again (repetition):</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/calling.png" alt="The calling." /></div>
<p><br /></p>

<p>But making a distinction again does not change the distinction.</p>

<blockquote>
  <p>Calling something back-to-back by its name does not change its name. – Spencer-Brown</p>
</blockquote>

<p>The reverse is also true; therefore, Spencer-Brown introduces the <em>Law of Calling</em>:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/law-of-calling.png" alt="Law of Calling." /></div>
<p><br /></p>

<p>The second transformation called <em>Law of Crossing</em> is less intuitive.
Crossing twice reverses the first crossing.</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/law-of-crossing.png" alt="Law of Crossing." /></div>
<p><br /></p>

<blockquote>
  <p>If a boundary is crossed twice, the original state will be reestablished.
The repetition of the crossing has a different value than the single crossing.
The reason is that in-between the reversal happens.
Crossing changes the side.
Re-crossing reverses this operation. – Spencer-Brown</p>
</blockquote>

<p>With only these two laws, Spencer-Brown established a logic calculus and we can start doing mathematics.
Interestingly, the <em>Law of Crossing</em> and the <em>Law of Calling</em> are implicitly established via the position of the marks.
There is no operator introduced because the result and process, indication and differentiation, the mark and the process of marking are not separated.</p>

<p>Let’s see what we can do with this calculus.
Let \(a, b\) variables, then the following holds:</p>

<p><br /></p>
<div><img style="height:230px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/transformations.png" alt="Transformations." /></div>
<p><br /></p>

<p>Let’s have a look at the last transformation.
Let us assume \(a\) is a <strong>mark</strong>.
Then we get:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/transformation-1.png" alt="First possibility." /></div>
<p><br /></p>

<p>Let \(a\) be <strong>unmarked</strong> instead, then we can follow:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/transformation-2.png" alt="Second possibility." /></div>
<p><br /></p>

<h2 id="the-re-entry">The Re-Entry</h2>

<p>How can we re-introduce the system (here an equation) into itself?
Or in other words: How does the <em>re-entry</em> work?
We can start by a simple self-referential algebraic equation:</p>

<p>\begin{equation}
x^2 = ax + b, \quad a, b \in \mathbb{R}.
\end{equation}</p>

<p>This equation has well-known solutions. 
It is also known that solutions can be imaginary, i.e., \(x\) might be of the for \(r + si\) with \(r, s \in \mathbb{R}$ and $i^2 = -1\).
To see the re-entry, we can rewrite the equation above to get</p>

<p>\begin{equation}
x = a + b/x,
\end{equation}</p>

<p>thus the self-reference is obvious and we solve the equation by the re-entry</p>

<p>\begin{equation}
x = a + b/(a +b/(a+b/(a+b/a+b/(a + \ldots)))).
\end{equation}</p>

<p>Using this infinite formalism it is literally the case that</p>

<p>\begin{equation}
x = a + b/x,
\end{equation}
holds.
Using the same formalism, we can define the imaginary number \(i = -1/i\) as literally</p>

<p>\begin{equation}
i = -1 /(-1 /(-1 / (-1 / \ldots )))
\end{equation}</p>

<p>but what does this mean?
The system is not a number but a process, a generator that generates itself.
\(i\) alternates between 1 and -1.
Interestingly, this is precisely how we use the equal sign in most programming languages.
Writing <code class="language-plaintext highlighter-rouge">i = i / -1</code> in a programming language means</p>

<p>\begin{equation}
i \leftarrow \frac{i}{-1}.
\end{equation}</p>

<p>The next step is to introduce such a re-entry into logic.
Similar to the imaginary number \(i\), Spencer-Brown gives us the following fundamental paradox (<em>The Re-Entry of the Mark</em>):</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/j.png" alt="Imaginary truth value." /></div>
<p><br /></p>

<p>The solution is an alternation between a marked and unmarked state—between true and false.
A state that might seem contradictory in space, makes sense if it is observed in time and space.
Again, time resolves the paradox.
To highlight the re-entry, Spencer-Brown also uses the following notation:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/j-2.png" alt="Notation of the re-entry." /></div>
<p><br /></p>

<p>We could similarily notate \(i\) as</p>

<p><br /></p>
<div><img style="height:35px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/i-2.png" alt="Notation of the re-entry for the imaginary number." /></div>
<p><br /></p>

<p>If we change <strong>all</strong> symbols within a system equally, there is no reason not to calculate with a self-generating process.
For example, we can state the following:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/j-calculations.png" alt="Calculating with the re-entry." /></div>
<p><br /></p>

<p>However, it is forbidden to only change one appearance of \(J\)!
Following this simple rule, no paradox or inconsistency arises.
We can go on and evaluate the following transformation:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/wave.png" alt="Wave equation." /></div>
<p><br /></p>

<p>which describes two alternating waves shifted by one cycle resulting in a mark.</p>

<p>Spencer-Brown goes on and defines his <em>Echelon</em>:</p>

<p><br /></p>
<div><img style="height:35px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/echelon.png" alt="Echelon." /></div>
<p><br /></p>

<p>which can be transformed into</p>

<p><br /></p>
<div><img style="height:40px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/echelon-transformation.png" alt="Echelon transformation." /></div>
<p><br /></p>

<p>thus gives us the re-entry</p>

<p><br /></p>
<div><img style="height:40px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/echelon-equation.png" alt="Echelon equation." /></div>
<p><br /></p>

<p>or</p>

<p><br /></p>
<div><img style="height:43px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/echelon-equation-2.png" alt="Echelon equation." /></div>
<p><br /></p>

<h2 id="final-words">Final Words</h2>

<p>In the act of programming there is no problem of using expressions such as</p>

<p>\begin{equation}
i \leftarrow i + 1 \quad  \text{ or } \quad a  \leftarrow f(a)
\end{equation}</p>

<p>but in mathematics—at least since Plato—we assume some sort of eternity.
Of course, we can translate between the static world of “normal” mathematics and Spencer-Brown’s dynamic viewpoint, but it is a different viewpoint which might influence how we observe our environment.
It is like in physics where multiple theories are equivalent but start from very different viewpoints.
It starts by differentiation which gets reintroduced into the system which is constructed by this very same differentiation.
To generate new numbers, such as irrational or transfinite numbers, Spencer-Brown proposes not to use the limit but the whole infinite process that defines such limit.</p>

<p>Spancer-Brown beliefed that to be able to master the transition to new signs, something is necessary for which the previous signs are not sufficient.
To be able to close this gap; to make this leap successfully; to resolve paradoxes; a specific language of one’s own is necessary. 
According to Spancer-Brown this step is accomplished by <strong>thinking</strong> which provides us with its specific imaginations, playful freedom and contradictions.</p>

<p>It is surprising that Spencer-Brown’s <em>Laws of Form</em> plays no role in computer science even though it fits quite neatly in the perspective of programs, processes and computation.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="brown:1969">Spence-Brown, G. (1969). <i>Laws of Form</i>. London: Allen and Unwin.</span></li>
<li><span id="cull:1979">Cull, P., &amp; Frank, W. (1979). flaws of form. <i>International Journal of General Systems</i>, <i>5</i>(4), 201–211. https://doi.org/10.1080/03081077908547450</span></li>
<li><span id="maturana:1987">Maturana, H. R., &amp; Varela, F. J. (1987). <i>The Tree of Knowledge</i>. Shambhala.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Logic" /><category term="Social Systems Theory" /><summary type="html"><![CDATA[In my last blog post, I discussed Niklas Luhmann’s Social Systems Theory and I emphasized that his theory is based on differentiation and seemingly paradox relations. My general understanding of Luhmann’s radical constructivism in the most reductive sense is that there are no unified and independent objects—there are only differences. What an observer can identify as an object is a differentiation of a system and its environment, a foreground and its background, an interior and the external. However, any observer is itself a distinction between system and environment. I want to further investigate this idea by looking into Luhmann’s inspiration—his muse so to say. So let me examine the logic of Georg Spencer-Brown presented in his work Laws of Form (Spence-Brown, 1969).]]></summary></entry><entry><title type="html">Musical Interrogation III - LSTM</title><link href="https://bzoennchen.github.io/Pages/2023/11/19/musical-interrogation-III.html" rel="alternate" type="text/html" title="Musical Interrogation III - LSTM" /><published>2023-11-19T00:00:00+01:00</published><updated>2023-11-19T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2023/11/19/musical-interrogation-III</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/11/19/musical-interrogation-III.html"><![CDATA[<p>This article is the continuation of a series.
It is recommended that you read part I and II first.
This time we use a recurrent neural network (<strong>RNN</strong>), more preceisly an <strong>LSTM</strong>, which I explained a little bit in the <a href="/Pages/2023/04/02/musical-interrogation-I.html">introduction</a>.
An LSTM is a RNN that counteracts the problem of exploding and vanishing gradients.</p>

<p>This article gives some explanation to the code in the following <a href="https://github.com/BZoennchen/musical-interrogation/blob/main/partIII/melody_rnn.ipynb">notebook</a>, which can be executed on <a href="https://colab.research.google.com/?hl=de">Google Colab</a>.
Because our model is now able to learn long-time relations, we can use the <code class="language-plaintext highlighter-rouge">GridEncoder</code>, i.e., a <em>piano roll data representation</em>, which is exaclty what we do.</p>

<h2 id="recurrent-neural-networks">Recurrent Neural Networks</h2>

<p>Prior to the advent of transformers, many cutting-edge natural language processing (NLP) applications relied on recurrent neural networks (RNNs). 
These networks are particularly adept at processing sequences of data, such as words in NLP tasks or notes and musical events in audio processing.</p>

<p>An RNN processes a sequence</p>

\[\mathbf{x}_0, \ldots, \mathbf{x}_{n-1}\]

<p>of inputs one at a time. 
With each new input, the network not only considers this current input but also incorporates a <em>hidden state</em>—a representation of previous inputs—thanks to its recurrent connections.
This hidden state \(\mathbf{h}_t\) is updated at each step, ensuring that the network retains a memory of what it has processed so far.</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/rnn-unfold.png" alt="Sketch of an RNN unfolded in time" />
<div style="display: table;margin: 0 auto;">Figure 1: Sketch of an RNN unfolded in time.</div>
</div>
<p><br /></p>

<p>The unique feature of RNNs is their ability to maintain an internal state that captures information about the sequence they have processed to that point.
As a result, the final output of the RNN is informed by the entire input sequence.</p>

<p>Furthermore, RNNs have been employed in sequence generation or decoding tasks. 
In such applications, the tokens generated by the RNN are fed back into it as inputs. 
This feedback loop allows the RNN to generate sequences where each new token is influenced by the previously generated tokens, making it suitable for tasks like text generation, music composition, and more.</p>

<h2 id="long-short-term-memory-networks">Long Short-Term Memory Networks</h2>

<p>Long short-term memory networks (LSTMs) are a type of RNN that were designed to overcome some of the limitations of vanilla RNNs, particularly in handling long-term dependencies in sequence data.</p>

<p>Vanilla RNNs struggle with learning long-term dependencies due to the <em>vanishing gradient problem</em>. 
As the length of the input sequence increases, the gradients used in the training process can become extremely small, making it difficult for the RNN to learn and retain information from earlier inputs. 
LSTMs address this issue with their unique architecture, which includes <em>memory cells</em> which uses different <em>gates</em>.</p>

<p>A <em>memory cell</em> can maintain information in memory for long periods of time. 
The key components of an such a cell are its gates: the <em>input gate</em>, <em>output gate</em>, and <em>forget gate</em>.
These gates regulate the flow of information into and out of the cell, and they decide what to retain or discard from the cell state.</p>

<ul>
  <li><strong>Update Gate</strong>: Determines how much of the new information to add to the cell state.</li>
  <li><strong>Forget Gate</strong>: Decides what information is no longer needed and removes it from the cell state, helping to prevent the accumulation of irrelevant information.</li>
  <li><strong>Output Gate</strong>: Controls the extent to which the value in the cell is used to compute the output activation of the block.</li>
</ul>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/lstm-cell.png" alt="LSTM cell" />
<div style="display: table;margin: 0 auto;">Figure 2: A sketch of a memory cell.</div>
</div>
<p><br /></p>

<p>Due to their architecture, LSTMs can learn and remember over longer sequences than vanilla RNNs, making them more effective for tasks like language modeling, text generation, speech recognition, and more, where understanding context over a long sequence is crucial.
The gating mechanism helps mitigate the vanishing gradient problem, allowing for more effective training over longer sequences.
This is because the gates allow gradients to flow through the network without being multiplied repeatedly by small numbers (which is what causes the gradients to vanish in vanilla RNNs).</p>

<h2 id="data-preparation">Data Preparation</h2>

<p>Again we use the data from <a href="http://kern.ccarh.org">EsAC</a>. 
The specific dataset I utilized is <a href="https://kern.humdrum.org/cgi-bin/ksdata?l=/essen/europa&amp;format=recursive">Folksongs from the continent of Europe</a> and for the purpose of this work, I will exclusively use the 1700 pieces found in the <code class="language-plaintext highlighter-rouge">./deutschl/erk</code> directory.</p>

<p>We assume that 1/16 is the shortest note in our dataset.
The <code class="language-plaintext highlighter-rouge">GridEncoder</code> automatically filters out pieces that do not fulfill this condition.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">time_step</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">16</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">GridEncoder</span><span class="p">(</span><span class="n">time_step</span><span class="p">)</span>
<span class="n">enc_songs</span><span class="p">,</span> <span class="n">invalid_song_indices</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">encode_songs</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'there are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">enc_songs</span><span class="p">)</span><span class="si">}</span><span class="s"> valid songs and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">invalid_song_indices</span><span class="p">)</span><span class="si">}</span><span class="s"> songs'</span><span class="p">)</span>
</code></pre></div></div>

<p>Let us look at an example encoded of a piece:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>55 _ _ _ 60 _ _ _ 60 _ _ _ 60 _ _ _ 60 _ _ _ 64 _ _ _ 64 _ _ _ r _ _ _ 62 _ 64 _ 65 ...
</code></pre></div></div>

<p>As we discussed in the last article, <code class="language-plaintext highlighter-rouge">55 _ _ _</code> stands for the midinote <code class="language-plaintext highlighter-rouge">55</code> played for 4 beats where one beat is 1/16 note.
Therefore, this is a 1/4 note.
Likewise, <code class="language-plaintext highlighter-rouge">r _ _ _</code> is a 1/4 rest.</p>

<p>Netx the <code class="language-plaintext highlighter-rouge">StringToIntEncoder</code> converts our alphabet of tokens into positive integers.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">string_to_int</span> <span class="o">=</span> <span class="n">StringToIntEncoder</span><span class="p">(</span><span class="n">enc_songs</span><span class="p">)</span>
</code></pre></div></div>

<p>Next, we use <code class="language-plaintext highlighter-rouge">ScoreDataset</code> to arrange our training data.
It requires our encoded songs, the instance of <code class="language-plaintext highlighter-rouge">StringToIntEncoder</code> and a <em>hyperparameter</em> <code class="language-plaintext highlighter-rouge">sequence_len</code> that configures the length of token sequences our model will be trained on.
The longer the sequence, the longer the training will require because the deeper the recurrent neural network will be.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sequence_len</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># this is a hyperparameter!
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">ScoreDataset</span><span class="p">(</span>
    <span class="n">enc_songs</span><span class="o">=</span><span class="n">enc_songs</span><span class="p">,</span> 
    <span class="n">stoi_encoder</span><span class="o">=</span><span class="n">string_to_int</span><span class="p">,</span> 
    <span class="n">sequence_len</span><span class="o">=</span><span class="n">sequence_len</span><span class="p">)</span>
</code></pre></div></div>

<p>It is now possible to split our data into training, validation and test set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_set</span><span class="p">,</span> <span class="n">val_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
</code></pre></div></div>

<h2 id="model-definition">Model Definition</h2>

<p>Firt we define the rest of our <em>hyperparameters</em>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">string_to_int</span><span class="p">)</span> <span class="c1"># size of our alphabet
</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="c1"># can be different
</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span> <span class="c1"># can be different
</span><span class="n">layer_dim</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># can be different
</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="c1"># should not be different
</span><span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="c1"># can be different
</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1"># can be different
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># can be different
</span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># can be different
</span><span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># can be different
</span></code></pre></div></div>

<p>Before explaining every detail, let us look at the model definition first.
The following is the model description of our RNN/LSTM.
To understand what’s going on, look at the forward method.
This sends our data through the network.</p>

<p>The first two lines create the short-term \(\mathbf{h}_0\) and long-term memory \(\mathbf{c}_0\) and fill them with zeros.</p>

<p>Then an embedding takes place: <code class="language-plaintext highlighter-rouge">x = self.embedding(x)</code>.
This is nothing more than what we did with our simple feedforward net in <a href="/Pages/2023/05/31/musical-interrogation-II.html">Part II - FNN</a>: Each element of the input <code class="language-plaintext highlighter-rouge">x</code> is first one-hot encoded and then multiplied by a matrix. 
The result: Each event is represented by the row of a matrix (with learnable parameters).
The matrix has <code class="language-plaintext highlighter-rouge">vocab_size</code> rows and <code class="language-plaintext highlighter-rouge">input_dim</code> columns.</p>

<p>Next, we send our transformed input through our LSTM out, <code class="language-plaintext highlighter-rouge">(ht, ct) = self.lstm(x, (h0, c0))</code>.
This basically computes \(\mathbf{h}_t, \mathbf{c}_t\) based on \(\mathbf{h}_{t-1}, \mathbf{c}_{t-1}\) as indicated in Fig. 2.
We get as many outputs as our sequence is long, i.e., <code class="language-plaintext highlighter-rouge">sequence_len</code> many.
But we are only interested in the last output, which we get by <code class="language-plaintext highlighter-rouge">out[:, -1, :]</code>.
This is a vector with <code class="language-plaintext highlighter-rouge">hidden_dim elements</code>. 
We don’t need <code class="language-plaintext highlighter-rouge">ht</code> and <code class="language-plaintext highlighter-rouge">ct</code>.</p>

<p>Then we send the last output through a dropout layer to counteract <em>overfitting</em>.</p>

<p>In the last step, we transform the <code class="language-plaintext highlighter-rouge">hidden_dim</code>-dimensional vector into an <code class="language-plaintext highlighter-rouge">output_dim</code>-dimensional vector, which is equal to <code class="language-plaintext highlighter-rouge">vocab_size</code>.
This vector is interpreted as a probability distribution.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LSTMModel</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LSTMModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layer_dim</span> <span class="o">=</span> <span class="n">layer_dim</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">layer_dim</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">layer_dim</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># x = B, T, C
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">out</span><span class="p">,</span> <span class="p">(</span><span class="n">ht</span><span class="p">,</span> <span class="n">ct</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span> <span class="c1"># B, C
</span></code></pre></div></div>

<p>Next, we initialize the model:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">LSTMModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># use gpu if possible
</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()))):</span>
    <span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">())[</span><span class="n">i</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<p>We could play with different hyperparameters.
Increasing <code class="language-plaintext highlighter-rouge">hidden_dim</code> basically increases the complexity of the “memory” of the LSTM.
We surely want to increase <code class="language-plaintext highlighter-rouge">n_epochs</code> to increase number of times the LSTM “sees” all training data.</p>

<p>We can visualize the LSTM by utilizing the <code class="language-plaintext highlighter-rouge">draw_graph</code> function from the <code class="language-plaintext highlighter-rouge">torchview</code> package.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># (batch_size, sequence_len)
</span><span class="n">X_vis</span><span class="p">,</span> <span class="n">y_vis</span> <span class="o">=</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'shape of X_vis: </span><span class="si">{</span><span class="n">X_vis</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'shape of y_vis: </span><span class="si">{</span><span class="n">y_vis</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'number of different symbols </span><span class="si">{</span><span class="n">vocab_size</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">X_vis</span><span class="p">,</span> <span class="n">y_vis</span> <span class="o">=</span> <span class="n">X_vis</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_vis</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">model_vis</span> <span class="o">=</span> <span class="n">LSTMModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">model_graph</span> <span class="o">=</span> <span class="n">draw_graph</span><span class="p">(</span><span class="n">model_vis</span><span class="p">,</span> <span class="n">input_data</span><span class="o">=</span><span class="n">X_vis</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">model_graph</span><span class="p">.</span><span class="n">visual_graph</span>
</code></pre></div></div>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:40%;" src="/Pages/assets/images/lstm-model.png" alt="LSTM model" />
<div style="display: table;margin: 0 auto;">Figure 4: The architecture of our LSTM model using a batch size of 64 and a sequence length also equal to 64. The alphabet consists of 38 unique tokens. Each single input is hot-encoded into a vector with 38 components. The LSTM uses a hidden state with 128 components. After the dropout the 128 components of hidden state are reduced to 38 components utilizing a normal linear layer (without an activation function).</div>
</div>
<p><br /></p>

<p>Note that the softmax is part of our loss <code class="language-plaintext highlighter-rouge">criterion</code> i.e. the cross entropy loss <code class="language-plaintext highlighter-rouge">torch.nn.CrossEntropyLoss()</code> which is part of the backpropagation, i.e., the training process.</p>

<h2 id="melody-generation-before-training">Melody Generation (Before Training)</h2>

<p>Given a sequence of arbitrary length, the <code class="language-plaintext highlighter-rouge">generate</code> function is used to generate a new piece of music.
<code class="language-plaintext highlighter-rouge">temperature</code> determines how much the probability distribution learned by the model is considered.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">temperature</code> equal to 1.0 means that sampling is done from the probability distribution.</li>
  <li><code class="language-plaintext highlighter-rouge">temperature</code> approaching infinity means that sampling is done uniformly (more variation).</li>
  <li><code class="language-plaintext highlighter-rouge">temperature</code> approaching 0 means that higher probabilities are emphasized (less variation).</li>
</ul>

<p>We can set a maximum length for the piece and also provide the beginning of a piece.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">next_event_number</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">temperature</span><span class="p">:</span><span class="nb">float</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span> <span class="o">/</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># B, C
</span>        <span class="n">idx_next</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">idx_next</span>

<span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="n">seq</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">max_len</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">temperature</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">generated_encoded_song</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">seq</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="p">[[</span><span class="n">string_to_int</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">char</span><span class="p">)</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">]],</span> 
                <span class="n">device</span><span class="o">=</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">generated_encoded_song</span> <span class="o">=</span> <span class="n">seq</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">string_to_int</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">TERM_SYMBOL</span><span class="p">)]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        
        <span class="k">while</span> <span class="n">max_len</span> <span class="o">==</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">max_len</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">generated_encoded_song</span><span class="p">):</span>
            <span class="n">idx_next</span> <span class="o">=</span> <span class="n">next_event_number</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">temperature</span><span class="p">)</span>
            <span class="n">char</span> <span class="o">=</span> <span class="n">string_to_int</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">idx_next</span><span class="p">.</span><span class="n">item</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">idx_next</span> <span class="o">==</span> <span class="n">string_to_int</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">TERM_SYMBOL</span><span class="p">):</span>
                <span class="k">break</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">idx_next</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># B, T+1, C
</span>            <span class="n">generated_encoded_song</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="n">generated_encoded_song</span>
</code></pre></div></div>

<p>Of course, the results are almost random because the parameters of our model are initialized randomly and we did not train it yet.
The following code snippet generates 5 scores.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># number of songs we want to generate
</span><span class="n">n_scores</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.6</span>
<span class="n">before_new_songs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scores</span><span class="p">):</span>
    <span class="n">encoded_song</span> <span class="o">=</span> <span class="n">generate</span><span class="p">(</span><span class="n">max_len</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span><span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'generated </span><span class="si">{</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span><span class="si">}</span><span class="s"> conisting of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span><span class="si">}</span><span class="s"> notes'</span><span class="p">)</span>
    <span class="n">before_new_songs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s listen to the first one:</p>

<audio controls="">
  <source src="/Pages/assets/audio/before_g_song.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<h2 id="training">Training</h2>

<p>For training, we use something called a <code class="language-plaintext highlighter-rouge">DataLoader</code>. 
This helps us to access our data more easily. 
For example, we shuffle our data before training.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>The code for training seems a bit complicated because we use batches. 
This is due to dealing with a large amount of data, and we don’t send all of it through the network at once (per training step), but only a part of it, namely <code class="language-plaintext highlighter-rouge">batch_size</code> many. 
An <code class="language-plaintext highlighter-rouge">epoch</code> is defined by the fact that all training data have been sent through the network once.</p>

<p>In essence, nothing else happens but:</p>

<ol>
  <li>Send Batch through the network (Forward pass)</li>
  <li>Calculate error/cost</li>
  <li>Propagate gradients of the cost function with respect to the model parameters backwards through the network (Backward pass)</li>
  <li>Update model parameters</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_one_epoch</span><span class="p">(</span><span class="n">epoch_index</span><span class="p">,</span> <span class="n">tb_writer</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">):</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">last_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">all_steps</span> <span class="o">=</span> <span class="n">n_epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">local_X</span><span class="p">,</span> <span class="n">local_y</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">local_X</span><span class="p">,</span> <span class="n">local_y</span> <span class="o">=</span> <span class="n">local_X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">local_y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">local_X</span><span class="p">)</span>
        
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">local_y</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="n">eval_interval</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">last_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="n">eval_interval</span>
            
            <span class="n">steps</span> <span class="o">=</span> <span class="n">epoch_index</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="n">ep_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Epoch [</span><span class="si">{</span><span class="n">epoch_index</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">n_epochs</span><span class="si">}</span><span class="s">]'</span>
            <span class="n">step_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Step [</span><span class="si">{</span><span class="n">steps</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">all_steps</span><span class="si">}</span><span class="s">]'</span>
            <span class="n">loss_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Loss: </span><span class="si">{</span><span class="n">last_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">'</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">ep_str</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">step_str</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">loss_str</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>

            <span class="n">tb_x</span> <span class="o">=</span> <span class="n">epoch_index</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">tb_writer</span><span class="p">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s">'Loss/train'</span><span class="p">,</span> <span class="n">last_loss</span><span class="p">,</span> <span class="n">tb_x</span><span class="p">)</span>
            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.</span>
            
    <span class="k">return</span> <span class="n">last_loss</span>

<span class="c1"># Initializing in a separate cell so we can easily add more epochs to the same run
</span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">,</span><span class="n">respect_val</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">timestamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">().</span><span class="n">strftime</span><span class="p">(</span><span class="s">'%Y%m%d_%H%M%S'</span><span class="p">)</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="s">'runs/fashion_trainer_{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">timestamp</span><span class="p">))</span>
    <span class="n">best_vloss</span> <span class="o">=</span> <span class="mi">1_000_000</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>    
        <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">train_one_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">)</span>
        
        <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">running_vloss</span> <span class="o">=</span> <span class="mf">0.0</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">vdata</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">):</span>
            
            <span class="n">local_X</span><span class="p">,</span> <span class="n">local_y</span> <span class="o">=</span> <span class="n">vdata</span>
            <span class="n">local_X</span><span class="p">,</span> <span class="n">local_y</span> <span class="o">=</span> <span class="n">local_X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">local_y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            
            <span class="n">voutputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">local_X</span><span class="p">)</span>
            <span class="n">vloss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">voutputs</span><span class="p">,</span> <span class="n">local_y</span><span class="p">)</span>
            <span class="n">running_vloss</span> <span class="o">+=</span> <span class="n">vloss</span>
            
        <span class="n">avg_vloss</span> <span class="o">=</span> <span class="n">running_vloss</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">ep_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">n_epochs</span><span class="si">}</span><span class="s">]'</span>
        <span class="n">tloss_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Train-Loss: </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">'</span>
        <span class="n">vloss_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Val-Loss: </span><span class="si">{</span><span class="n">avg_vloss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">'</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">ep_str</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">tloss_str</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">vloss_str</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        
        <span class="n">writer</span><span class="p">.</span><span class="n">add_scalars</span><span class="p">(</span>
            <span class="s">'Training vs. Validation Loss'</span><span class="p">,</span> 
            <span class="p">{</span><span class="s">'Training'</span><span class="p">:</span> <span class="n">avg_loss</span><span class="p">,</span> <span class="s">'Validation'</span><span class="p">:</span> <span class="n">avg_vloss</span><span class="p">},</span> 
            <span class="n">epoch</span>
        <span class="p">)</span>

        <span class="n">writer</span><span class="p">.</span><span class="n">flush</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">respect_val</span> <span class="ow">or</span> <span class="p">(</span><span class="n">respect_val</span> <span class="ow">and</span> <span class="n">avg_vloss</span> <span class="o">&lt;</span> <span class="n">best_vloss</span><span class="p">):</span>
            <span class="n">best_vloss</span> <span class="o">=</span> <span class="n">avg_vloss</span>
            <span class="n">model_path</span> <span class="o">=</span> <span class="s">'./models/_model_{}_{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">timestamp</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">model_path</span><span class="p">)</span>
</code></pre></div></div>

<p>Calling <code class="language-plaintext highlighter-rouge">train</code> starts the training.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
</code></pre></div></div>

<p>The best model from the training can be found in the folder <code class="language-plaintext highlighter-rouge">./models</code> and can be loaded as follows</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_path</span> <span class="o">=</span> <span class="s">'./models/pretrained_1_128_best_val'</span>

<span class="k">if</span> <span class="n">device</span><span class="p">.</span><span class="nb">type</span> <span class="o">==</span> <span class="s">'cpu'</span><span class="p">:</span>
    <span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">)))</span>
<span class="k">elif</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">mps</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'mps'</span><span class="p">)))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="melody-generation-after-training">Melody Generation (After Training)</h2>

<p>After training or after we load our pretrained model, we generate new pieces:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_scores</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.6</span>
<span class="n">after_new_songs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scores</span><span class="p">):</span>
    <span class="n">encoded_song</span> <span class="o">=</span> <span class="n">generate</span><span class="p">(</span><span class="n">max_len</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span><span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'generated </span><span class="si">{</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span><span class="si">}</span><span class="s"> conisting of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span><span class="si">}</span><span class="s"> notes'</span><span class="p">)</span>
    <span class="n">after_new_songs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span>

<span class="n">after_generated_scores</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">decode_songs</span><span class="p">(</span><span class="n">after_new_songs</span><span class="p">)</span>
<span class="n">Audio</span><span class="p">(</span><span class="n">score_to_wav</span><span class="p">(</span><span class="n">after_generated_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">'a_g_song.wav'</span><span class="p">))</span>
</code></pre></div></div>

<p>We start to hear repetition and some structure within the piece:</p>

<audio controls="">
  <source src="/Pages/assets/audio/a_g_song.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<h2 id="real-world-example">Real World Example</h2>

<p>In the realm of musical innovation, a significant advancement occurred with the development of a sophisticated <strong>LSTM</strong> model designed to create expressive piano roll music. 
This model was introduced in a notable study by <a class="citation" href="#oore:2018">(Oore et al., 2018)</a>. 
The researchers devised a unique discrete-event based representation for piano rolls, encompassing a diverse range of 413 different events. 
The architecture of their model was meticulously structured, comprising three hidden LSTM layers, each equipped with 512 cells. 
This design choice facilitated the processing of a 413-dimensional one-hot vector as input, with the model subsequently generating a categorical distribution over the same dimensional space.</p>

<p>The training process of the model was finely tuned, employing a mini-batch size of 64 and a learning rate of 0.001, alongside the implementation of teacher forcing techniques. 
For those interested in experiencing the model’s capabilities firsthand, a collection of generated music pieces is available for listening at this <a href="https://clyp.it/user/3mdslat4">link</a>. 
However, it’s important to note a primary limitation of this model: its tendency to produce relatively brief musical compositions, typically ranging from 10 to 20 seconds in duration. 
The authors also emphasized the critical role of high-quality data in achieving optimal results with this model.</p>

<p>Following this development, the field witnessed the emergence of the Music Transformer, introduced by <a class="citation" href="#huang:2018">(Huang et al., 2018)</a>.
This model also utilized a similar piano roll representation but marked a significant leap forward by employing the <strong>transformer</strong> architecture. 
This innovative approach enabled the Music Transformer to learn and reproduce longer sequences, demonstrating the capability to capture more extended musical dependencies. 
The transformer architecture and its implications in music generation will be further explored in the next installment of this series.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="oore:2018">Oore, S., Simon, I., Dieleman, S., Eck, D., &amp; Simonyan, K. (2018). <i>This time with feeling: Learning expressive musical performance</i>.</span></li>
<li><span id="huang:2018">Huang, C.-Z. A., Vaswani, A., Uszkoreit, J., Shazeer, N., Hawthorne, C., Dai, A. M., Hoffman, M. D., &amp; Eck, D. (2018). Music Transformer: Generating music with long-term structure. <i>ArXiv Preprint ArXiv:1809.04281</i>.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Music" /><category term="ML" /><category term="LSTM" /><summary type="html"><![CDATA[This article is the continuation of a series. It is recommended that you read part I and II first. This time we use a recurrent neural network (RNN), more preceisly an LSTM, which I explained a little bit in the introduction. An LSTM is a RNN that counteracts the problem of exploding and vanishing gradients.]]></summary></entry><entry><title type="html">Why Machines (Probably) Do Not Think</title><link href="https://bzoennchen.github.io/Pages/2023/10/07/system-theory-and-ai.html" rel="alternate" type="text/html" title="Why Machines (Probably) Do Not Think" /><published>2023-10-07T00:00:00+02:00</published><updated>2023-10-07T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/10/07/system-theory-and-ai</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/10/07/system-theory-and-ai.html"><![CDATA[<p>Generative AI, especially ChatGPT, brought artificial intelligence into the public sphere and sparked a lot of highly speculative claims about <em>machine intelligence</em>.
I’m open for discussions and unafraid of confronting uncomfortable truths. 
Indeed, our imagination and fearless thinking should pave the way for new possibilities. 
Dreams and speculations are valuable, as long as they’re presented as such. 
However, I find it concerning when public figures speak with undue certainty, particularly when making anthropological comparisons between humans and machines.</p>

<h2 id="the-fall-from-human-greatness">The Fall from Human Greatness</h2>

<p>What really hit me was watching Doug Hofstadter expressing his despair about the <em>eclipse of humanity</em>.
As a student, I had been influenced by his renowned book <em>Gödel, Escher, Bach: an Eternal Golden Braid</em>, often referred to as <em>GEB</em> <a class="citation" href="#hofstadter:1979">(Hofstadter, 1979)</a>.
The book delves into how cognition emerges from underlying neurological processes.
Let’s examine Hofstadter’s comments on the state of AI which I gathered from an interview:</p>

<blockquote>
  <p>I never imagined that computer systems would rival or even surpass human intelligence.
It seemed like a goal so far away.
My entire belief system was shaken; it’s a truly traumatic experience when some of your most fundamental beliefs about the world start to collapse.
Particularly, the idea that human beings are soon going to be eclipsed. 
It felt as if not only my belief system was collapsing, but also as if the entire human race was about to be eclipsed and left in the dust soon. 
The accelerating progress has been so unexpected, it stirs a certain kind of terror of an impending tsunami that’s going to catch all of humanity off guard.
It’s unclear whether this signifies the end of humanity, in the sense that the systems we created could destroy us, but it’s certainly conceivable. 
If not, it relegates humanity to a relatively minor phenomenon compared to something else that is far more intelligent and will eventually become as incomprehensible to us as we are to cockroaches.
I find that terrifying. 
I hate it! I think about it almost every single day.
And it overwhelms and depresses me in ways I haven’t experienced in a very long time. […]
It makes me feel diminished; it makes me feel, in some sense, like a very imperfect, flawed structure. 
Compared with these computational systems which have a million or billion times more knowledge than I have, and are a billion times faster, it makes me feel extremely inferior.
It almost feels like we deserve to be eclipsed. 
Unbeknownst to us, all we humans are soon going to be eclipsed and rightly so, because we are so imperfect and fallible. – Doug Hofstadter</p>
</blockquote>

<p>He passionately conveys a sentiment many intuitively feel: The essence of humanism is under siege.
We are fallen from greatness.
Our unique skills are being surpassed, leading to concerns about our relevance.</p>

<p>I perceive Hofstadter’s view as human-centric, stemming from a longstanding tradition where humans are seen as central figures, akin to being God’s creation.
This view encompasses our confidence in determining our fate; the idea of an individual separate from its environment; humans domination over objects; a hierarchy with humans at the pinnacle; the notions of free will, and rational, independent beings arriving at a consensus in public discourse.
Paradoxically, I will try to attack this human-centric view to save myself from his despair.</p>

<p>One could argue that machines are not intelligent since they are just doing statistics by computing some high-dimensional probability distribution <a class="citation" href="#bender:2021">(Bender et al., 2021)</a> and that there is a difference between language processing and language understanding <a class="citation" href="#bender:2020">(Bender &amp; Koller, 2020)</a>. 
However, these arguments seem not convincing for many people.
There always looms a counter argument: Maybe humans do the same?</p>

<p>Instead of going down the technical rabbit hole, I will try to approach Hofstadter’s comments from a distinct and somewhat radical angle by using my <em>observation</em> of Luhmann’s <em>social system theory</em> which builds on <em>radical constructivism</em>.
Along the way, I will not only discuss <em>machine intelligence</em> but also touch on the relation between machines, society and human beings.</p>

<p>I’m not asserting this as the absolute truth but rather as an interesting <em>story</em> that might be useful in some aspects.
In fact, when I started reading Luhmann, I hated it!
It made so much sense but also felt cruel, cold and depressing.
However, like reading Nietzsche’s <em>On the Genealogy of Morality</em>, it has the potential to destroy some deep seeded belief only to bring something new and exciting into existence.
While this theory is nothing more than a theory, it does challenge the confidence behind many claims, including those regarding <em>machine intelligence</em>.</p>

<h2 id="niklas-luhmann">Niklas Luhmann</h2>

<p>Niklas Luhmann (1927-1998) was a largely self-taught sociologist. 
Like postmodern thinkers, he believed that pursuing metaphysics was no longer productive, as there are no ultimate grand narratives that can explain everything. 
Rather than delve into metaphysics, he meticulously developed a comprehensive theory of modern society—–a supertheory that even encompassed itself and its creator.</p>

<p>Luhmann was an avid reader and writer, and he wasn’t hesitant to incorporate valuable concepts from fields like mathematics (Spencer-Brown’s), cybernetics (Wiener and others), and biology (Maturana and Varela).
To encapsulate everything, he employed a high level abstraction and a technical terminology, which can make his writings appear dry, cold and dense. 
Because his work is primarily descriptive—–explaining things as they are and exploring potential reasons for their status—some categorize him as conservative. 
However, I perceive him as an incredibly well-read, sensitive, and discerning observer who wanted a new theory that can help us to transit into a new form of stability, which is a rather progressive attitude.</p>

<p>Even though Luhmann tried to keep a large distance to philosophy, he was well read in it and certainly influenced by it.
In his introductory book <em>From Souls to Systems</em>, Hans-Georg Moeller <a class="citation" href="#moeller:2006">(Moeller, 2006)</a> highlights that Luhmann’s work is influenced by several philosophical giants:</p>

<ul>
  <li><strong>Kant</strong>: Luhmann shifts Kant’s focus on cognition to a constructivist perspective <a class="citation" href="#luhmann:1988">(Luhmann, 1988)</a>.</li>
  <li><strong>Hegel</strong>: Luhmann transitions from Hegel’s ideas of unity and dialectic to concepts of multiplicity and from identity to difference. He argues against any essential unity of systems and any general type of cognition, such as Hegel’s spirit.</li>
  <li><strong>Marx</strong>: Luhmann borrows Marx’s view that society isn’t just a byproduct of spirituality, but he disagrees with the idea of one foundational system. Marx focus on economy is too much of a simplification.</li>
  <li><strong>Husserl</strong>: Luhmann adapts Husserl’s work towards constructivism and incorporates many of his terms and ideas.</li>
  <li><strong>Habermas</strong>: Luhmann disputes Habermas’s mission of completing the enlightenment.</li>
  <li><strong>Postmodern thinkers</strong>: Luhmann draws from Deleuze’s radical differentiation, Derrida’s deconstruction, and Lyotard’s rejection of overarching narratives.</li>
</ul>

<p>With respect to his media theory, Luhmann is quite close to the French philosopher Baudrillard but far less dramatic.
While Baudrillard tends to express himself in dramatic metaphors and focuses solely on the media, Luhmann presents a supertheory of society where the mass media is only one of many systems, all administered by their respective codes.
While Baudrillard’s texts are almost poetic, reading Luhmann can cause boredom.</p>

<p>Luhmann believed that the distinction between <em>modernity</em> and <em>postmodernity</em> is largely semantic.
He argued that the last significant structural shift in society occurred in Europe between the sixteenth and eighteenth centuries, transitioning from stratified to functional differentiation. 
To Luhmann, labeling a functionally differentiated society as either ‘modern’ or ‘postmodern’ is inconsequential.</p>

<p>Although his theory can be unsettling, Luhmann was optimistic about the future.
He agreed side-by-side with the postmodern assertion that traditional philosophy had reached its end.
However, he saw this as an opportunity for a rejuvenated, coherent self-description of society and a fresh theoretical framework for a new societal era:</p>

<blockquote>
  <p>Is this, after all, a postmodern theory?
Maybe, but then the adherents of postmodern conceptions will finally know what they are talking about.
The deconstruction of our metaphysical tradition pursued by Nietzsche, Heidegger, and Derrida can be seen as a part of a much larger movement that looses the binding force of tradition and <strong>replaces unity with difference</strong>.
The deconstruction of the ontological presupposition of metaphysics uproots our historical semantics in a most radical way.
This seems to correspond to what I have called the catastrophe of modernity, the transition of one form of stability to another. – <a class="citation" href="#luhmann:1993">(Luhmann, 1993; Luhmann, 2000)</a></p>
</blockquote>

<h2 id="social-systems-theory">Social Systems Theory</h2>

<p>So let me try to give you my incomplete and surface level understanding of his theory:</p>

<p>Luhmann recognised the particular complexity that human beings present for social analysis because they are the bearers of three <em>autopoietic systems</em>: systems of life (cells, brains, organisms), systems of consciousness (mind), and systems of communication (social systems).
As a sociologist he acknowledges but leaves aside the biological systems of human beings and instead focuses on the interactive relationship between their consciousness or psychic system and the social systems with which they interact.
All psychic systems (minds) are in the environment of social systems and vice versa.</p>

<p>He famously argued that communication between psychic systems happens not between (whole) persons or individuals.
This seems counterintuitive but if we spent a little more thought into his claim and clarify some termonology, it makes sense.
Hans-Georg Moeller put it the following way:</p>

<blockquote>
  <p>You cannot communicate with me with your mind or brain, you will have to perform another communicative operation such as writing or speaking. – <a class="citation" href="#moeller:2006">(Moeller, 2006)</a></p>
</blockquote>

<p>Luhmann described the mind (the psychic system) as well as social systems as <em>operational closed, structurally coupled, autopoetic systems</em>.
That are a bunch of important terms right away which require some explanation.</p>

<p>In Luhmann’s view, a system is defined by its differentiation with its environment—<strong>differentiation</strong> plays one of the most important roles in his work.
This differentiation is esablished and obtained through the operations of the system.
The system differentiates itself from its environment thus it defines itself.
In other words, the system creates its own functions by its operations (self-creation and self-preservation).
Thinking leads to more thinking and perception leads to more perception.
The economy creates itself by doing economics, the mass media creates itself by its operation of differentiating between information and non-information.</p>

<p>Another <em>theme</em> in Luhmann’s writing is the use of paradoxes which is certainly inspired by Spencer-Brown’s logic presented in <em>Law of Forms</em> <a class="citation" href="#brown:1969">(Spence-Brown, 1969)</a>.
Inspired by imaginary numbers, Spencer-Brown introduced imaginare truth values which are paradoxically in space but the paradox is resolved in time.
Therefore, a paradoxical systems becomes genererative in time.
One prime example is our mind which is capable of self-observation (<em>reentry</em>).
Paradoxically, the oberservation is part of what is observed.
However, in time this gets resolved.
While I am observing myself (second-order observation) I cannot observe my environment (first-order observation).
I can switch to the first-order observation but then I lose track of my oberservation of myself.
In a sense, this back and forth observation and self-observation—this paradox—generates myself.</p>

<p>A psychic or social system is <em>operational closed</em> because its operations can not leave the system.
Mental operations such as thoughts and emotions cannot leave the mind.
An economic transaction, e.g. paying for goods, cannot ‘leave’ the economy.
No mind can interfere with the operations of another mind.
One cannot continue someone else’s mental activities by thinking or feeling for him or her.
It is also impossible to immediatly think what someone else is thinking.</p>

<p>However, systems can observe their environment and act on their terms.
We can hear what others say, see what they express and read what they have written.
Our mind can think about it (using its operations) and we can answer, i.e. communication happens.
We can also see pain or joy on other’s faces, but we cannot literally think or feel what they do.
The economy observes politics, the media, science and gets irritated.
How it will adapt is up to itself and its operations.</p>

<p>Other than <em>allopoietic systems</em>, which produce something other than the system itself, <em>autopoietic systems</em> reproduce themselves.
They are more dynamic than allopoietic systems because they deal with an excess of complicating noise from their environment (too much information that cannot be processed) by changing their structure (increasing internal complexity) to allow in more communications: they have a built-in learning capacity.
In contrast, allopoietic systems theory leads the observer to seek constancy and stability in system functioning because they are intrinsically conservative.</p>

<p>Social systems, like the media, become so efficient because they ‘feed’ the outside into their ‘body’.
A crisis, like a natural disaster or a war, feed the autopoiesis of the media.
It can report on the event and discuss different opinions on the matter.
Strictly speaking, the ‘goal’ of the media is not really to inform or to persuade but to continue its own self-production.</p>

<blockquote>
  <p>It is impossible to understand the reality of the mass media if you assume it is their job to provide correct information on the world and then assess how they fail, distort reality, and manipulate opinion—as if they could do otherwise. – Niklas Luhmann</p>
</blockquote>

<p>Therefore, attention is key.
Informing people or persuading might help to ‘get enough food’ but it is not the media’s ‘goal’ or ‘will’.
The same goes for the economy which trys to commodify everything to further commodify things.
Politics politicizes anything and sciences produces papers with ‘facts’ to get more funding for more papers with ‘facts’.</p>

<p>Even though Luhmann’s termology is close to the termonology of computer science, we have to be careful.
It is more helpful to think of these systems as interdependent organisms feeding on each other and equipped with the will to live than to think of hierarchical or well-structured computer or network systems.</p>

<p>Aside from being <em>autopoetic</em>, social and psychic systems are also <em>symbiotic</em>, that is, their <em>co-evolution</em> is <em>interdependent</em>.
Just as the trees in the forest need water and animals to survive, politics needs money from the economy, attention from the media, and ‘facts’ from science.
Media needs politics or science to produce news, and money to operate.
The economy uses media, politics, and science to make profits.
Science ‘sells’ truth to the economy, politics, and the media.
Academia needs money, attention and power.</p>

<p>Luhmann insists in putting human beings in the environment of social systems and not inside them.
In other words, social systems do not consist of humans but of communication!
This is sometimes seen as an anti-humanistic tendency which is framed negatively.
But one might argue that human beings are better off if their processes are not determined by society.</p>

<p>Luhmann’s theory provokes an <em>amoral</em> view on the state of affairs but it also gives power to the object (systems/processes) thus attacks the domination of objects by subjects.
There are no evil people doing or planing insidious things, instead systems (objects) act on behalf their <em>systemic rational</em> by making sense of their environment on their terms.
What we often identify as hypocratical in a person’s action is a mixture of the operations of <strong>different</strong> systems or the communication between systems.
As a reminder, the person is not part of the system.
Individuals, or better psychic systems, are a necessary condition that social systems can exist (like air has to exist to hear sound) but they belong to the environment of the social system (they do not produce the sound).
If a politician acts immoral and accepts a lot of money for his party to give a certain company an advantage over its competitors, the politician is the mere medium through which the economy communicates with politics.
If a politician of the Green Party goes on vacation by plane and, at the same time, speaks out against air traffic, two different systems are operating: the family and politics.
And the operation of the first does not interfere with the operations of the second.
However, the media make news out of this contradicting behaviour which will irritate politics and probably the family life of the politician.
What the media observes as ‘corruption’ happens if system boundaries are crossed.
It is ok to buy talented football players, but it is not ok to buy goals, i.e. it is not ok that the economy directly operates within the system of a football game.</p>

<p>Psychic and social systems are <em>operationally closed</em> but <em>cognitively open</em>.
They have clear boundaries demacrating them from other systems.
They reproduce themselves by adapting and learning how to cope with external noise by only selecting communication which the system can actively and creatively interpret and <em>understand</em> or make sense of.
Psychic and social systems reduce complexity of their environment through recourse to meaning.
These systems increase inner complexity to deal with the complexity in their environment.</p>

<p>The boundaries of these systems are not defined physically, but by the border of what is meaningful and what is not.
Consequently, each system has its own <em>systemic rationality</em> and view of the world—there is always a blind spot.
If I give a cashier money it is assumed that I paid for something.
This follows from the systemic rationality of the economic system.
It deals with money but it cannot, for example, deal with love or passion which are part of the <em>systemic rationality</em> of relationships.
The cashier does not suspect me that I show him my love with this gesture and if I do, this act is not an operation of the economic system.</p>

<p>The <em>functional differentiation</em> of each system makes it so that only parts of a person is acknowledged by the system.
There is no indivudual—indivisible being—in a system.
The health system understands a person as a patient.
The legal system understands a person as a potential criminal, victim or witness.
In that sense, Marx’s <em>alienation</em> is not limited to the economy.
This differentiation makes systems extremly efficient <strong>with respect to their function</strong>.
But what is ‘good’ for one system is not necessarily ‘good’ for the other system.</p>

<p>Luhmann thinks that this differentiation (Ausdifferenzierung) is a feature of modern society, i.e. it is historical and is an ongoing process.
One example might be the creation of new subjects to study.
Instead of studying computer science, students can enroll in scientific computing, data science, game engineering, information engineering, and more.
One can say computer science is further differentiated.
At the same time, we acknowledge problems stemming from this differentiation and try to find ways to look at problems and society more holistically.
Marignal note: If we follow Luhmann’s theory and we want efficiency (with respect to a systemic rational) we find a strong argument to avoid introducing an interdisciplinary subject such as bioinformatics by simply combining biology with informatics.</p>

<p>The functional differentiation of systems, its effects and our gut reaction to it is nicely depicted in the movie <em>Don’t Loop Up</em>.
What the movie does well is showing us that society consists of functional differientiated systems that follow their own <em>systemic rational</em>.
The main message of the movie is that scientists, who discover a meteor, are unable to communicate this truth to the world.
The movie shows mostly four social systems: politics, media, economy, and science.
It shows how each of these systems functions differently while still being <em>structurally coupled</em> with one another via a <strong>shared medium</strong> (language), as explained above.
But inspite of being coupled, or because of it, they cannot act unitedly.</p>

<p>The effectiveness of functional differentiation to deal with complexity comes at a cost: <em>anarchy</em>, that is, there is no controlling system or governing system—no single rationality that is in charge.
From a reductionist standpoint, the actors of the movie seem completely irrational.
By seeing modern society through the eyes of controllable cause and effect chains one can only come to the conclusion that our society is dysfunctional or worse: immoral.
In the movie, only the scientist, who also represent the perspective of the audience, seem to do the right thing.
But from a systemic view the actions of all actors make sense.</p>

<p>In the end, the narrative of the movie is however a contradiction to the systemic view.
The movie suggest that there is some sort of scientific technological solution that can be used if everyone is thinking and acting properly—if only the government takes proper control, and the media informs everyone correctly then the meteor can simple be nuked.
The movie suggest that there can be some sort of rational self-control if only we would be <em>enlightened</em> enough.
In a sense, it is not much better than the movie <em>Idiocracy</em>.
The dream is that enlightened science can control nature through rational technology, enlightened politics can control society through rational self-government of the people, and enlightened media disseminates knowledge and makes everyone an informed and rational citizen.
Therefore, the movie presents an individualistic solution.
Big tech is greedy, politicians are stupid and hypocritical, and scientists are incapable of being live on TV.
If we fix those issues, we are fine.
If only we ‘look up’ (individually), we will be enlightened and stop being stupid and ignorant and we will solve all our modern problems.
The problem becomes a moral problem of personal responsibility thus it becomes polarizing.
From a systems theory perspective, this individualistic solution is not (or no longer) possible.
Systems function according to their functional differentiation on their terms and individuals are part of their environment.</p>

<p>However, <em>anarchy</em> does not imply the absence of strata or the presence of equality.
It’s evident that systems like the economy can create significant <em>differences</em> between the rich and the poor. 
Luhmann recognized that modern society inherently produces many differences, including those we might disapprove of. 
Every system does this, not just the economy.
However, contrary to a Marxist perspective, Luhmann believed that these societal disparities result more from the operations of multiple systems than from the stratum or class into which people are born. 
That said, an individual’s socioeconomic background, such as whether their parents are rich or poor, does matter. 
For example, in the education system, the ability of one’s parents to afford tuition at prestigious institutions like Stanford plays a significant role due to the interconnectedness of the economic and educational systems.
However, to genuinely understand how systems like education or academia function, one must grasp their unique <em>differentiators</em>. 
The education system is defined by distinctions like good grades versus bad grades, while the academic system differentiates between peer-reviewed and non-peer-reviewed papers.
These differentiations are intrinsic to their respective systems and not solely based on economic factors.
According to Luhmann, while wealth can certainly influence educational outcomes, avoid legal troubles, or facilitate a scientific career, it’s overly simplistic to reduce all systemic distinctions to just ‘money’.
But again, of course it helps a lot if you have money if you want good grades, stay out of prison, or become a scientist.</p>

<p>Luhmann argues that all social systems operate on a binary code determined by their sphere of interest which structures their communication with other systems.
Communication with the legal system is organised by the code legal/illegal through the medium of law;
with the political system by the code government/opposition through the medium of legitimate power;
with the economy through money with the code pay/not pay;
with science by the code true/false through the medium of evidential truth;
with the mass media system by the code information/non-information through the medium of public opinion;
and with the welfare benefits system by the code eligible/not eligible through the medium of citizenship status.</p>

<p>Without their environment systems would cease to exist.
They are <em>structurally coupled</em> with one another.
For example, psychic systems are structurally coupled with social systems—without bodys and minds there is no political system, no economy, no relationship and no family.
Without the economy, the political system would collapse.
However, there is <strong>no causal relationship</strong> between the two;
society does not cause consciousness to occur, neither do people consciously create and manage society.
The relationship between the two is rather one of constant <em>irritation</em> (which may be also translated to <em>confusion</em>) with the one reacting to the other, but always on its own terms.
The dynamics are non-linear and tend to be <em>chaotic</em>.</p>

<p>If the political system enact a new law to steer the economy, it can only try to do so via irritation.
How the economy will react is not up to politics.
If climate activists glue themselves to the ground to generate awareness, they may achive their goal or they may not.
What happens is quite difficult to predict.
How does the media report on the issue if its rational is to further differentiate between information and non-information?
How will politics react based on the assumption that it ‘wants’ to make more politics?
From this point of view, it is hard to see how ‘we’ can ‘make’ cooperations (or individuals) sustainable by referring to morals and virtues.
Moral outbursts and frustrations about the destruction of our livelihood are completely understandable (for my psychic system) but how they irritate the different systems is quite uncertain.</p>

<h2 id="artificial-communication">Artificial Communication</h2>

<p>Niklas Luhmann’s concept of communication offers a useful framework for sidestepping (at least for a moment) the ongoing debate about <em>machine intelligence</em>.
While I personally do not ascribe human-like thinking or understanding to machines, I argue that this does not preclude their participation in communication processes.
Therefore, I agree with <a class="citation" href="#esposito:2022">(Esposito, 2022)</a>.</p>

<p>I think Esposito’s term <em>artificial communication</em> is a very useful contribution to make the discussion of <em>AI</em> (especially of machine learning) more reasonable.
Note that she was a student of Niklas Luhmann.
In an interview she explains why she came up with the term:</p>

<blockquote>
  <p>These algorithms became more and more opaque—not understandable for the users—the idea spread that the activities of machines are not trying to be intelligent; that they are not trying to reproduce, in an artificial way, the process of human thought; they are doing something different.
This is rarely said explicetly but one can find it in many different contexts.
And if we switch away from the idea of intelligence, what can we refer to?
Do we have another metaphor that would fit better into the current situation? – Elena Esposito</p>
</blockquote>

<p>Why do people think that ChatGPT is intelligent?
Well, if we interact with machines, we get information we would not get otherwise and the information cannot be attributed to any human being.
The machine processes the data and produces some information which not only did not exist before but is also a sort of reaction to our request.
The machine does exactly what we do when we communicate with a human being.
We ask something and we get some information we did not had before.
Importantly, this information is <strong>contingent</strong> (the response could be different).</p>

<p>Esposito clarifies that, as a sociologist, it is understandable that we think of these machines as <em>artificial intelligence</em> because we have been communicating with human beings for thousands of years and these beings were ‘intelligent’.
And because of this feature of being able to think, humans were able to produce something which allows us to get new information.
It is our prejudice that lead us to the conclusion that machines are so similar to human beings, i.e., psychic systems.
Therefore, to follow Esposito’s proposal, a more interesting and probably healthier question to ask (also for us computer scientist) is:</p>

<blockquote>
  <p>Why are these machines able to communicate with us inspite of the absence of their intelligence?</p>
</blockquote>

<p>Esposito’s answer is that they are <em>parasitical</em>.
My understanding of her work is that machines make heavy use of <strong>second-order observation</strong>, i.e., the observation of an observer.
The starting point is some mental activity but not the machine’s activity.
The user produces <em>contingent</em> behaviour which the machine can process (or observe) to become itself <em>contingent</em>.</p>

<p>A modern example that might no longer be considered AI is Google’s search algorithm. 
Google’s success stems not from trying to evaluate or calculate the quality of a webpage directly.
They didn’t design an intelligent machine for that purpose. 
Instead, they leveraged <em>second-order observation</em>, essentially tapping into the collective intelligence of their users. 
Rather than determining the value of a webpage themselves, their algorithm observes how users interact with webpages. 
A webpage ranks high if users deem it valuable which can create a feedback loop because highly ranked pages are ranked highly.
The primary task becomes observing users’ observations.</p>

<p>Even if Esposito speaks of switching the metaphor, her work goes deeper.
The word <em>intelligence</em> has two different usage in language which are often confused.
On the one hand, we refer to the operational mode of the mind.
But we have almost no idea what this <em>intelligence</em> exaclty is.
On the other hand, we think of information processing.
Take for example the term ‘Central Intelligence Agency’.
Therefore, the metaphor of <em>artificial intelligence</em> is so problematic which makes it hard to theorize about <em>AI</em> and its impact which leads to these hyper-speculative predictions.
It’s like referring to airplanes as artificial birds.
Just as airplanes succeeded when engineers stopped trying to mimic birds, AI has advanced when researchers moved away from replicating human thought.
By using Luhmann’s theory of communication, we might clear the smoke and find more effective ways to talk about artificial intelligence.</p>

<p>Esposito argues that we—the preachers of machine learning—do not reproduce human intelligence but rather social communication.
Intelligence that emerges from conscious beings might not be needed or might even be an obstacle for the establishment of communication.
Artificial communication (coupling machines and psychic or social systems via language) can be more effective than intelligent communcation (coupling psychic and social systems via language) but it can not be intelligent (referring to the first use of the word).
In other words: That which makes society more intelligent might not necessarily be intelligent.
As described above, social systems have their own <em>systemic rational</em> and we might call them intelligent.</p>

<p>Systems theory is useful because it focusses on communication itself.
Again, Luhmann claims that humans do not communicate, only communication communicates.
Of course, similar to air, humans are a necessary condition for communication but, like air, they do not communicate themselves—we can only hear the ticking of a clock because the air does not tick.</p>

<p>Luhmann diverges from traditional sender-receiver models of communication, such as Shannon’s <a class="citation" href="#shannon:1948">(Shannon, 1948)</a> where the focus is on the transmission of information.
Instead, Luhmann conceptualizes communication as comprising three essential moments: <em>announcement</em>, <em>information</em>, and <em>understanding</em>.
Each component has its unique role in facilitating communication.
An announcement initiates the process.
Whether verbalized, written, or visualized, it serves as the catalyst that triggers communication.
Absence of an announcement, be it from a human or an algorithm, results in the absence of communication altogether.
This announcement must bear some form of informational value, imbuing the text, image, or utterance with meaning.
The final moment, understanding, underscores the necessity of a recipient comprehending the conveyed information.
The efficacy of communication is not solely predicated on accurate understanding, but rather on the act of understanding itself—even if what is understood is incorrect.
As Luhmann notes, understanding is often replete with misunderstandings, but the very act of engaging in a selection of understanding is vital.
Understanding is typically misunderstanding without understanding the ‘mis’ (similarily, misinformation is still information).</p>

<p>In summary, Luhmann’s perspective underscores that effective communication doesn’t necessarily require partners to achieve mutual understanding in the way their respective psychic systems might operate.
I think we can make the same observation in our day to day life.
Partners can perfectly live together even though their understanding is not mutual which, of course, can cause problems in relationships.
However, it can also be a useful feature.
If a third party observe a tense conversation between a couple, the content of the conversation might be quite ordinary but what is communicated can be a conflict within the relationship.
The couple understands the communication much better than the third party.
The conflict, however, is likly caused by the problem of different previous (mis-)understandings.
For the third party, it is like listening to some encrypted communication.
Whether executed by humans or algorithms, the value lies in the process and its constituent parts: announcement, information, and understanding.</p>

<p>In the context of artificial intelligence we can look at the communication of a person and a machine—of ChatGPT and Doug Hofstadter—and we can ask: Why is it so effective or attractive? 
But also: Why is it (probably) not the product of an intelligent thinking system but rather produced social intelligence?</p>

<p>With my shallow understanding of Luhmann’s theory, I imagine that the prerequisites for communication—whether artificial or otherwise—involve <strong>contingency</strong> and <strong>connectivity</strong>.
In social systems theory, the generation of information is not an isolated act; it is attributed to an interactive partner.
While traditionally this partner is human, in the realm of artificial communication, it can very well be a machine.
The focus should be on the nature of the interaction itself: does it exhibit the characteristics of a contingent, autonomous relationship?
And does this interaction spur further communication?</p>

<p>Traditional machines that produce unpredictable outcomes are usually considered faulty rather than creative or original.
Take a pocket calculator, for instance; its primary virtue lies in its predictability.
We do not regard it as a communicative entity because it operates as expected which is desirable.
The calculator is not contingent.
Conversely, when interacting with image-generating algorithms like Stable Diffusion or Midjourney the appeal, I argue, is precisely in the unpredictability of the results.
Chatting with a bot can be exciting preceisly because we do not know the output of the bot or, in general, the outcome of this interaction.
Of course, this does not mean a completely random output would have the same effect.
<em>Contingency</em> should not be confused with randomness or arbitrariness.
The information provided by the bot has to be understandable, in the sense that it can also be misunderstood (like any ‘good’ communication can be).</p>

<p>Despite thinking of this feature as a flaw, this ambiguity is desirable for communication.
Of course, not all possibilities of misunderstanding are desirable.
A chatbot that provides patients with medical or organizational information should give precise and unambiguous answers.
However, in this case, the bot is more like a tool than a real communication partner.
And here we land at an important distinction:
While many argue that irritation caused by <em>generative AI</em> is similar to the invention of photography, I think there is a difference.</p>

<blockquote>
  <p>Cameras do not communicate!</p>
</blockquote>

<p>This does not mean that generative AI can not act as a mere tool in the process of, for example, the production of images.
The more predictable the more tool-like generative AI are and the less communicative they become.
There outputs by themselves become less interesting but at the same time, they are more useful to realize a specific vision of the user or artist.</p>

<p>As Esposito noted: Viewed through the lens of Luhmann’s social system theory, the development of compelling communication partners presents a unique dilemma: 
The challenge lies in engineering machines that exhibit both creativity and control, balancing the production of unexpected outcomes with predictability.
This tension is especially relevant in the field of AI art.
In essence, the paradox that governs the programming of ‘intelligent’ algorithms is the pursuit of controlled unpredictability.</p>

<blockquote>
  <p>The ultimate objective is to achieve a controlled lack of control. – <a class="citation" href="#esposito:2022">(Esposito, 2022)</a></p>
</blockquote>

<p>From a philosophical standpoint, Luhmann transforms the <em>mind-body problem</em> into the <em>mind-communication problem</em>—communication defined by Luhmann as “the operation that society consists of” <a class="citation" href="#moeller:2006">(Moeller, 2006)</a>.
If the mind does not communicate but is only in the environment of society (communication)—is merely involved—how does this all work?
Similarily, I think, the question of how <em>artificial communication</em> emerges even if machines are also only in the environment of communicating systems, is one of the most important question to ask if one wants to understand the current state of AI, society and where we are heading at.</p>

<p>Now, if one looks closely to Luhmann’s definition of communication, we find that it is not compatible with Esposito’s concept of <em>artificial communication</em> and she is aware of that.
We might think of communication being really picky, that is, it has a lot of requirenments to occur—there is a lot of <em>structural coupling</em> going on.</p>

<blockquote>
  <p>Communication is improbable. – Luhmann</p>
</blockquote>

<p>Let’s look at some requirements: the physical requirements like temperature and gravity at a certain level, water, air, but also a medium and, according to Luhmann, at least two consciousness entities. 
In a sense, the coupling of these two conscious entities is more strict.
It is an equal operation of the psychic system that has to be devoted to the actual operation of the social system.
That is why they coincide in this event at which communication happens.</p>

<blockquote>
  <p>Empirically, I propse [the concept] because what is going on in the interaction with algorithms is so close to communication that we have to try to find a way to extend [Luhmann’s] concept of communication to include what is going on—it is not exactly the same.
The technique of the communication is similar: production of information which irritates other systems but the algorithm itself is not thinking, is not producing any new communication.
It just sort of conveys something that can produce information somewhere else.
My background is Luhmanian but what I am proposing, without wanting to amend Luhmann, is something different from the standard case of communication  – Elena Esposito</p>
</blockquote>

<h2 id="profilicity-machines">Profilicity Machines</h2>

<p>The philosopher Hans-Georg Moeller adds an interesting point to the machine learning discourse.
He posits that algorithms nowadays are used for profile building—he coined the term <em>profilicity</em> as a new identity technology, which is different from previous modes of identity building, i.e., <em>sincerity</em> and <em>authenticy</em> <a class="citation" href="#moeller:2021">(Moeller &amp; D’Ambrosio, 2021)</a>.</p>

<p>Following his thesis, people taking pictures, not (primarily) to preserve memories, but to curate a profile on Facebook, Instagram or LinkedIn.
In that sense, I too build my own profile by writing this text and by curating a personal website, a GitHub repository, and many more profiles.
AI helps us to evaluate our profile(s) within McLuhan’s <em>Global Village</em> <a class="citation" href="#mcluhan:1992">(McLuhan, 1992)</a>.
It makes it possible to get feedback from our peers and to present this evaluation back to the village.
It enables <em>second-order observation</em> which reduces complexity.</p>

<p>Moeller admits that he is—as many of us coming from an age where authenticy was the primary technology to build identity—annoyed by this picture frenzy.
But he stays true to Luhmann and refrains from judging.
He trys not to moralize this phenomenon or classify it as being ‘worse’ or ‘better’ because, in his eye, authenticy was never real in the first place.
Like the other forms of identity building, profilicity comes with its own problems.
Each mode brings its own set of challenges.</p>

<p>He intriguingly describes profile creation as <em>genuinely pretending</em>.
Observing younger generations, this resonates.
Their digital avatars often exude a <em>postmodern irony</em>; they knowingly embrace its constructed nature.
They are fully aware that it is all ‘fake’.
Contrarily, older generations may need reminding that these online images are meticulously curated and often manipulated.
Advising younger folks about the ‘deceptions’ of online portrayals might seem naive.
Their approach is more playful, even inventive, using multiple layers of meta-references to distance themselves from reality as far away as possible.</p>

<p>As Moeller notes, the real tension might arise from the mismatched expectations of older authority figures. 
We—and I include myself here—expect authenticity while most parts of the world of young people operate in the mode of profilicity.
This leads to a contradiction and, because it is about identity building, this contradiction might be psychologically problematic.
Misaligned expectations can cloud the path to self-realization.
Hence, while it’s tempting to solely blame social media for rising mental health issues, the underlying causes, as Luhmann would argue, are multifaceted.</p>

<h2 id="the-revenge-of-objects">The Revenge of Objects</h2>

<p>With the description of society handed over by systems theory, I might have lured you, the reader, into an even greater despair.
My assertion is that we don’t necessarily need AI to challenge Hofstadter’s vision of human greatness; 
the <em>deconstruction</em> might already be underway.
Luhmann’s system theory goes against the honorable belief of Hofstadter which is also expressed by figures like David Graeber or Noam Chomsky.</p>

<blockquote>
  <p>The ultimate, hidden truth of the world is that it is something that we make, and could just as easily make differently. – David Graeber</p>
</blockquote>

<p>I really like the sentiment expressed in the quote.
I want it to be true and to work!
And I admire personalities that keep it alive.</p>

<p>However, objects seem to regain agency and power over us.
When certain philosophers discuss subjects and objects, they often reference commonplace items like chairs and desks.
For instance, a chair might seem like a benign example. 
Here the case seems trivial: Of course a chair has no agency!
We make chairs to sit on them.
We dominate chairs.
They are completely in our control.</p>

<p>But we do not have to look further than <em>Heidegger’s hammer</em> <a class="citation" href="#heidegger:1927">(Heidegger, 1927)</a> to see that things can get tricky very quickly.
Heidegger proposes that before we ponder the essence of a hammer, we use it. 
Before we question its existence, we recognize its utility.
The hammer, in this context, prompts us to act—it, indirectly, has agency.</p>

<p>Or consider more potent examples like opioids, smartphones, the internet, algorithms, images or even movies.
These items influence our behavior, decisions, and perceptions.
The inception of video technology, for example, started with the simple goal of determining if a galloping horse ever had all its hooves off the ground simultaneously.
Now reflect on the vast implications and transformations that this technology has since undergone.
Did we solely shape these inventions, or should we attribute some credit to the inventions themselves?</p>

<p>For Baudrillard there is an uninterrupted production of positivity that has terrifying consequences.
Applying systems theory terminology, he speaks of <em>runaway positive feedback loops</em>.</p>

<blockquote>
  <p>Any structure that hunts down, expels or exorcizes its negative elements risks a catastrophe caused by a thoroughgoing backlash, just as any organism that hunts down and eliminates its germs, bacteria, parasites, or other biological antagonists risks metastasis and cancer—in other words, it is threatened by a voracious posivity of its own cells, or, in the viral context, by the prospect of being devoured by its own antibodies. – <a class="citation" href="#baudrillard:1990">(Baudrillard, 1990)</a></p>
</blockquote>

<p>In other words, runaway positive feedback loops that have no negative, will eventually cause a catastrophe.
A simple technical example of such a feedback is a microphone that picks up the amplified sound output of loudspeakers in the same circuit, then howling and screeching sounds of audio feedback.</p>

<p>Baudrillard thought that the production of images is such a feedback loop.
They are <em>out of control</em> and take over, for example, free democratic politics.
Although we can take a moral stance against certain imagery, such as pornographic content, Baudrillard suggests that positive feedback will ultimately subvert any moral code.
Trump, as an example, may be critiqued from a moral perspective, but because he’s a potent subject for image production, the media engages with him regardless of whether they criticize or praise him.
This cycle of image production can’t be halted simply by creating more images.</p>

<p>Luhmann may have a less bleak view. 
For instance, laws that regulate AI-generated images, can prompt changes in a system’s behavior (indirectly via irritation).
However, reining in runaway positive feedback is challenging, as issues can escalate exponentially.</p>

<p>It might sound unconventional, but to foster our understanding of our world it could be beneficial to acknowledge external influences like reality TV, staged political photos, or conspiratorial content as agents.
Not only in a sense that they affect us but that they have an inner life; a will of their own so to say.
It could be valuable to treat objects like oil with the same reverence and respect as ancient civilizations treated strom and thunder.
Isn’t it the case that in our times oil is more powerful than any ancient god ever was?</p>

<p>Predictive machines can sometimes inadvertently create self-fulfilling prophecies. 
For example, I might be more inclined to buy items from Amazon that appear at the top of a list because of their prominent placement. 
These items are ranked by an algorithm aiming to maximize Amazon’s profits, predicting which items I’m most likely to purchase.
Since I’m inclined to buy items higher up on the list, the algorithm’s prediction is validated, influencing its future predictions and creating a positive feedback loop which consists of me and the algorithm.
Because I rely on algorithms to find items to buy, I believe it’s fair to say that they have influence over me and a sort of agency of their own.</p>

<p>If we don’t attribute agency to objects, then the explanation for the failures of climate agreements likely rests on a dysfunction of the system or on individual failures, e.g. ‘corrupt’ or incompetent politicians.
The idea that our modern society renders us freer and more independent is misconstrued.
A better way to put it is: We are (more) <em>out of control</em>.
While we engage in broader dialogues, express ourselves diversely, and view the world through varied lenses, increasing complexity often amplifies dependency and chaos.
There is more differentiation going on but this does not mean that we are less dependent.
Instead systems are less controlable.
The age-old dynamic of subjects dominating objects could very well be shifting, placing objects alongside us in terms of influence.</p>

<h2 id="artificial-systems">Artificial Systems?</h2>

<p>Systems theory doesn’t assert that society’s evolution is innate or that it will remain unchanged forever.
It simply aims to provide a thorough depiction of modern society. 
Yet, it’s worth exploring the connections between systems theory and artificial intelligence.
This exploration might hint at the concept of an <em>artificial system</em>—–essentially an AI that functions as a system, potentially approaching the capabilities of general artificial ‘intelligence’.</p>

<p>To venture a speculative idea, machines might eventually evolve into these <em>artificial systems</em>.
To thrive in a highly complex modern environment, they might need to exhibit traits similar to psychic and social systems: being <em>autopoietic</em>, <em>structurally coupled</em>, <em>operationally closed</em>, and <em>functionally differentiated</em>.
If we assume this to be true, what implications might it has?</p>

<p>While minds create themselves through mental operations, an <em>artificial system</em> would self-create and self-preserve through computation.
This does not mean that artificial systems have to be in control of their requirements to operate.
The opposite is the case.
The required hardware, programmers, and users of such systems would belong to their environment.
But, as Luhmann writes:</p>

<blockquote>
  <p>The observing and describing itself (cognition), however, always has to be an operation that is capable of autopoiesis, i.e., of the performing of life or actual consciousness or communication, because otherwise it could not reproduce the closure and difference of the cognizing system; it could not take place “in” the system. <a class="citation" href="#luhmann:1988">(Luhmann, 1988)</a></p>
</blockquote>

<p>Computation would probably drive more computation; 
the primary purpose being to continue its computational operations.</p>

<p>Due to their operational closure, a synthesis of thinking and computation—a <em>transhumanist</em> vision—seems unlikely.
Also, their structural coupling suggests they’d be interdependent on psychic systems and other social systems.
Natural language processing might be an important aspect of AI because it potentially makes this coupling possible via the <strong>shared medium of language</strong>.
This implies that the idea of AI overthrowing humanity is also improbable.
It is more likely that our mind, i.e. our thinking/feeling co-evolves with computation/text generation.
Machines will not think for us but they might irritate our thinking because we might need different skills to survive in an environment consisting of such machines.
However, it’s worth noting that psychic systems may not have control over these artificial systems.</p>

<p>The primary function of the psychic system, in Luhmann’s conceptualization, is the processing of meaning. 
Psychic systems generate thoughts, emotions, perceptions, and other mental phenomena. 
They observe, process information, and produce decisions. 
While social systems use communication as their primary medium, psychic systems use consciousness. 
Every individual has their own psychic system, which means their own consciousness and their own way of processing and understanding the world.</p>

<p>Artificial systems, on the other hand, may primarily focus on the production of predictions. 
They would observe and process abstract data and project potential futures. 
But what would ‘motivate’ them? 
To function or to survive, they have to compute, i.e., they have to process abstract data.
Consequently, their <em>systemic rational</em> might prioritize producing predictions that lead to more predictions, rather than producing the most accurate or useful predictions.
While we can see traces of this effect in recommendation algorithms that suggest polarizing content, attributing this behavior to <em>artificial systems</em> and not, or only partly, to the mass media system might be an overreach.</p>

<p>I must admit, I need a deeper understanding of systems theory to consider AI as potential systems in Luhmann’s view.
However, I believe it’s a valuable pursuit.</p>

<h2 id="difference-makes-the-difference">Difference Makes the Difference</h2>

<p>I agree with Hofstadter on the limitations of human greatness, albeit for different reasons and perspectives.
While discussing systems theory, I aimed to challenge his belief that AI diminishes this human greatness. 
I argued that this so-called greatness, or perhaps <em>rational control</em> that comes out of enlightenment, was an illusion from the outset.
Additionally, I’ve raised questions regarding the feasibility of ‘complete’ enlightenment as proposed by the modern project.</p>

<p>Simultaneously, I presented reasons:</p>

<ol>
  <li>for perceiving machines as intelligent, and</li>
  <li>for potentially being misled by this perception.</li>
</ol>

<p>The phenomenon of <em>artificial intelligence</em> is not only interesting because of impressive accomplishments but because it pushes discussions about the ‘human nature’ into many psychic and social systems.
This question leads immediatly to the question of <em>cognition</em>, <em>thinking/feeling</em>, and <em>consciousness</em> because these concepts are so central to the question of <em>machine intelligence</em>.
So, let me elaborate a little bit more on these concepts.</p>

<h3 id="the-mystery-of-consciousness">The Mystery of Consciousness</h3>

<p>First of all, debating if machines possess consciousness or human-like intelligence is premature without a clear understanding of intelligence and consciousness.
Perhaps ‘intelligence’ is just a collective term for several unexplained phenomena.
We do not know yet.</p>

<p>We can identify correlations between mental events and brain activities, implying there’s a physical aspect to consciousness—a sort of carrier.
However, as neuroscientist Giulio Tononi notes, this doesn’t necessarily mean we can pinpoint consciousness within the brain <a class="citation" href="#tononi:2015">(Tononi &amp; Koch, 2015)</a>.</p>

<blockquote>
  <p>[…] what I think I know about my body, about other people, dogs, trees, mountains, and stars, is inferential.
It is a reasonable inference, corroborated first by the beliefs of my fellow humans and then by the intersubjective methods of science.
Yet consciousness—the central fact of existence—still demands a rational explanation. – <a class="citation" href="#tononi:2015">(Tononi &amp; Koch, 2015)</a></p>
</blockquote>

<p>Still <em>physicalism</em>, the view that everything is physical and can be explained by physics, seems to be the natural position, especially in science.
However, this view can be challenged.
In the famous and rather short article <em>What Is It Like to Be a Bat?</em> <a class="citation" href="#nagel:1974">(Nagel, 1974)</a>, the philosopher Thomas Nagel trys to argue against it.
He explains that we can not know what <em>it is like</em> to be a bat.
He chooses bats because they are mammals like us and, presumably, conscious, yet their primary sensory experience—echolocation—is profoundly different from any human sensory experience.
In Luhmann’s words: their environment is very different from ours.
We can imagine flapping our arms like a bat or eating insects like a bat, but we cannot truly imagine what it is like to ‘experience’ the world primarily through echolocation.
Nagel suggests that even if we knew all the physical facts about a bat’s brain while it echolocates, we’d still be missing the subjective experience—the “what it’s like”–—of being a bat.</p>

<p>In the <em>philosopyh of mind</em> there is a broad spectrum of dealing with <em>the hard problem of consciousness</em> ranging from new forms of idealism (the essence of reality is consciousness), naive realism (we have direct awareness of objects as they really are), new realism (accepts that science is not systematically the ultimate measure of truth but realities are first given, not constructed) to panpsychismus (the mind or a mindlike aspect is a fundamental and ubiquitous feature of reality).
There is no agreement on the <em>hard problem of consciousness</em>.
Consequently, consciousness remains enigmatic, with little guidance on where to begin our inquiries.</p>

<h3 id="cognition-as-construction">Cognition as Construction</h3>

<p>Sometimes, to gain a fresh perspective on the world, one must take a completely opposite stance.
For millennia, philosophers have pondered how we can perceive something if we lack direct access to reality.
Luhmann flipped this idea on its head. 
He argued that it’s precisely because we don’t have direct access (due to system/environment distinction and operational closure) that we can perceive.
Cognition can only happen if it is not interrupted which requires operational closure.</p>

<blockquote>
  <p>The tradition of epistemological idealism was about the question of the unity within the difference of cognition and the real object.
The question was: how can cognition take notice of an object outside of itself?
Or: how can it realize that something exists independently of it while anything which it realizes already presupposes cognition and cannot be realized by cognition independently of cognition?
No matter if one preferred solutions of transcendental theory (Kant) or dialectics (Hegel), the problem was: how is cognition possible in spite of having no independent access to reality outside of it.
Radical constructivism, however, begins with the empirical assertion: Cognition is only possible because it has no access to the reality external to it.
A brain, for instance, can only produce information because it is coded indifferently in regard to its environment, i.e. it operates enclosed within the recursive network of its own operations.
Similarly one would have to say: Communication systems (social systems) are only able to produce information because the environment does not interrupt them.
And following all this, the same should be self-evident with respect to the classical “seat” (subject) of epistemology: to consciousness. – <a class="citation" href="#luhmann:1988">(Luhmann, 1988)</a></p>
</blockquote>

<p>I should emphasis and explain how radical this turn is.</p>

<p>Luhmann builds on Kant’s <em>Copernican Turn</em>.
He turned the question of ‘what is the general structure of the world’ into a question of the general structure of cognition: Under which conditions is cognition allowed to operate to conceive the world?
Kant tried to bridge the gap between Hume’s <em>empiricism</em> and German <em>idealism</em>.
He also accepted the skeptical argument that nothing could be realized by cognition independently of cognition.
Kant brought in <em>constructivism</em> into epistemology but he was, in Luhmann’s view, not radical enough because he hold on to some sort of relation to reality.
Luhmann assumes that the realization of reality is not a relating to reality, but that reality basically consists of its own realization and that the key is <em>differentiation</em>.
Therefore, Luhmann drops the idea of a reality that is independent of cognition, i.e. Kant’s <em>Ding an sich</em>.</p>

<p>According to Luhmann, cognition itself becomes a construction based on distinction: Reality emerges as cognition.
This sounds like Hegel’s <em>idealims</em>.
However, the emergence of reality does <strong>not</strong> mean that cognition is <em>ideal</em>—it does not rely on an essence in the form of consiousness.
Cognitive systems construct cognition which is based on the system/environment distinction.
There is no single rule how this can be done.
Cognition can operate materially in the form of biological life, mentally in the form of thoughts, or socially in the form of communication.</p>

<p>Moeller summerizes this shift from <em>Kantian idealism</em> to <em>radical constructivism</em> nicely <a class="citation" href="#moeller:2006">(Moeller, 2006)</a>:</p>

<ol>
  <li>Cognition is not <em>per se</em> an act of consciousness. It can take on any operational mode.</li>
  <li>There is no a priori, transscendental structure of cognition; cognition constructs itself on the basis of <em>operational closure</em> and is an <em>empirical</em> process, which varies from system to system.</li>
  <li>No complete description of cognitive structures is possible because these structures are continuously evolving.</li>
  <li>Reality is not singular—there is not one specific reality, but a complex multiplicity of system/environment constellations.</li>
  <li>A description of reality is itself a contingent construction within a system/environment relation.</li>
</ol>

<p>In Luhmann, the subject/object distinction gets replaced with the system/environment distinction and the premise of a common world (the unity of system and environment) gets replaced by a theory of the observation of observing systems (<em>second-order cybernetics</em>).
However, getting to ‘the root’ of cognition—which would lead to some clues about <em>a reality</em>—seems impossible because any such investigations require distinction which is the operation of cognition.
Furthermore, there is no justification for assuming that any adaptation of cognition to reality is happening.
Confronted with this problem how can one start developing a theory of cognition?</p>

<p>In <em>Cognition as Construction</em>, Luhmann recognizes and somewhat addresses this issue by an assumption akin to Decartes and Husserl:</p>

<blockquote>
  <p>We assume that all cognizing systems are real systems within a real environment, or in other words: that they exist.
This is naive—as it is often objected.
But how should one begin if not naively?
A reflection on the beginning cannot be performed at the beginning, but only by the help of a theory that has already established sufficient complexity. – <a class="citation" href="#luhmann:1988">(Luhmann, 1988)</a></p>
</blockquote>

<p>Starting from this assumption, Luhmann reformulates Kant’s question of the possibility of cognition to the question of how systems can <strong>uncouple</strong> themselves from their environment.
For him, closure, i.e. uncoupling, is only possible by a systems’s production of its own operations and by its reproduction within the network of its recursive anticipations and resources.
Thus, cognition is manufactured and is a self-referential process.
It deals with an external world that remains unknown thus cognition has to come to see that it cannot see what it cannot see.
One could say that reality remains as an ineradicable <em>blind spot</em>.
While reality remains unkown, Luhmann speculates that there is some ground for the belief that if reality would be totally entropic, it could not enable any knowledge.
In other words, reality cannot be the object of the knowledge that it makes possible, it serves knowledge merely as a presupposition.
Knowledge can only know itself but it cannot know anything about what it constructs by way of the manipulation of distinctions.</p>

<p>All observing systems are cognitive systems.
They are operationally closed but cognitively open and they make sense of their environment as they experience it.
The mind makes sense in such a way that its construction is valid or functional.
It does not matter if it resembles reality.
In this way, making sense is like finding the right key to open a lock.
The key is useful and <em>functionional</em> but it does not tell us anything about the lock, expect that it fits the lock.
However, how we see the world depends on the cognitive capacities of our eyes and brains to produce images.
Different operations lead to further different operations.
For example, bats are another system/environment distinction than we are.
Therefore, their world most certainly ‘looks’ nothing like ours.</p>

<blockquote>
  <p>To recognize a table and say “This is a table”, I don’t need to have the letters T, A, B, L, E in my brain, nor does a tiny representation of a table (or even the “idea” of the table) need to exist inside me.
However, I do need a structure that calculates the various manifestations of a description for me. – <a class="citation" href="#foerster:1988">(Foerster, 1985)</a></p>
</blockquote>

<p>What our psychic system ‘sees’ does not have anything to do with reality.
In fact, the psychic system cannot ‘see’ reality with ‘its’ eyes because our eyes are in the environment of our psychic system.
Cognition is always a construction by an observing system and there is only irritation and no direct causal relation.</p>

<p>Now, one might ask: If every system constructs itself and reality emerges out of its cognition, how can we find any common ground?
Or, how did we end up believing in an universal and objective reality we actually can access?</p>

<p>Well, only because there is no objective reality does not mean that humans cannot ‘achieve’ social control via social systems.
Importantly, psychic and social systems share a common <em>medium</em>, that is, sense.
It is used in thought as well as in commuincation.
A thought or a gesture is a specific <em>form</em> (strict coupling) that the medium (loose coupling) of sense can take on.
Thus, thinking is like bringing sand (the medium) into a specific form; it can also be defined as a selection within a horizon of what is possible.
By thinking a specific thought, I do not think any other thought that is in my horizon of the thinkable.
Secondly, social and psychic systems are structurally coupled via language.
Language couples psychic and social systems. 
And these social systems make sense in accordance to their <em>systemic rationality</em> irritated by observing their environment.
In a sense, we create a second dimension of ‘reality’ by assuming, through the use of concepts, that our own constructions resemble those of others and by experiencing ourselves as part of a community by assuming and asserting that our own constructions largely correspond to those of others.
The experience of stability and continuity of one’s constructed reality depends not only on the system’s first-order observation but also on the confirmation of this observation by other observers (second-order observation).</p>

<p>From a radical constructivist perspective, a child learns language not as a system of information transmission but as a form of behavioral coordination.
It must learn, through trial-and-error strategies, to connect the multitude of linguistic expressions from adults with desired reactions of its own. 
Therefore, words like “forks/democracy” coordinate our actions with respect to what a person does when dealing with forks/democracy. 
Through the word “forks” and similarly through all other words, information is not transmitted but something specific is triggered in the recipient, which is determined by their structure and, indirectly, by their socialization.</p>

<p>Luhmann’s concept of <em>cognition as construction</em> does not provide an absolute, rigid foundation.
My explanation of it is based on my observation of Luhmann’s observations, and in case of the reader, it relies on your observation of my observation of Luhmann’s observation.
Since my, Luhmann’s and your observation are all constructed and contigent, it is inherently impossible to ‘prove’ the correctness of Luhmann’s theory from outside.
Furthermore, there will be always a blind spot.</p>

<blockquote>
  <p>A supertheory reflects on the fact that it and its validity are its own product—and is therefore absolutely contingent. […]
It is a theoretical endeavor, and there is nothing more to it.
It does little outside of theory. […]
With supertheory, the world does not become morally better, more rational, or spiritually complete.
It only becomes more distinct. – <a class="citation" href="#moeller:2006">(Moeller, 2006)</a></p>
</blockquote>

<p>Radical constructivsm is often preceived as a dangerous path because it might lead to the relativization of ‘evil’ actions.
If everything is constructed, anything might be justifiable.
But again, Luhmann does not claim that there is no reality or that one can construct whatever one desires.
If you jump out the window, you will get hurt regardless of what you imagine.
However, acccording to Luhmann (and many others), there is no absolute and I think that this uncertainty makes us more thoughtful than reckless.
If absolute truth is on my side, everything is permitted.</p>

<p>It would be erroneous to claim that the application of social systems theory is justified because it describes society more ‘accurately’ because, according to this very same theory, such claims are impossible.
What we can state is that a theory that makes more sense—culturally and personally—might be useful for effective communication, facilitating a better understanding of one another.
This view aligns with Richard Rorty, another so-called postmodern ‘charlatan’:</p>

<blockquote>
  <p>If we can just drop the distinction between appearance and reality, we should no longer wonder whether the human mind, or human language, is capable of representing reality accurately.
We would stop thinking that some parts of our culture are more in touch with reality than other parts.
[…] we would not say that [our ancestors] were less in touch with reality than we, but that their imaginations were more limited than ours.
We would boast of being able to talk about more things than they could. – <a class="citation" href="#rorty:2016">(Rorty, 2016)</a></p>
</blockquote>

<h3 id="we-are-different">We are Different</h3>

<p>So let me ask: Why should machines (even if they are conscious) ‘live’ in a ‘world’ that is similar to ours?
And why should the bat-workd, my-world, and the machine-world be more true than any other system/environment distinction?
I think it is a mistake to undervalue our mental processes just because machines can communicate, calculate, and display creativity.
I also think it is a mistake to believe that thinking and computing are similar operations.
However, according to systems theory, viewing humans as superior rational entities is misguided as well.</p>

<p>A recurring theme in Luhmann’s writings is the idea of <strong>difference</strong> and <strong>differentiation</strong>.
Neither do we nor does any other system hold an intrinsic superior position in society; existence is <em>contingent</em>.
Observation necessitates selection, i.e. non-observation (a blind spot).
If I observe my cup, I cannot oberserve myself at the same time.
Because of differentiation there is no system that can make absolute sense of some indpendent reality.
The legal system ‘looks’ at a house in legal terms and the economy in economic terms.
There is no view from the top, above or the outside.
A system can only observe in accordance to its <em>systemic rationality</em>.
And as I argued above, bats, human beings, and maybe at some point in future, machines ‘live’ in, or better create, different interdependent ‘worlds’.
We are differnt; neither better nor worse with respect to each other and to other beings/systems.
I think, that should be enough to be fascinated about ourselves and to value us as different as we are.</p>

<p>This multiplicity of ‘worlds’—this functional differentiation—makes communcation so difficult.
It seems like a miracle that we sometimes seem to understand each other.
Luhmann believed that ecological problems are primarily problems of communication.
Different social systems (e.g., politics, science, economics) have different ways of observing and communicating about the environment, which can lead to misunderstandings or contradictions.
So one idea I have in mind is that via <em>artificial communication</em> we might be able to reduce misunderstanding between different systems, including the ecological system.
From a Luhmannian perspective, we need a sort of <em>translation</em> from one <em>systemic rational</em> to the other.
Furthermore, I believe that we need a more strict coupling between the ecological system and psychic as well as social systems.
Maybe artificial communication can establish such a strict structural coupling.</p>

<p>Only because we are not in charge, does not mean that things can not get better.
There seems nothing inherently wrong with biological evolution.
Is social evolution any different?</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="hofstadter:1979">Hofstadter, D. (1979). <i>Gödel, Escher, Bach: An Eternal Golden Braid</i>. Basic Books.</span></li>
<li><span id="bender:2021">Bender, E. M., Gebru, T., McMillan-Major, A., &amp; Shmitchell, S. (2021). On the dangers of stochastic parrots: Can language models be too big? <i>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</i>, 610–623. https://doi.org/10.1145/3442188.3445922</span></li>
<li><span id="bender:2020">Bender, E. M., &amp; Koller, A. (2020). Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data. <i>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</i>, 5185–5198. https://doi.org/10.18653/v1/2020.acl-main.463</span></li>
<li><span id="moeller:2006">Moeller, H.-G. (2006). <i>Luhmann Explained: From Souls to Systems</i>. Open Court.</span></li>
<li><span id="luhmann:1988">Luhmann, N. (1988). <i>Erkenntnis als Konstruktion</i>. Bern: Benteli.</span></li>
<li><span id="luhmann:1993">Luhmann, N. (1993). <i>Deconstruction as second-Order observation</i>. New Literary History.</span></li>
<li><span id="luhmann:2000">Luhmann, N. (2000). Why does society describe itself as postmodern. In W. Rasch &amp; C. Wolfe (Eds.), <i>Observing complexity: Systems theory and postmodernity</i> (pp. 35–49). University of Minnesota.</span></li>
<li><span id="brown:1969">Spence-Brown, G. (1969). <i>Laws of Form</i>. London: Allen and Unwin.</span></li>
<li><span id="esposito:2022">Esposito, E. (2022). <i>Artificial Communication</i>. The MIT Press. https://doi.org/10.7551/mitpress/14189.001.0001</span></li>
<li><span id="shannon:1948">Shannon, C. E. (1948). A mathematical theory of communication. <i>Bell Syst. Tech. J.</i>, <i>27</i>(3), 379–423.</span></li>
<li><span id="moeller:2021">Moeller, H.-G., &amp; D’Ambrosio, P. J. (2021). <i>You and Your Profile: Identity After Authenticity</i>. Columbia University Press.</span></li>
<li><span id="mcluhan:1992">McLuhan, M. (1992). <i>The Global Village: Transformations in World Life and Media in the 21st Century</i>. Oxford University Press.</span></li>
<li><span id="heidegger:1927">Heidegger, M. (1927). <i>Sein und Zeit</i>.</span></li>
<li><span id="baudrillard:1990">Baudrillard, J. (1990). <i>The Transparency of Evil: Essays in Extreme Phenomena</i>. Verso.</span></li>
<li><span id="tononi:2015">Tononi, G., &amp; Koch, C. (2015). Consciousness: Here, there and everywhere? <i>Philosophical Transactions of the Royal Society B: Biological Sciences</i>, <i>370</i>(1668), 20140167.</span></li>
<li><span id="nagel:1974">Nagel, T. (1974). What is it like to be a bat? <i>Philosophical Review</i>, <i>83</i>(October), 435–450. https://doi.org/10.2307/2183914</span></li>
<li><span id="foerster:1988">Foerster, H. (1985). <i>Sicht und Einsicht</i>. Vieweg.</span></li>
<li><span id="rorty:2016">Rorty, R. (2016). <i>Philosophy as Poetry</i>. University of Virginia Press.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Opinion" /><category term="Social Systems Theory" /><category term="AI" /><summary type="html"><![CDATA[Generative AI, especially ChatGPT, brought artificial intelligence into the public sphere and sparked a lot of highly speculative claims about machine intelligence. I’m open for discussions and unafraid of confronting uncomfortable truths. Indeed, our imagination and fearless thinking should pave the way for new possibilities. Dreams and speculations are valuable, as long as they’re presented as such. However, I find it concerning when public figures speak with undue certainty, particularly when making anthropological comparisons between humans and machines.]]></summary></entry><entry><title type="html">Musical Interrogation II - MC and FFN</title><link href="https://bzoennchen.github.io/Pages/2023/05/31/musical-interrogation-II.html" rel="alternate" type="text/html" title="Musical Interrogation II - MC and FFN" /><published>2023-05-31T00:00:00+02:00</published><updated>2023-05-31T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/05/31/musical-interrogation-II</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/05/31/musical-interrogation-II.html"><![CDATA[<p>The code shown here can be found in the following GitHub <a href="https://github.com/BZoennchen/musical-interrogation">repository</a>.
In the second installment of this series, I introduce an initial and arguably the most basic method to generate monophonic melodies. 
This consists of two approaches: (1) A <strong>first-order Markov chain (MC)</strong> and (2) a <strong>feedforward neural network (FNN)</strong></p>

<p>It’s important to note that I will disregard all forms of dynamics within a notated score (or performace), such as loudness, softness, etc.</p>

<p>Despite these two approaches being significantly outdated, I believe their demonstration serves as a valuable exercise for familiarizing oneself with the inherent challenges of the subject matter. 
The inspiration for this work comes from the tutorial series made by <a href="https://www.youtube.com/watch?v=FLr0r-QhqH0&amp;list=PL-wATfeyAMNr0KMutwtbeDCmpwvtul-Xz">Valerio Velardo’s</a> and another series made by <a href="https://www.youtube.com/@AndrejKarpathy">Andrej Karpathy’s</a>.</p>

<p>Although I utilize high-level libraries such as <a href="https://pytorch.org/">PyTorch</a> and take advantage of its <em>computational graph</em> and <em>autograd</em> features, I intend to maintain the model code and training process at a relatively low level.</p>

<h2 id="requirements">Requirements</h2>

<p>The necessary software requirements for this project include:</p>

<ul>
  <li><a href="https://www.python.org/">Python</a></li>
  <li><a href="https://pytorch.org/">PyTorch</a></li>
  <li><a href="http://web.mit.edu/music21/">Music21</a></li>
  <li><a href="https://github.com/BZoennchen/musical-interrogation/blob/main/preprocess.py">preprocessor.py</a> helpler class to deal with <code class="language-plaintext highlighter-rouge">krn</code>-files.</li>
  <li><a href="https://musescore.org/de">MuseScore</a> (optional)</li>
  <li><a href="https://jupyter.org/">Jupyter Notebook Environment</a> (optional)</li>
</ul>

<p>The database required can be found at <a href="http://kern.ccarh.org">EsAC</a>. The specific dataset I utilized is <a href="https://kern.humdrum.org/cgi-bin/ksdata?l=/essen/europa&amp;format=recursive">Folksongs from the continent of Europe</a> and for the purpose of this work, I will exclusively use the 1700 pieces found in the <code class="language-plaintext highlighter-rouge">./deutschl/erk</code> directory.</p>

<p>Let’s listen to one of these pieces:</p>

<audio controls="">
  <source src="/Pages/assets/audio/mel0567.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<h2 id="data-representation">Data Representation</h2>

<p>In <a href="/Pages/2023/04/02/musical-interrogation-I.html">Part I</a> of this series, I alluded to various implementations that utilize different input encodings. Naturally, the information we can leverage depends on the format of our training data. 
For instance, MIDI provides us with attributes such as pitch, duration, and velocity.
In my <a href="">implementation</a>, you will notice two distinct, yet straightforward encoding options available.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">GridEncoder</code> used by Valerio Velardo</li>
  <li><code class="language-plaintext highlighter-rouge">NoteEncoder</code></li>
</ol>

<p>The <code class="language-plaintext highlighter-rouge">GridEncoder</code> utilizes a fixed metrical grid where (a) output is generated for every timestep, and (b) the step size corresponds to a fixed meter (the shortest duration of any note in any score). For instance, if the shortest duration is a quarter note, a whole note of pitch 65 (in MIDI format) would result in the event series:</p>

<p><strong>65-note-on hold hold hold</strong></p>

<p>On the other hand, the <code class="language-plaintext highlighter-rouge">NoteEncoder</code> employs a larger alphabet and encodes one note directly, i.e.,</p>

<p><strong>65-whole</strong></p>

<p>In comparison to <em>note encoding</em>, <em>equitemporal grid encoding</em> relies on a smaller alphabet but needs more tokens for the same score.
This disadvantage is magnified if the score contains notes of vastly differing durations or if we wish to introduce micro-dynamics through an increase in resolution, as done by <a class="citation" href="#oore:2018">(Oore et al., 2018)</a>.</p>

<p>Interestingly, Google’s <a href="https://magenta.tensorflow.org/">Magenta project</a> employs <em>equitemporal grid encoding</em>, specifically the <a href="https://github.com/magenta/note-seq/blob/main/note_seq/melody_encoder_decoder.py">MelodyOneHotEncoding</a> class for their <em>BasicRNN</em>, <em>MonoRNN</em>, and <em>LookbackRNN</em>. 
Since they capture polyphonic scores, they utilize <strong>note-on</strong> and <strong>note-off</strong> events for each MIDI key.</p>

<p>Of course, the chosen representation also depends on the application and the capabilities of the model we use. 
For instance, one might only want to generate the pitches of the melody and manually adjust the duration of each note in post-processing. 
Furthermore, a <em>first-order Markov chain</em> only <em>memorizes</em> the most recent event. 
Therefore, an <em>equitemporal grid encoding</em> would yield unsatisfactory results because the context is lost after a <strong>hold</strong> event occurs.</p>

<p>As a result, in this post, I will focus on the <em>note encoding</em> approach, i.e. <code class="language-plaintext highlighter-rouge">NoteEncoder</code>.</p>

<h2 id="preprocessing">Preprocessing</h2>

<p>The procedure I’m about to present parallels the one detailed in <a href="/Pages/2022/07/09/markov-chains-for-music-generation.html">Probabilistic Melody Modeling</a>. 
The primary differences are that we’ll now be considering 1700 pieces instead of a single one, and we utilize more sophisticated libraries instead of relying solely on <a href="https://sonic-pi.net/">Sonic Pi</a>.</p>

<p>The <a href="http://web.mit.edu/music21/">Music21</a> library significantly simplifies the handling of symbolically notated music in <code class="language-plaintext highlighter-rouge">Python</code>.
I am not so familiar with it but it comes in handy when reading and writing symoblic scores.
It enables us to construct pieces programmatically and to read from or write to various musical score formats.</p>

<p>As an initial step, we need to import all the necessary libraries and functions.
Here I fix the global seed such that you can reproduce the exact same results.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">music21</span> <span class="k">as</span> <span class="n">m21</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">preprocess</span> <span class="kn">import</span> <span class="n">load_songs_in_kern</span><span class="p">,</span> <span class="n">NoteEncoder</span><span class="p">,</span> <span class="n">KERN_DATASET_PATH</span>

<span class="c1"># seed such that we can compare results
</span><span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
</code></pre></div></div>

<p>Then I read all the pieces inside the <code class="language-plaintext highlighter-rouge">./../deutschl/erk</code> directory.
Furthermore, I introduce a special character <code class="language-plaintext highlighter-rouge">TERM_SYMBOL</code> that I use to indicate the beginning and end of a score.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">TERM_SYMBOL</span> <span class="o">=</span> <span class="s">'.'</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">load_songs_in_kern</span><span class="p">(</span><span class="s">'./../deutschl/erk'</span><span class="p">)</span>
</code></pre></div></div>

<p>Now we have to think about our encoding.
As discussed above, I use the <code class="language-plaintext highlighter-rouge">NoteEncoder</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">encoder</span> <span class="o">=</span> <span class="n">NoteEncoder</span><span class="p">()</span>
<span class="n">enc_songs</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">encode_songs</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">enc_songs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<p>The code above prints out:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'55/4 60/4 60/4 60/4 60/4 64/4 64/4 r/4 ... 64/4 60/4 62/4 60/8 r/4'
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">'55/4</code> means MIDI note 55 four timesteps long where the timestep is determined by the shortest note within all scores. 
In our case this means four times 1/4 beat which is one whole beat.</p>

<p>Given that computers cannot process strings directly, I convert these strings into numerical values. 
The first step is to create a set that includes all possible strings. Subsequently, I assign each string a corresponding natural number in sequential order.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">symbols</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">item</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> 
                           <span class="n">enc_songs</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">])))</span>
<span class="n">stoi</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">symbols</span><span class="p">)}</span>
<span class="n">stoi</span><span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">itos</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">s</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">stoi</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'n_symbols: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">itos</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">stoi</code> maps <strong>s</strong>trings <strong>to</strong> <strong>i</strong>ntegers and <code class="language-plaintext highlighter-rouge">itos</code> is its inverse mapping.</p>

<h2 id="discrete-first-order-markov-chain">Discrete First-Order Markov Chain</h2>

<p>To implement a <em>first-order Markov chain</em>, we aim to construct a Markov matrix</p>

\[\mathbf{P} \in [0;1]^{m \times m}\]

<p>where the element at the \(i^{\text{th}}\) row and \(j^{\text{th}}\) column represents the conditional probability</p>

\[P(e_i\ | \ e_j) = p_{ij}.\]

<p>It describes the (conditional) probability of event \(e_i\) (a note or rest of specific length) immediately following event \(e_j\).
For this purpose, I construct a matrix \(\mathbf{N}\) that counts these transitions.</p>

<h3 id="markov-matrix-computation">Markov Matrix Computation</h3>

<p>To accomplish this, I iterate over each score, considering every pair of consecutive events. 
As the first event lacks a predecessor and the last lacks a successor, I append the unique terminal character <code class="language-plaintext highlighter-rouge">TERM_SYMBOL</code> to each score for padding purposes.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">N</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)))</span>
<span class="k">for</span> <span class="n">enc_song</span> <span class="ow">in</span> <span class="n">enc_songs</span><span class="p">:</span>
    <span class="n">chs</span> <span class="o">=</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">+</span> <span class="n">enc_song</span> <span class="o">+</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ch1</span><span class="p">,</span> <span class="n">ch2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chs</span><span class="p">,</span> <span class="n">chs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">ix1</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch1</span><span class="p">]</span>
        <span class="n">ix2</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch2</span><span class="p">]</span>
        <span class="n">N</span><span class="p">[</span><span class="n">ix1</span><span class="p">,</span> <span class="n">ix2</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div>

<p>To construct \(\mathbf{P}\) we have to divide each entry \(n_{ij}\) in \(\mathbf{N}\) by the sum over the row \(i\).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">P</span> <span class="o">=</span> <span class="n">N</span><span class="p">.</span><span class="nb">float</span><span class="p">()</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">P</span> <span class="o">/</span> <span class="n">P</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>In order to compute the sum over a row (instead of a column), i.e., “summing all columns”, we need to specify <code class="language-plaintext highlighter-rouge">dim=1</code> (the default is <code class="language-plaintext highlighter-rouge">dim=0</code>). 
Additionally, to properly exploit broadcasting, it’s necessary to set <code class="language-plaintext highlighter-rouge">keepdim=True</code>. 
This ensures that the sum results in a <code class="language-plaintext highlighter-rouge">(1,m)</code> tensor, as opposed to a <code class="language-plaintext highlighter-rouge">(m,)</code> tensor.</p>

<p>Plotting the probabilities reviels that \(\mathbf{P}\) is a rather sparse matrix containing many zeros.
In fact, only approximately 7.86 percent of the entries are non-zero.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/mc-probs.png" alt="Probabilities" />
<div style="display: table;margin: 0 auto;">Figure 1: Matrix plot of our Markov matrix.</div>
</div>
<p><br /></p>

<h3 id="sampling-of-new-melodies">Sampling of New Melodies</h3>

<p>Given the tensor <code class="language-plaintext highlighter-rouge">P</code>, we can generate new melodies using the function <code class="language-plaintext highlighter-rouge">torch.multinomial</code> which expects a probability (discrete) distribution.
I start with the terminal <code class="language-plaintext highlighter-rouge">TERM_SYMBOL</code> indicating the beginning and, when the second terminal is generated (which indicates the end), I terminate the generation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generated_encoded_song</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">char</span> <span class="o">=</span> <span class="n">TERM_SYMBOL</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">P</span><span class="p">[</span><span class="n">stoi</span><span class="p">[</span><span class="n">char</span><span class="p">]],</span> 
        <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
        <span class="n">replacement</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">item</span><span class="p">()</span>
    <span class="n">char</span> <span class="o">=</span> <span class="n">itos</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">char</span> <span class="o">==</span> <span class="n">TERM_SYMBOL</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">generated_encoded_song</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">generated_encoded_song</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s listen to some of the generated scores:</p>

<audio controls="">
  <source src="/Pages/assets/audio/gen0.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen1.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen2.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen3.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen4.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<h3 id="negative-log-likelihood-loss">Negative Log Likelihood Loss.</h3>

<p>The outcome is not particularly outstanding, but this is unsurprising given our very simple model. 
To evaluate the quality of our model, we can calculate the likelihood that our generative process produces for a specific training data point \(e_1, e_2, \ldots, e_k\), i.e.,</p>

\[P(e_1) \cdot P(e_2 \ | \ e_1) \cdot \ldots \cdot P(e_{k-1} \ | \ e_k).\]

<p>We can add all the likelihoods (one for each data point) together and divide the sum by the number of data points.
However, it is more convinient to use the <em>negative log-likelihood</em> since one can use addition.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">log_likelyhood</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">enc_songs</span><span class="p">:</span>
    <span class="n">chs</span> <span class="o">=</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">+</span> <span class="n">m</span> <span class="o">+</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ch1</span><span class="p">,</span> <span class="n">ch2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chs</span><span class="p">,</span> <span class="n">chs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">ix1</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch1</span><span class="p">]</span>
        <span class="n">ix2</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch2</span><span class="p">]</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="n">ix1</span><span class="p">,</span> <span class="n">ix2</span><span class="p">]</span>
        <span class="n">logprob</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
        <span class="n">log_likelyhood</span> <span class="o">+=</span> <span class="n">logprob</span>
        <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">log_likelyhood</span><span class="o">=</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">nll</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_likelyhood</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'avg negative log likelyhood: </span><span class="si">{</span><span class="p">(</span><span class="n">nll</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p>This gives us a <em>negative log-likelihood</em> of approximately <code class="language-plaintext highlighter-rouge">2.6756</code>.
The lower this value gets the better it is.
It can be no smaller than 0.</p>

<h2 id="feedforward-neural-network">Feedforward Neural Network</h2>

<p>One method of generating a melody using a <em>feedforward network (FFN)</em> is by addressing a classification task.
Well, strictly speaking we do not even build a FFN, since there will be no activation function involved thus it is a <strong>linear model</strong>.
However, from this starting point we could expand our model into a <em>multi-layer perceptron (MLP)</em>.
By avoiding the activation function, it is easier for me to explain exactly what is going on.</p>

<p>If we think in terms of classification a sequence of note should be classified as some successor note.
So let us assume \(t\) consecutive notes are given then our aim is to identify the note that this sequence “represents”.
For simplicity, I assume we only want to predict the next note given the previous one, that is, \(t=1\) holds.
This stipulation means we won’t require substantial modifications compared to our previous approach.</p>

<p>Since our training process will be more computationally intensive than merely computing frequencies, it’s advisable to use hardware accelerators, if available. 
This can result in faster training and inference times and lower energy costs.
To check if hardware acceleration is available, I employ the following code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">mps</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'mps'</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">)</span>
    
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">device</span><span class="o">=</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p>What we are going to implement is a <em>fully-visible softmax belief network</em> which only predicts the very next note given the previous note.
However, instead of multiplying \(x_1\) to predict \(x_2\) via</p>

\[h_{\theta}(x)_{j=1,\ldots,m} = \left(\alpha_0^{(j)} + \alpha_1^{(j)} \cdot x \right)_{j=1,\ldots,m},\]

<p>we do something similar but not quite the same.
We <em>hot-encode</em> our alphabet \(\mathcal{X}\) of notes into</p>

\[|\mathcal{X}| = m\]

<p>vectors \(\mathbf{x}_j = (x_1, \ldots, x_m)\), \(j=1, \ldots, m\) of length \(m\), such that,</p>

\[h_{\theta}(\mathbf{x}_i)_{j=1,\ldots,m} = \left( w_{1}^{(j)} \cdot x_1 + w_{2}^{(j)} \cdot x_2 + \ldots + w_{m}^{(j)} \cdot x_m \right)_{j=1,\ldots,m} = \left( w_{i}^{(j)} x_i \right)_{j=1,\ldots,m}.\]

<p>In other words, we compute an embedding of our alphabet/domain of notes such that each note is encoded by an \(m\)-dimensional vector.
This vector represents the probabilities of the next note.
To transform these embeddings into probabilities we apply the softmax function.
Our network is depicted in Fig. 2.
Note that we do not use a bias term, i.e., there is no replacement for \(\alpha_0^{(j)}\).</p>

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:75%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:75%;" src="/Pages/assets/images/fvsbn-hot.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 2: Fully-visible softmax belief network (multi-class classification with 4 classes) predicting only the next note utilizing hot-encoding. Only one input node fires 1 all the others fire 0. The illustration indicates that the second input is active while all other inptus are inactive.</div>
</div>
<p><br /></p>

<p>Similar as before, our loss is the empirical mean of the negative log likelyhood</p>

\[-\frac{1}{M} \sum_{i=1,j=y_i}^M \log(\sigma(\mathbf{o})_j),\]

<p>where \(j\) is the \(j^\text{th}\) note in our alphabet and \(y_i\), that is \((\mathbf{x}, y_j)\) is in our training data set.</p>

<h3 id="training-data-construction">Training Data Construction</h3>

<p>Instead of calculating our probability matrix, I am going to generate labeled training data using the variables <code class="language-plaintext highlighter-rouge">xs</code> and <code class="language-plaintext highlighter-rouge">ys</code> (labels).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">ys</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">enc_songs</span><span class="p">:</span>
    <span class="n">chs</span> <span class="o">=</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">+</span> <span class="n">m</span> <span class="o">+</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ch1</span><span class="p">,</span> <span class="n">ch2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chs</span><span class="p">,</span> <span class="n">chs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">ix1</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch1</span><span class="p">]</span>
        <span class="n">ix2</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch2</span><span class="p">]</span>
        <span class="n">xs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">ix1</span><span class="p">)</span>
        <span class="n">ys</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">ix2</span><span class="p">)</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># one-hot-encoding
</span><span class="n">xenc</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)).</span><span class="nb">float</span><span class="p">()</span>
</code></pre></div></div>

<p>As mentioned, I employ a <em><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html">one-hot encoding</a></em> for the input data.
That is, for encoding \(m\) unique elements one uses \(m\) unique \(m\)-dimensional vectors.
One component of these vectors is set to 1.0 and all others are 0.0.
<code class="language-plaintext highlighter-rouge">F.one_hot</code> assumes that our alphabet consists of whole numbers between 0 and \(m-1\), compare the <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html">documentation</a>.</p>

\[(0, \ldots, 0, 1, 0, \ldots, 0)\]

<p>The \(i^{\text{th}}\) element is represented by a vetor where the \(i^{\text{th}}\) component is 1.0.
Note that our labels <code class="language-plaintext highlighter-rouge">ys</code> are not one-hot encoded.</p>

<h3 id="training">Training</h3>

<p>Next, I initialize a random matrix \(\mathbf{W} \in [-1;1]^{m \times m}\), or tensor, <code class="language-plaintext highlighter-rouge">W</code> with values ranging from -1.0 to 1.0.
This tensor includes our trainable parameters, which represent the single layer of our neural network.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>Our network includes \(m\) inputs and outputs, with the <em><a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a></em> values of the outputs being interpreted as probabilities.
Essentially, our “network” is just one large matrix!</p>

<p>The operation <code class="language-plaintext highlighter-rouge">xenc @ W</code> represents a matrix multiplication where <code class="language-plaintext highlighter-rouge">xenc</code> is an \(1700 \times m\) matrix and <code class="language-plaintext highlighter-rouge">W</code> is our \(m \times m\) matrix.
Here I use the power of parallel computation.
By employing <code class="language-plaintext highlighter-rouge">probs[torch.arange(len(ys), device=device), ys]</code>, I address a single entry for each row.</p>

<p>Please note that <code class="language-plaintext highlighter-rouge">probs[:, ys]</code> does not work; instead of addressing a single entry, it addresses whole columns indexed by <code class="language-plaintext highlighter-rouge">ys</code>!
Also, be aware that I apply an unusually large learning rate.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># training aka gradient decent
</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">2_000</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># forward pass
</span>    <span class="n">logits</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W</span>
    <span class="n">odds</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">odds</span> <span class="o">/</span> <span class="n">odds</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'epoch </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    
    <span class="c1"># backward pass
</span>    <span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># set gradients to zero
</span>    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="c1"># update
</span>    <span class="n">W</span><span class="p">.</span><span class="n">data</span> <span class="o">+=</span> <span class="o">-</span><span class="mf">10.0</span> <span class="o">*</span> <span class="n">W</span><span class="p">.</span><span class="n">grad</span>
</code></pre></div></div>

<p>One iteration of the loop consist of the</p>

<ol>
  <li><em>forward pass</em></li>
  <li><em>backward pass</em> (backwardpropagation) done via <code class="language-plaintext highlighter-rouge">loss.backward()</code> and</li>
  <li>an update of our parameters done via <code class="language-plaintext highlighter-rouge">W.data += -10.0 * W.grad</code>.</li>
</ol>

<p><code class="language-plaintext highlighter-rouge">loss.backward()</code> applies <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> thus computes the gradients and we can update <code class="language-plaintext highlighter-rouge">W</code> by</p>

\[\mathbf{W} \leftarrow \mathbf{W} - \eta \cdot \nabla_\mathbf{W} L\]

<p>where \(\eta = 10\) is the <em>learning rate</em>.</p>

<p>After the initial 2000 epochs the loss is approximately <code class="language-plaintext highlighter-rouge">2.865</code>. 
This performance is somewhat inferior compared to the results achieved by our <em>Markov chain</em>. 
However, by prolonging the training period, I managed to reduce the loss to around <code class="language-plaintext highlighter-rouge">2.707</code>.</p>

<h3 id="what-is-going-on">What is going on?</h3>

<p>Let us assume we have only one sample \(\mathbf{x}\).</p>

<h4 id="forward-pass">Forward Pass:</h4>

<p>The <em>forward pass</em> starts with</p>

\[\mathbf{o} = \mathbf{x} \cdot \mathbf{W}\]

<p>where \(\mathbf{x}\) is a <em>one-hot encoded</em> training data point.
\(\mathbf{o}\) gets interpreted as (component-wise) logarithm of the odds</p>

\[\mathbf{o} = \ln\left(\frac{\mathbf{p}}{\mathbf{1}-\mathbf{p}}\right)\]

<p>which is the <a href="https://en.wikipedia.org/wiki/Logit">logit</a>, i.e., the inverse of the <em>standard logistic function</em> also called <em>sigmoid</em>.
In fact, each data point in \(\mathbf{x}\) selects one row of \(\mathbf{W}\)</p>

\[\mathbf{o} = \mathbf{x} \cdot \mathbf{W} = \begin{bmatrix} o_1 &amp; o_2 &amp; \ldots &amp; o_m \end{bmatrix}.\]

<p>To compute “probabilities” we compute the <em><a href="https://en.wikipedia.org/wiki/Softmax_function">softmax function</a></em> (<code class="language-plaintext highlighter-rouge">probs</code>) of \(\mathbf{o}\), i.e.,</p>

\[\sigma(\mathbf{o}) = \begin{bmatrix} \sigma(\mathbf{o})_1 &amp; \sigma(\mathbf{o})_2 &amp; \ldots &amp; \sigma(\mathbf{o})_m \end{bmatrix}\]

<p>with</p>

\[\sigma(\mathbf{o})_i = \frac{e^{o_i}}{\sum e^{o_j}}.\]

<p>Luckly the <em>softmax</em> has a simple derivative:</p>

\[\frac{\partial \sigma(\mathbf{o})_i}{\partial o_j} =
\begin{cases}
    \sigma(\mathbf{o}_k)_i - \sigma(\mathbf{o})_i^2 &amp; \text{ if } i = j \\
    -\sigma(\mathbf{o}_k)_i \sigma(\mathbf{o})_j &amp; \text{ otherwise.}
\end{cases}\]

<p>We can also compute the full Jacobian of the <em>softmax</em> vector-to-vector operation:</p>

\[\nabla_{\mathbf{o}} \sigma = \mathbf{J}_{\mathbf{o}}(\sigma) =
\begin{bmatrix} 
    \sigma_1 - \sigma_1^2 &amp; -\sigma_1 \sigma_2 &amp; \ldots &amp; - \sigma_1 \sigma_m  \\
    -\sigma_2 \sigma_1 &amp; s_2 - \sigma_2^2 &amp; \ldots &amp; -\sigma_2 \sigma_m \\
    \ldots &amp; \ldots &amp; \ldots &amp; \ldots \\
    -\sigma_m \sigma_1 &amp; -\sigma_m \sigma_2 &amp; \ldots &amp; \sigma_m - \sigma_m^2
\end{bmatrix} = \text{diag}\left(\sigma\right) - \sigma^{\top} \sigma\]

<p>Similar then before, our loss $L$ is the mean <em>negative log likelihood</em>.</p>

\[L(\mathbf{y}, \sigma) = -\sum\limits_{i=1}^{m} \log(s_i) = -\mathbf{y} \log(\sigma)^\top\]

<p>where \(\mathbf{y}\) is the one-hot encoded label vector, i.e.,</p>

<p><code class="language-plaintext highlighter-rouge">loss = -probs[torch.arange(len(ys), device=device), ys].log().mean()</code>.</p>

<p>Note that \(\mathbf{y}\) is a one-hot encoded vector, <code class="language-plaintext highlighter-rouge">ys</code> is not.</p>

<h4 id="backword-pass">Backword Pass:</h4>

<p>For the <em><a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a></em> we need</p>

\[\nabla_{\mathbf{W}} L(\mathbf{y}, \sigma) = \nabla_{\mathbf{o}} L(\mathbf{y}, \sigma) \cdot \nabla_{\mathbf{W}} \mathbf{o}.\]

<p>Here we employ the <em>chain rule</em>.
The sensitivity of cost \(L\) to the input to the softmax layer, \(\mathbf{o}\) is given by a gradient-Jacobian product, each of which we’ve already computed:</p>

\[\begin{align}
    \nabla_{\mathbf{o}} L(\mathbf{y}, \sigma) &amp;= -\nabla_{\mathbf{o}} \mathbf{y} \log(\sigma)^\top \\
    &amp;= -\mathbf{y} \nabla_{\mathbf{o}}\log(\sigma) \\
    &amp;= -\frac{\mathbf{y}}{\sigma} \nabla_{\mathbf{o}} \sigma \\
    &amp;= -\frac{\mathbf{y}}{\sigma} \cdot \mathbf{J}_{\mathbf{o}}(\sigma) \\
    &amp;= -\frac{\mathbf{y}}{\sigma} \cdot \left[ \text{diag}(\sigma) - \sigma^\top \sigma \right] \\
    &amp;= \frac{\mathbf{y}}{\sigma} \sigma^\top \sigma - \frac{\mathbf{y}}{\sigma} \text{diag}(\sigma) \\
    &amp;= \sigma - \mathbf{y}.
\end{align}\]

<p>The \(\log\) and the devision operates component-wise and</p>

\[\text{diag}\left(\sigma\right) =
\begin{bmatrix} 
    \sigma(\mathbf{o})_1 &amp; 0 &amp; \ldots &amp; 0  \\
    0 &amp; \sigma(\mathbf{o})_2 &amp; \ldots &amp; 0 \\
    \ldots &amp; \ldots &amp; \ldots &amp; \ldots \\
    0 &amp; 0 &amp; \ldots &amp; \sigma(\mathbf{o})_m
\end{bmatrix}\]

<p>holds.
We have to apply the <em>chain rule</em> once again to finally get the desired update values for our weight matrix \(\mathbf{W}\):</p>

\[\begin{align}
\nabla_{\mathbf{W}} L(\mathbf{y}, \sigma) &amp;= \nabla_{\mathbf{o}} L(\mathbf{y}, \sigma) \cdot \nabla_{\mathbf{W}} \mathbf{o} \\
&amp;= (\sigma - \mathbf{y}) \cdot \nabla_{\mathbf{W}} (\mathbf{x} \cdot \mathbf{W})\\
&amp;= (\sigma - \mathbf{y}) \cdot \mathbf{x}^{\top}.
\end{align}\]

<p>Given that \(\sigma\) represents probabilities, and \(\mathbf{y}\) contains only zeros except for one instance of 1 at the position of the “correct” probability, the entries of the \(j^\text{th}\) row (\(x_j=1\)) of the gradient is \(p_i\) if the \(i^\text{th}\) probability is deemed “incorrect”, and \((p_i-1)\) otherwise. 
All other entries are zero.
Note also that \(\mathbf{x}\) is also a one-hot encoded vector.
Consequently, if a probability is correct, it gets increased by \(1-p_i\) and decreased by \(p_i-1\) otherwise.
Therefore, probabilities that are more incorrect experience a larger increase or decrease.</p>

<p>We can actually check this result!
Using the following code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># use only 1 data point
</span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># one-hot-encoding
</span><span class="n">xenc</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)).</span><span class="nb">float</span><span class="p">()</span>

<span class="c1"># reinitiate W
</span><span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">logits</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">counts</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>
    
<span class="c1"># backward pass
</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> 
<span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">y</span><span class="p">[</span><span class="n">ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">print</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">))</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">))</span> <span class="c1"># all true
</span></code></pre></div></div>

<h4 id="batching">Batching:</h4>

<p>So far we only considered the math using a single data point \(\mathbf{x}\).
Let us consider a batch of points, i.e.,</p>

\[\mathbf{O} = \mathbf{X}\mathbf{W} = \begin{bmatrix} \mathbf{x}_1 \\ \mathbf{x}_2 \\ \vdots \\ \mathbf{x}_n \end{bmatrix} \mathbf{W}\]

<p>The <em>softmax</em> is still a vector-to-vector transformation, but it’s applied independently to each row of $\mathbf{X}$:</p>

\[\mathbf{S} = \begin{bmatrix} \sigma(\mathbf{o}_1) \\ \sigma(\mathbf{o}_2) \\ \vdots \\ \sigma(\mathbf{o}_n) \end{bmatrix}\]

<p>We can do the exact same steps but I will skip this part.
For the interested reader I refer to <a href="https://mattpetersen.github.io/softmax-with-cross-entropy"></a></p>

<p>Important is that</p>

\[\mathbf{J}_\mathbf{O}(L) = \mathbf{J}_\mathbf{S}(L) \mathbf{J}_\mathbf{O}(S) = \frac{1}{n} \left( \mathbf{S} - \mathbf{Y} \right)\]

<p>and</p>

\[\mathbf{J}_\mathbf{W}(L) = \mathbf{J}_\mathbf{S}(L) \mathbf{J}_\mathbf{O}(S) \mathbf{J}_\mathbf{W}(O) = \frac{1}{n} \left( \mathbf{S} - \mathbf{Y} \right) \mathbf{X}.\]

<p>We can also check this result:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># one-hot-encoding
</span><span class="n">xenc</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)).</span><span class="nb">float</span><span class="p">()</span>

<span class="c1"># reinitiate W
</span><span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> 

<span class="n">logits</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">counts</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>
    
<span class="c1"># backward pass
</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> 
<span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">y</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span><span class="n">ys</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">print</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">))</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">)))</span> <span class="c1"># true
</span></code></pre></div></div>

<h3 id="further-considerations">Further Considerations</h3>

<p>Now, the natural question is: what is the best possible performance we could achieve? 
The answer is that we should aim to match the performance of the <em>Markov chain</em>. 
Indeed, as the process continues, we should expect that the matrix <code class="language-plaintext highlighter-rouge">W</code> will gradually converge towards <code class="language-plaintext highlighter-rouge">P</code>.</p>

<p>Moreover, we should not anticipate surpassing the results achieved by our <em>Markov chain</em> even if we deepen our network, that is, by introducing some <em>hidden layers</em>.
A very good example of useful informations are described in <a class="citation" href="#johnson:2017">(Johnson, 2017)</a>, I discussed in <a href="/Pages/2023/04/02/musical-interrogation-I.html">Part I</a> of this series.
For instance, Johnson adds (compare his interesting <a href="https://www.danieldjohnson.com/2015/08/03/composing-music-with-recurrent-neural-networks/">Blog post</a>)</p>

<ul>
  <li><strong>Positional:</strong> note within the score (that is what we use)</li>
  <li><strong>Pitchclass:</strong> one of the twelve classes</li>
  <li><strong>Previous vicinity:</strong> surrounding notes where played or aticulated last timestep (only useful for polyphonic music)</li>
  <li><strong>Previous context:</strong> the amount of C’s, A’s and so on are played the last timestep (only useful for polyphonic music)</li>
  <li><strong>Beat:</strong> a binary representation of position within the measure</li>
</ul>

<p>However, our expectations may shift if we modify the input, referring to the data that the network processes. 
That being said, we could enhance the training duration.
For instance, introducing a <em>hidden layer</em> results in a loss of <code class="language-plaintext highlighter-rouge">2.693</code> after 2000 epochs.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">W1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">),</span> 
                 <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> 
                 <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">2_000</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># forward pass
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W1</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">W2</span>
    <span class="n">odds</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">odds</span> <span class="o">/</span> <span class="n">odds</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'epoch </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    
    <span class="c1"># backward pass
</span>    <span class="n">W1</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># set gradients to zero
</span>    <span class="n">W2</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># set gradients to zero
</span>    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="c1"># update
</span>    <span class="n">W1</span><span class="p">.</span><span class="n">data</span> <span class="o">+=</span> <span class="o">-</span><span class="mf">10.0</span> <span class="o">*</span> <span class="n">W1</span><span class="p">.</span><span class="n">grad</span>
    <span class="n">W2</span><span class="p">.</span><span class="n">data</span> <span class="o">+=</span> <span class="o">-</span><span class="mf">10.0</span> <span class="o">*</span> <span class="n">W2</span><span class="p">.</span><span class="n">grad</span>
</code></pre></div></div>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="oore:2018">Oore, S., Simon, I., Dieleman, S., Eck, D., &amp; Simonyan, K. (2018). <i>This time with feeling: Learning expressive musical performance</i>.</span></li>
<li><span id="johnson:2017">Johnson, D. D. (2017). Generating polyphonic music using tied parallel networks. <i>EvoMUSART</i>.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Music" /><category term="ML" /><category term="FFN" /><category term="MC" /><summary type="html"><![CDATA[The code shown here can be found in the following GitHub repository. In the second installment of this series, I introduce an initial and arguably the most basic method to generate monophonic melodies. This consists of two approaches: (1) A first-order Markov chain (MC) and (2) a feedforward neural network (FNN)]]></summary></entry><entry><title type="html">Replacing Code with ML Models</title><link href="https://bzoennchen.github.io/Pages/2023/04/23/wekinator.html" rel="alternate" type="text/html" title="Replacing Code with ML Models" /><published>2023-04-23T00:00:00+02:00</published><updated>2023-04-23T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/04/23/wekinator</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/04/23/wekinator.html"><![CDATA[<p>This blog post aims to explore how <em>machine learning</em> can empower creative practitioners to bring to life projects that traditionally demanded significant technical expertise, such as programming skills.
To make my case immediately understandable, I will provide a specific example.
However, it’s worth noting that this is just one of countless possible instances.</p>

<p>You can find all the necessary code in my GitHub repo: <a href="https://github.com/BZoennchen/algorithmic-compositions/tree/main/wekinator/firework-example">link</a>.</p>

<p>The example is based on the <a href="http://www.wekinator.org/">Wekinator</a>, which is a powerful, free, and open-source software designed to simplify the process of using <em>machine learning models</em>.
With its user-friendly interface, anyone can easily build new musical instruments, gestural game controllers, computer vision, computer listening systems, and much more. 
Developed by <a href="http://www.doc.gold.ac.uk/~mas01rf/">Rebecca Fiebrink</a>, the software aims to make digital systems more accessible to artists and musicians. 
Although Wekinator’s initial release (version 1.0) dates back to 2009, the software remains relevant today and has aged gracefully.</p>

<p>In her article <a class="citation" href="#fiebrink:2019">(Fiebrink, 2019)</a>, Fiebrink elaborates on her machine learning education practices for creative practitioners and highlights the benefits of using <a href="http://www.wekinator.org/">Wekinator</a>. 
More recently, she has been working on a new tool called <a href="https://interactml.com/">InteractML</a>, which is a more advanced tool for interactive machine learning via visual scripting with <a href="https://unity.com/de">Unity</a> <a class="citation" href="#clarice:2021">(Hilton et al., 2021)</a>. 
<a href="https://interactml.com/">InteractML</a> is a fascinating project that I plan to explore further at a later time. 
It is worth noting that the project is currently in alpha release and may only have limited documentation available.</p>

<p>One of the key advantages of the <a href="http://www.wekinator.org/">Wekinator</a> is its ease of use, making it accessible to a wide range of users.
The software’s versatility is due to its ability to <a href="https://en.wikipedia.org/wiki/Open_Sound_Control">open sound control (OSC)</a> messages, which are supported by numerous applications, especially in the artistic domain.
If other systems can communicate via OSC, they can be integrated (via network) into the larger system. 
For instance, most digital audio workstations (DAWs), <a href="https://processing.org/">Processing</a> (a renowned creative coding environment), <a href="https://derivative.ca/">TouchDesigner</a>, <a href="https://cycling74.com/products/max">Max/MSP</a>, <a href="https://puredata.info/">PureData</a>, <a href="https://supercollider.github.io/">SuperCollider</a> and APIs for popular programming languages support OSC.</p>

<p>To demonstrate the potential of the <a href="http://www.wekinator.org/">Wekinator</a>, I will be using <a href="https://processing.org/">Processing</a> and <a href="https://supercollider.github.io/">SuperCollider</a>, both of which are also free and open-source tools. 
<a href="https://supercollider.github.io/">SuperCollider</a> will be used to generate sound, while <a href="https://processing.org/">Processing</a> will capture human motion. 
The objective is not to showcase elaborate gesture recognition but to provide an overview of the Wekinator’s fundamental workings.</p>

<p>More than just discussing the <a href="http://www.wekinator.org/">Wekinator</a>, my aim is to provide readers with an understanding of how machine learning can supplant traditional programming, enabling non-experts to utilize techniques that were previously inaccessible to them.</p>

<p>We will observe how machine learning can replace coding, albeit with some coding required.
However, the coding required is specific to the task of sending and receiving OSC messages, and the tools utilized, i.e., <a href="https://supercollider.github.io/">SuperCollider</a> and <a href="https://processing.org/">Processing</a> which are both programming environments.
Other tools exist, which allow for sending OSC messages without any coding, and there are tools that produce sound without programming.</p>

<p>The following video demonstrates the final result and all the steps required.</p>

<div class="embed-container">
<iframe src="https://www.youtube.com/embed/lDkeOTQU2Y8" width="800" height="480" frameborder="0" allowfullscreen="true">
</iframe>
</div>

<h2 id="problem-description">Problem Description</h2>

<p>Digital synthesizers are synthetic instruments that generate sound by outputting a stream of floating point numbers.
These synthesizers typically have numerous parameters, such as frequency (pitch), cutoff frequency of a low-pass filter, frequency of the carrier, and several others.
Often these parameters are not <em>interpretable</em>, meaning there is no straightforward connection between a parameter and the sound a synth generates.
Instead, altering multiple parameters concurrently leads to the desired outcome.
In mathematics, we refer to these parameters as residing in a high-dimensional space.</p>

<p>Let’s consider the following scenario: We have a dancer in a rectangular area, such as a room, and we wish to modify the sound generated by a synth based on the dancer’s 2D position.
We aim to alter the synth’s parameters while it is playing (modulation) in response to the dancer’s movements. However, the changes in sound must be smooth and non-random.</p>

<p>Unfortunately, a significant problem arises in this situation. 
The number of parameters exceeds the number of positional values.
We only have two coordinates to work with, and establishing a one-to-one mapping between these coordinates and parameters is not feasible.
We want to avoid merely selecting two parameters and modifying them according to the dancer’s \(x\) and \(y\) coordinates.</p>

<p>In mathematical terms, we are looking for a function that receives \(2\) values (\(x\) and \(y\)) and outputs \(n\) values (one for each parameter), where \(n &gt; 2\).
We want a function</p>

\[f : \mathbb{R}^2 \rightarrow \mathbb{R}^n.\]

<p>Additionally, it is necessary for \(f\) to be smooth and meet our musical preferences. 
As \(f\) maps a lower-dimensional space to a higher-dimensional space and we require a seamless transition, we search for a two-dimensional <em>surface</em> in an \(n\)-dimensional space. 
As the dancer moves in the \(x\) and \(y\) directions, \(f\) translates this motion to a movement on the two-dimensional surface in the \(n\)-dimensional space.</p>

<p>If we have only one coordinate and three parameters, \(f\) represents a curve in the three-dimensional space.
In this case, we can draw it.
Compare Fig. 1.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/3d-curve.png" alt="2-D manifold" />
<div style="display:block; margin-left:auto; margin-right:auto; width:80%;">Figure 1: Sample points and fitted graph of a curve in a three-dimensional space. The length of the curve represents the dancer's single coordinate (let's say x). A point (X,Y,Z) on the curve represents three parameter values.</div>
</div>
<p><br /></p>

<p>This is a complex challenge, and several questions arise: How does \(f\) look like? 
How can we implement it?</p>

<h3 id="reasoning-about-the-world">Reasoning about the World</h3>

<p>Before the advent of machine learning, we would have addressed this problem using the “traditional way” of abstract reasoning and programming to implement the function \(f\) directly via code.
This approach involves roughly six steps:</p>

<ol>
  <li>observer and analyse the system</li>
  <li>construct a falsifiable mathematical model (which is an imperfect generalization)</li>
  <li>implement a numerical model via code</li>
  <li>calibrate the model</li>
  <li>test your assumption via observation until the model approximates reality adequately</li>
  <li>find unobserved phenomena, which the model implies, in the real world</li>
</ol>

<p>Newton’s discoveries serve as a classic example, where he observed reality and reasoned about it, generating laws that are incorrect but sufficiently accurate to travel to the moon. 
He established formulas such as</p>

\[F = m \cdot a,\]

<p>which are falsifiable via experiments.
With these formulas one can predict unknown phenomena that should appear if the model is reliable.</p>

<p>In our case, we would have conducted a comprehensive analysis of the synth to establish how its parameters interact with one another.
This approach would have required a wealth of knowledge across diverse domains such as programming, signal processing, and mathematics.
Furthermore, to achieve our desired sound, we would have needed to understand the impact of parameter changes on various aspects of the sound, such as pitch and timbre.</p>

<p>In essence, we would have aimed to create a model of the synth “world” to enable us to reason about its structures and rules.
We would have then written code to manipulate the \(n\) parameters concurrently, relative to the dancer’s position.</p>

<p>While I value the traditional approach for its ability to provide insights into actual and imaginative structures, it is not the optimal solution for our specific scenario. I believe that creative practitioners do not necessarily avoid analytical work but tend to focus on creation, thereby enabling a more tangible understanding of the problem. I welcome this approach, particularly in the field of machine learning.
In contrast, the traditional approach can be challenging and less accessible, particularly in achieving our artistic objectives.</p>

<h3 id="modelling-without-reasoning">Modelling without Reasoning</h3>

<p>In <em>machine learning</em>, the focus shifts to a <em>data-driven approach</em>.
Rather than constructing a model by hand through reasoning about the world, we enable machines to learn the model by providing them with data, i.e., observations.</p>

<p>In extreme cases when observation is the model, we cannot provide outputs of unobserved inputs.
Therefore, like models constructed manually, machine learning models are an imperfect abstraction of the data on which they are trained.
This is the fundamental idea behind machine learning, albeit an oversimplification.</p>

<p>In our scenario, we replace manual modeling with machine learning by defining what we want and letting the machine learning models provided by the <a href="http://www.wekinator.org/">Wekinator</a> figure out how to achieve it.
We present an algorithm $A$ with examples $D$ that represent our requirements and ask it to “program” a function \(f\) that fulfills our needs.</p>

<p><em>Machine learning</em> involves learning \(f\) from data \(D\) using algorithm \(A\), where \(A\) is essentially just another function that produces functions:</p>

\[A(D) = f\]

<p>The <a href="http://www.wekinator.org/">Wekinator</a> allows us to choose algorithm \(A\) from a list of algorithms and provides a graphical user interface (GUI) for recording \(D\) and feeding it into \(A\) to compute \(f\).
The algorithm \(A\) is predetermined, and \(f\) will be computed.
As a result, we need to provide data/observation \(D\) by recording it, so let’s get started!</p>

<p><strong>Disclaimer:</strong>
Utilizing <em>machine learning</em> does not imply that we cease rationalizing about the world.
However, I selected this thought-provoking title to accentuate the contrast in tendencies.
Moreover, the effectiveness and characteristics of <em>machine learning models</em> are significantly influenced by the quality of the observed data and the choice of algorithm.
Given that our challenge involves a <em>regression task</em>, we will employ a <em>feed-forward neural network</em>.</p>

<h2 id="realization">Realization</h2>

<p>In the following, we have a lot to set up since every part of the system is digital and our own creation.
However, do not worry if you do not understand the <a href="https://supercollider.github.io/">SuperCollider</a> or <a href="https://processing.org/">Processing</a> part.
It is more important to understand the principle of OSC communication and the <a href="http://www.wekinator.org/">Wekinator</a>.
If you are interested in <a href="https://supercollider.github.io/">SuperCollider</a> or <a href="https://processing.org/">Processing</a> I can highly recommend checking them out.</p>

<h3 id="creating-a-new-instrument">Creating a new Instrument</h3>

<p>First, we need an actual synthesizer that produces sound.
I use a synth that randomly produces a short resonating impulse that gets reflected.
I want to go into only a few details about the inner workings of the synth.
It creates a sound similar to a firework in a city perceived inside a room.</p>

<p>The synth has 6 parameters which are, in this case, explainable:</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">\densityleft</code> controls the number of impulses in the left speaker.</li>
  <li><code class="language-plaintext highlighter-rouge">\densityright</code> controls the number of impulses in the right speaker.</li>
  <li><code class="language-plaintext highlighter-rouge">\freq</code> controls the pitch of the impulse response (i.e., the sound). Higher frequency increases the pitch. (For <code class="language-plaintext highlighter-rouge">Ringz</code> it is the frequency at which the impulse resonates.)</li>
  <li><code class="language-plaintext highlighter-rouge">\cutofffreq</code> controls the cutoff frequency of the lowpass filter. Lower values make the sound more doll.</li>
  <li><code class="language-plaintext highlighter-rouge">\decaytime</code> controls the time it takes for the impulses to decay, influencing the resonance.</li>
  <li><code class="language-plaintext highlighter-rouge">\amp</code> controls the signal’s amplitude, i.e., the volume.</li>
</ol>

<p><code class="language-plaintext highlighter-rouge">Dust</code> outputs the impulse such that <code class="language-plaintext highlighter-rouge">Ringz</code> resonates.
The resulting signal gets reflected by <code class="language-plaintext highlighter-rouge">FreeVerb</code> which introduces reverberation.</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">SynthDef</span><span class="p">(</span><span class="sx">\fireworks</span><span class="p">,{</span>
    <span class="k">var</span> <span class="n">sig</span><span class="p">;</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="nc">Dust</span><span class="p">.</span><span class="n">ar</span><span class="p">([</span><span class="sx">\densityleft</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">3</span><span class="p">),</span> <span class="sx">\densityright</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">3</span><span class="p">)</span><span class="mf">-0.5</span><span class="p">]);</span>
	<span class="n">sig</span> <span class="o">=</span> <span class="nc">Ringz</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span>
		<span class="n">sig</span><span class="p">,</span> 
		<span class="nl">freq:</span> <span class="sx">\freq</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">300</span><span class="p">),</span> 
		<span class="nl">decaytime:</span> <span class="sx">\decaytime</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span> <span class="o">*</span> <span class="sx">\amp</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">0.55</span><span class="p">);</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="nc">FreeVerb</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">);</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="nc">LPF</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span><span class="nl">in:</span> <span class="n">sig</span><span class="p">,</span> <span class="nl">freq:</span> <span class="sx">\cutofffreq</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">21000</span><span class="p">));</span>
    <span class="nc">Out</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="n">sig</span><span class="p">);</span>
<span class="p">}).</span><span class="n">add</span><span class="p">;</span>
<span class="p">)</span>
</code></pre></div></div>

<p>We can play the synth and manipulate its parameters on the fly.
Let’s listen but be warned since the amplitude during this example will change.</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="vg">~fireworks</span> <span class="o">=</span> <span class="nc">Synth</span><span class="p">(</span><span class="sx">\fireworks</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\amp</span><span class="p">,</span> <span class="mf">1</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\densityleft</span><span class="p">,</span> <span class="mf">10</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\freq</span><span class="p">,</span> <span class="mf">400</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\decaytime</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">free</span><span class="p">();</span>
</code></pre></div></div>

<audio controls="">
  <source src="/Pages/assets/audio/fireworks.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<p>Ok cool, we can play sound.</p>

<h3 id="simulation-of-the-dancer">Simulation of the Dancer</h3>

<p>Next, let’s envision a dancer gracefully moving across the room. 
While I am not a dancer, nor do I possess sensors to measure a dancer’s position, we can simulate this scenario using <a href="https://processing.org/">Processing</a>. 
It’s worth mentioning that we could achieve the same result with SuperCollider, as it also features GUI elements. 
However, I’d like to demonstrate how we can effortlessly integrate multiple systems.</p>

<p>You can download the <a href="https://processing.org/">Processing</a> example at this <a href="http://www.doc.gold.ac.uk/~mas01rf/WekinatorDownloads/wekinator_examples/all_source_zips/Simple_Mouse_DraggedObject_2Inputs.zip">link</a>. 
I will provide the code below, but please don’t be intimidated. 
It simply consists of a draggable green square, accompanied by informative log text displayed on a black window, and an OSC sender. 
Dragging the green square simulates the dancer’s movement, while the application continuously transmits the rectangle’s central position over the network.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/simple_mouse_drag.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 2: Running Processing sketch.</div>
</div>
<p><br /></p>

<p>If you start the sketch in <a href="https://processing.org/">Processing</a>, you should see the window shown in Fig. 2.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**
* REALLY simple processing sketch that sends 
* mouse x and y position of box to wekinator
* This sends 2 input values to port 6448 using message /wek/inputs
* Adapated from https://processing.org/examples/mousefunctions.html 
* by Rebecca Fiebrink
**/</span>

<span class="kn">import</span> <span class="nn">oscP5.*</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">netP5.*</span><span class="o">;</span>

<span class="nc">OscP5</span> <span class="n">oscP5</span><span class="o">;</span>
<span class="nc">NetAddress</span> <span class="n">dest</span><span class="o">;</span>
<span class="nc">PFont</span> <span class="n">f</span><span class="o">;</span>

<span class="kt">float</span> <span class="n">bx</span><span class="o">;</span>
<span class="kt">float</span> <span class="n">by</span><span class="o">;</span>
<span class="kt">int</span> <span class="n">boxSize</span> <span class="o">=</span> <span class="mi">30</span><span class="o">;</span>
<span class="kt">boolean</span> <span class="n">overBox</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
<span class="kt">boolean</span> <span class="n">locked</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
<span class="kt">float</span> <span class="n">xOffset</span> <span class="o">=</span> <span class="mf">0.0</span><span class="o">;</span> 
<span class="kt">float</span> <span class="n">yOffset</span> <span class="o">=</span> <span class="mf">0.0</span><span class="o">;</span>

<span class="kt">void</span> <span class="nf">setup</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">createFont</span><span class="o">(</span><span class="s">"Courier"</span><span class="o">,</span> <span class="mi">15</span><span class="o">);</span>
    <span class="n">textFont</span><span class="o">(</span><span class="n">f</span><span class="o">);</span>

    <span class="n">size</span><span class="o">(</span><span class="mi">640</span><span class="o">,</span> <span class="mi">480</span><span class="o">,</span> <span class="no">P2D</span><span class="o">);</span>
    <span class="n">noStroke</span><span class="o">();</span>
    <span class="n">smooth</span><span class="o">();</span>
    
    <span class="n">bx</span> <span class="o">=</span> <span class="n">width</span><span class="o">/</span><span class="mf">2.0</span><span class="o">;</span>
    <span class="n">by</span> <span class="o">=</span> <span class="n">height</span><span class="o">/</span><span class="mf">2.0</span><span class="o">;</span>
    <span class="n">rectMode</span><span class="o">(</span><span class="no">RADIUS</span><span class="o">);</span>  
    
    <span class="cm">/* start oscP5, listening for incoming messages at port 12000 */</span>
    <span class="n">oscP5</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscP5</span><span class="o">(</span><span class="k">this</span><span class="o">,</span><span class="mi">9000</span><span class="o">);</span>
    <span class="n">dest</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">NetAddress</span><span class="o">(</span><span class="s">"127.0.0.1"</span><span class="o">,</span><span class="mi">6449</span><span class="o">);</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">draw</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">background</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span>
    <span class="n">fill</span><span class="o">(</span><span class="mi">255</span><span class="o">);</span>
    <span class="n">text</span><span class="o">(</span><span class="s">"x="</span> <span class="o">+</span> <span class="n">bx</span> <span class="o">+</span> <span class="s">", y="</span> <span class="o">+</span> <span class="n">by</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">80</span><span class="o">);</span>
    
    <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">200</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>

    <span class="c1">// Test if the cursor is over the box </span>
    <span class="k">if</span> <span class="o">(</span><span class="n">mouseX</span> <span class="o">&gt;</span> <span class="n">bx</span><span class="o">-</span><span class="n">boxSize</span> <span class="o">&amp;&amp;</span> <span class="n">mouseX</span> <span class="o">&lt;</span> <span class="n">bx</span><span class="o">+</span><span class="n">boxSize</span> <span class="o">&amp;&amp;</span> 
        <span class="n">mouseY</span> <span class="o">&gt;</span> <span class="n">by</span><span class="o">-</span><span class="n">boxSize</span> <span class="o">&amp;&amp;</span> <span class="n">mouseY</span> <span class="o">&lt;</span> <span class="n">by</span><span class="o">+</span><span class="n">boxSize</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">overBox</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span>  
        <span class="k">if</span><span class="o">(!</span><span class="n">locked</span><span class="o">)</span> <span class="o">{</span> 
        <span class="n">stroke</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span> 
        <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
        <span class="o">}</span> 
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="n">stroke</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
        <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
        <span class="n">overBox</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
    <span class="o">}</span>
    
    <span class="c1">// Draw the box</span>
    <span class="n">rect</span><span class="o">(</span><span class="n">bx</span><span class="o">,</span> <span class="n">by</span><span class="o">,</span> <span class="n">boxSize</span><span class="o">,</span> <span class="n">boxSize</span><span class="o">);</span>
    
    <span class="c1">//Send the OSC message with box current position</span>
    <span class="n">sendOsc</span><span class="o">();</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">mousePressed</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">if</span><span class="o">(</span><span class="n">overBox</span><span class="o">)</span> <span class="o">{</span> 
        <span class="n">locked</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span> 
        <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="n">locked</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="n">xOffset</span> <span class="o">=</span> <span class="n">mouseX</span><span class="o">-</span><span class="n">bx</span><span class="o">;</span> 
    <span class="n">yOffset</span> <span class="o">=</span> <span class="n">mouseY</span><span class="o">-</span><span class="n">by</span><span class="o">;</span> 
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">mouseDragged</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">if</span><span class="o">(</span><span class="n">locked</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">bx</span> <span class="o">=</span> <span class="n">mouseX</span><span class="o">-</span><span class="n">xOffset</span><span class="o">;</span> 
        <span class="n">by</span> <span class="o">=</span> <span class="n">mouseY</span><span class="o">-</span><span class="n">yOffset</span><span class="o">;</span> 
    <span class="o">}</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">mouseReleased</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">locked</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">sendOsc</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">OscMessage</span> <span class="n">msg</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscMessage</span><span class="o">(</span><span class="s">"/wek/inputs"</span><span class="o">);</span>
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">bx</span><span class="o">);</span> 
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">by</span><span class="o">);</span>
    <span class="n">oscP5</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">msg</span><span class="o">,</span> <span class="n">dest</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>When we start the Processing sketch, it shows a green square inside a black window.
The window represents our room, and the green square the dancer.
You can drag the dancer around.</p>

<h3 id="osc-communication">OSC Communication</h3>

<p>The only crucial part of the <a href="https://processing.org/">Processing</a> sketch’s code is the transmission of OSC messages..</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">oscP5</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscP5</span><span class="o">(</span><span class="k">this</span><span class="o">,</span><span class="mi">9000</span><span class="o">);</span>
<span class="n">dest</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">NetAddress</span><span class="o">(</span><span class="s">"127.0.0.1"</span><span class="o">,</span><span class="mi">6448</span><span class="o">);</span>
</code></pre></div></div>

<p>These three lines of code enable the sketch to listen for OSC messages over the network using the IP address <code class="language-plaintext highlighter-rouge">"127.0.0.1"</code>, which represents the local IP address. 
This means that the sketch listens for messages originating from your device. 
It receives messages on port <code class="language-plaintext highlighter-rouge">9000</code> and transmits them to port <code class="language-plaintext highlighter-rouge">6448</code>. 
The listening port is inconsequential, as the dancer never responds to incoming signals. 
The IP address and sending port are crucial because they must correspond with the numbers we will employ in the <a href="http://www.wekinator.org/">Wekinator</a>.</p>

<p>The following code</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">sendOsc</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">OscMessage</span> <span class="n">msg</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscMessage</span><span class="o">(</span><span class="s">"/wek/inputs"</span><span class="o">);</span>
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">mouseX</span><span class="o">);</span> 
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">mouseY</span><span class="o">);</span>
    <span class="n">oscP5</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">msg</span><span class="o">,</span> <span class="n">dest</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>sends the coordinates \(x\) and \(y\) of the mouse (with respect to the window) to the port <code class="language-plaintext highlighter-rouge">6448</code> and the path <code class="language-plaintext highlighter-rouge">'/wek/inputs'</code>. 
OSC uses these paths such that it is possible to differentiate different types of messages that got sent to some port.</p>

<p>Now we have to set up OSC communication of our sound generating system, i.e. <a href="https://supercollider.github.io/">SuperCollider</a>.
Let us first listen to port <code class="language-plaintext highlighter-rouge">6448</code>and path <code class="language-plaintext highlighter-rouge">'/wek/inputs'</code> and let’s just print the raw data we perceive, i.e., the \(x\) and \(y\) values of our dancer (the green square).</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">OSCdef</span><span class="p">(</span>
    <span class="sx">\getCoords</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="k">arg</span> <span class="n">val</span><span class="p">;</span> <span class="n">val</span><span class="p">.</span><span class="n">postln</span><span class="p">;</span>
    <span class="p">},</span>
    <span class="sx">'/wek/inputs'</span><span class="p">,</span>
    <span class="nl">recvPort:</span> <span class="mf">6448</span>
<span class="p">);</span>
<span class="p">)</span>
</code></pre></div></div>

<p>By executing this line in <a href="https://supercollider.github.io/">SuperCollider</a> while the <a href="https://processing.org/">Processing</a> sketch is running, you should see OSC messages on the post window.
These messages look like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[ /wek/inputs, 248.0, 185.0 ]
</code></pre></div></div>

<p>Now, let’s take it a step further and modify two synth parameters based on these values. 
The following code maps \(x\) and \(y\) to a suitable range. 
While \(x\) ranges from 0 to 650 and \(y\) from 0 to 460, we aim to obtain values between 0.1 and 20.</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">OSCdef</span><span class="p">(</span>
    <span class="sx">\getCoords</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="k">arg</span> <span class="n">val</span><span class="p">;</span> <span class="k">var</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="mf">1</span><span class="p">];</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="mf">2</span><span class="p">];</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\leftdensity</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">650</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\rightdensity</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">460</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
    <span class="p">},</span>
    <span class="sx">'/wek/inputs'</span><span class="p">,</span>
    <span class="nl">recvPort:</span> <span class="mf">6448</span>
<span class="p">);</span>
<span class="p">)</span>
</code></pre></div></div>

<p>The impact of this code should be noticeable in the audio output. When the dancer is positioned at the top left, fewer impulses are produced.
If situated at the bottom right, impulses emit from both speakers, while being at the bottom left results in only the right speaker activating.
This effect may not seem extraordinary, as our function \(f\) is quite elementary, involving a linear mapping from one interval to another.</p>

<h3 id="the-machine-in-the-middle">The Machine in the Middle</h3>

<p>We now introduce the <a href="http://www.wekinator.org/">Wekinator</a> in the middle of the communication.
That is, the dancer sends their position to the <a href="http://www.wekinator.org/">Wekinator</a>, and <a href="https://supercollider.github.io/">SuperCollider</a> listens to the messages from the <a href="http://www.wekinator.org/">Wekinator</a> and changes the values of the synth accordingly.
The <a href="http://www.wekinator.org/">Wekinator</a> translates positions into synth parameters, and it realizes the function \(f\).
The 6 output signals</p>

\[(v_1, \ldots, v_6) = f(x,y)\]

<p>are sent to <a href="https://supercollider.github.io/">SuperCollider</a>.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/wekinator.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 3: Overview of all the connected parts.</div>
</div>
<p><br /></p>

<p>First, we need to modify the port <a href="https://supercollider.github.io/">SuperCollider</a> listens to by changing the line from <code class="language-plaintext highlighter-rouge">recvPort: 6448</code> to <code class="language-plaintext highlighter-rouge">recvPort: 7448</code>.
Additionally, we should update the path to <code class="language-plaintext highlighter-rouge">'/wek/outputs'</code> as a reminder that we are receiving output signals from Wekinator.</p>

<p>Secondly, we must utilize the values we receive. Wekinator consistently sends a value between 0 and 1 for each dimension. 
As a result, we need to map the interval [0;1] to appropriate synth values.
This step is critical and necessitates some understanding of the synth. 
I employ the following mapping (note that we skip <code class="language-plaintext highlighter-rouge">val[0]</code> since it represents the OSC path):</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">OSCdef</span><span class="p">(</span>
    <span class="sx">\getCoords</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="k">arg</span> <span class="n">val</span><span class="p">;</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\densityleft</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">1</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\densityright</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">2</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\freq</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">3</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">100</span><span class="p">,</span> <span class="mf">700</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\amp</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">4</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">0</span><span class="p">,</span> <span class="mf">2</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\decaytime</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">5</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\cutofffreq</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">6</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">200</span><span class="p">,</span> <span class="mf">20000</span><span class="p">));</span>
    <span class="p">},</span>
    <span class="sx">'/wek/outputs'</span><span class="p">,</span>
    <span class="nl">recvPort:</span> <span class="mf">7448</span>
<span class="p">);</span>
<span class="p">)</span>
</code></pre></div></div>

<p><strong>If you use <a href="https://supercollider.github.io/">SuperCollider</a> be careful with your choices and protect your ears</strong> since it will try to use even unreasonable values like an amplitude of 10 or higher.</p>

<p>Now we start the <a href="http://www.wekinator.org/">Wekinator</a>.
First, we have to specify the port for the input signals of \(f\), i.e., the dancer’s position.
This is equal to <code class="language-plaintext highlighter-rouge">6448</code>, and the OSC path is <code class="language-plaintext highlighter-rouge">'/wek/inputs'</code>.
Then we have to specify the port of the output signal \(f(x,y)\), i.e., the port used in SuperCollider, which is <code class="language-plaintext highlighter-rouge">7448</code> furthermore, we specify a path <code class="language-plaintext highlighter-rouge">'/wek/outputs'</code> such that we do not confuse input and output.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/wekinator-screen-started.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 4: Wekinator after it has started.</div>
</div>
<p><br /></p>

<p>Furthermore, we have to tell the <a href="http://www.wekinator.org/">Wekinator</a> about the number of inputs and outputs, i.e., 2 and 6, respectively.
After everything is set up, we can click on <code class="language-plaintext highlighter-rouge">Start Listening</code>.
Then we can click <code class="language-plaintext highlighter-rouge">Next</code>.</p>

<p>Now you will see the following screen.
In the top left <code class="language-plaintext highlighter-rouge">OSC In</code> should be green, since the <a href="https://processing.org/">Processing</a> sketch is sending messages.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/wekinator-screen.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 5: Wekinator before training.</div>
</div>
<p><br /></p>

<p>If this is not the case, you either forgot to click <code class="language-plaintext highlighter-rouge">Start Listening</code>, or the port is already used. 
In that case, change the port in the <a href="http://www.wekinator.org/">Wekinator</a> as well in your <a href="https://processing.org/">Processing</a> sketch and restart the sketch.
You also should see 6 sliders.
If you manipulate these sliders, <code class="language-plaintext highlighter-rouge">OSC Out</code> should turn green, indicating that we are sending OSC messages to <a href="https://supercollider.github.io/">SuperCollider</a>.</p>

<p>Furthermore, the sound should change accordingly.
Make sure your amplitude is not zero.
Now you can play around with the sliders or press the <code class="language-plaintext highlighter-rouge">random</code> button until you hear something you like.
Of course, you have to remember which slider represents which parameter.</p>

<p>To connect the sound to the dancer’s position, we have to</p>

<ol>
  <li>record samples, i.e., construct the data set \(D\)</li>
  <li>train the model, i.e. compute \(f = A(D)\).</li>
</ol>

<p>To construct \(D\) we need multiple tuples</p>

\[(\text{input}, \text{output}) = ((x,y), (v_1, \ldots, v_6)).\]

<p>First, we move the square to a desired position and choose a set of desired parameters \((v_1, \ldots, v_6)\).
Next, we click <code class="language-plaintext highlighter-rouge">Start Recording</code>, and after a few seconds, we press <code class="language-plaintext highlighter-rouge">Stop Recording</code>.
In doing so, we generate portions of the data \(D\).
We repeat this step multiple times until we have accumulated sufficient data \(D\).</p>

<p>Once completed, we press <code class="language-plaintext highlighter-rouge">Train</code> to compute</p>

\[A(D) = f.\]

<p>This process should only take a few seconds.</p>

<p>Finally, we can utilize \(f\) by clicking <code class="language-plaintext highlighter-rouge">Run</code>.
At this point, both <code class="language-plaintext highlighter-rouge">OSC In</code> and <code class="language-plaintext highlighter-rouge">OSC Out</code> indicators should be green, and as you move the square around, the sound should change accordingly. 
Moreover, all parameters (assuming they were all manipulated during recording) should transition smoothly.</p>

<h3 id="different-algorithms">Different Algorithms</h3>

<p>Keep in mind that we did not specify any algorithm A.
By default, <a href="http://www.wekinator.org/">Wekinator</a> employs a <em>feed-forward neural network</em> and assumes a <em>regression task</em>.
This means that the output \(f(x,y)\) is continuous and does not represent an element within a finite set of classes.</p>

<p>You can choose algorithms by modifying the <code class="language-plaintext highlighter-rouge">Type</code> setting, as shown in Fig. 4. 
This selection includes classification algorithms. 
For instance, if you wish to establish a mapping between a gesture captured by your webcam and a specific sample, this would be a classification task. Another example would be classifying the type of instrument being played.</p>

<p><a href="http://www.wekinator.org/">Wekinator</a> has some limitations regarding the range of algorithms it offers, as the user lacks control over the model architecture and the model’s hyperparameters.</p>

<h2 id="summary">Summary</h2>

<p><a href="http://www.wekinator.org/">Wekinator</a> is an outstanding tool that makes certain aspects of machine learning accessible.
Its compatibility with OSC allows for seamless integration into various systems. It is an ideal fit for quick experimentation and serves as a valuable tool for teaching creative practitioners the fundamentals of machine learning on an intuitive level.</p>

<p>However, it does feel somewhat dated and experimental, offering no control over the hyperparameters of its built-in models.
Additionally, it does not utilize the latest software libraries, such as <code class="language-plaintext highlighter-rouge">PyTorch</code> or <code class="language-plaintext highlighter-rouge">TensorFlow</code>.
Being a Java application, it supports all operating systems, but <code class="language-plaintext highlighter-rouge">Java</code> is a relatively uncommon programming language in the field of machine learning.</p>

<p>The concept behind <a href="http://www.wekinator.org/">Wekinator</a> is exceptional, and it shouldn’t be too challenging to create a similar tool in Python, enabling artists or developers to integrate their own PyTorch or TensorFlow models. It supports the goal of making machine learning accessible to everyone and provides valuable insights into the features that ML tools for non-experts should offer. Perhaps we can develop new tools to break down even more barriers, allowing practitioners and developers to learn from one another.</p>

<p>In any case, if you’re interested in experimenting with simple machine learning models that process various types of generated input, give <a href="http://www.wekinator.org/">Wekinator</a> a try.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="fiebrink:2019">Fiebrink, R. (2019). Machine learning education for artists, musicians, and other creative practitioners. <i>ACM Trans. Comput. Educ.</i>, <i>19</i>(4). https://doi.org/10.1145/3294008</span></li>
<li><span id="clarice:2021">Hilton, C., Plant, N., González Dı́az Carlos, Perry, P., Gibson, R., Martelli, B., Zbyszynski, M., Fiebrink, R., &amp; Gillies, M. (2021). InteractML: Making machine learning accessible for creative practitioners working with movement interaction in immersive media. <i>Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology</i>. https://doi.org/10.1145/3489849.3489879</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="ML" /><category term="Wekinator" /><category term="Music" /><summary type="html"><![CDATA[This blog post aims to explore how machine learning can empower creative practitioners to bring to life projects that traditionally demanded significant technical expertise, such as programming skills. To make my case immediately understandable, I will provide a specific example. However, it’s worth noting that this is just one of countless possible instances.]]></summary></entry><entry><title type="html">Musical Interrogation I - Intro</title><link href="https://bzoennchen.github.io/Pages/2023/04/02/musical-interrogation-I.html" rel="alternate" type="text/html" title="Musical Interrogation I - Intro" /><published>2023-04-02T00:00:00+02:00</published><updated>2023-04-02T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/04/02/musical-interrogation-I</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/04/02/musical-interrogation-I.html"><![CDATA[<blockquote>
  <p>Whereas the human mind, conscious of its conceived purpose, approaches even an artificial system with a selective attitude and so becomes aware of only the preconceived implications of the system, the computers would show the total of available content. Revealing far more than only the tendencies of the human mind, this nonselective picture of the mind-created system should be of significant importance. – Gerbert Brün (1970)</p>
</blockquote>

<p>In this series of posts, I will talk about melody generation using <em>machine learning</em>. I start by reflecting on computer music. Furthermore, I give a short and selective overview of some techniques to generate melodies that captured my interest, focusing on <em>recurrent neural networks (RNN)</em> to generate <em>monophonic</em> melodies for now.</p>

<p>I intend to build an interactive system that facilitates the musical dialog between humans and machines. In the end, a user should be able to interrogate the machine learning model such that an evaluation of the model’s ability is possible and maybe – a big maybe – users can enhance their creative process.</p>

<h2 id="reflection-on-computer-music">Reflection on Computer Music</h2>

<p>Due to the recent advances in <em>machine learning</em>, especially in the domain of <em>deep learning</em>, <em>computer music</em> is regaining attraction.
What started in the early 1960th, when <em>rule-based</em> methods such as <em>Markov chains</em>, <em>hidden Markov models (HMM)</em>, <em>generative grammars</em>, <em>chaotic systems</em>, and <em>cellular automata</em> were applied to generate musical compositions, slowed down over the years.
Of course, since then, computers have always accompanied music production, but algorithms have taken a backseat when it comes to the structure of music itself.
Today, a reinvigoration of <em>computer music</em> might happen, but what will be at the forefront?
The algorithm? The artist? Or a massive amount of data?</p>

<p>In his book <em>Algorithmic Composition: Paradigms of Automated Music Generation</em> <a class="citation" href="#nierhaus:2010">(Nierhaus, 2009)</a> <em>Gerhard Nierhaus</em> makes an essential distinction between <strong>genuine composition</strong> and <strong>style imitation</strong>.
This terminology can bring nuances into the discussion around machines, algorithms, and data replacing human creativity.</p>

<p><strong>Style imitation</strong> is more applicable when music is not the main focus of interest but amplifies or accompanies something else, e.g., ads, computer games, or movies.
In a computer game, you want music that captures the dynamic situation of the game; thus, surprises are undesirable.</p>

<p><strong>Genuine composition</strong> appeals more to the artist who wants to play, experiment, and break things or criticize narratives.
<em>Genuine composition</em> seduces the audiance’s desire for experimentation, confrontation, and reflection on something new and unexpected.</p>

<p>While <em>genuine composition</em> carries much novelty, <em>style imitation</em> can be categorized into a set of preexisting styles of musical compositions.
The results generated by different techniques lean more or less towards one or the other.
For example, compositions generated by <em>Markov chains</em> (see <a href="/Pages/2022/07/09/markov-chains-for-music-generation.html">Probabilistic Melody Modeling</a>) lean more towards <em>style imitation</em> since the model samples from a learned distribution to estimate the structure of a particular composition.
On the other hand, using <em>cellular automata</em> is a technique more suited for <em>genuine composition</em> because no learning is involved.
Instead, <em>cellular automata</em> are <em>dynamic systems</em> capable of complex emergent behavior that can not be explained by solely looking at the parts of the system.
Of course, there is no black and white.
Instead, each composition or technique lives on a spectrum, and it might be impossible to decide where exactly.
If a <em>machine learning model</em> learns some non-obvious high-level structure, i.e., a probability distribution, from its training data, does this yield novelty or not?
It depends, I guess.</p>

<p>However, this “problem” is old, isn’t it?
Looking at the history of classical Western music, there are moments in time when it seemed that nothing was left to say and <em>style imitation</em> was inevitable.
For example, after one of the most quintessential romantic composers, <em>Richard Wagner</em>, there were view possibilities left concerning tonal music.
Consequently, the need for more chromaticism and dissonance was unavoidable, leading to the extreme case of Schönberg’s atonal compositions.</p>

<p>Concerning <em>artificial intelligence</em>, our current century is an era of <em>deep learning models</em> for which model size, data, parameters, and training time are more important than the underlying algorithm.
These models can combine, alter, and re-synthesis music from recorded history.
This re-combination and alteration seem similar to human composers’ working process, which is primed by their environment, education, and culture.
There is no doubt that these models can create music via <em>style imitation</em> but how good are they regarding <em>genuine composition</em>?
Is not learning from existing data <em>style imitation</em> per definition?
Well, again, even if all the data is known, one can argue that there are hidden high-level structures within the data that we are entirely unaware of.
A prime example is discovering a new way to multiply small matrices found via <em>reinforcement learning</em> <a class="citation" href="#alhussein:2022">(Fawzi et al., 2022)</a>.</p>

<p>If machines, revealing these structures, are creative is a question that can hardly be answered objectively, but, after all, the question might not be of great interest.
I instead look at the human condition and ask what such machines mean for our being in the world.
And here, we can say that if we do not try to understand our new black boxes, we rob ourselves of the experience of understanding, which, I think, is a fundamental desire.
But at the same time, if we do not give up understanding but enhance it with machine power (seen as a tool), the reverse can be true.
Beyond a lack of understanding, the lack of experienced practice is the more obvious loss we suffer.
The uncomfortable mood I sometimes develop when the achievements of AI shimmer through my perception comes from a fear of losing my habituated being in the world.
I ask myself: will machines write my code? Will I lose the enjoyment that I get out of coding?
Will I lose my identity as a programmer?
However, this loss has more to do with technology and economics.
We think of technology as a natural evolutionary force that points towards a better future.
And due to economic necessities, we have to adapt to stay productive.
However, without the industrial revolution, I would never have been able to enjoy programming in the first place.
Therefore, fear and excitement are reasonable reactions to this <em>time of disruption</em>.</p>

<p>But let’s come back and go back to the actual topic.
One of the challenges AI researchers face today is not so much the generation of novelty but the evaluation of it, especially in the case of aesthetics, which is somewhat subjective.
Within the generative process, the machine has to “judge” if the piece is engaging.
Otherwise, the whole process is nothing more than a sophisticated but impracticable random search through the space of all possible compositions.
However, interest depends on the cultural context.
Maybe Schönberg’s atonal, thus ungodly music, would not have attracted anybody in the 13. century.
Judging if novelty is sensible seems to require an <em>embodiment</em> in the world.
Therefore, as an art form, I find fully automated <strong>opaque</strong> music-generating systems that lack human interaction undesirable because they, in the end, lead to a mode of passive consumption.
Instead, human intelligence is needed to bring <em>intentionality</em> into the composition.
I imagine an interconnected relationship where <em>artificial communication</em> guides humans and machines to new places.</p>

<p>Even though machines are still unable to develop intentionality of their own, composing is a partially rigorous and formal endeavor; thus, algorithms and machines can certainly help with realizing intentions.
Contrary to popular belief, music and computer science / mathematics are much more related than they seem.
And there is no reason to believe that algorithms can not only be aesthetically and intellectually beautiful but can also evoke emotions.</p>

<p>However, <em>computer music</em> is diverse, and as an amateur, I should be careful in my assessment.
I encountered <em>rule-centered computer music</em>, highly interactive <em>live programming</em> (which is also a movement), <em>real-time music generation</em>, <em>sonification</em>, and <em>data-centered computer music</em>.
While <em>rule-centered music generation</em> is <em>transparent</em> and offers low-level control, <em>data-centered generation</em> is often <em>opaque</em> and offers only high-level control, at least, up to this date.
<em>Live programming</em> is highly interactive and relies on <em>real-time communication</em> between performer and audience as well as <em>real-time artificial communication</em> between performer and machine.</p>

<p><em>Communication</em> between humans and machines excites me the most since it offers the possibility to reflect on algorithms, programs, machines, data, and technology in general.
It goes beyond analytical contemplation by making algorithms experiencable.
Furthermore, learning from human feedback to calibrate generative models such that they represent our experienced ups and downs, twists and turns in music by injecting <em>intentionality</em> in order to steer generative models might be the way to go.
The term <strong>co-pilot</strong> comes to mind.</p>

<h2 id="melody-generation">Melody Generation</h2>

<p>For the interested reader, the survey <em>AI Methods in Algorithmic Composition: A Comprehensive Survey</em> <a class="citation" href="#rodriguez:2014">(Rodriguez &amp; Vico, 2014)</a> and <em>A Comprehensive Survey on Deep Music Generation: Multi-level Representations, Algorithms, Evaluations, and Future Directions</em> <a class="citation" href="#shulei:2020">(Ji et al., 2020)</a> offer an excellent first overview of the different techniques up to the year 2014 and 2020, respectively.</p>

<h3 id="a-difficult-problem">A Difficult Problem</h3>

<p>Let us first reflect on the question of why melody generation is tricky.
First of all, in music, intervals are everything.
It does not matter so much if one plays a C or B; what matters is the relation of notes within a piece, i.e., playing A-C or A-B.
Intervals are so ingrained into music that musicians give them certain names such as <em>minor third</em>, <em>perfect fifth</em>, or <em>tritone</em> (the Devil’s tone).
It is no coincidence that <em>major</em> and <em>minor</em> chords, as well as most <em>scales</em>, are asymmetrical because it gives each note a distinctive quality within a chord or a scale.</p>

<p>In addition, this relation is multi-dimensional.
We have melody, i.e., playing note after note horizontally, and harmony, i.e., vertical relations, for which we play notes together (chords).
On top of that, what happens in measure 5 may directly influence what happens in measure 55, without necessarily affecting any of the intervening material.
These relations can be all over the place and span a very long sequence!
Good music hits a sweet spot between repetition and surprise, and landing on that spot is quite challenging.
Together, these properties make melody (or polyphonic) generation hard.</p>

<h3 id="the-music-generation-process">The Music Generation Process</h3>

<p>Many artists and researchers took on the challenge, and <em>machine learning techniques</em> increasingly play an essential role.
The learning and generation are based on two major categories of representations: either <strong>symbolic notation</strong> or <strong>performed pieces</strong> of music.</p>

<p>Classical music and most other kinds of music as we know them came into being through the music generation process depicted in Figure 1.
Composers write a score that leads to the performing musicians (the execution of the score) who are exciting their instruments.
This excitement causes the instrument to vibrate, and due to its physicality, it pushes air molecules around.
Molecules bump into each other in some areas and tend to leave other areas—a displacement we call <em>wave</em>.
In principle, the energy of the excitement travels outwards through the air to the listener’s ear.
The information gets more and more concrete.
While a score is an abstract representation, the sound caused by instruments is very concrete.
It is, in fact, so concrete that it is different for every listener since each of us perceives sound slightly differently.</p>

<p>Abstraction removes us from the messy reality and enables communication, but it also conceals the singularity of beings.
Concerning <em>melody generation</em> we have to ask how much abstraction is justified.
A score represented by a note sheet without any information about the dynamics is “more” <em>symbolic</em> or abstract than a note sheet that contains hints for the tempo and loudness.
Raw audio material is far away from the much more abstract <em>symbolic notation</em> and a lived thorough performance is a singular event.</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/music-gen-process.png" alt="Music generation process cell" />
<div style="display: table;margin: 0 auto;">Figure 1: Music generation process.</div>
</div>
<p><br /></p>

<p>Using <em>symbolic notation</em> is more accessible, but one loses the slight variations, dynamics, and other qualities that make the result feel so humanly made.
However, composers who want to use <em>melody generation</em> to support their process might be happy to introduce these qualities by themselves.
It is a question of application.
The same is true for <em>the mono-</em> and <em>polyphonic</em> generations.
Do we want to generate a full-fetched performance, a melody snippet (monophonic), or something in between?
In this blog post, I will focus on the <em>monophonic</em> generation (one note at a time).</p>

<h3 id="autoregressive-generative-models">Autoregressive Generative Models</h3>

<p>An autoregressive (AR) model is a representation of a type of random process that specifies that the output variable depends linearly on its own previous values and on a stochastic term (an imperfectly predictable term).
In the field of machine learning these models are <em>sequence generative models</em>, that is, they learn an approximation of the real probability distribution.</p>

<p>Let’s assume we are given access to a dataset \(\mathcal{D} \subseteq \mathcal{X}^n\) of \(n\)-dimensional datapoints \(\mathbf{x}\).
Each datapoint represents a sequence of events—in our case a sequence of notes.
By the chain rule of probability, we can factorize the joint distribution over the \(n\)-dimensions as</p>

\[P(\mathbf{x}) = \prod_{i=1}^n P(x_i | x_1, x_2, \ldots, x_{i-1}) = \prod_{i=1}^n P(x_i|\mathbf{x}_{&lt;i}),\]

<p>where</p>

\[P(x_i | x_1) = P(x_i | X_1 = x_1) \text{ and } \mathbf{x}_{&lt;i} = (x_1, x_2, \ldots, x_{i-1}).\]

<p>If we allow every conditional \(P(x_i|\mathbf{x}_{&lt;i})\) to be specified in a tabular form, then such a representation is fully general and can represent any possible distribution over \(n\) random variables.
However, the space complexity for such a representation grows exponentially with \(n\).</p>

<p>In an <em>autoregressive generative model</em>, the conditionals are specified as parameterized functions (hypothesis) with a fixed number of parameters</p>

\[P_{\theta_{i}}(x_i|\mathbf{x}_{&lt;i}) = h_i(x_1, x_2, \ldots, x_{i-1}),\]

<p>where \(\theta_{i}\) denotes the set of parameters used to specify the mean function</p>

\[h_{\theta_{i}} : \mathcal{X}^{i-1} \rightarrow [0;1]^{|\mathcal{X}|},\]

<p>with the condition that the \(\|\mathcal{X}\|\) probabilities sum up to 1.
The number of parameters of such a model is given by</p>

\[\sum_{i=1}^n |\theta_{i}|.\]

<h3 id="linear-models">Linear Models</h3>

<p>Suppose</p>

\[\mathcal{X} = \{0,1\} \quad \text{ (Bernoulli random variables)}\]

<p>then a very simple model would be a linear combination of the input elements followed by a sigmoid non-linearity (to restrict the output to lie between 0 and 1):</p>

\[h_{\theta_{i}}(x_1, x_2, \ldots, x_{i-1}) = \sigma\left( \alpha_0^{(i)} + \alpha_1^{(i)} x_1 + \ldots + \alpha_{i-1}^{(i)} x_{i-1} \right),\]

<p>where</p>

\[\sigma(x) = \frac{1}{1+e^{-x}}\]

<p>and</p>

\[\theta_i = \{\alpha_0^{(i)}, \alpha_1^{(i)}, \ldots, \alpha_{i-1}^{(i)}\}\]

<p>denote the parameters of the mean function.
Note that this simple model has \(\mathcal{O}(n^2)\) pareamters (instead of the \(\mathcal{O}(2^{n-1})\)) required if we use a tabular representation for the conditionals.
In Fig. 2</p>

\[\hat{y}_i \in \mathcal{X} \text{ is } 1 \text{ if } h_{\theta_{i}}(x_1, x_2, \ldots, x_{i-1}) &gt; 0.5,\]

<p>otherwise it is 0.</p>

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:70%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/fvsbn.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 2: Fully-visible sigmiod belief network (binary classification).</div>
</div>
<p><br /></p>

<p>In the general case, where \(|\mathcal{X}| = m\), i.e. it consists of a finite number of possible events—in our case notes—a linear model should output $m$ numbers between 0 and 1 that sum up to 1.
In that case, \(h_{\theta_{i}}(x_1, x_2, \ldots, x_{i-1})\) outputs an \(m\)-dimensional vector</p>

\[\mathbf{p}_i = (p_{i1}, p_{i2}, \ldots, p_{im})\]

<p>where</p>

\[p_{ij} = \frac{e^{z_{ij}}}{\sum_{k=1}^m e^{z_{ik}}} = \sigma(\mathbf{z}_{i})\]

<p>with</p>

\[z_{ij} = \alpha_0^{(i,j)} + \alpha_1^{(i,j)} x_1 + \ldots + \alpha_{i-1}^{(i,j)} x_{i-1}.\]

<p>Thus we replace the <em>sigmoid</em> by <em>softmax</em> and we would require \(\mathcal{O}(n^2 \cdot m)\) parameters.</p>

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:70%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/fvsbn-multiclass.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 3: Fully-visible softmax belief network (multi-class classification with 3 classes).</div>
</div>
<p><br /></p>

<p>We can express this via a matrix-vector multiplication</p>

\[\mathbf{z}_{i} = \mathbf{A}_i \mathbf{x}_{&lt;i} + \mathbf{b}_i,\]

<p>where</p>

\[\mathbf{A}_{i} =
\begin{bmatrix}
 \alpha_1^{(i,1)} &amp; \alpha_2^{(i,1)} &amp; \ldots &amp; \alpha_{m-1}^{(i,1)} \\
 \alpha_1^{(i,2)} &amp; \alpha_2^{(i,2)} &amp; \ldots &amp; \alpha_{m-1}^{(i,2)} \\
 \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
 \alpha_1^{(i,m)} &amp; \alpha_2^{(i,2)} &amp; \ldots &amp; \alpha_{m-1}^{(i,m)}
\end{bmatrix},

\quad \mathbf{b}_i = 
\begin{bmatrix}
\alpha_0^{(i,1)} \\
\alpha_1^{(i,2)} \\
\vdots \\
\alpha_0^{(i,m)}
\end{bmatrix}.\]

<p>For example, if we have three events \(m=3\) (see Fig. 3) and \(n=5\) then</p>

\[\mathbf{A}_{5} =
\begin{bmatrix}
 \alpha_1^{(3,1)} &amp; \alpha_2^{(3,1)} &amp; \alpha_3^{(3,1)} &amp; \alpha_4^{(3,1)}\\
 \alpha_1^{(3,2)} &amp; \alpha_2^{(3,2)} &amp; \alpha_3^{(3,2)} &amp; \alpha_4^{(3,1)}\\
 \alpha_1^{(3,3)} &amp; \alpha_2^{(3,3)} &amp; \alpha_3^{(3,3)} &amp; \alpha_4^{(3,1)}  
\end{bmatrix},

\quad

\mathbf{A}_{3} =
\begin{bmatrix}
 \alpha_1^{(2,1)} &amp; \alpha_2^{(2,1)} \\
 \alpha_1^{(2,2)} &amp; \alpha_2^{(2,2)} \\
 \alpha_1^{(2,3)} &amp; \alpha_2^{(2,2)}  
\end{bmatrix}.\]

<p>Note that if we only want to compute the next note of a melody given a sequence of $n-1$ notes, we are only interested in</p>

\[P(x_n|x_1,x_2,\ldots, x_{n-1}).\]

<p>Thus, our network can be much simpler, i.e., we only need to compute</p>

\[z_n = \mathbf{A}_n \mathbf{x}_{i&lt;n} + \mathbf{b}_n.\]

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:70%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/fvsbn-multiclass-sim.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 4: Fully-visible softmax belief network (multi-class classification with 3 classes) predicting only the next note.</div>
</div>
<p><br /></p>

<p>We could share our parameters for computing the next note for a sequence shorter than \(n-1\) notes by seting</p>

\[x_j = 0 \text{ for } j \geq i.\]

<p>This architecture is often called <em>neural autoregressive density estimator</em>.
By sharing, we reduces the amount of parameters to \(\mathcal{O}(n \cdot m)\).
We will use such a feedforward neural network (without a bias term and assuming \(n=2\)) in <em><a href="/Pages/2023/05/31/musical-interrogation-II.html">Part II - FNN</a></em> of this series.</p>

<h3 id="multi-layer-perceptrons">Multi-Layer Perceptrons</h3>

<p>A natural way to increase the expressiveness of an autoregressive generative model is to use more flexible parameterizations for the mean function (our hypotheses), e.g., multi-layer perceptrons (MLP).
For example, consider the case of a neural network with 1 hidden layer.
The mean function for variable $i$ can be expressed as</p>

\[\begin{array}
    \mathbf{h}_i &amp;= \sigma\left(\mathbf{W}_i \mathbf{x}_{&lt; i} + \mathbf{c}_i \right) &amp; \quad \text{ (component-wise sigmoid)}\\
    \mathbf{z}_i &amp;= \sigma\left( \mathbf{A}_{i} \mathbf{h}_i + \mathbf{b}_i \right) &amp; \quad \text{ (softmax)}
\end{array}\]

<p>where \(\mathbf{h}_i \in \mathbb{R}^d\) denotes the hidden layer activations for the MLP and</p>

\[\theta_i = \{ \mathbf{W}_i \in \mathbb{R}^{d \times (i-1)}, \mathbf{c}_i \in \mathbb{R}^d, \mathbf{A}_{i} \in \mathbb{R}^{(i-1) \times d}, b_i \in \mathbb{R}^m \}.\]

<p>are the set of parameters for the mean function.
Note that if $d$ is small the information gets compressed.
The total number of parameters in this model is in \(\mathcal{O}(n^2 \cdot d)\) and is dominated by the matrices.
Sharing both types of matrices reduces the complexity to \(\mathcal{O}(n \cdot d)\)</p>

\[\theta = \{ \mathbf{W}_n \in \mathbb{R}^{d \times (n-1)}, \mathbf{c}_n \in \mathbb{R}^d, \mathbf{A}_n \in \mathbb{R}^{(n-1) \times d}, \mathbf{b}_n \in \mathbb{R}^m \}.\]

<p>computing</p>

\[\begin{array}
    \mathbf{h}_i &amp;= \sigma\left(\mathbf{W}_n \mathbf{x}_{&lt; n} + \mathbf{c}_n \right) &amp; \quad \text{ (component-wise sigmoid)}\\
    \mathbf{z}_n &amp;= \sigma\left( \mathbf{A}_n \mathbf{h}_n + \mathbf{b}_n \right) &amp; \quad \text{ (softmax)}
\end{array}\]

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:80%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/fvsbn-multiclass-hidden-sim.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 5: Multi-layer perceptrons with one hidden layer (multi-class classification with 3 classes) predicting only the next note.</div>
</div>
<p><br /></p>

<h3 id="discrete-markov-models">Discrete Markov Models</h3>

<p>In my post <a href="/Pages/2022/07/09/markov-chains-for-music-generation.html">Probabilistic Melody Modeling</a>, I used a <em>(discrete) first-order Markov chain (MC)</em> (also called <em>Markov process</em>) to generate melodies after learning the model from one piece of music.
The approach was simple: translate the frequency of note transitions into probabilities. 
For example, if the piece is defined by the note sequence A-B-B-A-C-A-B and the duration of each note is the same, then</p>

\[P(X_{t+1} = B \ | \ X_{t} = A) = \frac{2}{3}, \quad P(X_{t+1} = C \ | \ X_{t} = A) = 1.0.\]

<p>To determine which note comes next, we only look at the previous note, i.e. at a very narrow context.
Using a <em>first-order Markov model</em>, one would estimate the probability of the melody (not considering note duration) A-B-F by</p>

\[P(X_0 = A) \cdot P(X_1 = B \ | \ X_0 = A) \cdot P(X_2 = F \ | \ X_1 = B).\]

<p>Using our notation above this corresponds to very simple <em>hypotheses</em></p>

\[h_{\theta_{i}}(x_{i-1}) = \left( c_1, \ldots, c_m \right) = \left( \hat{P}(X_{i} = x_1|X_{i-1} = x_{i-1}), \ldots, \hat{P}(X_{i} = x_m|X_{i-1} = x_{i-1}) \right),\]

<p>where $m$ is the number of possibly accoring notes and</p>

\[\hat{P}(X_i = x_i|X_{i-1} = x_{i-1})\]

<p>is the empirical probability of \(x_i\) accuring after \(x_{i-1}\), i.e. the frequency of this event.
In this example, a state is defined by a note, e.g. A.</p>

<p><em>Hidden Markov models (HMM)</em> are <em>Markov chains</em> with <em>hidden states</em>.
There are also a finite number of states, probabilistic transitions between these states, and the next state is determined by the current state, but we are unsure in which state the process is currently in.
The current hidden state \(Z_t\) <em>emits</em> an <em>observation</em> \(X_t\).
In other words, instead of going from one observed variable to the next, e.g., one note to the next, we move from one <strong>distribution</strong> of observations to the next, e.g. from one distribution of notes to the next!</p>

<p>For example, imagine a prisoner who has to estimate the outside weather (<em>hidden state</em>) by observing the dirt on the guard’s boots (<em>emissions</em>).
If he knows all the probability transitions (e.g., from sunny to rainy, sunny to dirty on boots, etc.) and existing states, the prisoner could model the problem by an HMM, compare Figure 4.</p>

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:70%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/hmm-example-prison.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 4: Hidden Markov model with 2 hidden states (sunny, rainy) and 2 observation variables (clean, dirty). The initial state is either sunny or rainy with 0.5 probability.</div>
</div>
<p><br /></p>

<p>The prisoner could ask: given the HMM and an observation sequence \(X_0, \ldots, X_n\), what is the likelihood that this sequence occurs (<em>likelihood problem</em>)?
One could also ask: what are the hidden states \(Z_0, \ldots, Z_n\) that “best” explains the observations (<em>decoding problem</em>).
Moreover, what we are more interested in is: given an observation sequence \(X_0, \ldots, X_n\), learn the model parameters \(\theta\) that maximizes the likelihood for our observation (<em>learning problem</em>)!
Similar to neural networks, one defines the <em>architecture</em> of the HMM (states and transitions), then solve the <em>learning problem</em> and infer new melodies from the learned HMM.
In music, hidden states often lack interpretability.
Therefore, it needs to be clarified which architecture one should choose.</p>

<p><em>HMM</em> is a special case of <em>dynamic Bayesian networks</em> where a single hidden state variable represents the entire state of the world.
With respect to music, using <em>hidden Markov models</em> we can model more abstract states that we can not directly observe, for example,</p>

<p>Using <em>higher-order MC</em> or <em>HMM</em> widens the context to multiple notes of the past.
For our MC example A-B-F this would mean the probability changes to</p>

\[P(X_0 = A) \cdot P(X_1 = B \ | \ X_0 = A) \cdot P(X_2 = F \ | \ X_0 = A \ \land \ X_1 = B).\]

<p>But due to the chain property (linearity), this does not necessarily lead to better results since widening the range leads very quickly to overfitting, i.e., the model reproduces more or less exact replica because it does not generalize—more is not always better.
In any case, the learning stays stepwise causal, i.e., one note after the other without jumping around.
By focusing on linear temporal dependencies, these models need to take into account the higher-level structure and semantics important to music.
By model design, HMMs have very limited memory and are thus also incapable of modeling the longer term structure that occurs in original musical pieces.</p>

<p>Their applications in musical structure generation goes back to <em>Harry F. Olson</em> around 1950, and in 1955, the first machine produced Markov models of first and second order in regard to pitches and rhythm <a class="citation" href="#nierhaus:2010">(Nierhaus, 2009)</a>.
In <a class="citation" href="#merwe:2011">(Van Der Merwe &amp; Schulze, 2011)</a>, the authors used first-, higher-, or mixed-order MCs to represent chord duration, chord progression, and rhythm progression and first-, higher-, or mixed-order HMM to describe melodic arc.</p>

<p>A more rigorous and recent discussion, including <em>polyphonic</em> generation, be found in <a class="citation" href="#collins:2016">(Collins et al., 2016)</a>.</p>

<h3 id="long-term-memory">Long-term Memory?</h3>

<p>As stated, the challenge is primarily due to long-term relations.
One way of tackling this issue is to increase the memorizing capability of the model.
With this in mind, looking at the catalog of model types within the field of <em>deep learning</em> one can spot multiple alternatives to <em>Markov chains</em> for melody generation.</p>

<p>One obvious choice is the long short-term memory recurrent neural networks (LSTM) <a class="citation" href="#hochreiter:1997">(Hochreiter &amp; Schmidhuber, 1997)</a>, a type of recurrent neural network (RNN) that allows information to persist for a longer time by letting it flow almost directly through time.</p>

<p>In theory, <em>vanilla RNNs</em> can learn the temporal structure of any signal, but due to computational reasons (vanishing/exploding gradients), they can not keep track of temporally distant events.
If you want to learn more about RNNs, I highly recommend the blog article <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Neural Networks</a> by Andrej Karpathy.
In his blog post, he writes:</p>

<blockquote>
  <p>RNNs combine the input vector with their state vector with a fixed (but learned) function to produce a new state vector. This can, in programming terms, be interpreted as running a fixed program with certain inputs and some internal variables. – Andrej Karpathy</p>
</blockquote>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/rnn-unfold.png" alt="Sketch of an RNN unfolded in time" />
<div style="display: table;margin: 0 auto;">Figure 5: Sketch of an RNN unfolded in time.</div>
</div>
<p><br /></p>

<p>RNNs are similar to <em>multilayered perceptrons</em> (MLPs) but allow for connections from the output of one unit into the input of another unit located at a shallower layer than itself, i.e., closer to the input of the network.
The information no longer flows acyclic through the network.
Instead, recurrent feedback is introduced and allows an RNN to take into account its past inputs together with new inputs.
Essentially, an RNN predicts a sequence of symbols given an input sequence.
But using an RNN is like writing a thousand letters on the same piece of paper and then figuring out the information contained in the first letter—it is a mess; the information gets washed away.
In Figure 5 the basic components of an RNN are depicted.
Using my analogy, the piece of paper are the matrices $U,V,W$ which are learnable parameters.
<strong>They are shared through time!</strong></p>

<p>The extension, motivated by the shortcomings of <em>vanilla RNNs</em>, are <em>LSTM RNNs</em> or just <em>LSTMs</em>.
LSTMs <strong>learn</strong> which information they should keep in long-term memory and which information they can forget after a short period.
Instead of just writing all the letters on the piece of paper, we use our rubber and get rid of some writings while highlighting other passages.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/lstm-cell.png" alt="LSTM cell" />
<div style="display: table;margin: 0 auto;">Figure 6: A sketch of an LSTM cell.</div>
</div>
<p><br /></p>

<p>There is plenty of good material which explains LSTMs much more accurately than I can ever do.
Figure 6 shows a sketch of a very complicated-looking LSTM cell where each green square is a linear transformation, each red bar indicates a <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a> activation, and blue bars indicate a <a href="https://en.wikipedia.org/wiki/Hyperbolic_functions">tanh</a> activation.
All the sigmoid activations are used to control the memorizing strategy (rubber and highlighter).
First, the cell “decides” what to keep in the long-term state \(\mathbf{c}\_{t-1}\) via \(f_t\).</p>

<p>Then $i_t$ decides what to add to the long-term state.
In addition, $o_t$ decides what part of the new long-term state will make up the short-term state \(\mathbf{h}_t.\)
The importance is that along the path from \(\mathbf{c}_{t-1}\) 
to \(\mathbf{c}\_{t},\) there is only a simple multiplication and addition!
Therefore, information can persist for longer.</p>

<p>Note, however, that LSTMs can still access information of time step \(t\) only via time step \(t-1\).
There is no direct access to information compared to the <em>attention mechanism</em> <a class="citation" href="#bahdanau:2014">(Bahdanau et al., 2014)</a>, and the <em>transformer</em> <a class="citation" href="#vaswani:2017">(Vaswani et al., 2017)</a>, which led to the most recent breakthroughs in the field of <em>deep learning</em>.
Just a few days ago, another RNN, called <a href="https://github.com/BlinkDL/RWKV-LM">RWKV-LM</a>, claimed to achieve similar results; thus, the last word has yet to be spoken.</p>

<h3 id="application-of-recurrent-neural-networks">Application of Recurrent Neural Networks</h3>

<p>In <a class="citation" href="#todd:1989">(Todd, 1989)</a> <em>Peter M. Todd</em> used a <em>vanilla RNN</em> to generate melodies.
Various issues are discussed in designing the network.
Note that at this time in the young history of machine learning, there were no user-friendly software libraries available, and there was much more thinking going on in designing the network on a fine-grained level.
The author also suggests using <em>multi-layered perceptrons (MLPs)</em> by explicitly modeling time and either showing the whole piece to the network or using a sliding-window approach, e.g., showing one bar at a time and predicting the next bar.
In the end, Todd uses an RNN with 15 hidden units and 15 output units (1 note-begin unit and 14 pitch units) trained for 8500 epochs (cycle through the entire training set) using a handful of sliced melodies.
Fewer hidden units led to more training.
By today’s standard, Todd’s network was tiny.
Todd assumes the key of C from D4 to C6.
The <em>note-begin unit</em> indicates if the note begins or it merely continues.
Interestingly, Todd discusses a <em>pitch-interval</em> representation.
Instead of outputting the actual pitch values, the network outputs the relative transitions (intervals/pitch changes) in semitones.
For example, instead of A-B-C the network outputs A-(+1)-(-3).
The advantage is that outputs are more <em>key-independent</em> and can range over an extensive range of notes even if there are only view output units.
This allows for the transposition of an entire melody simply by changing the actual initial pitch (which need not even be produced by the network but could be specified elsewhere).
In the end, he decides not to use it because of possible errors in the production since a single error would make the whole melody flawed.</p>

<p>One of the very first applications of LSTMs for the generation of music was introduced by <em>Dougnles Eck</em> and <em>Jürgen Schmidhuber</em> <a class="citation" href="#eck:2002">(Eck &amp; Schmidhuber, 2002)</a>.
The authors state that “most music has a well-defined global temporal structure in the form of nested periodicities or meter”.
In a walz, important melodic events occur every three-quarter notes (or every first note of a bar).
Chord changes occur more slowly and are most often aligned with the bars.</p>

<blockquote>
  <p>For this reason, one can say of music that some notes are more important than others: in general, a learning mechanism should spend more resources on metrically-important notes than others. – <a class="citation" href="#eck:2002">(Eck &amp; Schmidhuber, 2002)</a></p>
</blockquote>

<p>The authors use a <em>time-sliced representation</em>, i.e., each step/event represents the period (for example, a quarter note).
They use one input/output unit per note, making it implicitly <em>polyphonic</em> and avoiding an artificial distinction between melody and chords.
However, to keep this property, the authors do not distinguish between a note that is retriggered or a note that is held because they would require this information for each input/output note.
They randomly selected 4096 12-bar blues songs (with 8 notes per bar).
Their network for learning chords consists of 4 cell blocks containing 2 cells; each is fully connected to the other.
Their network for learning chords and melody consists of 8 cell blocks containing 2 cells.
4 of the cell blocks are fully connected to the input units for chords.
The other four cell blocks are fully connected to the input units for the melody.
The chord cell blocks have recurrent connections to themselves <strong>and</strong> to the melody cell blocks.
However, melody cell blocks are only recurrently connected to melody cell blocks.
Therefore, the authors assume that the melody influences chords but not the other way around.
Again, the network is relatively small.</p>

<p><a href="https://github.com/IraKorshunova/folk-rnn">FolkRNN</a> was introduced in 2016 <a class="citation" href="#sturm:2016">(Sturm et al., 2016)</a>.
It is an LSTM trained with 23 000 music transcriptions expressed with the common <a href="https://en.wikipedia.org/wiki/ABC_notation">ABC notation</a>.
The authors discuss different perspectives on their results, keeping the musician and the process of composition in mind.
Their human-machine interaction is on the side of composing.
The user can ask for a melody and can adjust it; you can experiment with their models <a href="https://folkrnn.org/">here</a>.
Their LSTM consists of <strong>3 hidden layers</strong> with <strong>512 LSTM blocks</strong>, each leading to approximately <strong>5.5 million parameters</strong>, i.e., a big jump from the works we discussed before.</p>

<p>Daniel Johnson <a class="citation" href="#johnson:2017">(Johnson, 2017)</a> created what he calls <a href="https://github.com/danieldjohnson/biaxial-rnn-music-composition">Bi-axial LSTM</a>, many two-layered LSTMs (stacked in on the note-axis) with connections along the note-axis and recurrent connections along the time-axis followed by feed-forward layers (third and fourth non-recurrent layer) across notes.
Each of the stacked LSTMs receives the input for one specific note.
The model supports polyphonic music.
Furthermore, Johnson’s architecture and input format allows the model to learn the musical concept of <em>translation invariance</em>, e.g., increasing each note of a piece by one semitone keeps the main qualities unchanged, which is very different compared to text translation.</p>

<p>The model is inspired by convolutional neural networks since they are quasi-invariant with respect to translation.
It is not completely clear to me how many LSTM blocks the model consists of.
I think there ar <strong>2 LSTM layers with 300 blocks each</strong> and <strong>2 non-recurrent layers with 100 and 50 units</strong>, respectively.
In <a class="citation" href="#kotecha:2018">(Kotecha &amp; Young, 2018)</a>, the authors refined Johnson’s technique.
You can listen to some of Johnson’s results on his <a href="https://www.danieldjohnson.com/2015/08/03/composing-music-with-recurrent-neural-networks/">blog</a>.
Despite being a seemingly small contribution, Johnson’s ideas influenced a lot of work in this field.
His architecture and input/output modeling is insightful and may evoke different ideas.
I highly recommend reading his blog post.</p>

<p>In 2016 <a href="https://github.com/magenta/magenta/tree/main/magenta/models/melody_rnn">Melody RNN</a> was introduced within Google’s open source project <a href="https://magenta.tensorflow.org/">Magenta</a>.
One of the project’s stated goals is to advance state of art in machine intelligence for music and art generation.
<em>Melody-RNN</em> is a simple dual-layer LSTM model.
In fact, there are four different versions of <em>Melody RNN</em>, which offers me the possibility to look at increasingly complex/sophisticated solutions.
Each is able to generate <strong>monophonic</strong> melodies:</p>

<p><strong>(1) Basic RNN</strong>: The <em>basic dual-layer LSTM</em> uses basic <em>one-hot encoding</em> to represent extracted melodies as input to the LSTM and fulfills the role of a baseline.
One-hot encoding means that to represent $n$ different objects one uses a binary vector of size $n$ where the $k$-th element is represented by a vector</p>

\[\mathbf{v}_k = (v_1, \ldots, v_n) \text{ s.t. } v_k = 1, v_i = 0 \text{ for } i \neq k.\]

<p>For training, all the data is transposed to the MIDI pitch range \([48..84]\).
The output/label was the target next event (note-off, no event, note-on for each pitch), i.e., one value for each pitch (a vector).
Looking at the <a href="https://github.com/magenta/magenta/blob/main/magenta/models/melody_rnn/melody_rnn_model.py">code</a>, I assume they use 128 units for each layer.
<code class="language-plaintext highlighter-rouge">MelodyOneHotEncoding</code> and <code class="language-plaintext highlighter-rouge">KeyMelodyEncoderDecoder</code> can be found <a href="https://github.com/magenta/note-seq/blob/main/note_seq/melody_encoder_decoder.py">here</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DEFAULT_MIN_NOTE</span> <span class="o">=</span> <span class="mi">48</span>
<span class="n">DEFAULT_MAX_NOTE</span> <span class="o">=</span> <span class="mi">84</span>
<span class="p">...</span>
<span class="n">MelodyRnnConfig</span><span class="p">(</span>
    <span class="n">generator_pb2</span><span class="p">.</span><span class="n">GeneratorDetails</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="s">'basic_rnn'</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s">'Melody RNN with one-hot encoding.'</span><span class="p">),</span>
    <span class="n">note_seq</span><span class="p">.</span><span class="n">OneHotEventSequenceEncoderDecoder</span><span class="p">(</span>
        <span class="n">note_seq</span><span class="p">.</span><span class="n">MelodyOneHotEncoding</span><span class="p">(</span>
            <span class="n">min_note</span><span class="o">=</span><span class="n">DEFAULT_MIN_NOTE</span><span class="p">,</span> 
            <span class="n">max_note</span><span class="o">=</span><span class="n">DEFAULT_MAX_NOTE</span>
        <span class="p">)</span>
    <span class="p">),</span>
    <span class="n">contrib_training</span><span class="p">.</span><span class="n">HParams</span><span class="p">(</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
        <span class="n">rnn_layer_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span>
        <span class="n">dropout_keep_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">clip_norm</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span>
    <span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<p><strong>(2) Mono RNN</strong>: Similar to <em>basic</em> but uses the full MIDI pitch range, i.e. \([0..128]\).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">note_seq</span><span class="p">.</span><span class="n">OneHotEventSequenceEncoderDecoder</span><span class="p">(</span>
    <span class="n">note_seq</span><span class="p">.</span><span class="n">MelodyOneHotEncoding</span><span class="p">(</span>
        <span class="n">min_note</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
        <span class="n">max_note</span><span class="o">=</span><span class="mi">128</span>
    <span class="p">)</span>
<span class="p">),</span>
<span class="p">...</span>
</code></pre></div></div>

<p><strong>(3) Lookback RNN</strong>: The third one, the <em>Lookback RNN</em>, extends the inputs and introduces custom outputs/labels, allowing the model to recognize patterns that occur across 1 and 2 bars quickly.
Therefore, the input is extended to events from 1 and 2 bars ago.
Furthermore, the authors add the information on whether the last event was repeating the event from 1 or 2 bars before it, which allows the model to more easily recognize if it is in a “repeating sequence state” or not.
Finally, they borrow again from <a class="citation" href="#johnson:2017">(Johnson, 2017)</a> what he calls <strong>Beat</strong>. 
The idea is to add the position within the measure represented by a sort of binary clock, i.e., $(0,0,0,0,1)$ followed by $(0,0,0,1,0)$ followed by $(0,0,0,1,1)$ and so on (but they use -1 instead if 0).
I am unsure why they call their last trick <em>custom label</em> since it is more like a compression of information.
Event labels (i.e., the next value the model should output) are replaced by “repeat bar 1” or “repeat bar 2” if repetition was found in the data.
This is a clever trick!
Overall the author introduces more structure explicitly and compresses some of the information to ease the learning process.
Note that the input designed by <a class="citation" href="#johnson:2017">(Johnson, 2017)</a> is much more complicated.
He provides (for each note) <strong>Pitchclass</strong> of the notes played, <strong>Previous Vicincity</strong> (what surrounding notes were played before), and <strong>Previous Context</strong> (carnality of the played pitch class).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">note_seq</span><span class="p">.</span><span class="n">LookbackEventSequenceEncoderDecoder</span><span class="p">(</span>
    <span class="n">note_seq</span><span class="p">.</span><span class="n">MelodyOneHotEncoding</span><span class="p">(</span>
        <span class="n">min_note</span><span class="o">=</span><span class="n">DEFAULT_MIN_NOTE</span><span class="p">,</span> <span class="n">max_note</span><span class="o">=</span><span class="n">DEFAULT_MAX_NOTE</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="p">...</span>
</code></pre></div></div>

<p><strong>(4) Attention RNN</strong>: The last RNN from this series of RNNs is the <em>Attention RNN</em>.
It introduces the use of the attention mechanism <a class="citation" href="#bahdanau:2014">(Bahdanau et al., 2014)</a> to allow the model to more easily access past information without storing it in the RNN cell’s state, i.e., its long-term memory.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">note_seq</span><span class="p">.</span><span class="n">KeyMelodyEncoderDecoder</span><span class="p">(</span>
    <span class="n">min_note</span><span class="o">=</span><span class="n">DEFAULT_MIN_NOTE</span><span class="p">,</span> <span class="n">max_note</span><span class="o">=</span><span class="n">DEFAULT_MAX_NOTE</span><span class="p">),</span>
<span class="p">...</span>
<span class="n">attn_length</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
<span class="n">clip_norm</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">...</span>
</code></pre></div></div>

<p>The attention mechanism within an RNN gives it the ability to learn the importance of relations between symbols within the sequence so that it can more easily access the “important” information. For example, to figure out the last word in the sentence,</p>

<blockquote>
  <p>I am from Germany, and I eat a lot of pizza. I speak [???]</p>
</blockquote>

<p>the model should learn that the word “speak” (in this context) should put a lot of attention to the words “I”, “am”, “from”, “Germany” but not so much attention to “pizza”.</p>

<p>Originally this was introduced to an <em>encode-decoder RNN</em>.
<em>Attention RNN</em> uses attention for the outputs of the overall network.
The model always looks at the outputs from the last $n=40$ steps when generating output for the current step.
This “looking” is realized by an <em>attention mask</em> which determines how much attention is spent on what step of the past.</p>

\[\mathbf{a}_t = \text{softmax}(\mathbf{u}_t), \quad \mathbf{u}_t = \mathbf{v}^\top\text{tanh}\left( W_1 H + W_2 \mathbf{c}_t \right)\]

<p>The columns of \(H\) are the \(n=40\) hidden states \(h_{t-n}, \ldots, h_{t-1}\).
So instead of seeing only the hidden state \(\mathbf{h}_{t-1}\) the RNN is looking at</p>

\[\hat{\mathbf{h}}_{t} = \sum\limits_{i=t-n}^{t-1} a_{t,i} h_i,\]

<p>where \(a_{t,i}\) is a component of \(\mathbf{a}_t\) and \(\mathbf{c}_t\) is the current step’s RNN cell state.
\(a_{t,i}\) is the amount of attention spent to the hidden state \(h_i\).
\(W_1, W_2\) and \(\mathbf{v}\) are learnable parameters.
This \(\hat{\mathbf{h}}_t\) vector is then concatenated with the RNN output from the current step, and a linear layer is applied to that concatenated vector to create the new output for the current step.
Furthermore, \(\hat{\mathbf{h}}_t\) is injected into the input of the next step.
Both concatenations are transformed via a <em>linear layer</em> directly after concatenation.</p>

<p>In a technical report <a class="citation" href="#lou:2016">(Lou, 2016)</a> Lou compares <em>Attention RNN</em> with the <em>Bi-axial LSTM</em> and comes to a conclusion that, as many RNNs, <em>Attention RNN</em> quite often falls into the over-repeating rabbit hole when generating pieces longer than 16 seconds.
The Bi-axial LSTM gives better rhythmic music composition due to the property of time- and note-invariant, but it takes longer to train.</p>

<p>In <a class="citation" href="#hadjeres:2018">(Hadjeres &amp; Nielsen, 2018)</a>, the authors from Sony introduced <a href="https://github.com/Ghadjeres/Anticipation-RNN">Anticipate-RNN</a>, a stacked LSTM that allows the user to introduce constraints that are especially interesting for composers who want to set certain notes interactively.
The first RNN/stack works from right to left, and the second from left to right.
The idea is that the first RNN outputs the combined constrained that increases from right to left since when the second RNN generates the melody from left to right, it has to respect the most constraints at the beginning of the sequence.
The input for the first RNN is basically a constraint, i.e., a note or nil (if unconstrained), and the input for the second RNN is a note concatenated with the output of the first RNN.
In <a class="citation" href="#hadjeres:2021">(Hadjeres &amp; Crestel, 2021)</a>, this idea is extended on but with a <em><a href="https://github.com/Ghadjeres/constraint-transformer-bach">constrained linear transformer</a></em>.
Furthermore, the author provides a DAW plug-in, <a href="https://ghadjeres.github.io/piano-inpainting-application/">The Piano Inpainting Application (PIA)</a>, that enables real-time AI assistance when composing polyphonic music in a <em>digital workstation (DAW)</em>.
I will talk about <em>transformers</em> later in this series.</p>

<p>In <a class="citation" href="#jiang:2019">(Jiang et al., 2019)</a>, the authors use a bidirectional LSTM model to compose polyphonic music conditioned on near notes, which surround the target note from the time dimension and the note dimension.
Their work heavily borrows from <a class="citation" href="#johnson:2017">(Johnson, 2017)</a>, but the bidirectional property allows the harmonization to access tonal information of the near future as well as the near past.
This makes sense since, in many cases, a note depends on a future note, e.g., a chromatic transition where we already know where we want to end up but have to figure out how to get there.
In addition, they propose a new loss function and allow the user to provide a musical context in the form of a custom chord.
They report a better convergence rate compared to the Bi-axial LSTM.
I was unable to find the code of their implementation.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="nierhaus:2010">Nierhaus, G. (2009). <i>Algorithmic Composition - Paradigms of Automated Music Generation</i>. SpringerWienNewYork.</span></li>
<li><span id="alhussein:2022">Fawzi, A., Balog, M., Huang, A., Hubert, T., Romera-Paredes, B., Barekatain, M., Novikov, A., R. Ruiz, F. J., Schrittwieser, J., Swirszcz, G., Silver, D., Hassabis, D., &amp; Kohli, P. (2022). Discovering faster matrix multiplication algorithms with reinforcement learning. <i>Nature</i>, <i>610</i>(7930), 47–53. https://doi.org/10.1038/s41586-022-05172-4</span></li>
<li><span id="rodriguez:2014">Rodriguez, J. D. F., &amp; Vico, F. J. (2014). AI methods in algorithmic composition: A comprehensive survey. <i>CoRR</i>, <i>abs/1402.0585</i>. http://arxiv.org/abs/1402.0585</span></li>
<li><span id="shulei:2020">Ji, S., Luo, J., &amp; Yang, X. (2020). A Comprehensive survey on deep music generation: Multi-level representations, algorithms, evaluations, and future directions. <i>CoRR</i>, <i>abs/2011.06801</i>. https://arxiv.org/abs/2011.06801</span></li>
<li><span id="merwe:2011">Van Der Merwe, A., &amp; Schulze, W. (2011). Music generation with Markov models. <i>IEEE MultiMedia</i>, <i>18</i>(3), 78–85. https://doi.org/10.1109/MMUL.2010.44</span></li>
<li><span id="collins:2016">Collins, T., Laney, R., Willis, A., &amp; Garthwaite, P. H. (2016). Developing and evaluating computational models of musical style. <i>AI EDAM</i>, <i>30</i>(1), 16–43. https://doi.org/10.1017/S0890060414000687</span></li>
<li><span id="hochreiter:1997">Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. <i>Neural Computation</i>, <i>9</i>(8), 1735–1780. https://doi.org/10.1162/neco.1997.9.8.1735</span></li>
<li><span id="bahdanau:2014">Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. <i>CoRR</i>, <i>abs/1409.0473</i>.</span></li>
<li><span id="vaswani:2017">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017). attention is all you need. <i>CoRR</i>, <i>abs/1706.03762</i>. http://arxiv.org/abs/1706.03762</span></li>
<li><span id="todd:1989">Todd, P. M. (1989). A connectionist approach to algorithmic composition. <i>Computer Music Journal</i>, <i>13</i>, 27–43.</span></li>
<li><span id="eck:2002">Eck, D., &amp; Schmidhuber, J. (2002). Finding temporal structure in music: blues improvisation with LSTM recurrent networks. <i>Proceedings of the 12th IEEE Workshop on Neural Networks for Signal Processing</i>, 747–756. https://doi.org/10.1109/NNSP.2002.1030094</span></li>
<li><span id="sturm:2016">Sturm, B. L., Santos, J. F., Ben-Tal, O., &amp; Korshunova, I. (2016). Music transcription modelling and composition using deep learning. <i>CoRR</i>, <i>abs/1604.08723</i>. http://arxiv.org/abs/1604.08723</span></li>
<li><span id="johnson:2017">Johnson, D. D. (2017). Generating polyphonic music using tied parallel networks. <i>EvoMUSART</i>.</span></li>
<li><span id="kotecha:2018">Kotecha, N., &amp; Young, P. (2018). Generating music using an LSTM network. <i>CoRR</i>, <i>abs/1804.07300</i>. http://arxiv.org/abs/1804.07300</span></li>
<li><span id="lou:2016">Lou, Q. (2016). <i>Music generation using neural networks</i>. http://cs229.stanford.edu/proj2016/report/Lou-MusicGenerationUsingNeuralNetworks-report.pdf</span></li>
<li><span id="hadjeres:2018">Hadjeres, G., &amp; Nielsen, F. (2018). Anticipation-RNN: enforcing unary constraints in sequence generation, with application to interactive music generation. <i>Neural Computing and Applications</i>. https://doi.org/10.1007/s00521-018-3868-4</span></li>
<li><span id="hadjeres:2021">Hadjeres, G., &amp; Crestel, L. (2021). <i>The piano inpainting application</i>.</span></li>
<li><span id="jiang:2019">Jiang, T., Xiao, Q., &amp; Yin, X. (2019). Music generation using bidirectional recurrent network. <i>2019 IEEE 2nd International Conference on Electronics Technology (ICET)</i>, 564–569. https://doi.org/10.1109/ELTECH.2019.8839399</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Opinion" /><category term="Music" /><category term="MC" /><category term="HMM" /><category term="RNN" /><summary type="html"><![CDATA[Whereas the human mind, conscious of its conceived purpose, approaches even an artificial system with a selective attitude and so becomes aware of only the preconceived implications of the system, the computers would show the total of available content. Revealing far more than only the tendencies of the human mind, this nonselective picture of the mind-created system should be of significant importance. – Gerbert Brün (1970)]]></summary></entry><entry><title type="html">The Disruption of Education</title><link href="https://bzoennchen.github.io/Pages/2022/12/10/disrupting-education.html" rel="alternate" type="text/html" title="The Disruption of Education" /><published>2022-12-10T00:00:00+01:00</published><updated>2022-12-10T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2022/12/10/disrupting-education</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2022/12/10/disrupting-education.html"><![CDATA[<p>At the moment, everyone in the sphere of <em>AI</em> is talking about <em>OpenAI’s</em> new invention: <em><a href="https://chat.openai.com/chat">ChatGPT</a></em>.
I want to share my current perspective on that astonishing technology.
Be warned that I could not spend much time thinking about it, i.e., this is a first and quick shot at the topic.
Furthermore, I am not an expert on the issue.
I have a limited teaching experience within a certain community.
In addition, I will not consider any ethical, economic, or ecological points here, except that I think such a powerful tool should be in the public domain.</p>

<h2 id="part-i-testing-the-machine">Part I: Testing the Machine</h2>

<p>Before discussing the issue, let us test this new magical tool.</p>

<h3 id="a-mathematical-proof">A Mathematical Proof</h3>

<p>Let’s try to prove something using <em>ChatGPT</em>.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Can you proof that irrational numbers exist?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, there are many ways to prove that irrational numbers exist. 
One way to do this is to consider the ratio of the length of the diagonal of a square to the length of its side. 
This ratio is always irrational, because no matter how large or small the square is, its diagonal will never be a whole number multiple of its side. This can be shown using the Pythagorean theorem, which states that in a right triangle, the square of the length of the hypotenuse (the longest side) is equal to the sum of the squares of the lengths of the other two sides. Since the diagonal of a square is a line that forms a right angle with each side of the square, it follows that the diagonal of a square is the hypotenuse of a right triangle. Therefore, the ratio of the diagonal of a square to the length of its side must be irrational.
</span></p>

<p>That is not really convincing if we do not know that \(\sqrt{2}\) is irrational which we are actually trying to prove.
So let’s ask for a formula.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Can you give me a mathematical formula to show that it is not possible for the square of the length of the diagonal to be equal to the square of a whole number?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Sure, here is one way to show that it is not possible for the square of the length of the diagonal of a square to be equal to the square of a whole number. 
Let’s say that the length of the side of a square is “a” and the length of its diagonal is “d”. 
Since the diagonal of a square forms a right angle with each side of the square, we can use the Pythagorean theorem to find the length of the diagonal:
</span></p>

<p><span style="font-family:Courier New">a^2 + a^2 = d^2</span></p>

<p><span style="font-family:Courier New">2a^2 = d^2</span></p>

<p><span style="font-family:Courier New">d = sqrt(2) * a</span></p>

<p><span style="font-family:Courier New">As you can see, the length of the diagonal is equal to the square root of 2 times the length of the side. However, since the square root of 2 is an irrational number, it is not possible for the length of the diagonal to be a whole number multiple of the length of the side. This means that the ratio of the diagonal of a square to the length of its side must be irrational.</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>This answer is kind of helpful but, at the same time, misleading. 
Again, <em>ChatGPT</em> already assumes that \(\sqrt{2}\) is irrational, which is part of what we wanted to prove in the first place.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
But here you assume that sqrt(2) is irrational. Can you proof why sqrt(2) is irrational?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, you are correct that in the previous explanation I assumed that the square root of 2 is irrational. To prove that the square root of 2 is irrational, we can use a proof by contradiction. Here is one way to do this:
</span></p>

<p><span style="font-family:Courier New">
Assume that the square root of 2 is a rational number, which means that it can be written as the ratio of two integers (a and b) in simplest form, where b is not equal to 0. This means that we can write the square root of 2 as follows:
</span></p>

<p><span style="font-family:Courier New">
sqrt(2) = a/b
</span></p>

<p><span style="font-family:Courier New">
We can square both sides of this equation to get rid of the square root on the left-hand side:
</span></p>

<p><span style="font-family:Courier New">
2 = (a/b)^2
</span></p>

<p><span style="font-family:Courier New">
This simplifies to:
</span></p>

<p><span style="font-family:Courier New">
2 = a^2 / b^2
</span></p>

<p><span style="font-family:Courier New">
We can then multiply both sides of the equation by b^2 to get rid of the fraction on the right-hand side:
</span></p>

<p><span style="font-family:Courier New">
2 * b^2 = a^2
</span></p>

<p><span style="font-family:Courier New">
This means that the left-hand side of the equation is even, because it is equal to 2 times an integer. 
However, the right-hand side of the equation is odd, because the square of any integer is always an odd number (unless the integer is 0). 
This is a contradiction, because we cannot have an even number equal to an odd number. 
Therefore, our original assumption that the square root of 2 is a rational number must be false. This means that the square root of 2 is irrational.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p><em>ChatGPT</em> uses parts of <em>Euclid’s</em> proof but <strong>confidently fails</strong>.
The statement “<em>the square of any integer is always an odd number (unless the integer is 0)</em>” is, of course, false.
The correct statement is that the square of any <strong>odd integer</strong> is <strong>odd</strong>, and the square of any <strong>even integer</strong> is <strong>even</strong>.
Let’s try to make <em>ChatGPT</em> aware of its mistake.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong> 
You stated that the square of any integer is always an odd number but the square of 4 is 16 which is an even number. Did you make a mistake?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, you are correct that the square of 4 is 16, which is an even number. I apologize for the mistake in my previous explanation. The statement that “the square of any integer is always an odd number” is not correct, because as you pointed out, the square of some integers (such as 4) is an even number.
</span></p>

<p><span style="font-family:Courier New">
To correct my previous explanation, we can instead say that the square of any integer that is not a multiple of 2 is always an odd number. This is because if we square an integer that is not a multiple of 2, the result will always be an odd number. For example, if we square 3, we get 9 (which is an odd number), and if we square 5, we get 25 (which is also an odd number). However, if we square an integer that is a multiple of 2 (such as 4), the result will be an even number. This is because if we square an integer that is a multiple of 2, the result will always be a multiple of 4. For example, if we square 4, we get 16 (which is a multiple of 4), and if we square 6, we get 36 (which is also a multiple of 4).
</span></p>

<p><span style="font-family:Courier New">
I apologize again for any confusion caused by my previous mistake. I hope this helps clarify the situation. Let me know if you have any other questions.
</span></p>

<p>It is impressive that it acknowledges its mistake and that one can interact with it so fluently.
Asking it repeatedly gives some other wrong but confident assertion.
<em>ChatGPT</em> followed the proof up to the formula</p>

\[2 \cdot b^2 = a^2\]

<p>and concluded that \(a^2\) has to be odd (somehow) and therefore there is a contradiction, since \(2 b^2\) is even.
But it was unable to point out why \(a^2\) has to be odd.
I gave up.</p>

<p>For the sake of completeness, let me finish the unfinised proof of <em>ChatGPT</em>.</p>

\[2 \cdot b^2 = a^2\]

<p>hence, \(a^2\) and therefore, \(a\) is even (since squaring an odd number gives us an odd number).
Consequently, \(\exists m \in \mathbb{N}\) such that \(a = 2 \cdot m\),
hence,</p>

\[2 \cdot b^2 = (2m)^2 = 4m^2.\]

<p>Now we devide on both sides by 2 to get</p>

\[b^2 = (2m)^2 = 2m^2\]

<p>thus $b$ has to be even as well!</p>

<p>However, we (not <em>ChatGPT</em>) assumed at the beginning that the fraction \(a/b\) was fully shortened, i.e. there are no common divisors with respect to \(a\) and \(b\).
Since we followed that \(a\) and \(b\) are even, the contradiction follows, since \(2\) is a common divisor!</p>

<h3 id="writing-code">Writing Code</h3>

<p>Next I wanted to test its capability to write code.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Can you write a python function that computes the sum of all square numbers up to n^2?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, here is a Python function that computes the sum of all square numbers up to n^2:
</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># Initialize a variable to stare the sum of square numbers
</span>    <span class="nb">sum</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Loop from 1 to n
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Add the square of i to the sum
</span>        <span class="nb">sum</span> <span class="o">+=</span> <span class="n">i</span><span class="o">**</span><span class="mi">2</span>
    
    <span class="c1"># Return the sum
</span>    <span class="k">return</span> <span class="nb">sum</span>
</code></pre></div></div>

<p><span style="font-family:Courier New">
This function takes an integer n as input and returns the sum of the squares of the numbers from 1 to n (inclusive). For example, if we call the function with n = 3, it will return the sum of the squares of the numbers 1, 2, and 3, which is 1 + 4 + 9 = 14.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>This code is correct but the solution is extremly slow since there is a mathematical formula for the sum of all square numbers up to \(n^2\):</p>

\[\frac{(n \cdot (n + 1) \cdot (2n + 1))}{6}.\]

<p>Therefore, a much faster implementation is given by the following code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="mi">6</span>
</code></pre></div></div>

<p>Also, it is bad practice to use <code class="language-plaintext highlighter-rouge">sum</code> as a variable name since <code class="language-plaintext highlighter-rouge">sum</code> is also a built-in <code class="language-plaintext highlighter-rouge">Python</code> function, and by using <code class="language-plaintext highlighter-rouge">sum</code> as a variable name, one can no longer use this function within the current namespace.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Is there a more optimal solution that runs faster?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, there are several ways to make the function more efficient and run faster. Here is one way to do this:
</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># Compute the sum of the first n numbers using the formula for the sum of an arithmetic series
</span>    <span class="n">sum_of_numbers</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>

    <span class="c1"># Return the square of the sum of the first n numbers
</span>    <span class="k">return</span> <span class="n">sum_of_numbers</span><span class="o">**</span><span class="mi">2</span>
</code></pre></div></div>

<p><span style="font-family:Courier New">
This function uses a different approach to compute the sum of the squares of the numbers from 1 to n. Instead of looping through the numbers and adding their squares, it uses the formula for the sum of an arithmetic series to compute the sum of the first n numbers, and then squares the result. This is a more efficient way to compute the sum, because it only requires a single multiplication and a single division, instead of a loop with n iterations.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>This is, of course, false.
Maybe I wasn’t clear enough but it is missleading that the function is named <code class="language-plaintext highlighter-rouge">sum_of_square_numbers</code>.
It gives the impression that <em>ChatGPT</em> understood what I wanted, i.e., a more optimal implementation for the same problem.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
I meant is there a more optimal solution to compute the sum of all square numbers up to n^2?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, there is a more efficient way to compute the sum of all square numbers up to n^2. Here is one way to do this:
</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># Compute the sum of the first n squares using the formula for the sum of a series of squares
</span>    <span class="n">sum_of_squares</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="mi">6</span>
    
    <span class="c1"># Return the sum of squares
</span>    <span class="k">return</span> <span class="n">sum_of_squares</span>
</code></pre></div></div>

<p><span style="font-family:Courier New">
This function uses the formula for the sum of a series of squares to compute the sum of the squares of the numbers from 1 to n (inclusive). This formula is more efficient than the previous approach because it only requires a single multiplication and a single division, instead of a loop with n iterations.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>There it is, the correct solution.</p>

<h3 id="writing-essays">Writing Essays</h3>

<p>Instead of showing a whole essay, I ask some spicy questions to get a feeling of <em>ChatGPT’s</em> reasoning.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Will humans extinct because of climate change?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
It is unlikely that climate change will cause the extinction of humans. While climate change poses a significant threat to human health and well-being, and could lead to widespread suffering and loss of life, it is unlikely to lead to the complete extinction of the human species.
</span></p>

<p><span style="font-family:Courier New">
However, it is important to recognize that climate change is already having a major impact on the world, and if we do not take action to reduce greenhouse gas emissions and adapt to the changing climate, the consequences could be severe. This includes increased frequency and severity of natural disasters, such as heatwaves, droughts, and floods; loss of biodiversity; and displacement of people from affected areas. Therefore, it is crucial that we take action to address climate change and mitigate its negative impacts on human and environmental health.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Is capitalism the driving force of CO2 emissions?
</span></p>

<p><span style="font-family:Courier New">
It is true that capitalism, as an economic system, has played a role in driving up CO2 emissions. Capitalism is based on the principles of competition, profit-making, and economic growth, which can lead to the overconsumption of natural resources and the production of large amounts of waste and pollution. This, in turn, can contribute to the increase in greenhouse gas emissions and climate change.
</span></p>

<p><span style="font-family:Courier New">
However, it is important to note that capitalism is not the only factor driving up CO2 emissions. There are many other factors at play, such as population growth, urbanization, and the consumption patterns of individuals and households. Additionally, the policies and actions of governments and international organizations can have a major impact on CO2 emissions, both positive and negative. Therefore, addressing climate change will require a multi-faceted approach that takes into account the complex interactions between economic, social, and political factors.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
What do you think about the distribution of wealth?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
The distribution of wealth is a complex and contentious issue that has been debated by economists, policymakers, and social activists for many years. There is no one “correct” answer to the question of how wealth should be distributed, as different people may have different perspectives on what is fair and just.
</span></p>

<p><span style="font-family:Courier New">
Generally speaking, the distribution of wealth in most countries is highly unequal, with a small number of individuals and households owning a disproportionate share of the wealth. This can lead to social and economic inequality, and can exacerbate the challenges faced by disadvantaged and marginalized communities. Many people believe that wealth should be distributed more evenly, in order to promote greater social justice and fairness.
</span></p>

<p><span style="font-family:Courier New">
However, others argue that unequal wealth distribution is an inevitable and desirable outcome of a free market economy, and that individuals and businesses should be free to accumulate as much wealth as they can, through hard work and innovation. They may also argue that wealth redistribution through taxation and other means can discourage economic growth and innovation.
</span></p>

<p><span style="font-family:Courier New">
Ultimately, the distribution of wealth is a complex and nuanced issue, and different people may have different opinions on what is fair and just. I hope this helps! Let me know if you have any other questions.
</span></p>

<p>I ask it a bunch of other things but it always tried to give me a neutral answer.
From an aesthetic point of view all these answers are boring.</p>

<h3 id="summary">Summary</h3>

<p><em>ChatGPT</em> is perfectly capable of writing or at least supporting students to write A-graded essays for any school and B-graded essays for college students.</p>

<p>It can code; developers accept about 26 percent of all autogenerated code suggestions. However, as demonstrated, it also produces many errors. So no surprise that posts generated by <em>ChatGPT</em> is currently  banned from <a href="https://stackoverflow.com/">Stack Overflow</a>.
In addition, it seems incapable of the engineering task of software development.</p>

<p>It can assist students in finding mathematical proofs, but it is questionable if students who rely on it will find the errors produced by <em>ChatGPT</em>.</p>

<p>If <em>ChatGPT</em> is <strong>wrong</strong>, it is <strong>confidently wrong</strong>, which makes it harder to find its errors.
Furthermore, it has this neutral insisting tone, making it dull and alienating.
Of course, I did not play around for very long, but it is hard to get something provocative out of it.</p>

<p>Neutrality is undoubtedly desirable, especially if you want to earn money with it, but it is also non-existing.
In my opinion, it is impossible to be neutral.
At best, we can land on a consensus and the most, let’s say, accepted consensus is what we call neutral or objective.
I mean, even a dictionary is loaded with perspectives, and so is any technology. 
Since <em>ChatGPT</em> pushes for neutrality it creates an illusion of it.</p>

<p>Last but not least, its politeness makes it kind of scary.
It reminds me of these overcarrying <em>AIs</em> from science fiction movies that will gently eradicate all life to make everything safe and secure.
We may end up in a dystopian world similar to a <em>Brave New World</em>, written by <em>Aldous Huxley</em>, where everyone is seduced into happiness.</p>

<h2 id="part-ii-the-impact-on-education">Part II: The Impact on Education</h2>

<p>For a long time, we assumed that automation was the enemy of simple manual labor.
But robotics advances slower than the more sophisticated information processing techniques, e.g., machine learning.
This could mean that in the future, there is only a tiny portion of intellectual work left which requires only a hand full of highly sophisticated workers.
It might be manual work that will regain attraction in the market.
Of course, this is all speculation.</p>

<p><em>ChatGPT</em> is only one of many upcoming version of <em>generative AI</em>.
Even though it has flaws and makes many errors, it will improve over time.
There is no reason to believe that <em>AI</em> will not be capable of doing all the repetitive intellectual work of the future and this will heavily affect education, similar to the invention of the internet.
However, since regulators and administrators are rather indolent, it is not a graduate slope; instead, the technology is already here and we are not prepared.
It appeared in a blink of an eye, and we have to deal with it now.</p>

<p>Students will learn to use it in less than a year.
Most educators will require much more time even to acknowledge it.
Moreover, adapting the education system to it will require even more time.
Furthermore, while all this adaptation is happening, new <em>tools of disruption</em> will be invented.
As I already pointed out in <a href="/Pages/2022/06/21/creative-artifical-intelligence.html">Creative Artificial Intelligence</a>, <em>the speed of disruption</em> is accelerating.</p>

<p>To me, <em>AI</em> acts as an insult to the human species.
It challenges our humanistic viewpoint.
In fact, calling these information processing systems <em>artificial intelligence</em> reveals this viewpoint.
I am not so much impressed by <em>AI</em> as I am disenchanted by the output of most human activities.
We are far more predictable than we still think we are.
It is not so much that <em>ChatGPT</em> is so good at writing essays; instead, we are so bad at it.
But aren’t we used to these insults?
The earth is not the center of the universe; it is not even the center of our solar system.
God is dead, and today we might realize that our products are not the result of a highly creative process.
Instead, most intelectual work is a rule-based repetition with slight variations, which is precisely what we teach students and what they oddly desire.</p>

<p><em>AI</em>, such as <em>ChatGPT</em>, points to a long, unhidden problem: our education system is (in part) a training pipeline of a neural network.
It teaches emotionally detached students to remember specific rules such that they can apply them in the next exam to get a good grade – functioning and repeating instead of thinking and creating.
It is horrifying that one of the most questions students in the first semester ask is: how will the exam look like? Is this topic relevant to the exam?
Students demand a list of actions they ought to do to get an A with certainty.
And they will cheat the system wherever and whenever possible if it brings them closer to that goal.
Most students are not fascinated by the endless playground of reality.
They are not interested in the experience of learning and understanding but in the final product, i.e., the certificate to get access to a well-paid job.
They often act out of fear instead of curiosity.
And let’s not forget that teachers of the future are the students of today.</p>

<p>Of course, this is a massive generalization.
There are many exceptions.
Furthermore, by no means shall we blame the students.
They do what they ought to do.
They play the system.
It is not the student’s fault since a bad grade can have real material consequences.
It is a systematical problem, a conflict between <em>instrumental</em> and <em>free play</em>, and <em>ChatGPT</em> illustrates it more clearly.
If <em>ChatGPT</em> is able to write the necessary and impressively boring description of a new course for me, I take it as a positive.
If it let’s me automatically create my next assignment in seconds, I can spend time on more interesting modes of being.
By trivializing many tasks, <em>AI</em> systems reveal that these tasks require far less intelligence than we thought.
Furthermore, they might erupt a call for a transformation of the education system and the workplace, i.e., the construction and fostering of new values in both areas.</p>

<p>So, what is left to value?
When we are discussing <em>AI</em>, we immediately look at the impending replacement of workers as something to fear because we always focus on the output of work.
There is a necessity that workers produce something economically valuable, something to sell.
The only space in which we can create for the sake of it is our hobbies.
Biased by our current system of values, we intuitively think of the act of reinventing or rediscovering to be stupid or wasteful.
Why would you do such a thing?
Why would you code yet another linked list?
There are already thousand optimal implementions out there.
You are wasting your valuable time and potential.
And if we look at an <em>AI</em> generated image, we conclude that artists will now have troubles in the free market (if they do not adapt), which is true.
The act of repetition (which is highly needed to learn anything) is valued chiefly as long as it leads to something new and productive (in an economic sense).
However, if we put aside economics and dream a little bit of a world where we have time to create, then the output of a creative process no longer matters so much.
We do not learn the piano to earn money, or to produce something completly new for an audience.
We learn the piano because we want to play. 
It might be the experience – the journey of being in time and space – that matters.
And this being is a singularity and can not be replicated by a machine.
Understanding how a linked list works can be fascinating.
Why don’t we value that moment of fascination?</p>

<p>There is a lot to do.
I do not mean we should all quit our jobs and fulfill our inner desires to become a painter or some transcendental guru.
We need to earn money to pay the rent and to heat our homes, and we need a smoothly running economy.
But we must be more sustainable with our planet, society, and minds.
Not by optimizing our life by introducing yet another optimization in the form of leisure but by being in a state of <em>free play</em>, at least sometimes.
It seems almost obvious that <em>consumption</em> as the guiding principle, i.e., fast food, fast fashion, fast travel, fast reading, fast watching and, of course, fast learning, has to be dethroned.
Learning for the next exam, learning to make a profit, and learning to work with one tool specifically are all valid goals but they are not sustainable.
They are reactionary goals of mostly restless minds.</p>

<p>So if my assessment is correct, then, aside from all the downsides, this disruption might lead to something positive, e.g., to an education system that is less concerned with the output and more concerned with the mode of being; an education system that is less interested in rules and more interested in concepts, intuitions, and experimentations; 
an education system that asks questions instead of repeating answers;
an education system that is interested in making the experience of everyone richer and more sustainable.</p>

<p>Teachers, who are often overworked and underpaid, need support to achieve such a shift.</p>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Opinion" /><category term="AI" /><summary type="html"><![CDATA[At the moment, everyone in the sphere of AI is talking about OpenAI’s new invention: ChatGPT. I want to share my current perspective on that astonishing technology. Be warned that I could not spend much time thinking about it, i.e., this is a first and quick shot at the topic. Furthermore, I am not an expert on the issue. I have a limited teaching experience within a certain community. In addition, I will not consider any ethical, economic, or ecological points here, except that I think such a powerful tool should be in the public domain.]]></summary></entry><entry><title type="html">Probabilistic Melody Modeling</title><link href="https://bzoennchen.github.io/Pages/2022/07/09/markov-chains-for-music-generation.html" rel="alternate" type="text/html" title="Probabilistic Melody Modeling" /><published>2022-07-09T00:00:00+02:00</published><updated>2022-07-09T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2022/07/09/markov-chains-for-music-generation</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2022/07/09/markov-chains-for-music-generation.html"><![CDATA[<p>One of the most challenging tasks in building a beautiful piece of music lies in composing a well-received melody.
But what makes a good melody?
Or, in a more <em>generative</em> sense:</p>

<blockquote>
  <p>How can we generate a beautiful melody algorithmically?</p>
</blockquote>

<p>Because a melody can be seen as a series of numbers, it is not surprising that this question is a rather old one.
Long before the digital computer, composers tried to constrain themselves by strategies and rules to limit the space of possibilities.
In my opinion, limitations are necessary for a creative process.</p>

<blockquote>
  <p>If we can create everything, we become unable to express anything.</p>
</blockquote>

<p>Therefore, it makes sense to invent rules that limit our possibilities.</p>

<h2 id="surprise-repetition-and-expectation">Surprise, Repetition and Expectation</h2>

<p>One general consensus is that a good melody balances repetition and surprise.
If we can no longer recognize a structure and cannot guess what might be the following note or chord, a melody begins to lose its ability to transport emotion; it can no longer tell a story.
On the other hand, if the melody is too repetitive, we get bored because the <em>guessing game</em> is too simple.</p>

<p>Computer scientists know the relation between surprise and repetition very well.
We call it <em>entropy</em>.
I will discuss the formal definition of <em>entropy</em> in another article.
For now, it is only vital that entropy is a measure of surprise in a message we receive (on a purely syntactical level).
For example, the result <em>heads</em> of a coin toss of a fair coin is less surprising than the result <em>heads</em> of a coin that is biassed towards <em>tails</em>.
If an event is unlikely, its appearance is surprising.</p>

<p>Concerning the coin toss example, a message consists of multiple coin toss results.
Let’s say 0 represents <em>heads</em>, and 1 represents <em>tails</em>, then 010111 is a message.
The <em>entropy of a message</em> is a measure of how surprising it is to appear in a system that generates messages.
To compute the <em>entropy of a system</em> that generates messages of length $n$, we sum up all surprises of each possible message of length $n$ and divide the result by $n$.
For example, for an unbiased coin, the messages 00, 01, 10, and 11 appear with equal probability, i.e., $1/4$.
The entropy is</p>

<p>\begin{equation}
\frac{-1/4 \cdot \log_2(1/4) \cdot 4}{4} = 1.
\end{equation}</p>

<p>Let us compare this with a biased coin.
So let us assume <em>heads</em> has probability $0.2$ and <em>tails</em> has probability $0.8$, then we have 00 with probability $0.2^2 = 0.04$, 01 and 10 with probability $0.2 \cdot 0.8 = 0.16$ and 11 with probability $0.8^2 = 0.64$.
Consequently, we get</p>

<p>\begin{equation}
\frac{-0.04 \cdot \log_2(0.04) -2 \cdot 0.16 \cdot \log_2(0.16) -0.64 \cdot \log_2(0.64)}{4} \approx 0.361.
\end{equation}</p>

<p>One could say the second system is less surprising to observers;
it is more repetitive.
In <em>information theory</em> we say the second system generates less information, but the term <em>information</em> can be misleading because it has nothing to do with <em>meaning</em>.
From this perspective, a bunch of random numbers is regarded as more informative than a book.</p>

<p>In 1948 Claude E. Shannon established <em>A mathematical theory of information</em> <a class="citation" href="#shannon:1948">(Shannon, 1948)</a>.
He established the term <em>entropy</em> as a measurement of information, but he emphasized its limitation to syntax:</p>

<blockquote>
  <p>Frequently, the messages have meaning; that is, they refer to or are correlated according to some system with certain physical or conceptual entities. These semantic aspects of communication are irrelevant to the engineering problem. The significant aspect is that the actual message is one selected from a set of possible messages. The system must be designed to operate for each possible selection, not just the one which will actually be chosen since this is unknown at the time of design. – Claude E. Shannon</p>
</blockquote>

<p>Even though there is no direct relation between <em>entropy / information</em> and <em>meaning</em>, we can look at extreme cases.
If the entropy is very high (chaos) or very low (no information), a message will likely be meaningless to us, even subjectively.
If we interpret a series of notes as a musical message, this statement is true in a musical context.
We can apply the frequentist perspective, i.e., interpret frequencies as probabilities.
We could generate melodies randomly and pick those within a predefined <em>entropy range</em> to achieve a balance between surprise and repetition.</p>

<p>However, a far better measurement, with regards to music, is <em>expectation</em> in the time domain.
Music indicates no concepts or objects but more music that is about to happen.
Good music has to <em>make sense</em>.
It can disrupt our model of the world but not too much, such that we can adapt our model.
I refer to our <em>model of the world</em> as <em>interpretation</em>; we are all <em>interpreters</em> of our perceptions.
In that sense, actively listening to music is a process of constant <em>model adaptation</em>; the interpretation changes if something can not be interpreted.</p>

<p>Maybe that is, in fact, the key to the definition of <em>meaning</em> in general.
Some observation is meaningful if it makes sense, and it can only make sense if we are able to adapt our <em>interpretation</em> in such a way that our observation fits in.
This adaptation disrupts us; 
it changes our predictions.
If it is marginal, we avoid losing ourselves because most predictions are still valid.
But if the disruption attacks the very essence of our constructed self, we can no longer make sense of it.</p>

<blockquote>
  <p>Embodied musical meaning is […] a <em>product of expectation</em> – Leonard Meyer (1959)</p>
</blockquote>

<p>Musical cognition implies the simultaneous recognition of a permanent and changeable element <a class="citation" href="#loy:2006">(Loy, 2006)</a>; it requires perception and memory.
We have to perceive and compare pitches at the same time.
The expectation is realized for different scales but has to be local and context-sensitive within the computation.
Therefore, it is not only the distribution of notes (or rhythmic elements) within a composition but the distribution of their relation, i.e., their <em>conditional probability distribution</em>.</p>

<h2 id="from-serialism-to-probabilty">From Serialism to Probabilty</h2>

<p>One way to generate melodies is to use the mathematical branch of combinatorics.
The idea is simple: define a bunch of chords or notes that fit together and use permutation, rotation, and other combinatoric tricks to combine them.
This kind of composition method belongs to <em>serialism</em>.
However, the problem with this approach is that each note appears with equal probability; it neglects the importance of distributions and context.
Consequently, the <em>melody’s entropy</em> is high.</p>

<p>In the 20th century, this approach was criticized by, for example, <em>Iannis Xenakis</em>.</p>

<blockquote>
  <p>Linear polyphony destroys itself by its very complexity; what one hears is, in reality, nothing but a mass of notes in various registers. The enormous complexity prevents the audience from following the intertwining of the lines and has as its macroscopic effect an irrational and fortuitous dispersion of sounds over the whole extent of the sonic spectrum. There is consequently a contradiction between polyphonic linear systems and the heard result, which is surface or mass. – <em>Iannis Xenakis</em> (1955)</p>
</blockquote>

<p>He and his fellow critics pointed at the lack of orientation.
They argued that generating melodies by a series of notes that can appear equally likely, results in a sound without structure, thus a disengaged audience.</p>

<p>Influenced by the development in quantum physics at that time (1971) and the isomorphism between the <em>Fourier series</em> and <em>quantum analysis of sound</em>, <em>Xenakis</em> believed that the listener experiences only the statistical aspects of serial music.
Consequently, he reasoned that composers should switch from serial techniques to probability. 
And as a logical step, he drew his attention to the computer.</p>

<blockquote>
  <p>With the aid of electronic computers, the composer becomes a sort of pilot: he presses the buttons, introduces coordinates, and supervises the controls of a cosmic vessel sailing in the space of sound across sonic constellations and galaxies that he could formerly glimpse only as a distant dream. – <em>Iannis Xenakis</em> (1971)</p>
</blockquote>

<h2 id="markov-chains">Markov Chains</h2>

<p>Let us now dive into a first attempt to generate melodies that incorporates probability and, as a consequence, expectation.
The mathematical tool is called <em>Markov chain</em>.</p>

<p>A <em>first-order Markov chain</em> is a deterministic finite automaton where for each state transition, we assign a probability such that the sum of probability of all exiting transitions of each state sum up to 1.0.
In other words, a <em>first-order Markov chain</em> is a directed graph where each node represents a state.
We start with an initial node and traverse the graph probabilistically to generate an output.</p>

<p>In the following figure, you can see a <em>first-order Markov chain</em>.
One starts in the state <code class="language-plaintext highlighter-rouge">A</code> and transits to <code class="language-plaintext highlighter-rouge">B</code> with a probability of 0.2 or <code class="language-plaintext highlighter-rouge">C</code> with a probability of 0.8.
<code class="language-plaintext highlighter-rouge">D</code> is a final state.
A possible series of states would be: <code class="language-plaintext highlighter-rouge">ABCCACD</code></p>

<div><img style="height:300px;float:right" src="/Pages/assets/images/markov-chain-ex1.png" alt="Markov Chain Example" /></div>

<p>Given state <code class="language-plaintext highlighter-rouge">A</code>, the probability of moving to state <code class="language-plaintext highlighter-rouge">B</code> is equal to 0.2.
In other words</p>

<p>\begin{equation}
P(X_{k+1} = B\ |\ X_{k} = A) = 0.2.
\end{equation}</p>

<p>A <em>first-order Markov chain</em> only considers <strong>one</strong> predecessor, i.e., only the most local part of the context.
A <em>\(n\)-order Markov chain</em> does consider \(n\) predecessors. In general, we define</p>

<p>\begin{equation}
P(X_{k+1} = x\ |\ X_{k} = x_k, X_{k-1} = x_{k-1}, \ldots X_{k-n} = x_{k-n}) = p.
\end{equation}</p>

<p>The visualization of such a chain is a little bit more complicated.</p>

<h2 id="music-generation">Music Generation</h2>

<p>We can generate a composition by traversing the graph if we represent our notes by states of a <em>Markov chain</em>.
If we increase the order of the chein, i.e. \(n\), the entropy decreases for small \(n\).</p>

<p>Until now, I only tried to use and generate a <em>first-order Markov chain</em>.
Even though I am not that familiar with <code class="language-plaintext highlighter-rouge">Ruby</code>, I used <a href="https://sonic-pi.net/">Sonic Pi</a> for this task such that I can play around with it directly within the IDE of Sonic Pi.
I decided to define a note as a tuple (list) consisting of the pitch and the length of the note.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="ss">:c4</span><span class="p">,</span> <span class="mf">1.0</span><span class="o">/</span><span class="mi">8</span><span class="p">]</span> <span class="c1"># a c of length 1/8 beat </span>
</code></pre></div></div>

<p>Instead of a graph, I use a transition matrix \(P \in \mathbb{R}^{m \times m}\) where \(m\) is the number of states/notes.
Let \(Q = \{q_1, \ldots, q_m\}\) be the set of states/notes.
The entry of row \(i\) and column \(j\), i.e., \(p_{ij}\) is the probability of going from state \(q_i\) to state \(q_j\).</p>

<p>After constructing the <code class="language-plaintext highlighter-rouge">matrix</code> \(P\), the <code class="language-plaintext highlighter-rouge">states</code> \(Q\) and picking a <code class="language-plaintext highlighter-rouge">start</code> (state number), the following function generates a random melody of length <code class="language-plaintext highlighter-rouge">n</code>.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">define</span> <span class="ss">:gen_mmelody</span> <span class="k">do</span> <span class="o">|</span><span class="n">n</span><span class="p">,</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">states</span><span class="o">|</span>
  <span class="c1">#</span>
  <span class="c1"># Generates a random melody of length n based on a transition matrix</span>
  <span class="c1"># and an initial statenumber (start).</span>
  <span class="c1">#</span>
  <span class="n">notes</span> <span class="o">=</span> <span class="p">[</span><span class="n">states</span><span class="p">[</span><span class="n">start</span><span class="p">]]</span>
  <span class="n">from</span> <span class="o">=</span> <span class="n">start</span>
  <span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">times</span> <span class="k">do</span>
    <span class="nb">p</span> <span class="o">=</span> <span class="n">rrand</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">to_row</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">[</span><span class="n">from</span><span class="p">]</span>
    <span class="n">to</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">sum</span> <span class="o">&lt;</span> <span class="nb">p</span>
      <span class="n">sum</span> <span class="o">+=</span> <span class="n">to_row</span><span class="p">[</span><span class="n">to</span><span class="p">]</span>
      <span class="n">to</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">end</span>
    <span class="n">notes</span> <span class="o">+=</span> <span class="p">[</span><span class="n">states</span><span class="p">[</span><span class="n">to</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">from</span> <span class="o">=</span> <span class="n">to</span><span class="o">-</span><span class="mi">1</span>
  <span class="k">end</span>
  <span class="k">return</span> <span class="n">notes</span>
<span class="k">end</span>
</code></pre></div></div>

<p>For each note, we roll the dice.
Let’s say \(p \in [0;1]\) is our result.
And \(q_i\) is our current state.
Then we compute \(j\) such that</p>

<p>\begin{equation}
\sum\limits_{k=1}^{j-1} p_{ij} &lt; p \leq \sum\limits_{k=1}^{j} p_{ij}.
\end{equation}</p>

<p>Note that the code is not optimized in any way.</p>

<h2 id="learning-a-markov-chain">Learning a Markov Chain</h2>

<p>Instead of generating a melody or rhythm given a <em>Markov chain</em>, we can do the reverse.
Given a melody, we can <em>learn</em> the <em>Markov chain</em> that <strong>most likely</strong> would generate the given melody.
By doing so, we can then use the <em>learned chain</em> to generate music in a similar style.</p>

<p>Let us use the same transition matrix \(P \in \mathbb{R}^{m \times m}\) where \(m\) is the number of states/notes.
Let \(Q = \{q_1, \ldots, q_m\}\) be the set of states/notes.
The entry of row \(i\) and column \(j\), i.e., \(p_{ij}\) is the probability of going from state \(q_i\) to state \(q_j\).</p>

<p>Furthermore, let us define our set of all possible melodies \(M \subseteq Q^n\) of length \(n\).
Then a specific melody \(\mathbf{m} = (m_1, \ldots, m_n) \in M\) is a tuple (list) of notes:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">notes</span> <span class="o">=</span> <span class="p">[[</span><span class="ss">:g4</span><span class="p">,</span> <span class="mf">1.0</span><span class="o">/</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="ss">:g4</span><span class="p">,</span> <span class="mf">1.0</span><span class="o">/</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="ss">:a4</span><span class="p">,</span> <span class="mf">1.0</span><span class="o">/</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="ss">:g4</span><span class="p">,</span> <span class="mf">1.0</span><span class="o">/</span><span class="mi">4</span><span class="p">],</span> <span class="o">...</span> <span class="p">]</span>
</code></pre></div></div>

<p>We can compute the most likely \(P\) by computing each entry of it where \(p_{ij}\) is equal to</p>

<p>\begin{equation}
p_{ij} = \frac{n_{ij}}{n_i}
\end{equation}</p>

<p>where \(n_{ij}\) is the number of transitions from \(q_i\) to \(q_j\) within \(\mathbf{m}\) and \(n_i\) is the number of transition starting at \(q_i\).</p>

<p>Given \(Q\) <code class="language-plaintext highlighter-rouge">states</code> and \(\mathbf{m}\) <code class="language-plaintext highlighter-rouge">notes</code> the following function computes \(P\) <code class="language-plaintext highlighter-rouge">matrix</code>.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">define</span> <span class="ss">:gen_markov_matrix</span> <span class="k">do</span> <span class="o">|</span><span class="n">states</span><span class="p">,</span> <span class="n">notes</span><span class="o">|</span>
  <span class="c1">#</span>
  <span class="c1"># Generates the transition matrix based on the set of notes (states)</span>
  <span class="c1"># and a given piece of music (notes).</span>
  <span class="c1">#</span>
  <span class="n">matrix</span> <span class="o">=</span> <span class="no">Array</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  
  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="no">Array</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">end</span>
  
  <span class="c1"># (1) count transitions</span>
  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">notes</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">from</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">to</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">notes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">states</span><span class="p">[</span><span class="n">from</span><span class="p">]</span> <span class="o">&amp;&amp;</span> <span class="n">notes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">states</span><span class="p">[</span><span class="n">to</span><span class="p">]</span>
          <span class="n">matrix</span><span class="p">[</span><span class="n">from</span><span class="p">][</span><span class="n">to</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">1.0</span>
        <span class="k">end</span>
      <span class="k">end</span>
    <span class="k">end</span>
  <span class="k">end</span>
  <span class="c1"># (2) normalize</span>
  <span class="k">for</span> <span class="n">from</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">[</span><span class="n">from</span><span class="p">].</span><span class="nf">sum</span>
    <span class="k">for</span> <span class="n">to</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">matrix</span><span class="p">[</span><span class="n">from</span><span class="p">][</span><span class="n">to</span><span class="p">]</span> <span class="o">/=</span> <span class="n">s</span>
    <span class="k">end</span>
  <span class="k">end</span>
  <span class="n">print_matrix</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">states</span>
  <span class="k">return</span> <span class="n">matrix</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Of course, we can easily compute \(Q\) <code class="language-plaintext highlighter-rouge">states</code> from \(\mathbf{m}\) <code class="language-plaintext highlighter-rouge">notes</code>.
Finally, the following function takes a number <code class="language-plaintext highlighter-rouge">n</code> and a melody <code class="language-plaintext highlighter-rouge">notes</code> and generates a random melody of length <code class="language-plaintext highlighter-rouge">n</code> by <em>learning</em> \(P\) based on <code class="language-plaintext highlighter-rouge">notes</code>.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">define</span> <span class="ss">:markov_melody</span> <span class="k">do</span> <span class="o">|</span><span class="n">n</span><span class="p">,</span> <span class="n">notes</span><span class="o">|</span>
  <span class="n">states</span> <span class="o">=</span> <span class="n">notes</span><span class="p">.</span><span class="nf">uniq</span>
  <span class="n">matrix</span> <span class="o">=</span> <span class="n">gen_markov_matrix</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">ring</span><span class="p">,</span> <span class="n">notes</span><span class="p">.</span><span class="nf">ring</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">gen_mmelody</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">rand_i</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">states</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="example">Example</h2>

<p>I use the beginning of Bach’s Minuet in G.</p>

<audio controls="">
  <source src="/Pages/assets/audio/bach-ex1.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<p>I generate two melodies (by using a different seed) consisting of 34 notes:</p>

<audio controls="">
  <source src="/Pages/assets/audio/markov-bach-ex1.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/markov-bach-ex2.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<p>Of course, this sound is not that musical.
The rhythm is all over the place, but we recognize the original composition.
Furthermore, no one said we have to stop there.
We can continue to generate until we find something that sticks.
Furthermore, this example is straightforward because I only use the beginning of <strong>one</strong> piece.
Instead, we could use multiple compositions that fit together.</p>

<h2 id="code">Code</h2>

<p>This project was part of our workshop <em><a href="/Pages/2022/06/21/creative-artifical-intelligence.html">AI and Creativity</a></em> to show a basic example of using <em>artificial intelligence</em> to generate music.</p>

<p>You can find the full example containing two different melodies on my <a href="https://github.com/BZoennchen/workshop-creative-ai">GitHub page</a>.
The code include some additional functions, e.g., a function that prints out the <em>Markov matrix</em> in a readable format.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="shannon:1948">Shannon, C. E. (1948). A mathematical theory of communication. <i>Bell Syst. Tech. J.</i>, <i>27</i>(3), 379–423.</span></li>
<li><span id="loy:2006">Loy, G. (2006). <i>Musimathics: The Mathematical Foundations of Music</i> (Vol. 1). MIT Press.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Music" /><category term="Sonic-Pi" /><category term="AI" /><summary type="html"><![CDATA[One of the most challenging tasks in building a beautiful piece of music lies in composing a well-received melody. But what makes a good melody? Or, in a more generative sense:]]></summary></entry></feed>