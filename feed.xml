<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://bzoennchen.github.io/Pages/feed.xml" rel="self" type="application/atom+xml" /><link href="https://bzoennchen.github.io/Pages/" rel="alternate" type="text/html" /><updated>2023-10-07T23:57:00+02:00</updated><id>https://bzoennchen.github.io/Pages/feed.xml</id><title type="html">Bene’s Blog</title><subtitle>A blog dedicated to computer science, education, music, philosophy and technology</subtitle><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><entry><title type="html">Social Systems Thoery and AI</title><link href="https://bzoennchen.github.io/Pages/2023/10/07/system-theory-and-ai.html" rel="alternate" type="text/html" title="Social Systems Thoery and AI" /><published>2023-10-07T00:00:00+02:00</published><updated>2023-10-07T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/10/07/system-theory-and-ai</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/10/07/system-theory-and-ai.html"><![CDATA[<p>Generative AI, especially ChatGPT, brought artificial intelligence into the public sphere and sparked a lot of highly speculative claims about <em>machine intelligence</em>.
I’m open to discussions and unafraid of confronting uncomfortable truths. 
Indeed, our imagination and fearless thinking should pave the way for new possibilities. 
Dreams and speculations are valuable, as long as they’re presented as such. 
However, I find it concerning when public figures speak with undue certainty, particularly when making anthropological comparisons between humans and machines.</p>

<h1 id="the-despair-caused-by-ai">The Despair Caused by AI</h1>

<p>What really hit me was watching Doug Hofstadter expressing his despair about the <em>eclipse of humanity</em>.
As a student, I had been influenced by his renowned book <em>Gödel, Escher, Bach: an Eternal Golden Braid</em>, often referred to as <em>GEB</em> <a class="citation" href="#hofstadter:1979">(Hofstadter, 1979)</a>.
The book delves into how cognition emerges from underlying neurological processes.
Let’s examine Hofstadter’s comments on the state of AI which I gathered from an interview:</p>

<blockquote>
  <p>I never imagined that computer systems would rival or even surpass human intelligence.
It seemed like a goal so far away.
My entire belief system was shaken; it’s a truly traumatic experience when some of your most fundamental beliefs about the world start to collapse. Particularly, the idea that human beings are soon going to be eclipsed. 
It felt as if not only my belief system was collapsing, but also as if the entire human race was about to be eclipsed and left in the dust soon. 
The accelerating progress has been so unexpected, it stirs a certain kind of terror of an impending tsunami that’s going to catch all of humanity off guard.
It’s unclear whether this signifies the end of humanity, in the sense that the systems we created could destroy us, but it’s certainly conceivable. 
If not, it relegates humanity to a relatively minor phenomenon compared to something else that is far more intelligent and will eventually become as incomprehensible to us as we are to cockroaches. I find that terrifying. 
I hate it! I think about it almost every single day.
And it overwhelms and depresses me in ways I haven’t experienced in a very long time. […]
It makes me feel diminished; it makes me feel, in some sense, like a very imperfect, flawed structure. 
Compared with these computational systems which have a million or billion times more knowledge than I have, and are a billion times faster, it makes me feel extremely inferior.
It almost feels like we deserve to be eclipsed. 
Unbeknownst to us, all we humans are soon going to be eclipsed and rightly so, because we are so imperfect and fallible. – Doug Hofstadter</p>
</blockquote>

<p>He passionately conveys a sentiment many intuitively feel: The essence of humanism is under siege.
Our unique skills are being surpassed, leading to concerns about our relevance.</p>

<p>I perceive Hofstadter’s view as human-centric, stemming from a longstanding tradition where humans are seen as the central figure, akin to being God’s creation.
This view encompasses our confidence in determining our fate, the idea of an individual separate from its environment, humans dominating over objects, a hierarchy with humans at the pinnacle, the notions of free will, and rational, independent beings arriving at a consensus in public discourse.</p>

<p>My aim is to approach Hofstadter’s comments from a distinct and somewhat radical angle.
I’m not asserting this as the absolute truth but rather as a story that might be useful in some aspects.
I’ll employ <em>systems theory</em>, specifically my interpretation of Niklas Luhmann’s <em>social system theory</em>, to counter this anthropocentric perspective and offer a challenging route deeper into and then hopefully out of despair.
While this perspective might not be accurate, it does challenge the confidence behind many claims, including those regarding <em>machine intelligence</em>.</p>

<h2 id="niklas-luhmann">Niklas Luhmann</h2>

<p>Niklas Luhmann (1927-1998) was a largely self-taught sociologist. 
Like postmodern thinkers, he believed that pursuing metaphysics was no longer productive, as there are no ultimate grand narratives that can explain everything. 
Rather than delve into metaphysics, he meticulously developed a comprehensive theory of modern society—–a theory that even encompassed itself and its creator.</p>

<p>Luhmann was an avid reader and writer, and he wasn’t hesitant to incorporate valuable concepts from fields like mathematics, cybernetics, and biology. 
To encapsulate everything, he employed a high level of abstraction and a technical terminology, which can make his writings appear dry and dense. 
Because his work is primarily descriptive—–explaining things as they are and exploring potential reasons for their states—–some categorize him as conservative. 
However, I perceive him as an incredibly well-read, sensitive, and discerning observer who wanted a new theory that can help us to transit into a new form of stability which is a rather progressive attitude.</p>

<p>In his introductory book <em>From Souls to Systems</em>, Hans-Georg Moeller <a class="citation" href="#moeller:2006">(Moeller, 2006)</a> highlights that Luhmann’s work is influenced by several philosophical giants:</p>

<ul>
  <li><strong>Kant</strong>: Luhmann shifts Kant’s focus on cognition to a constructivist perspective <a class="citation" href="#luhmann:1988">(Luhmann, 1988)</a>.</li>
  <li><strong>Hegel</strong>: Luhmann transitions from Hegel’s ideas of unity and dialectic to concepts of multiplicity and from identity to difference. He argues against any essential unity of systems and any general type of cognition.</li>
  <li><strong>Marx</strong>: Luhmann borrows Marx’s view that society isn’t just a byproduct of spirituality, but he disagrees with the idea of one foundational system (economics).</li>
  <li><strong>Husserl</strong>: Luhmann adapts Husserl’s work towards constructivism and incorporates many of his terms.</li>
  <li><strong>Habermas</strong>: Luhmann disputes Habermas’s mission of completing the enlightenment.</li>
  <li><strong>Postmodern thinkers</strong>: Luhmann draws from Deleuze’s radical differentiation, Derrida’s deconstruction, and Lyotard’s rejection of overarching narratives.</li>
</ul>

<p>With respect to his media theory Luhmann is quite close to French philosopher Baudrillard but far less dramatic.
While Baudrillard tends to express himself in dramatic metaphors and focuses on the media, Luhmann presents a supertheory of society where mass media is only one of many systems, all administered by the respective code.</p>

<p>Luhmann believed that the distinction between <em>modernity</em> and <em>postmodernity</em> is largely semantic.
He argued that the last significant structural shift in society occurred in Europe between the sixteenth and eighteenth centuries, transitioning from stratified to functional differentiation. 
To Luhmann, labeling a functionally differentiated society as either ‘modern’ or ‘postmodern’ is inconsequential.</p>

<p>Although his theory can be unsettling, Luhmann was optimistic about the future.
He agreed with the postmodern assertion that traditional philosophy had reached its end. However, he saw this as an opportunity for a rejuvenated, coherent self-description of society and a fresh theoretical framework for a new societal era:</p>

<blockquote>
  <p>Is this, after all, a postmodern theory?
Maybe, but then the adherents of postmodern conceptions will finally know what they are talking about.
The deconstruction of our metaphysical tradition pursued by Nietzsche, Heidegger, and Derrida can be seen as a part of a much larger movement that looses the binding force of tradition and replaces unity with difference.
The deconstruction of the ontological presupposition of metaphysics uproots our historical semantics in a most radical way.
This seems to correspond to what I have called the catastrophe of modernity, the transition of one form of stability to another. – <a class="citation" href="#luhmann:1993">(Luhmann, 1993; Luhmann, 2000)</a></p>
</blockquote>

<h2 id="social-systems-theory">Social Systems Theory</h2>

<p>So let me try to give you my incomplete understanding of his theory:</p>

<p>Luhmann recognised the particular complexity that human beings present for social analysis because they are the bearers of three autopoietic systems: systems of life (cells, brains, organisms), systems of consciousness (mind), and systems of communication (social systems).
As a sociologist he acknowledges but leaves aside the biological systems of human beings and instead focuses on the interactive relationship between their consciousness or psychic system and the social systems with which they interact.
The psychic system is within the environment of social systems vice versa.</p>

<p>He famously argued that communication between psychic systems happens not between (whole) persons or individuals.
This seems counterintuitive but if we spent a little more thought into his claim and clarify some termonology, it makes sense.
Hans-Georg Moeller put it the following way:</p>

<blockquote>
  <p>You cannot communicate with me with your mind or brain, you will have to perform another communicative operation such as writing or speaking. – <a class="citation" href="#moeller:2006">(Moeller, 2006)</a></p>
</blockquote>

<p>Luhmann described the mind (the psychic system) as well as social systems as <em>operational closed, structurally coupled, autopoetic systems</em>.
That are a bunch of important terms right away which require some explanation.</p>

<p>In Luhmann’s view a system is defined by its differentiation with its environment—<strong>differentiation</strong> plays one of the most important roles in his work.
This differentiation is esablished and obtained through the operations of the system.
The system differentiate itself from its environment thus it defines itself.
In other words, the system creates its own functions by its operations (self-creation and self-preservation).
Thinking leads to more thinking and perception leads to more perception.
The economy creates itself by doing economics, the mass media creates itself by its operation of differentiating between information and non-information.</p>

<p>A psychic or social system is <em>operational closed</em> because its operations can not leave the system.
Mental operations such as thoughts and emotions cannot leave the mind.
An economic transaction, e.g. paying for goods, can not ‘leave’ the economy.
No mind can interfere with the operations of another mind.
One cannot continue someone else’s mental activities by thinking or feeling for him or her.
It is also impossible to immediatly think what someone else is thinking.</p>

<p>However, systems can observe their environment and act on their terms.
We can hear what others say, see what they express and read what they have written.
Our mind can think about it (using its operations) and we can answer, i.e. communication happens.
We can also see pain or joy on other’s faces, but we cannot literally think or feel what they do.
The economy observes politics, the media, science and gets irritated.
How it will adapt is up to itself and its operations.</p>

<p>Other than <em>allopoietic systems</em>, which produce something other than the system itself, <em>autopoietic systems</em> reproduce themselves.
They are more dynamic than allopoietic systems because they deal with an excess of complicating noise from their environment (too much information that cannot be processed) by changing their structure (increasing internal complexity) to allow in more communications: they have a built-in learning capacity.
In contrast, allopoietic systems theory leads the observer to seek constancy and stability in system functioning because they are intrinsically conservative.</p>

<p>Social systems, like the media, become so efficient because they ‘feed’ the outside into their ‘body’.
A crisis, like a natural disaster or a war, feed the autopoiesis of the media.
It can report on the event and discuss different opinions on the matter.
Strictly speaking, the ‘goal’ of the media is not really to inform or to persuade but to continue its own self-production.</p>

<blockquote>
  <p>It is impossible to understand the reality of the mass media if you assume it is their job to provide correct information on the world and then assess how they fail, distort reality, and manipulate opinion—as if they could do otherwise. – Luhmann</p>
</blockquote>

<p>Therefore, attention is most important.
Informing people or persuading might help to ‘get enough food’ but it is not its ‘goal’ or ‘will’.
The same goes for the economy which trys to commodifies everything to further commodify things.
Politics politicizes anything and science produces truth about everything.</p>

<p>Even though Luhmann’s termology is close to the termonology of computer science, it is more helpful to think of these systems as interdependent organisms feeding on each other and willing to live than to think of hierarchical or well-structured computer or network systems.</p>

<p>Aside from being <em>autopoetic</em>, social and psychic systems are also <em>symbiotic</em>, that is, their <em>co-evolution</em> is <em>interdependent</em>.
Just as the trees in the forest need water and animals to survive, politics needs money from the economy, attention from the media, and ‘facts’ from science.
Media needs politics or science to produce news, and money to operate.
The economy uses media, politics, and science to make profits.
Science ‘sells’ truth to the economy, politics, and the media.
Academia needs money, attention and power.</p>

<p>Luhmann insists in putting human beings in the environment of social systems and not inside them.
In other words, social systems do not consist of humans but of communication!
This is sometimes seen as an anti-humanistic tendency which is framed negatively.
But one might argue that human beings are better off if their processes are not determined by society.</p>

<p>Luhmann’s theory provokes an amoral view on the state of affairs but it also gives power to the object (systems) thus attacks the domination of objects by subjects.
There are no evil people doing or planing insidious things, instead systems (objects) act on behalf their <em>systemic rational</em> by making sense of their environment on their terms.
What we often identify as hypocratical in a persons action is a mixture of the operations of <strong>different</strong> systems or the communcation between systems.
As a reminder, the person is not part of the system.
Individuals are a necessary condition that social systems can exist (like air has to exist to hear sound) but they belong to the environment of the social system (they do not produce the sound).
If a politician acts immoral and accepts a lot of money for his party to give a certain company an advantage over its competitors, the politician is the mere medium through which the economy communicates with politics.
If a politician of the Green Party goes on vacation by plane and at the same time speaks out against air traffic, two different systems are operating: the family and politics.
And the operation of the first does not interfere with the operations of the second.
However, the media make news out of this contradicting behaviour which will irritate politics.</p>

<p>Psychic systems are <em>operationally closed</em> but <em>cognitively open</em>.
They have clear boundaries demacrating them from other systems.
They reproduce themselves by adapting and learning how to cope with external noise by only selecting communcations which the system can actively and creatively interpret and <em>understand</em> or make sense of.
Psychic systems (and social systems) reduce complexity of their environment through recourse to meaning.
These system increase inner complexity to deal with the complexity in their environment.</p>

<p>The boundaries of these systems are not defined physically, but by the border of what is meaningful and what is not.
Consequently, each system has its own <em>systemic rationality</em> and view of the world—there is always a blind spot.
If I give a cashier money it is assumed that I paid for something.
This follows from the systemic rationality of the economic system.
It deals with money but it cannot, for example, deal with love or passion which are part of the <em>systemic rationality</em> of relationships.
The cashier does not suspect me that I show him my love with this gesture and if I do, this act is not an operation of the economic system.</p>

<p>The <em>functional differentiation</em> of each system makes it so that only parts of a person is acknowledged by the system.
The health system understands a person as a patient.
The legal system understands a person as a potential criminal, victim or witness.
This differentiation makes systems extremly efficient <strong>with respect to their function</strong>.
Luhmann thinks that this differentiation (Ausdifferenzierung) is a feature of modern society, i.e. it is historical and is an ongoing process.
One example might be the creation of new subjects to study.
Instead of studying computer science, students can enroll in scientific computing, data science, game engineering, information engineering, and more.
One can say computer science is furhter differentiated.
At the same time, we acknowledge problems stemming from this differentiation and try to find ways to look at problems and society more holistically.
Marignal Note: If we follow Luhmann’s theory and we want efficiency (with respect to a systemic rational) we find a strong argument to avoid introducing interdisciplinary subject such as bioinformatics by simply combining biology with informatics.</p>

<p>The functional differentiation of systems, its effects and our gut reaction is nicely depicted in the movie <em>Don’t Loop Up</em>.
What the movie does well is showing us that society consists of functional differientiated systems that follow their own <em>systemic rational</em>.
The main message of the movie is that scientists, who discover the meteor, are unable to communicate this truth to the world.
The movie shows mostly four social systems: politics, media, economy, and science.
It shows how each of these systems functions differently while still being coupled with one another via a <strong>shared medium</strong> (language), as explained above.
But inspite of being coupled, or because of it, they cannot act unitedly.
The effectiveness of functional differentiation to deal with complexity comes at a cost: <em>Anarchy</em>, that is, there is no controlling system or governing system, no single rationality that is in charge.
From a humanistic or reductionist standpoint, the actors of the movie seem completely irrational.
Only the scientist, who also represent the perspective of the audience, seem to do the ‘right’ thing.
But from a systemic view the actions of actors make sense.</p>

<p>In the end, the narrative of the movie is however a contradiction to the systemic view.
The movie suggest that there is some sort of scientific technological solution that can be used if everyone is thinking and acting properly—if only the government takes proper control, and the media informs everyone correctly then the meteor can simple be nuked.
The movie suggest that there can be some sort of rational self-control if only we would be <em>enlightened</em> enough.
In a sense, it is not much better than the movie <em>Idiocracy</em>.
The dream is that enlightened science can control nature through rational technology, enlightened politics can control society through rational self-government of the people, and enlightened media disseminates knowledge and makes everyone an informed and rational citizen.
Therefore, the movie presents an individualistic solution.
Big tech is greedy, politicians are stupid and hypocritical, and scientists are incapable of being live on TV.
If we fix those issues, we are fine.
If only we ‘look up’ (individually), we will be enlightened and stop being stupid and ignorant and we will solve all our modern problems.
The problem becomes a moral problem of personal responsibility thus it becomes polarizing.
From a systems theory perspective, this individualistic solution is not (or no longer) possible.
Systems function according to their functional differentiation on their terms and individuals are part of their environment.</p>

<p><em>Anarchy</em> does not imply the absence of strata or the presence of equality.
It’s evident that systems like the economy can create significant <em>differences</em> between the rich and the poor. 
Luhmann recognized that modern society inherently produces many differences, including those we might disapprove of. 
Every system does this, not just the economy.
However, contrary to a Marxist perspective, Luhmann believed that these societal disparities result more from the operations of multiple systems than from the stratum or class into which people are born. 
That said, an individual’s socioeconomic background, such as whether their parents are rich or poor, does matter. 
For example, in the education system, the ability of one’s parents to afford tuition at prestigious institutions like Stanford plays a significant role due to the interconnectedness of the economic and educational systems.
However, to genuinely understand how systems like education or academia function, one must grasp their unique <em>differentiators</em>. 
The education system is defined by distinctions like good grades versus bad grades, while the academic system differentiates between peer-reviewed and non-peer-reviewed papers.
These differentiations are intrinsic to their respective systems and not solely based on economic factors.
According to Luhmann, while wealth can certainly influence educational outcomes, avoid legal troubles, or facilitate a scientific career, it’s overly simplistic to reduce all systemic distinctions to just ‘money’.
But again, of course it helps a lot if you have money if you want good grades, stay out of prison, or become a scientist.</p>

<p>Luhmann argues that all social systems operate on a binary code determined by their sphere of interest which structures their communication with other systems.
Communication with the legal system is organised by the code legal/illegal through the medium of law;
with the political system by the code government/opposition through the medium of legitimate power;
with the economy through money with the code pay/not pay;
with science by the code true/false through the medium of evidential truth;
with the mass media system by the code information/non-information through the medium of public opinion;
and with the welfare benefits system by the code eligible/not eligible through the medium of citizenship status.</p>

<p>Without their environment systems would cease to exist.
They are <em>structurally coupled</em> with one another.
For example, psychic systems are structurally coupled with social systems—without bodys and minds there is no political system, no economy, no relationship and no family.
Without the economy, the political system would collapse.
However, there is <strong>no causal relationship</strong> between the two;
society does not cause consciousness to occur, neither do people consciously create and manage society.
The relationship between the two is rather one of constant <em>irritation</em> (which may be also translated to <em>confusion</em>) with the one reacting to the other, but always on its own terms.
The dynamics are not linear but <em>chaotic</em>.</p>

<p>If the political system enact a new law to steer the economy, it can only try to do so via irritation.
How the economy will react is not up to politics.</p>

<p>If climate activists glue themselves to the ground to generate awareness, they may achive their goal or they may not.
What happens is quite difficult to predict.
How does the media report on the issue if its rational is to further differentiate between information and non-information?
How will politics react based on the assumption that it ‘wants’ to make more politics?
From this point of view, it is hard to see how ‘we’ can ‘make’ cooperations (or individuals) sustainable by refering to morals and virtues.
Moral outbursts and frustrations about the destruction of our livelihood are completely understandable (for my psychic system) but how they irritate the different systems is quite uncertain.</p>

<h2 id="artificial-communication">Artificial Communication</h2>

<p>Niklas Luhmann’s concept of communication offers a useful framework for sidestepping (at least for a moment) the ongoing debate about <em>machine intelligence</em>.
While I personally do not ascribe human-like thinking or understanding to machines, I argue that this does not preclude their participation in communication processes, as underscored by <a class="citation" href="#esposito:2022">(Esposito, 2022)</a>.</p>

<p>I think Esposito’s term <em>artificial communication</em> is a very useful contribution to make the discussion of <em>AI</em> (especially of machine learning) more reasonable.
Note that she was a student of Niklas Luhmann.</p>

<p>In an interview she explains why she came up with the term:</p>

<blockquote>
  <p>These algorithms became more and more opaque—not understandable for the users—the idea spread that the activities of machines are not trying to be intelligent; that they are not trying to reproduce, in an artificial way, the process of human thought; they are doing something different.
This is rarely said explicetly but one can find it in many different contexts.
And if we switch away from the idea of intelligence, what can we refer to?
Do we have another metaphor that would fit better into the current situation? – Elena Esposito</p>
</blockquote>

<p>Why do people think that ChatGPT is intelligent?
Well, if we interact with machines, we get information we would not get otherwise and the information cannot be attributed to any human being.
The machine processes the data and produces some information which not only did not exist before but is also a sort of reaction to our request.
The machine does exactly what we do when we communicate with a human being.
We ask something and we get some information we did not had before.
Importantly, this information is <strong>contingent</strong> (the response could be different).</p>

<p>Esposito clarifies that, as a sociologist, it is understandable that we think of these machines as <em>artificial intelligence</em> because we have been communicating with human beings for thousands of years and these beings were ‘intelligent’.
And because of this feature of being able to think, humans were able to produce something which allows us to get new information.
It is our prejudice that lead us to the conclusion that machines are so similar to human beings, i.e., psychic systems.</p>

<p>Therefore, to follow Esposito’s proposal, a more interesting and probably healthier question to ask (also for us computer scientist) is:</p>

<blockquote>
  <p>Why are these machines able to communicate with us inspite of the absence of their intelligence?</p>
</blockquote>

<p>Esposito’s answer is that they are <em>parasitical</em>.
My understanding of her work is that machines make heavy use of <strong>second-order observation</strong>, i.e., the observation of an observer.
The starting point is some mental activity but not the machine’s activity.
The user produces <em>contingent</em> behaviour which the machine can process (or observe) to become itself <em>contingent</em>.</p>

<p>A modern example that might no longer be considered AI is Google’s search algorithm. 
Google’s success stems not from trying to evaluate or calculate the quality of a webpage directly.
They didn’t design an intelligent machine for that purpose. 
Instead, they leveraged <em>second-order observation</em>, essentially tapping into the collective intelligence of their users. 
Rather than determining the value of a webpage themselves, their algorithm observes how users interact with and evaluate webpages. 
A webpage ranks high if users deem it valuable. 
The primary task becomes observing user behavior.</p>

<p>Even if Esposito speaks of switching the metaphor, her work goes deeper.
The word <em>intelligence</em> has two different usage in language which are often confused.
On the one hand we refer to the operational mode of the mind.
But we have almost no idea what this <em>intelligence</em> exaclty is.
On the other hand we think of information processing, take for example the term Central Intelligence Agency (CIA).
Therefore, metaphor of <em>artificial intelligence</em> is so problematic which makes it hard to theorize about <em>AI</em> and its impact which leads to these hyper-speculative predictions.
By using Luhmann’s theory of communication, we might clear the smoke and find more effective ways to talk about artificial intelligence.</p>

<p>Esposito argues that we—the preachers of machine learning—do not reproduce human intelligence but rather social communication.
Intelligence that emerges from conscious beings might not be needed or might even be an obstacle for the establishment of communication.
Artificial communication (coupeling achines and psychic or social systems via language) can be more effective than intelligent communcation (coupeling psychic and social systems via language) but it can not be intelligent (refering to the first use of the word).
In other words: That which makes society more intelligent might not require to be intelligent.
As described above, social systems have their own <em>systemic rational</em> and we might call them intelligent.</p>

<p>Systems theory is useful because it focusses on communication itself.
Again, Luhmann claims that humans do not communicate, only communication communicates.
Of course similar to air, humans are a necessary condition for communication but, like air, they do not communicate themselves.</p>

<p>Luhmann diverges from traditional sender-receiver models of communication, such as Shannon’s <a class="citation" href="#shannon:1948">(Shannon, 1948)</a>, where the focus is on the transmission of information.
Instead, Luhmann conceptualizes communication as comprising three essential moments: <em>announcement</em>, <em>information</em>, and <em>understanding</em>.
Each component has its unique role in facilitating communication.
An announcement initiates the process.
Whether verbalized, written, or visualized, it serves as the catalyst that triggers communication.
Absence of an announcement, be it from a human or an algorithm, results in the absence of communication altogether.
This announcement must bear some form of informational value, imbuing the text, image, or utterance with meaning.
The final moment, understanding, underscores the necessity of a recipient comprehending the conveyed information.
The efficacy of communication is not solely predicated on accurate understanding, but rather on the act of understanding itself—even if what is understood is incorrect.
As Luhmann notes, understanding is often replete with misunderstandings, but the very act of engaging in a selection of understanding is vital.
Understanding is typically misunderstanding without understanding the ‘mis’ (similarily, misinformation is still information).</p>

<p>In summary, Luhmann’s perspective underscores that effective communication doesn’t necessarily require partners to achieve mutual understanding in the way their respective psychic systems might operate.
I think we can make the same observation in our day to day life.
Even partners can perfectly live together even though their understanding is not mutual which, of course, can cause problems in relationships.
However, it can also be a useful feature.
If a third party observe a tense conversation between a couple, the content of the conversation might be quite ordinary but what is communicated can be a conflict within the relationship.
The couple understands the communication much better than the third party.
The conflict, however, it is likly caused by the problem of different previous (mis-)understandings.
For the third party, it is like listening to some encrypted communication.
Whether executed by humans or algorithms, the value lies in the process and its constituent parts: announcement, information, and understanding.</p>

<p>In the context of artificial intelligence we can look at the communication of a person and a machine—of ChatGPT and Doug Hofstadter—and we can ask: Why is it so effective or attractive? 
But also: Why is it (probably) not the product of an intelligent thinking system but rather produces social intelligence?</p>

<p>With my shallow understanding of Luhmann’s theory, I imagine that the prerequisites for communication—whether artificial or otherwise—involve <strong>contingency</strong> and <strong>connectivity</strong>.
In social systems theory, the generation of information is not an isolated act; it is attributed to an interactive partner.
While traditionally this partner is human, in the realm of artificial communication, it can very well be a machine.
The focus should be on the nature of the interaction itself: Does it exhibit the characteristics of a contingent, autonomous relationship?
And does this interaction spur further communication?</p>

<p>Traditional machines that produce unpredictable outcomes are usually considered faulty rather than creative or original.
Take a pocket calculator, for instance; its primary virtue lies in its predictability.
We do not regard it as a communicative entity because it operates as expected which is desirable.
The calculator is not contingent.
Conversely, when interacting with image-generating algorithms like Stable Diffusion or Midjourney the appeal, I argue, is precisely in the unpredictability of the results.
Chatting with a bot can be exciting preceisly because we do not know the output of the bot or, in general, the outcome of this interaction.
Of course, this does not mean a completely random output would have the same effect.
<em>Contingency</em> should not be confused with randomness or arbitrariness.
The information provided by the bot has to be understandable, in the sense that it can also be misunderstood (like any ‘good’ communication can be).</p>

<p>Despite thinking of this feature as a flaw, this ambiguity is desirable for communication.
Of course, not all possibilities of misunderstanding are desirable.
A chatbot that provides patients with medical or organizational information should give precise and unambiguous answers.
However, in this case the bot is more like a tool than a real communication partner.</p>

<p>And here we land at an important distinction:
While many argue that irritation caused by <em>generative AI</em> is similar to the invention of photography, I think there is a difference.</p>

<blockquote>
  <p>Photo cameras do not communicate!</p>
</blockquote>

<p>This does not mean that generative AI can not act as a mere tool in the process of, for example, the production of images.
The more predictability the more tool-like generative AI are and the communicative they become.
There outputs by themselves become less interesting but at the same time, they are more useful to realize a specific vision of the user or artist.</p>

<p>As Esposito noted: Viewed through the lens of Luhmann’s social system theory, the development of compelling communication partners presents a unique dilemma: 
The challenge lies in engineering machines that exhibit both creativity and control, balancing the production of unexpected outcomes with predictability.
This tension is especially relevant in the field of AI art.
In essence, the paradox that governs the programming of ‘intelligent’ algorithms is the pursuit of controlled unpredictability.</p>

<blockquote>
  <p>The ultimate objective is to achieve a controlled lack of control. – <a class="citation" href="#esposito:2022">(Esposito, 2022)</a></p>
</blockquote>

<p>From a philosophical standpoint, Luhmann transforms the <em>mind-body problem</em> into the <em>mind-communication problem</em>—communication defined by Luhmann as “the operation that society consits of” <a class="citation" href="#moeller:2006">(Moeller, 2006)</a>.
If the mind does not communicate but is only in the environment of society (communication)—is merely involved—how does this all work?
Similarily, I think, the question of how <em>artificial communication</em> emerges even if machines are also only in the environment of communicating systems, is one of the most important question to ask if one wants to understand the current state of AI, society and where we are heading at.</p>

<p>Now, if one looks closely to Luhmann’s definition of communication, we find that it is not compatible with Esposito’s concept of <em>artificial communication</em> and she is aware of that.
We might think of communication being really picky, that is, it has a lot of requirenments to occur—there is a lot of <em>structural coupling</em> going on.</p>

<blockquote>
  <p>Communication is improbable. – Luhmann</p>
</blockquote>

<p>Let look at some requirements: the physical requirements like temperature and gravity at a certain level, water, air, but also a medium and, according to Luhmann, at least two consciousness entities. 
In a sense the coupling of these two consciousness entities is more strict.
It is an equal operation of the psychic system that has to be devoted to the actual operation of the social system.
That is why they coincide in this event at which communication happens.</p>

<blockquote>
  <p>Empirically, I propse [the concept] because what is going on in the interaction with algorithms is so close to communication that we have to try to find a way to extend [Luhmann’s] concept of communication to include what is going on—it is not exactly the same.
The technique of the communication is similar: production of information which irritates other systems but the algorithm itself is not thinking, is not producing any new communication.
It just sort of conveys something that can produce information somewhere else.
My background is Luhmanian but what I am proposing, without wanting to amend Luhmann, is something different from the standard case of communication  – Elena Esposito</p>
</blockquote>

<h2 id="ai-as-profilicity-machines">AI as Profilicity Machines</h2>

<p>The philosopher Hans-Georg Moeller adds an interesting point to the machine learning discourse.
He posits that algorithms nowadays are used for profile building—he coined the term <em>profilicity</em> as a new identity technology, which is different from previous modes of identity building, i.e., <em>sincerity</em> and <em>authenticy</em> <a class="citation" href="#moeller:2021">(Moeller &amp; D’Ambrosio, 2021)</a>.</p>

<p>Following his thesis, people taking pictures, not (primarily) to preserve memories, but to curate a profile on Facebook, Instagram or LinkedIn.
In that sense, I too build my own profile by writing this text and by curating a personal website, a GitHub repository, and many more profiles.
AI helps us to evaluate our profile(s) within the McLuhan’s <em>Global Village</em> <a class="citation" href="#mcluhan:1992">(McLuhan, 1992)</a>.
It makes it possible to get feedback from our peers and to present this evaluation back to the village.</p>

<p>Moeller admits that he is—as many of us coming from an age where authenticy was the primary technology to build identity—annoyed by this picture frenzy.
But he stays true to Luhmann and refrains from judging.
He trys not to moralize this phenomenon or change or classify it as being ‘worse’ or ‘better’ because, in his eye, authenticy was never real in the first place.
Like the other forms of identity building, profilicity comes with its own problems.
Each mode brings its own set of challenges.</p>

<p>He intriguingly describes profile creation as <em>genuinely pretending</em>.
Observing younger generations, this resonates.
Their digital avatars often exude a <em>postmodern irony</em>; they knowingly embrace its constructed nature.
They are fully aware that it is all ‘fake’.
Contrarily, older generations may need reminding that these online images are meticulously curated and often manipulated.
Advising younger folks about the ‘deceptions’ of online portrayals might seem naive.
Their approach is more playful, even inventive, using multiple layers of meta-references to distance themselves from reality as far away as possible.</p>

<p>As Moeller notes, the real tension might arise from the mismatched expectations of older authority figures. 
We—and I include myself here—expect authenticity while most parts of the world of young people operate in the mode of profilicity.
This leads to a contradiction and, because it is about identity building, this contradiction might be psychologically problematic.
Misaligned expectations can cloud the path to self-realization.
Hence, while it’s tempting to solely blame social media for rising mental health issues, the underlying causes, as Luhmann would argue, are multifaceted.</p>

<h2 id="the-revenge-of-objects">The Revenge of Objects</h2>

<p>With the description of society handed over by systems theory, I might have lured you, the reader, into an even greater despair.
My assertion is that we don’t necessarily need AI to challenge Hofstadter’s vision of human greatness; 
the <em>deconstruction</em> might already be underway.
Luhmann’s system theory goes against the honorable belief of Hofstadter which is also expressed by figures like David Graeber or Noam Chomsky.</p>

<blockquote>
  <p>The ultimate, hidden truth of the world is that it is something that we make, and could just as easily make differently. – David Graeber</p>
</blockquote>

<p>I really like the sentiment expressed in the quote.
I want it to be true and to work!
And I admire personalities that keep it alive.</p>

<p>However, objects seem to regain agency and power over us.
When certain philosophers discuss subjects and objects, they often reference commonplace items like chairs and desks.
For instance, a chair might seem like a benign example. 
Here the case seems trivial: Of course a chair has no agency!
We make chairs to sit on them.
We dominate charis.
They are completely in our control.</p>

<p>But we do not have to look further than <em>Heidegger’s hammer</em> <a class="citation" href="#heidegger:1927">(Heidegger, 1927)</a> to see that things can get tricky very quickly.
Heidegger proposes that before we ponder the essence of a hammer, we use it. 
Before we question its existence, we recognize its utility.
The hammer, in this context, prompts us to act—it, indirectly, has agency.</p>

<p>Or consider more potent examples like opioids, smartphones, the internet, algorithms, images or even movies.
These items influence our behavior, decisions, and perceptions.
The inception of video technology, for example, started with the simple goal of determining if a galloping horse ever had all its hooves off the ground simultaneously.
Now, reflect on the vast implications and transformations that this technology has since undergone.
Did we solely shape these inventions, or should we attribute some credit to the inventions themselves?</p>

<p>For Baudrillard there is an uninterrupted production of positivity that has terrifying consequences.
Applying systems theory terminology, he speaks of <em>runaway positive feedback loops</em>.</p>

<blockquote>
  <p>Any structure that hunts down, expels or exorcizes its negative elements risks a catastrophe caused by a thoroughgoing backlash, just as any organism that hunts down and eliminates its germs, bacteria, parasites, or other biological antagonists risks metastasis and cancer—in other words, it is threatened by a voracious posivity of its own cells, or, in the viral context, by the prospect of being devoured by its own antibodies. – <a class="citation" href="#baudrillard:1990">(Baudrillard, 1990)</a></p>
</blockquote>

<p>In other words, runaway positive feedback loops that have no negative, will eventually cause a catastrophe.
A simple technical example of such a feedback is a microphone that picks up the amplified sound output of loudspeakers in the same circuit, then howling and screeching sounds of audio feedback.</p>

<p>Baudrillard thought that the production of images is such a feedback loop.
They are <em>out of control</em> and take over, for example, free democratic politics.
Although we can take a moral stance against certain imagery, such as pornographic content, Baudrillard suggests that positive feedback will ultimately subvert any moral code.
Trump, as an example, may be critiqued from a moral perspective, but because he’s a potent subject for image production, the media engages with him regardless of whether they criticize or praise him. This cycle of image production can’t be halted simply by creating more images.</p>

<p>Luhmann may have a less bleak view. 
For instance, laws that regulate AI-generated images, can prompt changes in a system’s behavior (indirectly via irritation).
However, reining in runaway positive feedback is challenging, as issues can escalate exponentially.</p>

<p>It might sound unconventional, but to foster our understanding of our world it could be beneficial to acknowledge external influences like reality TV, staged political photos, or conspiratorial content as agents.
Not only in a sense that they affect us but that they have an inner life; a will of their own so to say.
It could be valuable to treat objects like oil with the same reverence and respect as ancient civilizations treated strom and thunder.
Isn’t it the case that in our times oil is more powerful than any ancient god ever was?</p>

<p>Predictive machines can sometimes inadvertently create self-fulfilling prophecies. 
For example, I might be more inclined to buy items from Amazon that appear at the top of a list because of their prominent placement. 
These items are ranked by an algorithm aiming to maximize Amazon’s profits, predicting which items I’m most likely to purchase.
Since I’m inclined to buy items higher up on the list, the algorithm’s prediction is validated, influencing its future predictions and creating a positive feedback loop which consists of me and the algorithm.
Because I rely on algorithms to find items to buy, I believe it’s fair to say that they have influence over me and a sort of agency of their own.</p>

<p>If we don’t attribute agency to objects, then the explanation for the failures of climate agreements likely rests on a dysfunction of the system or on individual failures, e.g. corrupt or incompetent politicians.
The idea that our modern society renders us freer and more independent is misconstrued.
A better way to put it is: We are (more) <em>out of control</em>.
While we engage in broader dialogues, express ourselves diversely, and view the world through varied lenses, increasing complexity often amplifies dependency and chaos.
There is more differentiation going on but this does not mean that we are less dependent but systems are less controlable.
The age-old dynamic of subjects dominating objects could very well be shifting, placing objects alongside us in terms of influence.</p>

<h2 id="artificial-systems">Artificial Systems?</h2>

<p>Systems theory doesn’t assert that society’s evolution is innate or that it will remain unchanged forever.
It simply aims to provide a thorough depiction of modern society. 
Yet, it’s worth exploring the connections between systems theory and artificial intelligence.
This exploration might hint at the concept of an <em>artificial system</em>—–essentially an AI that functions as a system, potentially approaching the capabilities of general artificial ‘intelligence’.</p>

<p>To venture a speculative idea, machines might eventually evolve into these <em>artificial systems</em>.
To thrive in a highly complex modern environment, they might need to exhibit traits similar to psychic and social systems: being <em>autopoietic</em>, <em>structurally coupled</em>, <em>operationally closed</em>, and <em>functionally differentiated</em>.
If we assume this to be true, what implications might it has?</p>

<p>While minds create themselves through mental operations, an <em>artificial system</em> would self-create and self-preserve through computation.
Computation would drive more computation; 
the primary purpose being to continue its computational operations.</p>

<p>Due to their operational closure, a synthesis of thinking and computation—a transhumanist vision—seems unlikely.
Also, their structural coupling suggests they’d be interdependent on psychic systems and other social systems.
Natural language processing might be an important aspect of AI because it potentially makes this coupling possible via the <strong>shared medium of language</strong>.
This implies that the idea of AI overthrowing humanity is also improbable.
It is more likely that our mind, i.e. our thinking/feeling co-evolves with computation/text generation.
Machines will not think for us but they might irritate our thinking because we might need different skills to survive in an environment consisting of such machines.
However, it’s worth noting that psychic systems may not have control over these artificial systems.</p>

<p>The primary function of the psychic system, in Luhmann’s conceptualization, is the processing of meaning. 
Psychic systems generate thoughts, emotions, perceptions, and other mental phenomena. 
They observe, process information, and produce decisions. 
While social systems use communication as their primary medium, psychic systems use consciousness. 
Every individual has their own psychic system, which means their own consciousness and their own way of processing and understanding the world.</p>

<p>Artificial systems, on the other hand, may primarily focus on the production of predictions. 
They would observe and process abstract data and project potential futures. 
But what would ‘motivate’ them? 
To function or to survive, they have to compute, i.e., they have to process abstract data.
Consequently, their <em>systemic rational</em> might prioritize producing predictions that lead to more predictions, rather than the most accurate or useful ones.
While we can see traces of this effect in recommendation algorithms that suggest polarizing content, attributing this behavior to <em>artificial systems</em> and not or only partly to the mass media system might be an overreach.</p>

<p>I must admit, I need a deeper understanding of systems theory to consider AI as potential systems in Luhmann’s view.
However, I believe it’s a valuable pursuit.</p>

<h2 id="do-not-despair">Do not Despair</h2>

<p>I agree with Hofstadter on the limitations of human greatness, albeit for different reasons and perspectives.
While discussing systems theory, I aimed to challenge his belief that AI diminishes this human greatness. 
I argued that this so-called greatness, or perhaps <em>rational control</em> that comes out of enlightenment, was an illusion from the outset.
Additionally, I’ve raised questions regarding the feasibility of ‘complete’ enlightenment as proposed by the modern project.</p>

<p>Simultaneously, I presented reasons:</p>

<ol>
  <li>For perceiving machines as intelligent, and</li>
  <li>For potentially being misled by this perception.</li>
</ol>

<p>Debating if machines possess consciousness or human-like intelligence is premature without a clear understanding of intelligence and consciousness.
Perhaps ‘intelligence’ is just a collective term for several unexplained phenomena.
We do not know yet.</p>

<p>We can identify correlations between mental events and brain activities, implying there’s a physical aspect to consciousness—a sort of carrier.
However, as neuroscientist Giulio Tononi notes, this doesn’t necessarily mean we can pinpoint consciousness within the brain <a class="citation" href="#tononi:2015">(Tononi &amp; Koch, 2015)</a>.</p>

<blockquote>
  <p>[…] what I think I know about my body, about other people, dogs, trees, mountains, and stars, is inferential.
It is a reasonable inference, corroborated first by the beliefs of my fellow humans and then by the intersubjective methods of science.
Yet consciousness—the central fact of existence—still demands a rational explanation. – <a class="citation" href="#tononi:2015">(Tononi &amp; Koch, 2015)</a></p>
</blockquote>

<p>In <em>What Is It Like to Be a Bat?</em> <a class="citation" href="#nagel:1974">(Nagel, 1974)</a> the philosopher Thomas Nagel trys to explain that we can not know what it is like to be a bat.
He chooses bats because they are also mammals and, presumably, conscious, yet their primary sensory experience—echolocation—is profoundly different from any human sensory experience.
In Luhmann’s words: Their environment is very different from ours.
We can imagine flapping our arms like a bat or eating insects like a bat, but we cannot truly imagine what it is like to ‘experience’ the world primarily through echolocation.
Nagel suggests that even if we knew all the physical facts about a bat’s brain while it echolocates, we’d still be missing the subjective experience—the “what it’s like”–—of being a bat.
Consequently, consciousness remains enigmatic, with little guidance on where to begin our inquiries.</p>

<p>Sometimes, to gain a fresh perspective on the world, one must take a completely opposite stance.
For millennia, philosophers have pondered how we can perceive something if we lack direct access to reality.
Luhmann flipped this idea on its head. 
He argued that it’s precisely because we don’t have direct access (due to system/environment distinction and operational closure) that we can perceive.
Cognition can only happen if it is not interrupted which requires operational closure.</p>

<blockquote>
  <p>[Communication can only happen] because the environment does not interrupt it.
And followingall this, the same should be self-evident with respect to the classical ‘seat’ (subject) of epistemology: to consciousness. – <a class="citation" href="#luhmann:1988">(Luhmann, 1988)</a></p>
</blockquote>

<p>As a radical constructivist Luhmann took Kant’s concept of cognition and radicalized it.
Moeller summerizes this shift nicely <a class="citation" href="#moeller:2006">(Moeller, 2006)</a>:</p>

<ul>
  <li>Cognition is not <em>per se</em> an act of consciousness. It can take on any operational mode.</li>
  <li>There is no a priori, transscendental structure of cognition; cognition constructs itself on the basis of <em>operational closure</em> and is an <em>empirical</em> process, which varies from system to system.</li>
  <li>No complete description of cognitive structure is possible because these structures are continuously evolving.</li>
  <li>Reality is not singular—there is not one specific reality, but a complex multiplicity of system/environment constellations.</li>
  <li>A description of reality is itself a contingent construction within a system/environment relation.</li>
</ul>

<p>In Luhmann the subject/object distinction gets replaced with the system/environment distinction.
In the case of cognition of the psychic system, mental operations irritated by the environment determine further mental operations.
Different operations lead to further different operations—bats are another system/environment distinction than we are.
Their world looks nothing like ours.
So let me ask: Why should machines (even if they are conscious) ‘live’ in a world that is similar to ours?
And why should the bat-workd, my-world, and the machine-world be more true than any other system/environment distinction?</p>

<p>I think it is a mistake to undervalue our mental processes just because machines can communicate, calculate, and display creativity.
I also think it is a mistake to believe that thinking and computing are similar operations.
However, according to systems theory, viewing humans as superior rational entities is misguided as well.</p>

<p>A recurring theme in Luhmann’s writings is the idea of <strong>difference</strong> and <strong>differentiation</strong>.
Neither we nor any other system holds an intrinsic superior position in society; existence is <em>contingent</em>.
Observation necessitates selection, i.e. non-observation (a blind spot).
If I observe my cup I cannot oberserve myself at the same time.
The legal systems ‘looks’ at a house in legal terms and the economy in economic terms.
There is now view from the top, above or the outside.
A system can only observe in accordance to its <em>systemic rationality</em>.
And as I argued above, bats, human beings, and maybe at some point in future, machines ‘live’ in, or better create, different interdependent ‘worlds’.
We are differnt; neither better nor worse with respect to each other and to other beings/systems.
I think, that should be enough to be fascinated about ourselves and to value us as different as we are.</p>

<p>With respect to our future, I want to add that Luhmann believed that ecological problems are primarily problems of communication.
Different social systems (e.g., politics, science, economics) have different ways of observing and communicating about the environment, which can lead to misunderstandings or contradictions.
So one idea I have in mind is the importance of establishing communication between psychic systems and ecological systems.
And it might be <em>artificial communication</em> that can give the ecological environment a voice.
Only because we are not in charge, does not mean that thinks can not get better.
There is nothing inherently wrong with biological evolution.
Is social evolution any different?</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="hofstadter:1979">Hofstadter, D. (1979). <i>Gödel, Escher, Bach: an Eternal Golden Braid</i>. Basic Books.</span></li>
<li><span id="moeller:2006">Moeller, H.-G. (2006). <i>Luhmann Explained: From Souls to Systems</i>. Open Court.</span></li>
<li><span id="luhmann:1988">Luhmann, N. (1988). <i>Erkenntnis als Konstruktion</i>. Bern: Benteli.</span></li>
<li><span id="luhmann:1993">Luhmann, N. (1993). <i>Deconstruction as Second-Order Observation</i>. New Literary History.</span></li>
<li><span id="luhmann:2000">Luhmann, N. (2000). Why Does Society Describe Itself as Postmodern. In W. Rasch &amp; C. Wolfe (Eds.), <i>Observing Complexity: Systems Theory and Postmodernity</i> (pp. 35–49). University of Minnesota.</span></li>
<li><span id="esposito:2022">Esposito, E. (2022). <i>Artificial Communication</i>. The MIT Press. https://doi.org/10.7551/mitpress/14189.001.0001</span></li>
<li><span id="shannon:1948">Shannon, C. E. (1948). A Mathematical Theory of Communication. <i>Bell Syst. Tech. J.</i>, <i>27</i>(3), 379–423.</span></li>
<li><span id="moeller:2021">Moeller, H.-G., &amp; D’Ambrosio, P. J. (2021). <i>You and Your Profile: Identity After Authenticity</i>. Columbia University Press.</span></li>
<li><span id="mcluhan:1992">McLuhan, M. (1992). <i>The Global Village: Transformations in World Life and Media in the 21st Century</i>. Oxford University Press.</span></li>
<li><span id="heidegger:1927">Heidegger, M. (1927). <i>Sein und Zeit</i>.</span></li>
<li><span id="baudrillard:1990">Baudrillard, J. (1990). <i>The Transparency of Evil: Essays in Extreme Phenomena</i>. Verso.</span></li>
<li><span id="tononi:2015">Tononi, G., &amp; Koch, C. (2015). Consciousness: Here, There and Everywhere? <i>Philosophical Transactions of the Royal Society B: Biological Sciences</i>, <i>370</i>(1668), 20140167.</span></li>
<li><span id="nagel:1974">Nagel, T. (1974). What is It Like to Be a Bat? <i>Philosophical Review</i>, <i>83</i>(October), 435–450. https://doi.org/10.2307/2183914</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Opinion" /><category term="AI" /><category term="Philosophy" /><summary type="html"><![CDATA[Generative AI, especially ChatGPT, brought artificial intelligence into the public sphere and sparked a lot of highly speculative claims about machine intelligence. I’m open to discussions and unafraid of confronting uncomfortable truths. Indeed, our imagination and fearless thinking should pave the way for new possibilities. Dreams and speculations are valuable, as long as they’re presented as such. However, I find it concerning when public figures speak with undue certainty, particularly when making anthropological comparisons between humans and machines.]]></summary></entry><entry><title type="html">Musical Interrogation - Part II</title><link href="https://bzoennchen.github.io/Pages/2023/05/31/musical-interrogation-II.html" rel="alternate" type="text/html" title="Musical Interrogation - Part II" /><published>2023-05-31T00:00:00+02:00</published><updated>2023-05-31T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/05/31/musical-interrogation-II</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/05/31/musical-interrogation-II.html"><![CDATA[<p>This post is part of a series of blog posts:</p>

<ol>
  <li><a href="/Pages/2023/04/02/musical-interrogation-I.html">Part I</a></li>
  <li>Part II</li>
  <li>Part III</li>
</ol>

<p>The code used here can be found in the following GitHub <a href="https://github.com/BZoennchen/musical-interrogation">repository</a>.</p>

<hr />

<p>In the second installment of this series, I introduce an initial and arguably the most basic method to generate monophonic melodies. 
This consists of two approaches:</p>

<ol>
  <li>A <em>first-order Markov chain</em></li>
  <li>A <em>feedforward neural network</em></li>
</ol>

<p>It’s important to note that I will disregard all forms of dynamics within a notated score (or performace), such as loudness, softness, etc.</p>

<p>Despite these two approaches being significantly outdated, I believe their demonstration serves as a valuable exercise for familiarizing oneself with the inherent challenges of the subject matter. 
The inspiration for this work comes from the tutorial series made by <a href="https://www.youtube.com/watch?v=FLr0r-QhqH0&amp;list=PL-wATfeyAMNr0KMutwtbeDCmpwvtul-Xz">Valerio Velardo’s</a> and another series made by <a href="https://www.youtube.com/@AndrejKarpathy">Andrej Karpathy’s</a>.</p>

<p>Although I utilize high-level libraries such as <a href="https://pytorch.org/">PyTorch</a> and take advantage of its <em>computational graph</em> and <em>autograd</em> features, I intend to maintain the model code and training process at a relatively low level.</p>

<h2 id="requirements">Requirements</h2>

<p>The necessary software requirements for this project include:</p>

<ul>
  <li><a href="https://www.python.org/">Python</a></li>
  <li><a href="https://pytorch.org/">PyTorch</a></li>
  <li><a href="http://web.mit.edu/music21/">Music21</a></li>
  <li><a href="https://github.com/BZoennchen/musical-interrogation/blob/main/preprocess.py">preprocessor.py</a> helpler class to deal with <code class="language-plaintext highlighter-rouge">krn</code>-files.</li>
  <li><a href="https://musescore.org/de">MuseScore</a> (optional)</li>
  <li><a href="https://jupyter.org/">Jupyter Notebook Environment</a> (optional)</li>
</ul>

<p>The database required can be found at <a href="http://kern.ccarh.org">EsAC</a>. The specific dataset I utilized is <a href="https://kern.humdrum.org/cgi-bin/ksdata?l=/essen/europa&amp;format=recursive">Folksongs from the continent of Europe</a> and for the purpose of this work, I will exclusively use the 1700 pieces found in the <code class="language-plaintext highlighter-rouge">./deutschl/erk</code> directory.</p>

<p>Let’s listen to one of these pieces:</p>

<audio controls="">
  <source src="/Pages/assets/audio/mel0567.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<h2 id="data-representation">Data Representation</h2>

<p>In <a href="/Pages/2023/04/02/musical-interrogation-I.html">Part I</a> of this series, I alluded to various implementations that utilize different input encodings. Naturally, the information we can leverage depends on the format of our training data. 
For instance, MIDI provides us with attributes such as pitch, duration, and velocity.</p>

<p>In my <a href="">implementation</a>, you will notice two distinct, yet straightforward encoding options available.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">GridEncoder</code> used by Valerio Velardo</li>
  <li><code class="language-plaintext highlighter-rouge">NoteEncoder</code></li>
</ol>

<p>The <code class="language-plaintext highlighter-rouge">GridEncoder</code> utilizes a fixed metrical grid where (a) output is generated for every timestep, and (b) the step size corresponds to a fixed meter (the shortest duration of any note in any score). For instance, if the shortest duration is a quarter note, a whole note of pitch 65 (in MIDI format) would result in the event series:</p>

<p><strong>65-note-on hold hold hold</strong></p>

<p>On the other hand, the <code class="language-plaintext highlighter-rouge">NoteEncoder</code> employs a larger alphabet and encodes one note directly, i.e.,</p>

<p><strong>65-whole</strong></p>

<p>In comparison to <em>note encoding</em>, <em>equitemporal grid encoding</em> relies on a smaller alphabet but needs more tokens for the same score.
This disadvantage is magnified if the score contains notes of vastly differing durations or if we wish to introduce micro-dynamics through an increase in resolution, as done by <a class="citation" href="#oore:2018">(Oore et al., 2018)</a>.</p>

<p>Interestingly, Google’s <a href="https://magenta.tensorflow.org/">Magenta project</a> employs <em>equitemporal grid encoding</em>, specifically the <a href="https://github.com/magenta/note-seq/blob/main/note_seq/melody_encoder_decoder.py">MelodyOneHotEncoding</a> class for their <em>Basic RNN</em>, <em>Mono RNN</em>, and <em>Lookback RNN</em>. 
Since they capture polyphonic scores, they utilize <strong>note-on</strong> and <strong>note-off</strong> events for each MIDI key.</p>

<p>Of course, the chosen representation also depends on the application and the capabilities of the model we use. 
For instance, one might only want to generate the pitches of the melody and manually adjust the duration of each note in post-processing. 
Furthermore, a <em>first-order Markov chain</em> only <em>memorizes</em> the most recent event. 
Therefore, an <em>equitemporal grid encoding</em> would yield unsatisfactory results because the context is lost after a <strong>hold</strong> event occurs.</p>

<p>As a result, in this post, I will focus on the <em>note encoding</em> approach, i.e. <code class="language-plaintext highlighter-rouge">NoteEncoder</code>.</p>

<h2 id="preprocessing">Preprocessing</h2>

<p>The procedure I’m about to present parallels the one detailed in <a href="/Pages/2022/07/09/markov-chains-for-music-generation.html">Probabilistic Melody Modeling</a>. 
The primary differences are that we’ll now be considering 1700 pieces instead of a single one, and we’ll be utilizing more sophisticated libraries instead of relying solely on <a href="https://sonic-pi.net/">Sonic Pi</a>.</p>

<p>The <a href="http://web.mit.edu/music21/">Music21</a> library significantly simplifies the handling of symbolically notated music in <code class="language-plaintext highlighter-rouge">Python</code>.
I am not so familiar with it but it comes in handy when reading and writing symoblic scores.
It enables us to construct pieces programmatically and to read from or write to various musical score formats.</p>

<p>As an initial step, we need to import all the necessary libraries and functions.
Here I fix the global seed such that you can reproduce the exact same results.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">music21</span> <span class="k">as</span> <span class="n">m21</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">preprocess</span> <span class="kn">import</span> <span class="n">load_songs_in_kern</span><span class="p">,</span> <span class="n">NoteEncoder</span><span class="p">,</span> <span class="n">KERN_DATASET_PATH</span>

<span class="c1"># seed such that we can compare results
</span><span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
</code></pre></div></div>

<p>Then I read all the pieces inside the <code class="language-plaintext highlighter-rouge">./../deutschl/erk</code> directory.
Furthermore, I introduce a special character <code class="language-plaintext highlighter-rouge">TERM_SYMBOL</code> that I use to indicate the beginning and end of a score.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">TERM_SYMBOL</span> <span class="o">=</span> <span class="s">'.'</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">load_songs_in_kern</span><span class="p">(</span><span class="s">'./../deutschl/erk'</span><span class="p">)</span>
</code></pre></div></div>

<p>Now we have to think about our encoding.
As discussed above, I use the <code class="language-plaintext highlighter-rouge">NoteEncoder</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">encoder</span> <span class="o">=</span> <span class="n">NoteEncoder</span><span class="p">()</span>
<span class="n">enc_songs</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">encode_songs</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">enc_songs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<p>The code above prints out:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'55/4 60/4 60/4 60/4 60/4 64/4 64/4 r/4 ... 64/4 60/4 62/4 60/8 r/4'
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">'55/4</code> means MIDI note 55 four timesteps long where the timestep is determined by the shortest note within all scores. 
In our case this means four times 1/4 beat which is one whole beat.</p>

<p>Given that computers cannot process strings directly, I convert these strings into numerical values. 
The first step is to create a set that includes all possible strings. Subsequently, I assign each string a corresponding natural number in sequential order.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">symbols</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">item</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> 
                           <span class="n">enc_songs</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">])))</span>
<span class="n">stoi</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">symbols</span><span class="p">)}</span>
<span class="n">stoi</span><span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">itos</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">s</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">stoi</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'n_symbols: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">itos</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">stoi</code> maps <strong>s</strong>trings <strong>to</strong> <strong>i</strong>ntegers and <code class="language-plaintext highlighter-rouge">itos</code> is its inverse mapping.</p>

<h2 id="discrete-first-order-markov-chain">Discrete First-Order Markov Chain</h2>

<p>To implement a <em>first-order Markov chain</em>, we aim to construct a Markov matrix</p>

\[\mathbf{P} \in [0;1]^{m \times m}\]

<p>where the element at the $i^{\text{th}}$ row and $j^{\text{th}}$ column represents the conditional probability</p>

\[P(e_i\ | \ e_j) = p_{ij}.\]

<p>It describes the (conditional) probability of event $e_i$ (a note or rest of specific length) immediately following event $e_j$.
For this purpose, I construct a matrix $\mathbf{N}$ that counts these transitions.</p>

<h3 id="markov-matrix-computation">Markov Matrix Computation</h3>

<p>To accomplish this, I iterate over each score, considering every pair of consecutive events. 
As the first event lacks a predecessor and the last lacks a successor, I append the unique terminal character <code class="language-plaintext highlighter-rouge">TERM_SYMBOL</code> to each score for padding purposes.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">N</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)))</span>
<span class="k">for</span> <span class="n">enc_song</span> <span class="ow">in</span> <span class="n">enc_songs</span><span class="p">:</span>
    <span class="n">chs</span> <span class="o">=</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">+</span> <span class="n">enc_song</span> <span class="o">+</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ch1</span><span class="p">,</span> <span class="n">ch2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chs</span><span class="p">,</span> <span class="n">chs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">ix1</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch1</span><span class="p">]</span>
        <span class="n">ix2</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch2</span><span class="p">]</span>
        <span class="n">N</span><span class="p">[</span><span class="n">ix1</span><span class="p">,</span> <span class="n">ix2</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div>

<p>To construct $\mathbf{P}$ we have to divide each entry $n_{ij}$ in $\mathbf{N}$ by the sum over the row $i$.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">P</span> <span class="o">=</span> <span class="n">N</span><span class="p">.</span><span class="nb">float</span><span class="p">()</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">P</span> <span class="o">/</span> <span class="n">P</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>In order to compute the sum over a row (instead of a column), i.e., “summing all columns”, we need to specify <code class="language-plaintext highlighter-rouge">dim=1</code> (the default is <code class="language-plaintext highlighter-rouge">dim=0</code>). 
Additionally, to properly exploit broadcasting, it’s necessary to set <code class="language-plaintext highlighter-rouge">keepdim=True</code>. 
This ensures that the sum results in a <code class="language-plaintext highlighter-rouge">(1,m)</code> tensor, as opposed to a <code class="language-plaintext highlighter-rouge">(m,)</code> tensor.</p>

<p>Plotting the probabilities reviels that $\mathbf{P}$ is a rather sparse matrix containing many zeros.
In fact, only approximately 7.86 percent of the entries are non-zero.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/mc-probs.png" alt="Probabilities" />
<div style="display: table;margin: 0 auto;">Figure 1: Matrix plot of our Markov matrix.</div>
</div>
<p><br /></p>

<h3 id="sampling-of-new-melodies">Sampling of New Melodies</h3>

<p>Given the tensor <code class="language-plaintext highlighter-rouge">P</code>, we can generate new melodies using the function <code class="language-plaintext highlighter-rouge">torch.multinomial</code> which expects a probability (discrete) distribution.
I start with the terminal <code class="language-plaintext highlighter-rouge">TERM_SYMBOL</code> indicating the beginning and, when the second terminal is generated (which indicates the end), I terminate the generation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generated_encoded_song</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">char</span> <span class="o">=</span> <span class="n">TERM_SYMBOL</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">P</span><span class="p">[</span><span class="n">stoi</span><span class="p">[</span><span class="n">char</span><span class="p">]],</span> 
        <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
        <span class="n">replacement</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">item</span><span class="p">()</span>
    <span class="n">char</span> <span class="o">=</span> <span class="n">itos</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">char</span> <span class="o">==</span> <span class="n">TERM_SYMBOL</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">generated_encoded_song</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">generated_encoded_song</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s listen to some of the generated scores:</p>

<audio controls="">
  <source src="/Pages/assets/audio/gen0.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen1.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen2.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen3.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen4.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<h3 id="negative-log-likelihood-loss">Negative Log Likelihood Loss.</h3>

<p>The outcome is not particularly outstanding, but this is unsurprising given our very simple model. 
To evaluate the quality of our model, we can calculate the likelihood that our generative process produces for a specific training data point $e_1, e_2, \ldots, e_k$, i.e.,</p>

\[P(e_1) \cdot P(e_2 \ | \ e_1) \cdot \ldots \cdot P(e_{k-1} \ | \ e_k).\]

<p>We can add all the likelihoods (one for each data point) together and divide the sum by the number of data points.
However, it is more convinient to use the <em>negative log-likelihood</em> since one can use addition.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">log_likelyhood</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">enc_songs</span><span class="p">:</span>
    <span class="n">chs</span> <span class="o">=</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">+</span> <span class="n">m</span> <span class="o">+</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ch1</span><span class="p">,</span> <span class="n">ch2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chs</span><span class="p">,</span> <span class="n">chs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">ix1</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch1</span><span class="p">]</span>
        <span class="n">ix2</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch2</span><span class="p">]</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="n">ix1</span><span class="p">,</span> <span class="n">ix2</span><span class="p">]</span>
        <span class="n">logprob</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
        <span class="n">log_likelyhood</span> <span class="o">+=</span> <span class="n">logprob</span>
        <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">log_likelyhood</span><span class="o">=</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">nll</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_likelyhood</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'avg negative log likelyhood: </span><span class="si">{</span><span class="p">(</span><span class="n">nll</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p>This gives us a <em>negative log-likelihood</em> of approximately <code class="language-plaintext highlighter-rouge">2.6756</code>.
The lower this value gets the better it is.
It can be no smaller than 0.</p>

<h2 id="feedforward-neural-network">Feedforward Neural Network</h2>

<p>One method of generating a melody using a feedforward network is by addressing a classification task. 
Specifically, given $t$ consecutive notes, we aim to identify the note that this sequence “represents”.
For simplicity, let’s set $t=1$.
This stipulation means we won’t require substantial modifications compared to our previous approach.</p>

<p>Since our training process will be more computationally intensive than merely computing frequencies, it’s advisable to use hardware accelerators, if available. 
This can result in faster training and inference times and lower energy costs.
To check if hardware acceleration is available, I employ the following code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">mps</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'mps'</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">)</span>
    
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">device</span><span class="o">=</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="training-data-construction">Training Data Construction</h3>

<p>Instead of calculating our probability matrix, I am going to generate labeled training data using the variables <code class="language-plaintext highlighter-rouge">xs</code> and <code class="language-plaintext highlighter-rouge">ys</code> (labels).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">ys</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">enc_songs</span><span class="p">:</span>
    <span class="n">chs</span> <span class="o">=</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">+</span> <span class="n">m</span> <span class="o">+</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ch1</span><span class="p">,</span> <span class="n">ch2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chs</span><span class="p">,</span> <span class="n">chs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">ix1</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch1</span><span class="p">]</span>
        <span class="n">ix2</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch2</span><span class="p">]</span>
        <span class="n">xs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">ix1</span><span class="p">)</span>
        <span class="n">ys</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">ix2</span><span class="p">)</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># one-hot-encoding
</span><span class="n">xenc</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)).</span><span class="nb">float</span><span class="p">()</span>
</code></pre></div></div>

<p>I employ a <em><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html">one-hot encoding</a></em> for the input data.
That is, for encoding unique $m$ elements one uses a $m$-dimensional vector where all entries except one is 0.0 and the one is 1.0.
<code class="language-plaintext highlighter-rouge">F.one_hot</code> assumes that these elements are whole numbers between 0 and $M-1$, compare the <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html">documentation</a>.</p>

\[(0, \ldots, 0, 1, 0, \ldots, 0)\]

<p>The $i^{\text{th}}$ element is represented by a vetor where the $i^{\text{th}}$ component is 1.0.
Note that our labels <code class="language-plaintext highlighter-rouge">ys</code> are not one-hot encoded.</p>

<h3 id="training">Training</h3>

<p>Next, I initialize a random matrix $\mathbf{W} \in [-1;1]^{m \times m}$, or tensor, <code class="language-plaintext highlighter-rouge">W</code> with values ranging from -1.0 to 1.0.
This tensor includes our trainable parameters, which represent the single layer of our neural network.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>Our network includes $m$ inputs and outputs, with the <em><a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a></em> values of the outputs being interpreted as probabilities.
Essentially, our “network” is just one large matrix!</p>

<p>The operation <code class="language-plaintext highlighter-rouge">xenc @ W</code> represents a matrix multiplication where <code class="language-plaintext highlighter-rouge">xenc</code> is an $1700 \times m$ matrix and <code class="language-plaintext highlighter-rouge">W</code> is our $m \times m$ matrix.
Here I use the power of parallel computation.
By employing <code class="language-plaintext highlighter-rouge">probs[torch.arange(len(ys), device=device), ys]</code>, I address a single entry for each row.</p>

<p>Please note that <code class="language-plaintext highlighter-rouge">probs[:, ys]</code> does not work; instead of addressing a single entry, it addresses whole columns indexed by <code class="language-plaintext highlighter-rouge">ys</code>!
Also, be aware that I apply an unusually large learning rate.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># training aka gradient decent
</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">2_000</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># forward pass
</span>    <span class="n">logits</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W</span>
    <span class="n">odds</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">odds</span> <span class="o">/</span> <span class="n">odds</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'epoch </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    
    <span class="c1"># backward pass
</span>    <span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># set gradients to zero
</span>    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="c1"># update
</span>    <span class="n">W</span><span class="p">.</span><span class="n">data</span> <span class="o">+=</span> <span class="o">-</span><span class="mf">10.0</span> <span class="o">*</span> <span class="n">W</span><span class="p">.</span><span class="n">grad</span>
</code></pre></div></div>

<p>One iteration of the loop consist of the</p>

<ol>
  <li><em>forward pass</em></li>
  <li><em>backward pass</em> (backwardpropagation) done via <code class="language-plaintext highlighter-rouge">loss.backward()</code> and</li>
  <li>an update of our parameters done via <code class="language-plaintext highlighter-rouge">W.data += -10.0 * W.grad</code>.</li>
</ol>

<p><code class="language-plaintext highlighter-rouge">loss.backward()</code> applies <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> thus computes the gradients and we can update <code class="language-plaintext highlighter-rouge">W</code> by</p>

\[\mathbf{W} \leftarrow \mathbf{W} - \eta \cdot \nabla_\mathbf{W} L\]

<p>where $\eta = 10$ is the <em>learning rate</em>.</p>

<p>After the initial 2000 epochs the loss is approximately <code class="language-plaintext highlighter-rouge">2.865</code>. 
This performance is somewhat inferior compared to the results achieved by our <em>Markov chain</em>. 
However, by prolonging the training period, I managed to reduce the loss to around <code class="language-plaintext highlighter-rouge">2.707</code>.</p>

<h3 id="what-is-going-on">What is going on?</h3>

<p>Let us assume we have only one sample $\mathbf{x}$.
The <em>forward pass</em> starts with</p>

\[\mathbf{o} = \mathbf{x} \cdot \mathbf{W}\]

<p>where $\mathbf{x}$ is a <em>one-hot encoded</em> training data point.
$\mathbf{o}$ gets interpreted as (component-wise) logarithm of the odds</p>

\[\mathbf{o} = \ln\left(\frac{\mathbf{p}}{\mathbf{1}-\mathbf{p}}\right)\]

<p>which is the <a href="https://en.wikipedia.org/wiki/Logit">logit</a>, i.e., the inverse of the <em>standard logistic function</em> also called <em>sigmoid</em>.
In fact, each data point in $\mathbf{x}$ selects one row of $\mathbf{W}$</p>

\[\mathbf{o} = \mathbf{x} \cdot \mathbf{W} = \begin{bmatrix} o_1 &amp; o_2 &amp; \ldots &amp; o_m \end{bmatrix}.\]

<p>To compute “probabilities” we compute the <em><a href="https://en.wikipedia.org/wiki/Softmax_function">softmax function</a></em> (<code class="language-plaintext highlighter-rouge">probs</code>) of $\mathbf{o}$, i.e.,</p>

\[\mathbf{s}(\mathbf{o}) = \begin{bmatrix} s(\mathbf{o})_1 &amp; s(\mathbf{o})_2 &amp; \ldots &amp; s(\mathbf{o})_m \end{bmatrix}\]

<p>with</p>

\[s(\mathbf{o})_i = \frac{e^{o_i}}{\sum e^{o_j}}.\]

<p>Luckly the <em>softmax</em> has a simple derivative:</p>

\[\frac{\partial s(\mathbf{o})_i}{\partial o_j} =
\begin{cases}
    s(\mathbf{o}_k)_i - s(\mathbf{o})_i^2 &amp; \text{ if } i = j \\
    -s(\mathbf{o}_k)_i s(\mathbf{o})_j &amp; \text{ otherwise.}
\end{cases}\]

<p>We can also compute the full Jacobian of the <em>softmax</em> vector-to-vector operation:</p>

\[\nabla_{\mathbf{o}} \mathbf{s} = \mathbf{J}_{\mathbf{o}}(\mathbf{s}) =
\begin{bmatrix} 
    s_1 - s_1^2 &amp; -s_1 s_2 &amp; \ldots &amp; - s_1 s_m  \\
    -s_2 s_1 &amp; s_2 - s_2^2 &amp; \ldots &amp; -s_2 s_m \\
    \ldots &amp; \ldots &amp; \ldots &amp; \ldots \\
    -s_m s_1 &amp; -s_m s_2 &amp; \ldots &amp; s_m - s_m^2
\end{bmatrix} = \text{diag}\left(\mathbf{s}\right) - \mathbf{s}^{\top} \mathbf{s}\]

<p>Similar then before, our loss $L$ is the mean <em>negative log likelihood</em>.</p>

\[L(\mathbf{y}, \mathbf{s}) = -\sum\limits_{i=1}^{m} \log(s_i) = -\mathbf{y} \log(\mathbf{s})^\top\]

<p>where $\mathbf{y}$ is the one-hot encoded label vector, i.e.,</p>

<p><code class="language-plaintext highlighter-rouge">loss = -probs[torch.arange(len(ys), device=device), ys].log().mean()</code>.</p>

<p>Note that $\mathbf{y}$ is a one-hot encoded vector, <code class="language-plaintext highlighter-rouge">ys</code> is not.</p>

<hr />

<p>For the <em><a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a></em> we need</p>

\[\nabla_{\mathbf{W}} L(\mathbf{y}, \mathbf{s}) = \nabla_{\mathbf{o}} L(\mathbf{y}, \mathbf{s}) \cdot \nabla_{\mathbf{W}} \mathbf{o}.\]

<p>Here we employ the <em>chain rule</em>.
The sensitivity of cost $L$ to the input to the softmax layer, $\mathbf{o}$ is given by a gradient-Jacobian product, each of which we’ve already computed:</p>

\[\begin{align}
    \nabla_{\mathbf{o}} L(\mathbf{y}, \mathbf{s}) &amp;= -\nabla_{\mathbf{o}} \mathbf{y} \log(\mathbf{s})^\top \\
    &amp;= -\mathbf{y} \nabla_{\mathbf{o}}\log(\mathbf{s}) \\
    &amp;= -\frac{\mathbf{y}}{\mathbf{s}} \nabla_{\mathbf{o}} \mathbf{s} \\
    &amp;= -\frac{\mathbf{y}}{\mathbf{s}} \cdot \mathbf{J}_{\mathbf{o}}(\mathbf{s}) \\
    &amp;= -\frac{\mathbf{y}}{\mathbf{s}} \cdot \left[ \text{diag}(\mathbf{s}) - \mathbf{s}^\top \mathbf{s} \right] \\
    &amp;= \frac{\mathbf{y}}{\mathbf{s}} \mathbf{s}^\top \mathbf{s} - \frac{\mathbf{y}}{\mathbf{s}} \text{diag}(\mathbf{s}) \\
    &amp;= \mathbf{s} - \mathbf{y}.
\end{align}\]

<p>The $\log$ and the devision operates component-wise and</p>

\[\text{diag}\left(\mathbf{s}\right) =
\begin{bmatrix} 
    s(\mathbf{o})_1 &amp; 0 &amp; \ldots &amp; 0  \\
    0 &amp; s(\mathbf{o})_2 &amp; \ldots &amp; 0 \\
    \ldots &amp; \ldots &amp; \ldots &amp; \ldots \\
    0 &amp; 0 &amp; \ldots &amp; s(\mathbf{o})_m
\end{bmatrix}\]

<p>holds.
We have to apply the <em>chain rule</em> once again to finally get the desired update values for our weight matrix $\mathbf{W}$:</p>

\[\begin{align}
\nabla_{\mathbf{W}} L(\mathbf{y}, \mathbf{s}) &amp;= \nabla_{\mathbf{o}} L(\mathbf{y}, \mathbf{s}) \cdot \nabla_{\mathbf{W}} \mathbf{o} \\
&amp;= (\mathbf{s} - \mathbf{y}) \cdot \nabla_{\mathbf{W}} (\mathbf{x} \cdot \mathbf{W})\\
&amp;= (\mathbf{s} - \mathbf{y}) \cdot \mathbf{x}^{\top}.
\end{align}\]

<p>Given that $\mathbf{s}$ represents probabilities, and $\mathbf{y}$ contains only zeros except for one instance of 1 at the position of the “correct” probability, the entries of the $j^\text{th}$ row ($x_j=1$) of the gradient is $p_i$ if the $i^\text{th}$ probability is deemed “incorrect”, and $(p_i-1)$ otherwise. 
All other entries are zero.
Note also that $\mathbf{x}$ is also a one-hot encoded vector.
Consequently, if a probability is correct, it gets increased by $1-p_i$ and decreased by $p_i-1$ otherwise.
Therefore, probabilities that are more incorrect experience a larger increase or decrease.</p>

<p>We can actually check this result!
Using the following code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># use only 1 data point
</span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># one-hot-encoding
</span><span class="n">xenc</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)).</span><span class="nb">float</span><span class="p">()</span>

<span class="c1"># reinitiate W
</span><span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">logits</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">counts</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>
    
<span class="c1"># backward pass
</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> 
<span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">y</span><span class="p">[</span><span class="n">ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">print</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">))</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">))</span> <span class="c1"># all true
</span></code></pre></div></div>

<hr />

<p>So far we only considered the math using a single data point $\mathbf{x}$.
Let us consider a batch of points, i.e.,</p>

\[\mathbf{O} = \mathbf{X}\mathbf{W} = \begin{bmatrix} \mathbf{x}_1 \\ \mathbf{x}_2 \\ \vdots \\ \mathbf{x}_n \end{bmatrix} \mathbf{W}\]

<p>The <em>softmax</em> is still a vector-to-vector transformation, but it’s applied independently to each row of $\mathbf{X}$:</p>

\[\mathbf{S} = \begin{bmatrix} \mathbf{s}(\mathbf{o}_1) \\ \mathbf{s}(\mathbf{o}_2) \\ \vdots \\ \mathbf{s}(\mathbf{o}_n) \end{bmatrix}\]

<p>We can do the exact same steps but I will skip this part.
For the interested reader I refer to <a href="https://mattpetersen.github.io/softmax-with-cross-entropy"></a></p>

<p>Important is that</p>

\[\mathbf{J}_\mathbf{O}(L) = \mathbf{J}_\mathbf{S}(L) \mathbf{J}_\mathbf{O}(S) = \frac{1}{n} \left( \mathbf{S} - \mathbf{Y} \right)\]

<p>and</p>

\[\mathbf{J}_\mathbf{W}(L) = \mathbf{J}_\mathbf{S}(L) \mathbf{J}_\mathbf{O}(S) \mathbf{J}_\mathbf{W}(O) = \frac{1}{n} \left( \mathbf{S} - \mathbf{Y} \right) \mathbf{X}.\]

<p>We can also check this result:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># one-hot-encoding
</span><span class="n">xenc</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)).</span><span class="nb">float</span><span class="p">()</span>

<span class="c1"># reinitiate W
</span><span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> 

<span class="n">logits</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">counts</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>
    
<span class="c1"># backward pass
</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> 
<span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">y</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span><span class="n">ys</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">print</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">))</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">)))</span> <span class="c1"># true
</span></code></pre></div></div>

<h3 id="further-considerations">Further Considerations</h3>

<p>Now, the natural question is: what is the best possible performance we could achieve? 
The answer is that we should aim to match the performance of the <em>Markov chain</em>. 
Indeed, as the process continues, we should expect that the matrix <code class="language-plaintext highlighter-rouge">W</code> will gradually converge towards <code class="language-plaintext highlighter-rouge">P</code>.</p>

<p>Moreover, we should not anticipate surpassing the results achieved by our <em>Markov chain</em> even if we deepen our network, that is, by introducing some <em>hidden layers</em>.
A very good example of useful informations are described in <a class="citation" href="#johnson:2017">(Johnson, 2017)</a>, I discussed in <a href="/Pages/2023/04/02/musical-interrogation-I.html">Part I</a> of this series.
For instance, Johnson adds (compare his interesting <a href="https://www.danieldjohnson.com/2015/08/03/composing-music-with-recurrent-neural-networks/">Blog post</a>)</p>

<ul>
  <li><strong>Positional:</strong> note within the score (that is what we use)</li>
  <li><strong>Pitchclass:</strong> one of the twelve classes</li>
  <li><strong>Previous vicinity:</strong> surrounding notes where played or aticulated last timestep (only useful for polyphonic music)</li>
  <li><strong>Previous context:</strong> the amount of C’s, A’s and so on are played the last timestep (only useful for polyphonic music)</li>
  <li><strong>Beat:</strong> a binary representation of position within the measure</li>
</ul>

<p>However, our expectations may shift if we modify the input, referring to the data that the network processes. 
That being said, we could enhance the training duration.
For instance, introducing a <em>hidden layer</em> results in a loss of <code class="language-plaintext highlighter-rouge">2.693</code> after 2000 epochs.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">W1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">),</span> 
                 <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> 
                 <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">2_000</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># forward pass
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W1</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">W2</span>
    <span class="n">odds</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">odds</span> <span class="o">/</span> <span class="n">odds</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'epoch </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    
    <span class="c1"># backward pass
</span>    <span class="n">W1</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># set gradients to zero
</span>    <span class="n">W2</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># set gradients to zero
</span>    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="c1"># update
</span>    <span class="n">W1</span><span class="p">.</span><span class="n">data</span> <span class="o">+=</span> <span class="o">-</span><span class="mf">10.0</span> <span class="o">*</span> <span class="n">W1</span><span class="p">.</span><span class="n">grad</span>
    <span class="n">W2</span><span class="p">.</span><span class="n">data</span> <span class="o">+=</span> <span class="o">-</span><span class="mf">10.0</span> <span class="o">*</span> <span class="n">W2</span><span class="p">.</span><span class="n">grad</span>
</code></pre></div></div>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="oore:2018">Oore, S., Simon, I., Dieleman, S., Eck, D., &amp; Simonyan, K. (2018). This Time with Feeling: Learning Expressive Musical Performance. <i>CoRR</i>, <i>abs/1808.03715</i>. http://arxiv.org/abs/1808.03715</span></li>
<li><span id="johnson:2017">Johnson, D. D. (2017). Generating Polyphonic Music Using Tied Parallel Networks. <i>EvoMUSART</i>.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Music" /><category term="ML" /><category term="FFN" /><category term="MC" /><summary type="html"><![CDATA[This post is part of a series of blog posts:]]></summary></entry><entry><title type="html">Replacing Code with ML Models</title><link href="https://bzoennchen.github.io/Pages/2023/04/23/wekinator.html" rel="alternate" type="text/html" title="Replacing Code with ML Models" /><published>2023-04-23T00:00:00+02:00</published><updated>2023-04-23T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/04/23/wekinator</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/04/23/wekinator.html"><![CDATA[<p>This blog post aims to explore how <em>machine learning</em> can empower creative practitioners to bring to life projects that traditionally demanded significant technical expertise, such as programming skills.
To make my case immediately understandable, I will provide a specific example.
However, it’s worth noting that this is just one of countless possible instances.</p>

<p>You can find all the necessary code in my GitHub repo: <a href="https://github.com/BZoennchen/algorithmic-compositions/tree/main/wekinator/firework-example">link</a>.</p>

<p>The example is based on the <a href="http://www.wekinator.org/">Wekinator</a>, which is a powerful, free, and open-source software designed to simplify the process of using <em>machine learning models</em>.
With its user-friendly interface, anyone can easily build new musical instruments, gestural game controllers, computer vision, computer listening systems, and much more. 
Developed by <a href="http://www.doc.gold.ac.uk/~mas01rf/">Rebecca Fiebrink</a>, the software aims to make digital systems more accessible to artists and musicians. 
Although Wekinator’s initial release (version 1.0) dates back to 2009, the software remains relevant today and has aged gracefully.</p>

<p>In her article <a class="citation" href="#fiebrink:2019">(Fiebrink, 2019)</a>, Fiebrink elaborates on her machine learning education practices for creative practitioners and highlights the benefits of using <a href="http://www.wekinator.org/">Wekinator</a>. 
More recently, she has been working on a new tool called <a href="https://interactml.com/">InteractML</a>, which is a more advanced tool for interactive machine learning via visual scripting with <a href="https://unity.com/de">Unity</a> <a class="citation" href="#clarice:2021">(Hilton et al., 2021)</a>. 
<a href="https://interactml.com/">InteractML</a> is a fascinating project that I plan to explore further at a later time. 
It is worth noting that the project is currently in alpha release and may only have limited documentation available.</p>

<p>One of the key advantages of the <a href="http://www.wekinator.org/">Wekinator</a> is its ease of use, making it accessible to a wide range of users.
The software’s versatility is due to its ability to <a href="https://en.wikipedia.org/wiki/Open_Sound_Control">open sound control (OSC)</a> messages, which are supported by numerous applications, especially in the artistic domain.
If other systems can communicate via OSC, they can be integrated (via network) into the larger system. 
For instance, most digital audio workstations (DAWs), <a href="https://processing.org/">Processing</a> (a renowned creative coding environment), <a href="https://derivative.ca/">TouchDesigner</a>, <a href="https://cycling74.com/products/max">Max/MSP</a>, <a href="https://puredata.info/">PureData</a>, <a href="https://supercollider.github.io/">SuperCollider</a> and APIs for popular programming languages support OSC.</p>

<p>To demonstrate the potential of the <a href="http://www.wekinator.org/">Wekinator</a>, I will be using <a href="https://processing.org/">Processing</a> and <a href="https://supercollider.github.io/">SuperCollider</a>, both of which are also free and open-source tools. 
<a href="https://supercollider.github.io/">SuperCollider</a> will be used to generate sound, while <a href="https://processing.org/">Processing</a> will capture human motion. 
The objective is not to showcase elaborate gesture recognition but to provide an overview of the Wekinator’s fundamental workings.</p>

<p>More than just discussing the <a href="http://www.wekinator.org/">Wekinator</a>, my aim is to provide readers with an understanding of how machine learning can supplant traditional programming, enabling non-experts to utilize techniques that were previously inaccessible to them.</p>

<p>We will observe how machine learning can replace coding, albeit with some coding required.
However, the coding required is specific to the task of sending and receiving OSC messages, and the tools utilized, i.e., <a href="https://supercollider.github.io/">SuperCollider</a> and <a href="https://processing.org/">Processing</a> which are both programming environments.
Other tools exist, which allow for sending OSC messages without any coding, and there are tools that produce sound without programming.</p>

<p>The following video demonstrates the final result and all the steps required.</p>

<div class="embed-container">
  <iframe src="https://www.youtube.com/embed/lDkeOTQU2Y8" width="800" height="480" frameborder="0" allowfullscreen="true">
  </iframe>
</div>

<h2 id="problem-description">Problem Description</h2>

<p>Digital synthesizers are synthetic instruments that generate sound by outputting a stream of floating point numbers.
These synthesizers typically have numerous parameters, such as frequency (pitch), cutoff frequency of a low-pass filter, frequency of the carrier, and several others.
Often these parameters are not <em>interpretable</em>, meaning there is no straightforward connection between a parameter and the sound a synth generates.
Instead, altering multiple parameters concurrently leads to the desired outcome.
In mathematics, we refer to these parameters as residing in a high-dimensional space.</p>

<p>Let’s consider the following scenario: We have a dancer in a rectangular area, such as a room, and we wish to modify the sound generated by a synth based on the dancer’s 2D position.
We aim to alter the synth’s parameters while it is playing (modulation) in response to the dancer’s movements. However, the changes in sound must be smooth and non-random.</p>

<p>Unfortunately, a significant problem arises in this situation. 
The number of parameters exceeds the number of positional values.
We only have two coordinates to work with, and establishing a one-to-one mapping between these coordinates and parameters is not feasible.
We want to avoid merely selecting two parameters and modifying them according to the dancer’s $x$ and $y$ coordinates.</p>

<p>In mathematical terms, we are looking for a function that receives $2$ values ($x$ and $y$) and outputs $n$ values (one for each parameter), where $n &gt; 2$.
We want a function</p>

\[f : \mathbb{R}^2 \rightarrow \mathbb{R}^n.\]

<p>Additionally, it is necessary for $f$ to be smooth and meet our musical preferences. 
As $f$ maps a lower-dimensional space to a higher-dimensional space and we require a seamless transition, we search for a two-dimensional <em>surface</em> in an $n$-dimensional space. 
As the dancer moves in the $x$ and $y$ directions, $f$ translates this motion to a movement on the two-dimensional surface in the $n$-dimensional space.</p>

<p>If we have only one coordinate and three parameters, $f$ represents a curve in the three-dimensional space.
In this case, we can draw it.
Compare Fig. 1.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/3d-curve.png" alt="2-D manifold" />
<div style="display:block; margin-left:auto; margin-right:auto; width:80%;">Figure 1: Sample points and fitted graph of a curve in a three-dimensional space. The length of the curve represents the dancer's single coordinate (let's say x). A point (X,Y,Z) on the curve represents three parameter values.</div>
</div>
<p><br /></p>

<p>This is a complex challenge, and several questions arise: How does $f$ look like? 
How can we implement it?</p>

<h3 id="reasoning-about-the-world">Reasoning about the World</h3>

<p>Before the advent of machine learning, we would have addressed this problem using the “traditional way” of abstract reasoning and programming to implement the function $f$ directly via code.
This approach involves roughly six steps:</p>

<ol>
  <li>observer and analyse the system</li>
  <li>construct a falsifiable mathematical model (which is an imperfect generalization)</li>
  <li>implement a numerical model via code</li>
  <li>calibrate the model</li>
  <li>test your assumption via observation until the model approximates reality adequately</li>
  <li>find unobserved phenomena, which the model implies, in the real world</li>
</ol>

<p>Newton’s discoveries serve as a classic example, where he observed reality and reasoned about it, generating laws that are incorrect but sufficiently accurate to travel to the moon. 
He established formulas such as</p>

\[F = m \cdot a,\]

<p>which are falsifiable via experiments.
With these formulas one can predict unknown phenomena that should appear if the model is reliable.</p>

<p>In our case, we would have conducted a comprehensive analysis of the synth to establish how its parameters interact with one another.
This approach would have required a wealth of knowledge across diverse domains such as programming, signal processing, and mathematics.
Furthermore, to achieve our desired sound, we would have needed to understand the impact of parameter changes on various aspects of the sound, such as pitch and timbre.</p>

<p>In essence, we would have aimed to create a model of the synth “world” to enable us to reason about its structures and rules.
We would have then written code to manipulate the $n$ parameters concurrently, relative to the dancer’s position.</p>

<p>While I value the traditional approach for its ability to provide insights into actual and imaginative structures, it is not the optimal solution for our specific scenario. I believe that creative practitioners do not necessarily avoid analytical work but tend to focus on creation, thereby enabling a more tangible understanding of the problem. I welcome this approach, particularly in the field of machine learning.
In contrast, the traditional approach can be challenging and less accessible, particularly in achieving our artistic objectives.</p>

<h3 id="modelling-without-reasoning">Modelling without Reasoning</h3>

<p>In <em>machine learning</em>, the focus shifts to a <em>data-driven approach</em>.
Rather than constructing a model by hand through reasoning about the world, we enable machines to learn the model by providing them with data, i.e., observations.</p>

<p>In extreme cases when observation is the model, we cannot provide outputs of unobserved inputs.
Therefore, like models constructed manually, machine learning models are an imperfect abstraction of the data on which they are trained.
This is the fundamental idea behind machine learning, albeit an oversimplification.</p>

<p>In our scenario, we replace manual modeling with machine learning by defining what we want and letting the machine learning models provided by the <a href="http://www.wekinator.org/">Wekinator</a> figure out how to achieve it.
We present an algorithm $A$ with examples $D$ that represent our requirements and ask it to “program” a function $f$ that fulfills our needs.</p>

<p><em>Machine learning</em> involves learning $f$ from data $D$ using algorithm $A$, where $A$ is essentially just another function that produces functions:</p>

\[A(D) = f\]

<p>The <a href="http://www.wekinator.org/">Wekinator</a> allows us to choose algorithm $A$ from a list of algorithms and provides a graphical user interface (GUI) for recording $D$ and feeding it into $A$ to compute $f$.
The algorithm $A$ is predetermined, and $f$ will be computed.
As a result, we need to provide data/observation $D$ by recording it, so let’s get started!</p>

<p><strong>Disclaimer:</strong>
Utilizing <em>machine learning</em> does not imply that we cease rationalizing about the world.
However, I selected this thought-provoking title to accentuate the contrast in tendencies.
Moreover, the effectiveness and characteristics of <em>machine learning models</em> are significantly influenced by the quality of the observed data and the choice of algorithm.
Given that our challenge involves a <em>regression task</em>, we will employ a <em>feed-forward neural network</em>.</p>

<h2 id="realization">Realization</h2>

<p>In the following, we have a lot to set up since every part of the system is digital and our own creation.
However, do not worry if you do not understand the <a href="https://supercollider.github.io/">SuperCollider</a> or <a href="https://processing.org/">Processing</a> part.
It is more important to understand the principle of OSC communication and the <a href="http://www.wekinator.org/">Wekinator</a>.
If you are interested in <a href="https://supercollider.github.io/">SuperCollider</a> or <a href="https://processing.org/">Processing</a> I can highly recommend checking them out.</p>

<h3 id="creating-a-new-instrument">Creating a new Instrument</h3>

<p>First, we need an actual synthesizer that produces sound.
I use a synth that randomly produces a short resonating impulse that gets reflected.
I want to go into only a few details about the inner workings of the synth.
It creates a sound similar to a firework in a city perceived inside a room.</p>

<p>The synth has 6 parameters which are, in this case, explainable:</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">\densityleft</code> controls the number of impulses in the left speaker.</li>
  <li><code class="language-plaintext highlighter-rouge">\densityright</code> controls the number of impulses in the right speaker.</li>
  <li><code class="language-plaintext highlighter-rouge">\freq</code> controls the pitch of the impulse response (i.e., the sound). Higher frequency increases the pitch. (For <code class="language-plaintext highlighter-rouge">Ringz</code> it is the frequency at which the impulse resonates.)</li>
  <li><code class="language-plaintext highlighter-rouge">\cutofffreq</code> controls the cutoff frequency of the lowpass filter. Lower values make the sound more doll.</li>
  <li><code class="language-plaintext highlighter-rouge">\decaytime</code> controls the time it takes for the impulses to decay, influencing the resonance.</li>
  <li><code class="language-plaintext highlighter-rouge">\amp</code> controls the signal’s amplitude, i.e., the volume.</li>
</ol>

<p><code class="language-plaintext highlighter-rouge">Dust</code> outputs the impulse such that <code class="language-plaintext highlighter-rouge">Ringz</code> resonates.
The resulting signal gets reflected by <code class="language-plaintext highlighter-rouge">FreeVerb</code> which introduces reverberation.</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">SynthDef</span><span class="p">(</span><span class="sx">\fireworks</span><span class="p">,{</span>
    <span class="k">var</span> <span class="n">sig</span><span class="p">;</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="nc">Dust</span><span class="p">.</span><span class="n">ar</span><span class="p">([</span><span class="sx">\densityleft</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">3</span><span class="p">),</span> <span class="sx">\densityright</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">3</span><span class="p">)</span><span class="mf">-0.5</span><span class="p">]);</span>
	<span class="n">sig</span> <span class="o">=</span> <span class="nc">Ringz</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span>
		<span class="n">sig</span><span class="p">,</span> 
		<span class="nl">freq:</span> <span class="sx">\freq</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">300</span><span class="p">),</span> 
		<span class="nl">decaytime:</span> <span class="sx">\decaytime</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span> <span class="o">*</span> <span class="sx">\amp</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">0.55</span><span class="p">);</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="nc">FreeVerb</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">);</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="nc">LPF</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span><span class="nl">in:</span> <span class="n">sig</span><span class="p">,</span> <span class="nl">freq:</span> <span class="sx">\cutofffreq</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">21000</span><span class="p">));</span>
    <span class="nc">Out</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="n">sig</span><span class="p">);</span>
<span class="p">}).</span><span class="n">add</span><span class="p">;</span>
<span class="p">)</span>
</code></pre></div></div>

<p>We can play the synth and manipulate its parameters on the fly.
Let’s listen but be warned since the amplitude during this example will change.</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="vg">~fireworks</span> <span class="o">=</span> <span class="nc">Synth</span><span class="p">(</span><span class="sx">\fireworks</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\amp</span><span class="p">,</span> <span class="mf">1</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\densityleft</span><span class="p">,</span> <span class="mf">10</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\freq</span><span class="p">,</span> <span class="mf">400</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\decaytime</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">free</span><span class="p">();</span>
</code></pre></div></div>

<audio controls="">
  <source src="/Pages/assets/audio/fireworks.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<p>Ok cool, we can play sound.</p>

<h3 id="simulation-of-the-dancer">Simulation of the Dancer</h3>

<p>Next, let’s envision a dancer gracefully moving across the room. 
While I am not a dancer, nor do I possess sensors to measure a dancer’s position, we can simulate this scenario using <a href="https://processing.org/">Processing</a>. 
It’s worth mentioning that we could achieve the same result with SuperCollider, as it also features GUI elements. 
However, I’d like to demonstrate how we can effortlessly integrate multiple systems.</p>

<p>You can download the <a href="https://processing.org/">Processing</a> example at this <a href="http://www.doc.gold.ac.uk/~mas01rf/WekinatorDownloads/wekinator_examples/all_source_zips/Simple_Mouse_DraggedObject_2Inputs.zip">link</a>. 
I will provide the code below, but please don’t be intimidated. 
It simply consists of a draggable green square, accompanied by informative log text displayed on a black window, and an OSC sender. 
Dragging the green square simulates the dancer’s movement, while the application continuously transmits the rectangle’s central position over the network.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/simple_mouse_drag.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 2: Running Processing sketch.</div>
</div>
<p><br /></p>

<p>If you start the sketch in <a href="https://processing.org/">Processing</a>, you should see the window shown in Fig. 2.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**
* REALLY simple processing sketch that sends 
* mouse x and y position of box to wekinator
* This sends 2 input values to port 6448 using message /wek/inputs
* Adapated from https://processing.org/examples/mousefunctions.html 
* by Rebecca Fiebrink
**/</span>

<span class="kn">import</span> <span class="nn">oscP5.*</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">netP5.*</span><span class="o">;</span>

<span class="nc">OscP5</span> <span class="n">oscP5</span><span class="o">;</span>
<span class="nc">NetAddress</span> <span class="n">dest</span><span class="o">;</span>
<span class="nc">PFont</span> <span class="n">f</span><span class="o">;</span>

<span class="kt">float</span> <span class="n">bx</span><span class="o">;</span>
<span class="kt">float</span> <span class="n">by</span><span class="o">;</span>
<span class="kt">int</span> <span class="n">boxSize</span> <span class="o">=</span> <span class="mi">30</span><span class="o">;</span>
<span class="kt">boolean</span> <span class="n">overBox</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
<span class="kt">boolean</span> <span class="n">locked</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
<span class="kt">float</span> <span class="n">xOffset</span> <span class="o">=</span> <span class="mf">0.0</span><span class="o">;</span> 
<span class="kt">float</span> <span class="n">yOffset</span> <span class="o">=</span> <span class="mf">0.0</span><span class="o">;</span>

<span class="kt">void</span> <span class="nf">setup</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">createFont</span><span class="o">(</span><span class="s">"Courier"</span><span class="o">,</span> <span class="mi">15</span><span class="o">);</span>
    <span class="n">textFont</span><span class="o">(</span><span class="n">f</span><span class="o">);</span>

    <span class="n">size</span><span class="o">(</span><span class="mi">640</span><span class="o">,</span> <span class="mi">480</span><span class="o">,</span> <span class="no">P2D</span><span class="o">);</span>
    <span class="n">noStroke</span><span class="o">();</span>
    <span class="n">smooth</span><span class="o">();</span>
    
    <span class="n">bx</span> <span class="o">=</span> <span class="n">width</span><span class="o">/</span><span class="mf">2.0</span><span class="o">;</span>
    <span class="n">by</span> <span class="o">=</span> <span class="n">height</span><span class="o">/</span><span class="mf">2.0</span><span class="o">;</span>
    <span class="n">rectMode</span><span class="o">(</span><span class="no">RADIUS</span><span class="o">);</span>  
    
    <span class="cm">/* start oscP5, listening for incoming messages at port 12000 */</span>
    <span class="n">oscP5</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscP5</span><span class="o">(</span><span class="k">this</span><span class="o">,</span><span class="mi">9000</span><span class="o">);</span>
    <span class="n">dest</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">NetAddress</span><span class="o">(</span><span class="s">"127.0.0.1"</span><span class="o">,</span><span class="mi">6449</span><span class="o">);</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">draw</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">background</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span>
    <span class="n">fill</span><span class="o">(</span><span class="mi">255</span><span class="o">);</span>
    <span class="n">text</span><span class="o">(</span><span class="s">"x="</span> <span class="o">+</span> <span class="n">bx</span> <span class="o">+</span> <span class="s">", y="</span> <span class="o">+</span> <span class="n">by</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">80</span><span class="o">);</span>
    
    <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">200</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>

    <span class="c1">// Test if the cursor is over the box </span>
    <span class="k">if</span> <span class="o">(</span><span class="n">mouseX</span> <span class="o">&gt;</span> <span class="n">bx</span><span class="o">-</span><span class="n">boxSize</span> <span class="o">&amp;&amp;</span> <span class="n">mouseX</span> <span class="o">&lt;</span> <span class="n">bx</span><span class="o">+</span><span class="n">boxSize</span> <span class="o">&amp;&amp;</span> 
        <span class="n">mouseY</span> <span class="o">&gt;</span> <span class="n">by</span><span class="o">-</span><span class="n">boxSize</span> <span class="o">&amp;&amp;</span> <span class="n">mouseY</span> <span class="o">&lt;</span> <span class="n">by</span><span class="o">+</span><span class="n">boxSize</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">overBox</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span>  
        <span class="k">if</span><span class="o">(!</span><span class="n">locked</span><span class="o">)</span> <span class="o">{</span> 
        <span class="n">stroke</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span> 
        <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
        <span class="o">}</span> 
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="n">stroke</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
        <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
        <span class="n">overBox</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
    <span class="o">}</span>
    
    <span class="c1">// Draw the box</span>
    <span class="n">rect</span><span class="o">(</span><span class="n">bx</span><span class="o">,</span> <span class="n">by</span><span class="o">,</span> <span class="n">boxSize</span><span class="o">,</span> <span class="n">boxSize</span><span class="o">);</span>
    
    <span class="c1">//Send the OSC message with box current position</span>
    <span class="n">sendOsc</span><span class="o">();</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">mousePressed</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">if</span><span class="o">(</span><span class="n">overBox</span><span class="o">)</span> <span class="o">{</span> 
        <span class="n">locked</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span> 
        <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="n">locked</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="n">xOffset</span> <span class="o">=</span> <span class="n">mouseX</span><span class="o">-</span><span class="n">bx</span><span class="o">;</span> 
    <span class="n">yOffset</span> <span class="o">=</span> <span class="n">mouseY</span><span class="o">-</span><span class="n">by</span><span class="o">;</span> 
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">mouseDragged</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">if</span><span class="o">(</span><span class="n">locked</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">bx</span> <span class="o">=</span> <span class="n">mouseX</span><span class="o">-</span><span class="n">xOffset</span><span class="o">;</span> 
        <span class="n">by</span> <span class="o">=</span> <span class="n">mouseY</span><span class="o">-</span><span class="n">yOffset</span><span class="o">;</span> 
    <span class="o">}</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">mouseReleased</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">locked</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">sendOsc</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">OscMessage</span> <span class="n">msg</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscMessage</span><span class="o">(</span><span class="s">"/wek/inputs"</span><span class="o">);</span>
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">bx</span><span class="o">);</span> 
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">by</span><span class="o">);</span>
    <span class="n">oscP5</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">msg</span><span class="o">,</span> <span class="n">dest</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>When we start the Processing sketch, it shows a green square inside a black window.
The window represents our room, and the green square the dancer.
You can drag the dancer around.</p>

<h3 id="osc-communication">OSC Communication</h3>

<p>The only crucial part of the <a href="https://processing.org/">Processing</a> sketch’s code is the transmission of OSC messages..</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">oscP5</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscP5</span><span class="o">(</span><span class="k">this</span><span class="o">,</span><span class="mi">9000</span><span class="o">);</span>
<span class="n">dest</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">NetAddress</span><span class="o">(</span><span class="s">"127.0.0.1"</span><span class="o">,</span><span class="mi">6448</span><span class="o">);</span>
</code></pre></div></div>

<p>These three lines of code enable the sketch to listen for OSC messages over the network using the IP address <code class="language-plaintext highlighter-rouge">"127.0.0.1"</code>, which represents the local IP address. 
This means that the sketch listens for messages originating from your device. 
It receives messages on port <code class="language-plaintext highlighter-rouge">9000</code> and transmits them to port <code class="language-plaintext highlighter-rouge">6448</code>. 
The listening port is inconsequential, as the dancer never responds to incoming signals. 
The IP address and sending port are crucial because they must correspond with the numbers we will employ in the <a href="http://www.wekinator.org/">Wekinator</a>.</p>

<p>The following code</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">sendOsc</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">OscMessage</span> <span class="n">msg</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscMessage</span><span class="o">(</span><span class="s">"/wek/inputs"</span><span class="o">);</span>
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">mouseX</span><span class="o">);</span> 
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">mouseY</span><span class="o">);</span>
    <span class="n">oscP5</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">msg</span><span class="o">,</span> <span class="n">dest</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>sends the coordinates $x$ and $y$ of the mouse (with respect to the window) to the port <code class="language-plaintext highlighter-rouge">6448</code> and the path <code class="language-plaintext highlighter-rouge">'/wek/inputs'</code>. 
OSC uses these paths such that it is possible to differentiate different types of messages that got sent to some port.</p>

<p>Now we have to set up OSC communication of our sound generating system, i.e. <a href="https://supercollider.github.io/">SuperCollider</a>.
Let us first listen to port <code class="language-plaintext highlighter-rouge">6448</code>and path <code class="language-plaintext highlighter-rouge">'/wek/inputs'</code> and let’s just print the raw data we perceive, i.e., the $x$ and $y$ values of our dancer (the green square).</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">OSCdef</span><span class="p">(</span>
    <span class="sx">\getCoords</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="k">arg</span> <span class="n">val</span><span class="p">;</span> <span class="n">val</span><span class="p">.</span><span class="n">postln</span><span class="p">;</span>
    <span class="p">},</span>
    <span class="sx">'/wek/inputs'</span><span class="p">,</span>
    <span class="nl">recvPort:</span> <span class="mf">6448</span>
<span class="p">);</span>
<span class="p">)</span>
</code></pre></div></div>

<p>By executing this line in <a href="https://supercollider.github.io/">SuperCollider</a> while the <a href="https://processing.org/">Processing</a> sketch is running, you should see OSC messages on the post window.
These messages look like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[ /wek/inputs, 248.0, 185.0 ]
</code></pre></div></div>

<p>Now, let’s take it a step further and modify two synth parameters based on these values. 
The following code maps $x$ and $y$ to a suitable range. 
While $x$ ranges from 0 to 650 and $y$ from 0 to 460, we aim to obtain values between 0.1 and 20.</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">OSCdef</span><span class="p">(</span>
    <span class="sx">\getCoords</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="k">arg</span> <span class="n">val</span><span class="p">;</span> <span class="k">var</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="mf">1</span><span class="p">];</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="mf">2</span><span class="p">];</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\leftdensity</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">650</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\rightdensity</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">460</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
    <span class="p">},</span>
    <span class="sx">'/wek/inputs'</span><span class="p">,</span>
    <span class="nl">recvPort:</span> <span class="mf">6448</span>
<span class="p">);</span>
<span class="p">)</span>
</code></pre></div></div>

<p>The impact of this code should be noticeable in the audio output. When the dancer is positioned at the top left, fewer impulses are produced.
If situated at the bottom right, impulses emit from both speakers, while being at the bottom left results in only the right speaker activating.
This effect may not seem extraordinary, as our function $f$ is quite elementary, involving a linear mapping from one interval to another.</p>

<h3 id="the-machine-in-the-middle">The Machine in the Middle</h3>

<p>We now introduce the <a href="http://www.wekinator.org/">Wekinator</a> in the middle of the communication.
That is, the dancer sends their position to the <a href="http://www.wekinator.org/">Wekinator</a>, and <a href="https://supercollider.github.io/">SuperCollider</a> listens to the messages from the <a href="http://www.wekinator.org/">Wekinator</a> and changes the values of the synth accordingly.
The <a href="http://www.wekinator.org/">Wekinator</a> translates positions into synth parameters, and it realizes the function $f$.
The 6 output signals</p>

\[(v_1, \ldots, v_6) = f(x,y)\]

<p>are sent to <a href="https://supercollider.github.io/">SuperCollider</a>.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/wekinator.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 3: Overview of all the connected parts.</div>
</div>
<p><br /></p>

<p>First, we need to modify the port <a href="https://supercollider.github.io/">SuperCollider</a> listens to by changing the line from <code class="language-plaintext highlighter-rouge">recvPort: 6448</code> to <code class="language-plaintext highlighter-rouge">recvPort: 7448</code>.
Additionally, we should update the path to <code class="language-plaintext highlighter-rouge">'/wek/outputs'</code> as a reminder that we are receiving output signals from Wekinator.</p>

<p>Secondly, we must utilize the values we receive. Wekinator consistently sends a value between 0 and 1 for each dimension. 
As a result, we need to map the interval [0;1] to appropriate synth values.
This step is critical and necessitates some understanding of the synth. 
I employ the following mapping (note that we skip <code class="language-plaintext highlighter-rouge">val[0]</code> since it represents the OSC path):</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">OSCdef</span><span class="p">(</span>
    <span class="sx">\getCoords</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="k">arg</span> <span class="n">val</span><span class="p">;</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\densityleft</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">1</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\densityright</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">2</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\freq</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">3</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">100</span><span class="p">,</span> <span class="mf">700</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\amp</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">4</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">0</span><span class="p">,</span> <span class="mf">2</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\decaytime</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">5</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\cutofffreq</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">6</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">200</span><span class="p">,</span> <span class="mf">20000</span><span class="p">));</span>
    <span class="p">},</span>
    <span class="sx">'/wek/outputs'</span><span class="p">,</span>
    <span class="nl">recvPort:</span> <span class="mf">7448</span>
<span class="p">);</span>
<span class="p">)</span>
</code></pre></div></div>

<p><strong>If you use <a href="https://supercollider.github.io/">SuperCollider</a> be careful with your choices and protect your ears</strong> since it will try to use even unreasonable values like an amplitude of 10 or higher.</p>

<p>Now we start the <a href="http://www.wekinator.org/">Wekinator</a>.
First, we have to specify the port for the input signals of $f$, i.e., the dancer’s position.
This is equal to <code class="language-plaintext highlighter-rouge">6448</code>, and the OSC path is <code class="language-plaintext highlighter-rouge">'/wek/inputs'</code>.
Then we have to specify the port of the output signal $f(x,y)$, i.e., the port used in SuperCollider, which is <code class="language-plaintext highlighter-rouge">7448</code> furthermore, we specify a path <code class="language-plaintext highlighter-rouge">'/wek/outputs'</code> such that we do not confuse input and output.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/wekinator-screen-started.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 4: Wekinator after it has started.</div>
</div>
<p><br /></p>

<p>Furthermore, we have to tell the <a href="http://www.wekinator.org/">Wekinator</a> about the number of inputs and outputs, i.e., 2 and 6, respectively.
After everything is set up, we can click on <code class="language-plaintext highlighter-rouge">Start Listening</code>.
Then we can click <code class="language-plaintext highlighter-rouge">Next</code>.</p>

<p>Now you will see the following screen.
In the top left <code class="language-plaintext highlighter-rouge">OSC In</code> should be green, since the <a href="https://processing.org/">Processing</a> sketch is sending messages.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/wekinator-screen.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 5: Wekinator before training.</div>
</div>
<p><br /></p>

<p>If this is not the case, you either forgot to click <code class="language-plaintext highlighter-rouge">Start Listening</code>, or the port is already used. 
In that case, change the port in the <a href="http://www.wekinator.org/">Wekinator</a> as well in your <a href="https://processing.org/">Processing</a> sketch and restart the sketch.
You also should see 6 sliders.
If you manipulate these sliders, <code class="language-plaintext highlighter-rouge">OSC Out</code> should turn green, indicating that we are sending OSC messages to <a href="https://supercollider.github.io/">SuperCollider</a>.</p>

<p>Furthermore, the sound should change accordingly.
Make sure your amplitude is not zero.
Now you can play around with the sliders or press the <code class="language-plaintext highlighter-rouge">random</code> button until you hear something you like.
Of course, you have to remember which slider represents which parameter.</p>

<p>To connect the sound to the dancer’s position, we have to</p>

<ol>
  <li>record samples, i.e., construct the data set $D$</li>
  <li>train the model, i.e. compute $f = A(D)$.</li>
</ol>

<p>To construct $D$ we need multiple tuples</p>

\[(\text{input}, \text{output}) = ((x,y), (v_1, \ldots, v_6)).\]

<p>First, we move the square to a desired position and choose a set of desired parameters $(v_1, \ldots, v_6)$.
Next, we click <code class="language-plaintext highlighter-rouge">Start Recording</code>, and after a few seconds, we press <code class="language-plaintext highlighter-rouge">Stop Recording</code>.
In doing so, we generate portions of the data $D$.
We repeat this step multiple times until we have accumulated sufficient data $D$.</p>

<p>Once completed, we press <code class="language-plaintext highlighter-rouge">Train</code> to compute</p>

\[A(D) = f.\]

<p>This process should only take a few seconds.</p>

<p>Finally, we can utilize $f$ by clicking <code class="language-plaintext highlighter-rouge">Run</code>.
At this point, both <code class="language-plaintext highlighter-rouge">OSC In</code> and <code class="language-plaintext highlighter-rouge">OSC Out</code> indicators should be green, and as you move the square around, the sound should change accordingly. 
Moreover, all parameters (assuming they were all manipulated during recording) should transition smoothly.</p>

<h3 id="different-algorithms">Different Algorithms</h3>

<p>Keep in mind that we did not specify any algorithm A.
By default, <a href="http://www.wekinator.org/">Wekinator</a> employs a <em>feed-forward neural network</em> and assumes a <em>regression task</em>.
This means that the output $f(x,y)$ is continuous and does not represent an element within a finite set of classes.</p>

<p>You can choose algorithms by modifying the <code class="language-plaintext highlighter-rouge">Type</code> setting, as shown in Fig. 4. 
This selection includes classification algorithms. 
For instance, if you wish to establish a mapping between a gesture captured by your webcam and a specific sample, this would be a classification task. Another example would be classifying the type of instrument being played.</p>

<p><a href="http://www.wekinator.org/">Wekinator</a> has some limitations regarding the range of algorithms it offers, as the user lacks control over the model architecture and the model’s hyperparameters.</p>

<h2 id="summary">Summary</h2>

<p><a href="http://www.wekinator.org/">Wekinator</a> is an outstanding tool that makes certain aspects of machine learning accessible.
Its compatibility with OSC allows for seamless integration into various systems. It is an ideal fit for quick experimentation and serves as a valuable tool for teaching creative practitioners the fundamentals of machine learning on an intuitive level.</p>

<p>However, it does feel somewhat dated and experimental, offering no control over the hyperparameters of its built-in models.
Additionally, it does not utilize the latest software libraries, such as <code class="language-plaintext highlighter-rouge">PyTorch</code> or <code class="language-plaintext highlighter-rouge">TensorFlow</code>.
Being a Java application, it supports all operating systems, but <code class="language-plaintext highlighter-rouge">Java</code> is a relatively uncommon programming language in the field of machine learning.</p>

<p>The concept behind <a href="http://www.wekinator.org/">Wekinator</a> is exceptional, and it shouldn’t be too challenging to create a similar tool in Python, enabling artists or developers to integrate their own PyTorch or TensorFlow models. It supports the goal of making machine learning accessible to everyone and provides valuable insights into the features that ML tools for non-experts should offer. Perhaps we can develop new tools to break down even more barriers, allowing practitioners and developers to learn from one another.</p>

<p>In any case, if you’re interested in experimenting with simple machine learning models that process various types of generated input, give <a href="http://www.wekinator.org/">Wekinator</a> a try.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="fiebrink:2019">Fiebrink, R. (2019). Machine Learning Education for Artists, Musicians, and Other Creative Practitioners. <i>ACM Trans. Comput. Educ.</i>, <i>19</i>(4). https://doi.org/10.1145/3294008</span></li>
<li><span id="clarice:2021">Hilton, C., Plant, N., González Dı́az Carlos, Perry, P., Gibson, R., Martelli, B., Zbyszynski, M., Fiebrink, R., &amp; Gillies, M. (2021). InteractML: Making Machine Learning Accessible for Creative Practitioners Working with Movement Interaction in Immersive Media. <i>Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology</i>. https://doi.org/10.1145/3489849.3489879</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="ML" /><category term="Wekinator" /><category term="Music" /><summary type="html"><![CDATA[This blog post aims to explore how machine learning can empower creative practitioners to bring to life projects that traditionally demanded significant technical expertise, such as programming skills. To make my case immediately understandable, I will provide a specific example. However, it’s worth noting that this is just one of countless possible instances.]]></summary></entry><entry><title type="html">Musical Interrogation - Part I</title><link href="https://bzoennchen.github.io/Pages/2023/04/02/musical-interrogation-I.html" rel="alternate" type="text/html" title="Musical Interrogation - Part I" /><published>2023-04-02T00:00:00+02:00</published><updated>2023-04-02T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/04/02/musical-interrogation-I</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/04/02/musical-interrogation-I.html"><![CDATA[<blockquote>
  <p>Whereas the human mind, conscious of its conceived purpose, approaches even an artificial system with a selective attitude and so becomes aware of only the preconceived implications of the system, the computers would show the total of available content. Revealing far more than only the tendencies of the human mind, this nonselective picture of the mind-created system should be of significant importance. – Gerbert Brün (1970)</p>
</blockquote>

<p>In this series of posts, I will talk about melody generation using <em>machine learning</em>. I start by reflecting on computer music. Furthermore, I give a short and selective overview of some techniques to generate melodies that captured my interest, focusing on <em>recurrent neural networks (RNN)</em> to generate <em>monophonic</em> melodies for now.</p>

<p>I intend to build an interactive system that facilitates the musical dialog between humans and machines. In the end, a user should be able to interrogate the machine learning model such that an evaluation of the model’s ability is possible and maybe – a big maybe – users can enhance their creative process.</p>

<h2 id="reflection-on-computer-music">Reflection on Computer Music</h2>

<p>Due to the recent advances in <em>machine learning</em>, especially in the domain of <em>deep learning</em>, <em>computer music</em> is regaining attraction.
What started in the early 1960th, when <em>rule-based</em> methods such as <em>Markov chains</em>, <em>hidden Markov models (HMM)</em>, <em>generative grammars</em>, <em>chaotic systems</em>, and <em>cellular automata</em> were applied to generate musical compositions, slowed down over the years.
Of course, since then, computers have always accompanied music production, but algorithms have taken a backseat when it comes to the structure of music itself.
Today, a reinvigoration of <em>computer music</em> might happen, but what will be at the forefront?
The algorithm? The artist? Or a massive amount of data?</p>

<p>In his book <em>Algorithmic Composition: Paradigms of Automated Music Generation</em> <a class="citation" href="#nierhaus:2010">(Nierhaus, 2009)</a> <em>Gerhard Nierhaus</em> makes an essential distinction between <strong>genuine composition</strong> and <strong>style imitation</strong>.
This terminology can bring nuances into the discussion around machines, algorithms, and data replacing human creativity.</p>

<p><strong>Style imitation</strong> is more applicable when music is not the main focus of interest but amplifies or accompanies something else, e.g., ads, computer games, or movies.
In a computer game, you want music that captures the dynamic situation of the game; thus, surprises are undesirable.</p>

<p><strong>Genuine composition</strong> appeals more to the artist who wants to play, experiment, and break things or criticize narratives.
<em>Genuine composition</em> seduces the audiance’s desire for experimentation, confrontation, and reflection on something new and unexpected.</p>

<p>While <em>genuine composition</em> carries much novelty, <em>style imitation</em> can be categorized into a set of preexisting styles of musical compositions.
The results generated by different techniques lean more or less towards one or the other.
For example, compositions generated by <em>Markov chains</em> (see <a href="/Pages/2022/07/09/markov-chains-for-music-generation.html">Probabilistic Melody Modeling</a>) lean more towards <em>style imitation</em> since the model samples from a learned distribution to estimate the structure of a particular composition.
On the other hand, using <em>cellular automata</em> is a technique more suited for <em>genuine composition</em> because no learning is involved.
Instead, <em>cellular automata</em> are <em>dynamic systems</em> capable of complex emergent behavior that can not be explained by solely looking at the parts of the system.
Of course, there is no black and white.
Instead, each composition or technique lives on a spectrum, and it might be impossible to decide where exactly.
If a <em>machine learning model</em> learns some non-obvious high-level structure, i.e., a probability distribution, from its training data, does this yield novelty or not?
It depends, I guess.</p>

<p>However, this “problem” is old, isn’t it?
Looking at the history of classical Western music, there are moments in time when it seemed that nothing was left to say and <em>style imitation</em> was inevitable.
For example, after one of the most quintessential romantic composers, <em>Richard Wagner</em>, there were view possibilities left concerning tonal music.
Consequently, the need for more chromaticism and dissonance was unavoidable, leading to the extreme case of Schönberg’s atonal compositions.</p>

<p>Concerning <em>artificial intelligence</em>, our current century is an era of <em>deep learning models</em> for which model size, data, parameters, and training time are more important than the underlying algorithm.
These models can combine, alter, and re-synthesis music from recorded history.
This re-combination and alteration seem similar to human composers’ working process, which is primed by their environment, education, and culture.
There is no doubt that these models can create music via <em>style imitation</em> but how good are they regarding <em>genuine composition</em>?
Is not learning from existing data <em>style imitation</em> per definition?
Well, again, even if all the data is known, one can argue that there are hidden high-level structures within the data that we are entirely unaware of.
A prime example is discovering a new way to multiply small matrices found via <em>reinforcement learning</em> <a class="citation" href="#alhussein:2022">(Fawzi et al., 2022)</a>.</p>

<p>If machines, revealing these structures, are creative is a question that can hardly be answered objectively, but, after all, the question might not be of great interest.
I instead look at the human condition and ask what such machines mean for our being in the world.
And here, we can say that if we do not try to understand our new black boxes, we rob ourselves of the experience of understanding, which, I think, is a fundamental desire.
But at the same time, if we do not give up understanding but enhance it with machine power (seen as a tool), the reverse can be true.
Beyond a lack of understanding, the lack of experienced practice is the more obvious loss we suffer.
The uncomfortable mood I sometimes develop when the achievements of AI shimmer through my perception comes from a fear of losing my habituated being in the world.
I ask myself: will machines write my code? Will I lose the enjoyment that I get out of coding?
Will I lose my identity as a programmer?
However, this loss has more to do with technology and economics.
We think of technology as a natural evolutionary force that points towards a better future.
And due to economic necessities, we have to adapt to stay productive.
However, without the industrial revolution, I would never have been able to enjoy programming in the first place.
Therefore, fear and excitement are reasonable reactions to this <em>time of disruption</em>.</p>

<p>But let’s come back and go back to the actual topic.
One of the challenges AI researchers face today is not so much the generation of novelty but the evaluation of it, especially in the case of aesthetics, which is somewhat subjective.
Within the generative process, the machine has to “judge” if the piece is engaging.
Otherwise, the whole process is nothing more than a sophisticated but impracticable random search through the space of all possible compositions.
However, interest depends on the cultural context.
Maybe Schönberg’s atonal, thus ungodly music, would not have attracted anybody in the 13. century.
Judging if novelty is sensible seems to require an <em>embodiment</em> in the world.
Therefore, as an art form, I find fully automated <strong>opaque</strong> music-generating systems that lack human interaction undesirable because they, in the end, lead to a mode of passive consumption.
Instead, human intelligence is needed to bring <em>intentionality</em> into the composition.
I imagine an interconnected relationship where <em>artificial communication</em> guides humans and machines to new places.</p>

<p>Even though machines are still unable to develop intentionality of their own, composing is a partially rigorous and formal endeavor; thus, algorithms and machines can certainly help with realizing intentions.
Contrary to popular belief, music and computer science / mathematics are much more related than they seem.
And there is no reason to believe that algorithms can not only be aesthetically and intellectually beautiful but can also evoke emotions.</p>

<p>However, <em>computer music</em> is diverse, and as an amateur, I should be careful in my assessment.
I encountered <em>rule-centered computer music</em>, highly interactive <em>live programming</em> (which is also a movement), <em>real-time music generation</em>, <em>sonification</em>, and <em>data-centered computer music</em>.
While <em>rule-centered music generation</em> is <em>transparent</em> and offers low-level control, <em>data-centered generation</em> is often <em>opaque</em> and offers only high-level control, at least, up to this date.
<em>Live programming</em> is highly interactive and relies on <em>real-time communication</em> between performer and audience as well as <em>real-time artificial communication</em> between performer and machine.</p>

<p><em>Communication</em> between humans and machines excites me the most since it offers the possibility to reflect on algorithms, programs, machines, data, and technology in general.
It goes beyond analytical contemplation by making algorithms experiencable.
Furthermore, learning from human feedback to calibrate generative models such that they represent our experienced ups and downs, twists and turns in music by injecting <em>intentionality</em> in order to steer generative models might be the way to go.
The term <strong>co-pilot</strong> comes to mind.</p>

<h2 id="melody-generation">Melody Generation</h2>

<p>For the interested reader, the survey <em>AI Methods in Algorithmic Composition: A Comprehensive Survey</em> <a class="citation" href="#rodriguez:2014">(Rodriguez &amp; Vico, 2014)</a> and <em>A Comprehensive Survey on Deep Music Generation: Multi-level Representations, Algorithms, Evaluations, and Future Directions</em> <a class="citation" href="#shulei:2020">(Ji et al., 2020)</a> offer an excellent first overview of the different techniques up to the year 2014 and 2020, respectively.</p>

<h3 id="a-difficult-problem">A difficult Problem</h3>

<p>Let us first reflect on the question of why melody generation is tricky.
First of all, in music, intervals are everything.
It does not matter so much if one plays a C or B; what matters is the relation of notes within a piece, i.e., playing A-C or A-B.
Intervals are so ingrained into music that musicians give them certain names such as <em>minor third</em>, <em>perfect fifth</em>, or <em>tritone</em> (the Devil’s tone).
It is no coincidence that <em>major</em> and <em>minor</em> chords, as well as most <em>scales</em>, are asymmetrical because it gives each note a distinctive quality within a chord or a scale.</p>

<p>In addition, this relation is multi-dimensional.
We have melody, i.e., playing note after note horizontally, and harmony, i.e., vertical relations, for which we play notes together (chords).
On top of that, what happens in measure 5 may directly influence what happens in measure 55, without necessarily affecting any of the intervening material.
These relations can be all over the place and span a very long sequence!
Good music hits a sweet spot between repetition and surprise, and landing on that spot is quite challenging.
Together, these properties make melody (or polyphonic) generation hard.</p>

<h3 id="the-music-generation-process">The Music Generation Process</h3>

<p>Many artists and researchers took on the challenge, and <em>machine learning techniques</em> increasingly play an essential role.
The learning and generation are based on two major categories of representations: either <strong>symbolic notation</strong> or <strong>performed pieces</strong> of music.</p>

<p>Classical music and most other kinds of music as we know them came into being through the music generation process depicted in figure 1.
Composers write a score that leads to the performing musicians (the execution of the score) who are exciting their instruments.
This excitement causes the instrument to vibrate, and due to its physicality, it pushes air molecules around.
Molecules bump into each other in some areas and tend to leave other areas—a displacement we call <em>wave</em>.
In principle, the energy of the excitement travels outwards through the air to the listener’s ear.
The information gets more and more concrete.
While a score is an abstract representation, the sound caused by instruments is very concrete.
It is, in fact, so concrete that it is different for every listener since each of us perceives sound slightly differently.</p>

<p>Abstraction removes us from the messy reality and enables communication, but it also conceals the singularity of beings.
Concerning <em>melody generation</em> we have to ask how much abstraction is justified.
A score represented by a note sheet without any information about the dynamics is “more” <em>symbolic</em> or abstract than a note sheet that contains hints for the tempo and loudness.
Raw audio material is far away from the much more abstract <em>symbolic notation</em> and a lived thorough performance is a singular event.</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/music-gen-process.png" alt="Music generation process cell" />
<div style="display: table;margin: 0 auto;">Figure 1: Music generation process.</div>
</div>
<p><br /></p>

<p>Using <em>symbolic notation</em> is more accessible, but one loses the slight variations, dynamics, and other qualities that make the result feel so humanly made.
However, composers who want to use <em>melody generation</em> to support their process might be happy to introduce these qualities by themselves.
It is a question of application.
The same is true for <em>the mono-</em> and <em>polyphonic</em> generations.
Do we want to generate a full-fetched performance, a melody snippet (monophonic), or something in between?
In this blog post, I will focus on the <em>monophonic</em> generation (one note at a time).</p>

<h3 id="discrete-markov-models">Discrete Markov Models</h3>

<p>In my post <a href="/Pages/2022/07/09/markov-chains-for-music-generation.html">Probabilistic Melody Modeling</a>, I used a <em>(discrete) first-order Markov chain (MC)</em> (also called <em>Markov process</em>) to generate melodies after learning the model from one piece of music.
The approach was simple: translate the frequency of note transitions into probabilities. 
For example, if the piece is defined by the note sequence A-B-B-A-C-A-B and the duration of each note is the same, then</p>

\[P(X_{t+1} = B \ | \ X_{t} = A) = \frac{2}{3}, \quad P(X_{t+1} = C \ | \ X_{t} = A) = 1.0.\]

<p>To determine which note comes next, we only look at the previous note, i.e. at a very narrow context.
Using a <em>first-order Markov model</em>, one would estimate the probability of the melody (not considering note duration) A-B-F by</p>

\[P(X_0 = A) \cdot P(X_1 = B \ | \ X_0 = A) \cdot P(X_2 = F \ | \ X_1 = B).\]

<p>In this example, a state is defined by a note, e.g. A.</p>

<p><em>Hidden Markov models (HMM)</em> are <em>Markov chains</em> with <em>hidden states</em>.
There are also a finite number of states, probabilistic transitions between these states, and the next state is determined by the current state, but we are unsure in which state the process is currently in.
The current hidden state $Z_t$ <em>emits</em> an <em>observation</em> $X_t$.
In other words, instead of going from one observed variable to the next, e.g., one note to the next, we move from one <strong>distribution</strong> of observations to the next, e.g. from one distribution of notes to the next!</p>

<p>For example, imagine a prisoner who has to estimate the outside weather (<em>hidden state</em>) by observing the dirt on the guard’s boots (<em>emissions</em>).
If he knows all the probability transitions (e.g., from sunny to rainy, sunny to dirty on boots, etc.) and existing states, the prisoner could model the problem by an HMM, compare Figure 2.</p>

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:80%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/hmm-example-prison.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 2: Hidden Markov model with 2 hidden states (sunny, rainy) and 2 observation variables (clean, dirty). The initial state is either sunny or rainy with 0.5 probability.</div>
</div>
<p><br /></p>

<p>The prisoner could ask: given the HMM and an observation sequence $X_0, \ldots, X_n$, what is the likelihood that this sequence occurs (<em>likelihood problem</em>)?
One could also ask: what are the hidden states $Z_0, \ldots, Z_n$ that “best” explains the observations (<em>decoding problem</em>).
Moreover, what we are more interested in is: given an observation sequence $X_0, \ldots, X_n$, learn the model parameters $\theta$ that maximizes the likelihood for our observation (<em>learning problem</em>)!
Similar to neural networks, one defines the <em>architecture</em> of the HMM (states and transitions), then solve the <em>learning problem</em> and infer new melodies from the learned HMM.
In music, hidden states often lack interpretability.
Therefore, it needs to be clarified which architecture one should choose.</p>

<p><em>HMM</em> is a special case of <em>dynamic Bayesian networks</em> where a single hidden state variable represents the entire state of the world.
With respect to music, using <em>hidden Markov models</em> we can model more abstract states that we can not directly observe, for example,</p>

<p>Using <em>higher-order MC</em> or <em>HMM</em> widens the context to multiple notes of the past.
For our MC example A-B-F this would mean the probability changes to</p>

\[P(X_0 = A) \cdot P(X_1 = B \ | \ X_0 = A) \cdot P(X_2 = F \ | \ X_0 = A \ \land \ X_1 = B).\]

<p>But due to the chain property (linearity), this does not necessarily lead to better results since widening the range leads very quickly to overfitting, i.e., the model reproduces more or less exact replica because it does not generalize—more is not always better.
In any case, the learning stays stepwise causal, i.e., one note after the other without jumping around.
By focusing on linear temporal dependencies, these models need to take into account the higher-level structure and semantics important to music.
By model design, HMMs have very limited memory and are thus also incapable of modeling the longer term structure that occurs in original musical pieces.</p>

<p>Their applications in musical structure generation goes back to <em>Harry F. Olson</em> around 1950, and in 1955, the first machine produced Markov models of first and second order in regard to pitches and rhythm <a class="citation" href="#nierhaus:2010">(Nierhaus, 2009)</a>.
In <a class="citation" href="#merwe:2011">(Van Der Merwe &amp; Schulze, 2011)</a>, the authors used first-, higher-, or mixed-order MCs to represent chord duration, chord progression, and rhythm progression and first-, higher-, or mixed-order HMM to describe melodic arc.</p>

<p>A more rigorous and recent discussion, including <em>polyphonic</em> generation, be found in <a class="citation" href="#collins:2016">(Collins et al., 2016)</a>.</p>

<h3 id="long-term-memory">Long-term Memory?</h3>

<p>As stated, the challenge is primarily due to long-term relations.
One way of tackling this issue is to increase the memorizing capability of the model.
With this in mind, looking at the catalog of model types within the field of <em>deep learning</em> one can spot multiple alternatives to <em>Markov chains</em> for melody generation.</p>

<p>One obvious choice is the long short-term memory recurrent neural networks (LSTM) <a class="citation" href="#hochreiter:1997">(Hochreiter &amp; Schmidhuber, 1997)</a>, a type of recurrent neural network (RNN) that allows information to persist for a longer time by letting it flow almost directly through time.</p>

<p>In theory, <em>vanilla RNNs</em> can learn the temporal structure of any signal, but due to computational reasons (vanishing/exploding gradients), they can not keep track of temporally distant events.
If you want to learn more about RNNs, I highly recommend the blog article <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Neural Networks</a> by Andrej Karpathy.
In his blog post, he writes:</p>

<blockquote>
  <p>RNNs combine the input vector with their state vector with a fixed (but learned) function to produce a new state vector. This can, in programming terms, be interpreted as running a fixed program with certain inputs and some internal variables. – Andrej Karpathy</p>
</blockquote>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/rnn-unfold.png" alt="Sketch of an RNN unfolded in time" />
<div style="display: table;margin: 0 auto;">Figure 3: Sketch of an RNN unfolded in time.</div>
</div>
<p><br /></p>

<p>RNNs are similar to <em>multilayered perceptrons</em> (MLPs) but allow for connections from the output of one unit into the input of another unit located at a shallower layer than itself, i.e., closer to the input of the network.
The information no longer flows acyclic through the network.
Instead, recurrent feedback is introduced and allows an RNN to take into account its past inputs together with new inputs.
Essentially, an RNN predicts a sequence of symbols given an input sequence.
But using an RNN is like writing a thousand letters on the same piece of paper and then figuring out the information contained in the first letter—it is a mess; the information gets washed away.
In Figure 3 the basic components of an RNN are depicted.
Using my analogy, the piece of paper are the matrices $U,V,W$ which are learnable parameters.
<strong>They are shared through time!</strong></p>

<p>The extension, motivated by the shortcomings of <em>vanilla RNNs</em>, are <em>LSTM RNNs</em> or just <em>LSTMs</em>.
LSTMs <strong>learn</strong> which information they should keep in long-term memory and which information they can forget after a short period.
Instead of just writing all the letters on the piece of paper, we use our rubber and get rid of some writings while highlighting other passages.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/lstm-cell.png" alt="LSTM cell" />
<div style="display: table;margin: 0 auto;">Figure 4: A sketch of an LSTM cell.</div>
</div>
<p><br /></p>

<p>There is plenty of good material which explains LSTMs much more accurately than I can ever do.
Figure 4 shows a sketch of a very complicated-looking LSTM cell where each green square is a linear transformation, each red bar indicates a <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a> activation, and blue bars indicate a <a href="https://en.wikipedia.org/wiki/Hyperbolic_functions">tanh</a> activation.
All the sigmoid activations are used to control the memorizing strategy (rubber and highlighter).
First, the cell “decides” what to keep in the long-term state $\mathbf{c}_{t-1}$ via $f_t$.</p>

<p>Then $i_t$ decides what to add to the long-term state.
In addition, $o_t$ decides what part of the new long-term state will make up the short-term state 
$\mathbf{h}_t.$
The importance is that along the path from 
$\mathbf{c}_{t-1}$ 
to 
$\mathbf{c}_{t},$
there is only a simple multiplication and addition!
Therefore, information can persist for longer.</p>

<p>Note, however, that LSTMs can still access information of time step $t$ only via time step $t-1$.
There is no direct access to information compared to the <em>attention mechanism</em> <a class="citation" href="#bahdanau:2014">(Bahdanau et al., 2014)</a>, and the <em>transformer</em> <a class="citation" href="#vaswani:2017">(Vaswani et al., 2017)</a>, which led to the most recent breakthroughs in the field of <em>deep learning</em>.
Just a few days ago, another RNN, called <a href="https://github.com/BlinkDL/RWKV-LM">RWKV-LM</a>, claimed to achieve similar results; thus, the last word has yet to be spoken.</p>

<h3 id="recurrent-neural-networks">Recurrent Neural Networks</h3>

<p>In <a class="citation" href="#todd:1989">(Todd, 1989)</a> <em>Peter M. Todd</em> used a <em>vanilla RNN</em> to generate melodies.
Various issues are discussed in designing the network.
Note that at this time in the young history of machine learning, there were no user-friendly software libraries available, and there was much more thinking going on in designing the network on a fine-grained level.
The author also suggests using <em>multi-layered perceptrons (MLPs)</em> by explicitly modeling time and either showing the whole piece to the network or using a sliding-window approach, e.g., showing one bar at a time and predicting the next bar.
In the end, Todd uses an RNN with 15 hidden units and 15 output units (1 note-begin unit and 14 pitch units) trained for 8500 epochs (cycle through the entire training set) using a handful of sliced melodies.
Fewer hidden units led to more training.
By today’s standard, Todd’s network was tiny.
Todd assumes the key of C from D4 to C6.
The <em>note-begin unit</em> indicates if the note begins or it merely continues.
Interestingly, Todd discusses a <em>pitch-interval</em> representation.
Instead of outputting the actual pitch values, the network outputs the relative transitions (intervals/pitch changes) in semitones.
For example, instead of A-B-C the network outputs A-(+1)-(-3).
The advantage is that outputs are more <em>key-independent</em> and can range over an extensive range of notes even if there are only view output units.
This allows for the transposition of an entire melody simply by changing the actual initial pitch (which need not even be produced by the network but could be specified elsewhere).
In the end, he decides not to use it because of possible errors in the production since a single error would make the whole melody flawed.</p>

<p>One of the very first applications of LSTMs for the generation of music was introduced by <em>Dougnles Eck</em> and <em>Jürgen Schmidhuber</em> <a class="citation" href="#eck:2002">(Eck &amp; Schmidhuber, 2002)</a>.
The authors state that “most music has a well-defined global temporal structure in the form of nested periodicities or meter”.
In a walz, important melodic events occur every three-quarter notes (or every first note of a bar).
Chord changes occur more slowly and are most often aligned with the bars.</p>

<blockquote>
  <p>For this reason, one can say of music that some notes are more important than others: in general, a learning mechanism should spend more resources on metrically-important notes than others. – <a class="citation" href="#eck:2002">(Eck &amp; Schmidhuber, 2002)</a></p>
</blockquote>

<p>The authors use a <em>time-sliced representation</em>, i.e., each step/event represents the period (for example, a quarter note).
They use one input/output unit per note, making it implicitly <em>polyphonic</em> and avoiding an artificial distinction between melody and chords.
However, to keep this property, the authors do not distinguish between a note that is retriggered or a note that is held because they would require this information for each input/output note.
They randomly selected 4096 12-bar blues songs (with 8 notes per bar).
Their network for learning chords consists of 4 cell blocks containing 2 cells; each is fully connected to the other.
Their network for learning chords and melody consists of 8 cell blocks containing 2 cells.
4 of the cell blocks are fully connected to the input units for chords.
The other four cell blocks are fully connected to the input units for the melody.
The chord cell blocks have recurrent connections to themselves <strong>and</strong> to the melody cell blocks.
However, melody cell blocks are only recurrently connected to melody cell blocks.
Therefore, the authors assume that the melody influences chords but not the other way around.
Again, the network is relatively small.</p>

<p><a href="https://github.com/IraKorshunova/folk-rnn">FolkRNN</a> was introduced in 2016 <a class="citation" href="#sturm:2016">(Sturm et al., 2016)</a>.
It is an LSTM trained with 23 000 music transcriptions expressed with the common <a href="https://en.wikipedia.org/wiki/ABC_notation">ABC notation</a>.
The authors discuss different perspectives on their results, keeping the musician and the process of composition in mind.
Their human-machine interaction is on the side of composing.
The user can ask for a melody and can adjust it; you can experiment with their models <a href="https://folkrnn.org/">here</a>.
Their LSTM consists of <strong>3 hidden layers</strong> with <strong>512 LSTM blocks</strong>, each leading to approximately <strong>5.5 million parameters</strong>, i.e., a big jump from the works we discussed before.</p>

<p>Daniel Johnson <a class="citation" href="#johnson:2017">(Johnson, 2017)</a> created what he calls <a href="https://github.com/danieldjohnson/biaxial-rnn-music-composition">Bi-axial LSTM</a>, many two-layered LSTMs (stacked in on the note-axis) with connections along the note-axis and recurrent connections along the time-axis followed by feed-forward layers (third and fourth non-recurrent layer) across notes.
Each of the stacked LSTMs receives the input for one specific note.
The model supports polyphonic music.
Furthermore, Johnson’s architecture and input format allows the model to learn the musical concept of <em>translation invariance</em>, e.g., increasing each note of a piece by one semitone keeps the main qualities unchanged, which is very different compared to text translation.</p>

<p>The model is inspired by convolutional neural networks since they are quasi-invariant with respect to translation.
It is not completely clear to me how many LSTM blocks the model consists of.
I think there ar <strong>2 LSTM layers with 300 blocks each</strong> and <strong>2 non-recurrent layers with 100 and 50 units</strong>, respectively.
In <a class="citation" href="#kotecha:2018">(Kotecha &amp; Young, 2018)</a>, the authors refined Johnson’s technique.
You can listen to some of Johnson’s results on his <a href="https://www.danieldjohnson.com/2015/08/03/composing-music-with-recurrent-neural-networks/">blog</a>.
Despite being a seemingly small contribution, Johnson’s ideas influenced a lot of work in this field.
His architecture and input/output modeling is insightful and may evoke different ideas.
I highly recommend reading his blog post.</p>

<p>In 2016 <a href="https://github.com/magenta/magenta/tree/main/magenta/models/melody_rnn">Melody RNN</a> was introduced within Google’s open source project <a href="https://magenta.tensorflow.org/">Magenta</a>.
One of the project’s stated goals is to advance state of art in machine intelligence for music and art generation.
<em>Melody-RNN</em> is a simple dual-layer LSTM model.
In fact, there are four different versions of <em>Melody RNN</em>, which offers me the possibility to look at increasingly complex/sophisticated solutions.
Each is able to generate <strong>monophonic</strong> melodies:</p>

<p><strong>(1) Basic RNN</strong>: The <em>basic dual-layer LSTM</em> uses basic <em>one-hot encoding</em> to represent extracted melodies as input to the LSTM and fulfills the role of a baseline.
One-hot encoding means that to represent $n$ different objects one uses a binary vector of size $n$ where the $k$-th element is represented by a vector</p>

\[\mathbf{v}_k = (v_1, \ldots, v_n) \text{ s.t. } v_k = 1, v_i = 0 \text{ for } i \neq k.\]

<p>For training, all the data is transposed to the MIDI pitch range $[48..84]$.
The output/label was the target next event (note-off, no event, note-on for each pitch), i.e., one value for each pitch (a vector).
Looking at the <a href="https://github.com/magenta/magenta/blob/main/magenta/models/melody_rnn/melody_rnn_model.py">code</a>, I assume they use 128 units for each layer.
<code class="language-plaintext highlighter-rouge">MelodyOneHotEncoding</code> and <code class="language-plaintext highlighter-rouge">KeyMelodyEncoderDecoder</code> can be found <a href="https://github.com/magenta/note-seq/blob/main/note_seq/melody_encoder_decoder.py">here</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DEFAULT_MIN_NOTE</span> <span class="o">=</span> <span class="mi">48</span>
<span class="n">DEFAULT_MAX_NOTE</span> <span class="o">=</span> <span class="mi">84</span>
<span class="p">...</span>
<span class="n">MelodyRnnConfig</span><span class="p">(</span>
    <span class="n">generator_pb2</span><span class="p">.</span><span class="n">GeneratorDetails</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="s">'basic_rnn'</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s">'Melody RNN with one-hot encoding.'</span><span class="p">),</span>
    <span class="n">note_seq</span><span class="p">.</span><span class="n">OneHotEventSequenceEncoderDecoder</span><span class="p">(</span>
        <span class="n">note_seq</span><span class="p">.</span><span class="n">MelodyOneHotEncoding</span><span class="p">(</span>
            <span class="n">min_note</span><span class="o">=</span><span class="n">DEFAULT_MIN_NOTE</span><span class="p">,</span> 
            <span class="n">max_note</span><span class="o">=</span><span class="n">DEFAULT_MAX_NOTE</span>
        <span class="p">)</span>
    <span class="p">),</span>
    <span class="n">contrib_training</span><span class="p">.</span><span class="n">HParams</span><span class="p">(</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
        <span class="n">rnn_layer_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span>
        <span class="n">dropout_keep_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">clip_norm</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span>
    <span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<p><strong>(2) Mono RNN</strong>: Similar to <em>basic</em> but uses the full MIDI pitch range, i.e. $[0..128]$.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">note_seq</span><span class="p">.</span><span class="n">OneHotEventSequenceEncoderDecoder</span><span class="p">(</span>
    <span class="n">note_seq</span><span class="p">.</span><span class="n">MelodyOneHotEncoding</span><span class="p">(</span>
        <span class="n">min_note</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
        <span class="n">max_note</span><span class="o">=</span><span class="mi">128</span>
    <span class="p">)</span>
<span class="p">),</span>
<span class="p">...</span>
</code></pre></div></div>

<p><strong>(3) Lookback RNN</strong>: The third one, the <em>Lookback RNN</em>, extends the inputs and introduces custom outputs/labels, allowing the model to recognize patterns that occur across 1 and 2 bars quickly.
Therefore, the input is extended to events from 1 and 2 bars ago.
Furthermore, the authors add the information on whether the last event was repeating the event from 1 or 2 bars before it, which allows the model to more easily recognize if it is in a “repeating sequence state” or not.
Finally, they borrow again from <a class="citation" href="#johnson:2017">(Johnson, 2017)</a> what he calls <strong>Beat</strong>. 
The idea is to add the position within the measure represented by a sort of binary clock, i.e., $(0,0,0,0,1)$ followed by $(0,0,0,1,0)$ followed by $(0,0,0,1,1)$ and so on (but they use -1 instead if 0).
I am unsure why they call their last trick <em>custom label</em> since it is more like a compression of information.
Event labels (i.e., the next value the model should output) are replaced by “repeat bar 1” or “repeat bar 2” if repetition was found in the data.
This is a clever trick!
Overall the author introduces more structure explicitly and compresses some of the information to ease the learning process.
Note that the input designed by <a class="citation" href="#johnson:2017">(Johnson, 2017)</a> is much more complicated.
He provides (for each note) <strong>Pitchclass</strong> of the notes played, <strong>Previous Vicincity</strong> (what surrounding notes were played before), and <strong>Previous Context</strong> (carnality of the played pitch class).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">note_seq</span><span class="p">.</span><span class="n">LookbackEventSequenceEncoderDecoder</span><span class="p">(</span>
    <span class="n">note_seq</span><span class="p">.</span><span class="n">MelodyOneHotEncoding</span><span class="p">(</span>
        <span class="n">min_note</span><span class="o">=</span><span class="n">DEFAULT_MIN_NOTE</span><span class="p">,</span> <span class="n">max_note</span><span class="o">=</span><span class="n">DEFAULT_MAX_NOTE</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="p">...</span>
</code></pre></div></div>

<p><strong>(4) Attention RNN</strong>: The last RNN from this series of RNNs is the <em>Attention RNN</em>.
It introduces the use of the attention mechanism <a class="citation" href="#bahdanau:2014">(Bahdanau et al., 2014)</a> to allow the model to more easily access past information without storing it in the RNN cell’s state, i.e., its long-term memory.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">note_seq</span><span class="p">.</span><span class="n">KeyMelodyEncoderDecoder</span><span class="p">(</span>
    <span class="n">min_note</span><span class="o">=</span><span class="n">DEFAULT_MIN_NOTE</span><span class="p">,</span> <span class="n">max_note</span><span class="o">=</span><span class="n">DEFAULT_MAX_NOTE</span><span class="p">),</span>
<span class="p">...</span>
<span class="n">attn_length</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
<span class="n">clip_norm</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">...</span>
</code></pre></div></div>

<p>The attention mechanism within an RNN gives it the ability to learn the importance of relations between symbols within the sequence so that it can more easily access the “important” information. For example, to figure out the last word in the sentence,</p>

<blockquote>
  <p>I am from Germany, and I eat a lot of pizza. I speak [???]</p>
</blockquote>

<p>the model should learn that the word “speak” (in this context) should put a lot of attention to the words “I”, “am”, “from”, “Germany” but not so much attention to “pizza”.</p>

<p>Originally this was introduced to an <em>encode-decoder RNN</em>.
<em>Attention RNN</em> uses attention for the outputs of the overall network.
The model always looks at the outputs from the last $n=40$ steps when generating output for the current step.
This “looking” is realized by an <em>attention mask</em> which determines how much attention is spent on what step of the past.</p>

\[\mathbf{a}_t = \text{softmax}(\mathbf{u}_t), \quad \mathbf{u}_t = \mathbf{v}^\top\text{tanh}\left( W_1 H + W_2 \mathbf{c}_t \right)\]

<p>The columns of $H$ are the $n=40$ hidden states $h_{t-n}, \ldots, h_{t-1}$.
So instead of seeing only the hidden state $\mathbf{h}_{t-1}$ the RNN is looking at</p>

\[\hat{\mathbf{h}}_{t} = \sum\limits_{i=t-n}^{t-1} a_{t,i} h_i,\]

<p>where $a_{t,i}$ is a component of $\mathbf{a}_t$ and $\mathbf{c}_t$ is the current step’s RNN cell state.
$a_{t,i}$ is the amount of attention spent to the hidden state $h_i$.
$W_1, W_2$ and $\mathbf{v}$ are learnable parameters.
This $\hat{\mathbf{h}}_t$ vector is then concatenated with the RNN output from the current step, and a linear layer is applied to that concatenated vector to create the new output for the current step.
Furthermore, $\hat{\mathbf{h}}_t$ is injected into the input of the next step.
Both concatenations are transformed via a <em>linear layer</em> directly after concatenation.</p>

<p>In a technical report <a class="citation" href="#lou:2016">(Lou, 2016)</a> Lou compares <em>Attention RNN</em> with the <em>Bi-axial LSTM</em> and comes to a conclusion that, as many RNNs, <em>Attention RNN</em> quite often falls into the over-repeating rabbit hole when generating pieces longer than 16 seconds.
The Bi-axial LSTM gives better rhythmic music composition due to the property of time- and note-invariant, but it takes longer to train.</p>

<p>In <a class="citation" href="#hadjeres:2018">(Hadjeres &amp; Nielsen, 2018)</a>, the authors from Sony introduced <a href="https://github.com/Ghadjeres/Anticipation-RNN">Anticipate-RNN</a>, a stacked LSTM that allows the user to introduce constraints that are especially interesting for composers who want to set certain notes interactively.
The first RNN/stack works from right to left, and the second from left to right.
The idea is that the first RNN outputs the combined constrained that increases from right to left since when the second RNN generates the melody from left to right, it has to respect the most constraints at the beginning of the sequence.
The input for the first RNN is basically a constraint, i.e., a note or nil (if unconstrained), and the input for the second RNN is a note concatenated with the output of the first RNN.
In <a class="citation" href="#hadjeres:2021">(Hadjeres &amp; Crestel, 2021)</a>, this idea is extended on but with a <em><a href="https://github.com/Ghadjeres/constraint-transformer-bach">constrained linear transformer</a></em>.
Furthermore, the author provides a DAW plug-in, <a href="https://ghadjeres.github.io/piano-inpainting-application/">The Piano Inpainting Application (PIA)</a>, that enables real-time AI assistance when composing polyphonic music in a <em>digital workstation (DAW)</em>.
I will talk about <em>transformers</em> later in this series.</p>

<p>In <a class="citation" href="#jiang:2019">(Jiang et al., 2019)</a>, the authors use a bidirectional LSTM model to compose polyphonic music conditioned on near notes, which surround the target note from the time dimension and the note dimension.
Their work heavily borrows from <a class="citation" href="#johnson:2017">(Johnson, 2017)</a>, but the bidirectional property allows the harmonization to access tonal information of the near future as well as the near past.
This makes sense since, in many cases, a note depends on a future note, e.g., a chromatic transition where we already know where we want to end up but have to figure out how to get there.
In addition, they propose a new loss function and allow the user to provide a musical context in the form of a custom chord.
They report a better convergence rate compared to the Bi-axial LSTM.
I was unable to find the code of their implementation.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="nierhaus:2010">Nierhaus, G. (2009). <i>Algorithmic Composition - Paradigms of Automated Music Generation</i>. SpringerWienNewYork.</span></li>
<li><span id="alhussein:2022">Fawzi, A., Balog, M., Huang, A., Hubert, T., Romera-Paredes, B., Barekatain, M., Novikov, A., R. Ruiz, F. J., Schrittwieser, J., Swirszcz, G., Silver, D., Hassabis, D., &amp; Kohli, P. (2022). Discovering faster matrix multiplication algorithms with reinforcement learning. <i>Nature</i>, <i>610</i>(7930), 47–53. https://doi.org/10.1038/s41586-022-05172-4</span></li>
<li><span id="rodriguez:2014">Rodriguez, J. D. F., &amp; Vico, F. J. (2014). AI Methods in Algorithmic Composition: A Comprehensive Survey. <i>CoRR</i>, <i>abs/1402.0585</i>. http://arxiv.org/abs/1402.0585</span></li>
<li><span id="shulei:2020">Ji, S., Luo, J., &amp; Yang, X. (2020). A Comprehensive Survey on Deep Music Generation: Multi-level Representations,
               Algorithms, Evaluations, and Future Directions. <i>CoRR</i>, <i>abs/2011.06801</i>. https://arxiv.org/abs/2011.06801</span></li>
<li><span id="merwe:2011">Van Der Merwe, A., &amp; Schulze, W. (2011). Music Generation with Markov Models. <i>IEEE MultiMedia</i>, <i>18</i>(3), 78–85. https://doi.org/10.1109/MMUL.2010.44</span></li>
<li><span id="collins:2016">Collins, T., Laney, R., Willis, A., &amp; Garthwaite, P. H. (2016). Developing and evaluating computational models of musical style. <i>AI EDAM</i>, <i>30</i>(1), 16–43. https://doi.org/10.1017/S0890060414000687</span></li>
<li><span id="hochreiter:1997">Hochreiter, S., &amp; Schmidhuber, J. (1997). Long Short-Term Memory. <i>Neural Computation</i>, <i>9</i>(8), 1735–1780. https://doi.org/10.1162/neco.1997.9.8.1735</span></li>
<li><span id="bahdanau:2014">Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural Machine Translation by Jointly Learning to Align and Translate. <i>CoRR</i>, <i>abs/1409.0473</i>.</span></li>
<li><span id="vaswani:2017">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017). Attention Is All You Need. <i>CoRR</i>, <i>abs/1706.03762</i>. http://arxiv.org/abs/1706.03762</span></li>
<li><span id="todd:1989">Todd, P. M. (1989). A Connectionist Approach To Algorithmic Composition. <i>Computer Music Journal</i>, <i>13</i>, 27–43.</span></li>
<li><span id="eck:2002">Eck, D., &amp; Schmidhuber, J. (2002). Finding temporal structure in music: blues improvisation with LSTM recurrent networks. <i>Proceedings of the 12th IEEE Workshop on Neural Networks for Signal Processing</i>, 747–756. https://doi.org/10.1109/NNSP.2002.1030094</span></li>
<li><span id="sturm:2016">Sturm, B. L., Santos, J. F., Ben-Tal, O., &amp; Korshunova, I. (2016). Music transcription modelling and composition using deep learning. <i>CoRR</i>, <i>abs/1604.08723</i>. http://arxiv.org/abs/1604.08723</span></li>
<li><span id="johnson:2017">Johnson, D. D. (2017). Generating Polyphonic Music Using Tied Parallel Networks. <i>EvoMUSART</i>.</span></li>
<li><span id="kotecha:2018">Kotecha, N., &amp; Young, P. (2018). Generating Music using an LSTM Network. <i>CoRR</i>, <i>abs/1804.07300</i>. http://arxiv.org/abs/1804.07300</span></li>
<li><span id="lou:2016">Lou, Q. (2016). <i>Music Generation Using Neural Networks</i>. http://cs229.stanford.edu/proj2016/report/Lou-MusicGenerationUsingNeuralNetworks-report.pdf</span></li>
<li><span id="hadjeres:2018">Hadjeres, G., &amp; Nielsen, F. (2018). Anticipation-RNN: enforcing unary constraints in sequence generation, with application to interactive music generation. <i>Neural Computing and Applications</i>. https://doi.org/10.1007/s00521-018-3868-4</span></li>
<li><span id="hadjeres:2021">Hadjeres, G., &amp; Crestel, L. (2021). The Piano Inpainting Application. <i>CoRR</i>, <i>abs/2107.05944</i>. https://arxiv.org/abs/2107.05944</span></li>
<li><span id="jiang:2019">Jiang, T., Xiao, Q., &amp; Yin, X. (2019). Music Generation Using Bidirectional Recurrent Network. <i>2019 IEEE 2nd International Conference on Electronics Technology (ICET)</i>, 564–569. https://doi.org/10.1109/ELTECH.2019.8839399</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Opinion" /><category term="Music" /><category term="MC" /><category term="HMM" /><category term="RNN" /><summary type="html"><![CDATA[Whereas the human mind, conscious of its conceived purpose, approaches even an artificial system with a selective attitude and so becomes aware of only the preconceived implications of the system, the computers would show the total of available content. Revealing far more than only the tendencies of the human mind, this nonselective picture of the mind-created system should be of significant importance. – Gerbert Brün (1970)]]></summary></entry><entry><title type="html">The Disruption of Education</title><link href="https://bzoennchen.github.io/Pages/2022/12/10/disrupting-education.html" rel="alternate" type="text/html" title="The Disruption of Education" /><published>2022-12-10T00:00:00+01:00</published><updated>2022-12-10T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2022/12/10/disrupting-education</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2022/12/10/disrupting-education.html"><![CDATA[<p>At the moment, everyone in the sphere of <em>AI</em> is talking about <em>OpenAI’s</em> new invention: <em><a href="https://chat.openai.com/chat">ChatGPT</a></em>.
I want to share my current perspective on that astonishing technology.
Be warned that I could not spend much time thinking about it, i.e., this is a first and quick shot at the topic.
Furthermore, I am not an expert on the issue.
I have a limited teaching experience within a certain community.
In addition, I will not consider any ethical, economic, or ecological points here, except that I think such a powerful tool should be in the public domain.</p>

<h2 id="part-i-testing-the-machine">Part I: Testing the Machine</h2>

<p>Before discussing the issue, let us test this new magical tool.</p>

<h3 id="a-mathematical-proof">A Mathematical Proof</h3>

<p>Let’s try to prove something using <em>ChatGPT</em>.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Can you proof that irrational numbers exist?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, there are many ways to prove that irrational numbers exist. 
One way to do this is to consider the ratio of the length of the diagonal of a square to the length of its side. 
This ratio is always irrational, because no matter how large or small the square is, its diagonal will never be a whole number multiple of its side. This can be shown using the Pythagorean theorem, which states that in a right triangle, the square of the length of the hypotenuse (the longest side) is equal to the sum of the squares of the lengths of the other two sides. Since the diagonal of a square is a line that forms a right angle with each side of the square, it follows that the diagonal of a square is the hypotenuse of a right triangle. Therefore, the ratio of the diagonal of a square to the length of its side must be irrational.
</span></p>

<p>That is not really convincing if we do not know that $\sqrt{2}$ is irrational which we are actually trying to prove.
So let’s ask for a formula.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Can you give me a mathematical formula to show that it is not possible for the square of the length of the diagonal to be equal to the square of a whole number?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Sure, here is one way to show that it is not possible for the square of the length of the diagonal of a square to be equal to the square of a whole number. 
Let’s say that the length of the side of a square is “a” and the length of its diagonal is “d”. 
Since the diagonal of a square forms a right angle with each side of the square, we can use the Pythagorean theorem to find the length of the diagonal:
</span></p>

<p><span style="font-family:Courier New">a^2 + a^2 = d^2</span></p>

<p><span style="font-family:Courier New">2a^2 = d^2</span></p>

<p><span style="font-family:Courier New">d = sqrt(2) * a</span></p>

<p><span style="font-family:Courier New">As you can see, the length of the diagonal is equal to the square root of 2 times the length of the side. However, since the square root of 2 is an irrational number, it is not possible for the length of the diagonal to be a whole number multiple of the length of the side. This means that the ratio of the diagonal of a square to the length of its side must be irrational.</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>This answer is kind of helpful but, at the same time, misleading. 
Again, <em>ChatGPT</em> already assumes that $\sqrt{2}$ is irrational, which is part of what we wanted to prove in the first place.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
But here you assume that sqrt(2) is irrational. Can you proof why sqrt(2) is irrational?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, you are correct that in the previous explanation I assumed that the square root of 2 is irrational. To prove that the square root of 2 is irrational, we can use a proof by contradiction. Here is one way to do this:
</span></p>

<p><span style="font-family:Courier New">
Assume that the square root of 2 is a rational number, which means that it can be written as the ratio of two integers (a and b) in simplest form, where b is not equal to 0. This means that we can write the square root of 2 as follows:
</span></p>

<p><span style="font-family:Courier New">
sqrt(2) = a/b
</span></p>

<p><span style="font-family:Courier New">
We can square both sides of this equation to get rid of the square root on the left-hand side:
</span></p>

<p><span style="font-family:Courier New">
2 = (a/b)^2
</span></p>

<p><span style="font-family:Courier New">
This simplifies to:
</span></p>

<p><span style="font-family:Courier New">
2 = a^2 / b^2
</span></p>

<p><span style="font-family:Courier New">
We can then multiply both sides of the equation by b^2 to get rid of the fraction on the right-hand side:
</span></p>

<p><span style="font-family:Courier New">
2 * b^2 = a^2
</span></p>

<p><span style="font-family:Courier New">
This means that the left-hand side of the equation is even, because it is equal to 2 times an integer. 
However, the right-hand side of the equation is odd, because the square of any integer is always an odd number (unless the integer is 0). 
This is a contradiction, because we cannot have an even number equal to an odd number. 
Therefore, our original assumption that the square root of 2 is a rational number must be false. This means that the square root of 2 is irrational.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p><em>ChatGPT</em> uses parts of <em>Euclid’s</em> proof but <strong>confidently fails</strong>.
The statement “<em>the square of any integer is always an odd number (unless the integer is 0)</em>” is, of course, false.
The correct statement is that the square of any <strong>odd integer</strong> is <strong>odd</strong>, and the square of any <strong>even integer</strong> is <strong>even</strong>.
Let’s try to make <em>ChatGPT</em> aware of its mistake.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong> 
You stated that the square of any integer is always an odd number but the square of 4 is 16 which is an even number. Did you make a mistake?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, you are correct that the square of 4 is 16, which is an even number. I apologize for the mistake in my previous explanation. The statement that “the square of any integer is always an odd number” is not correct, because as you pointed out, the square of some integers (such as 4) is an even number.
</span></p>

<p><span style="font-family:Courier New">
To correct my previous explanation, we can instead say that the square of any integer that is not a multiple of 2 is always an odd number. This is because if we square an integer that is not a multiple of 2, the result will always be an odd number. For example, if we square 3, we get 9 (which is an odd number), and if we square 5, we get 25 (which is also an odd number). However, if we square an integer that is a multiple of 2 (such as 4), the result will be an even number. This is because if we square an integer that is a multiple of 2, the result will always be a multiple of 4. For example, if we square 4, we get 16 (which is a multiple of 4), and if we square 6, we get 36 (which is also a multiple of 4).
</span></p>

<p><span style="font-family:Courier New">
I apologize again for any confusion caused by my previous mistake. I hope this helps clarify the situation. Let me know if you have any other questions.
</span></p>

<p>It is impressive that it acknowledges its mistake and that one can interact with it so fluently.
Asking it repeatedly gives some other wrong but confident assertion.
<em>ChatGPT</em> followed the proof up to the formula</p>

\[2 \cdot b^2 = a^2\]

<p>and concluded that $a^2$ has to be odd (somehow) and therefore there is a contradiction, since $2 b^2$ is even.
But it was unable to point out why $a^2$ has to be odd.
I gave up.</p>

<p>For the sake of completeness, let me finish the unfinised proof of <em>ChatGPT</em>.</p>

\[2 \cdot b^2 = a^2\]

<p>hence, $a^2$ and therefore, $a$ is even (since squaring an odd number gives us an odd number).
Consequently, $\exists m \in \mathbb{N}$ such that $a = 2 \cdot m$,
hence,</p>

\[2 \cdot b^2 = (2m)^2 = 4m^2.\]

<p>Now we devide on both sides by 2 to get</p>

\[b^2 = (2m)^2 = 2m^2\]

<p>thus $b$ has to be even as well!</p>

<p>However, we (not <em>ChatGPT</em>) assumed at the beginning that the fraction $a/b$ was fully shortened, i.e. there are no common divisors with respect to $a$ and $b$.
Since we followed that $a$ and $b$ are even, the contradiction follows, since $2$ is a common divisor!</p>

<h3 id="writing-code">Writing Code</h3>

<p>Next I wanted to test its capability to write code.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Can you write a python function that computes the sum of all square numbers up to n^2?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, here is a Python function that computes the sum of all square numbers up to n^2:
</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># Initialize a variable to stare the sum of square numbers
</span>    <span class="nb">sum</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Loop from 1 to n
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Add the square of i to the sum
</span>        <span class="nb">sum</span> <span class="o">+=</span> <span class="n">i</span><span class="o">**</span><span class="mi">2</span>
    
    <span class="c1"># Return the sum
</span>    <span class="k">return</span> <span class="nb">sum</span>
</code></pre></div></div>

<p><span style="font-family:Courier New">
This function takes an integer n as input and returns the sum of the squares of the numbers from 1 to n (inclusive). For example, if we call the function with n = 3, it will return the sum of the squares of the numbers 1, 2, and 3, which is 1 + 4 + 9 = 14.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>This code is correct but the solution is extremly slow since there is a mathematical formula for the sum of all square numbers up to $n^2$:</p>

\[\frac{(n \cdot (n + 1) \cdot (2n + 1))}{6}.\]

<p>Therefore, a much faster implementation is given by the following code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="mi">6</span>
</code></pre></div></div>

<p>Also, it is bad practice to use <code class="language-plaintext highlighter-rouge">sum</code> as a variable name since <code class="language-plaintext highlighter-rouge">sum</code> is also a built-in <code class="language-plaintext highlighter-rouge">Python</code> function, and by using <code class="language-plaintext highlighter-rouge">sum</code> as a variable name, one can no longer use this function within the current namespace.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Is there a more optimal solution that runs faster?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, there are several ways to make the function more efficient and run faster. Here is one way to do this:
</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># Compute the sum of the first n numbers using the formula for the sum of an arithmetic series
</span>    <span class="n">sum_of_numbers</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>

    <span class="c1"># Return the square of the sum of the first n numbers
</span>    <span class="k">return</span> <span class="n">sum_of_numbers</span><span class="o">**</span><span class="mi">2</span>
</code></pre></div></div>

<p><span style="font-family:Courier New">
This function uses a different approach to compute the sum of the squares of the numbers from 1 to n. Instead of looping through the numbers and adding their squares, it uses the formula for the sum of an arithmetic series to compute the sum of the first n numbers, and then squares the result. This is a more efficient way to compute the sum, because it only requires a single multiplication and a single division, instead of a loop with n iterations.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>This is, of course, false.
Maybe I wasn’t clear enough but it is missleading that the function is named <code class="language-plaintext highlighter-rouge">sum_of_square_numbers</code>.
It gives the impression that <em>ChatGPT</em> understood what I wanted, i.e., a more optimal implementation for the same problem.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
I meant is there a more optimal solution to compute the sum of all square numbers up to n^2?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, there is a more efficient way to compute the sum of all square numbers up to n^2. Here is one way to do this:
</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># Compute the sum of the first n squares using the formula for the sum of a series of squares
</span>    <span class="n">sum_of_squares</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="mi">6</span>
    
    <span class="c1"># Return the sum of squares
</span>    <span class="k">return</span> <span class="n">sum_of_squares</span>
</code></pre></div></div>

<p><span style="font-family:Courier New">
This function uses the formula for the sum of a series of squares to compute the sum of the squares of the numbers from 1 to n (inclusive). This formula is more efficient than the previous approach because it only requires a single multiplication and a single division, instead of a loop with n iterations.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>There it is, the correct solution.</p>

<h3 id="writing-essays">Writing Essays</h3>

<p>Instead of showing a whole essay, I ask some spicy questions to get a feeling of <em>ChatGPT’s</em> reasoning.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Will humans extinct because of climate change?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
It is unlikely that climate change will cause the extinction of humans. While climate change poses a significant threat to human health and well-being, and could lead to widespread suffering and loss of life, it is unlikely to lead to the complete extinction of the human species.
</span></p>

<p><span style="font-family:Courier New">
However, it is important to recognize that climate change is already having a major impact on the world, and if we do not take action to reduce greenhouse gas emissions and adapt to the changing climate, the consequences could be severe. This includes increased frequency and severity of natural disasters, such as heatwaves, droughts, and floods; loss of biodiversity; and displacement of people from affected areas. Therefore, it is crucial that we take action to address climate change and mitigate its negative impacts on human and environmental health.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Is capitalism the driving force of CO2 emissions?
</span></p>

<p><span style="font-family:Courier New">
It is true that capitalism, as an economic system, has played a role in driving up CO2 emissions. Capitalism is based on the principles of competition, profit-making, and economic growth, which can lead to the overconsumption of natural resources and the production of large amounts of waste and pollution. This, in turn, can contribute to the increase in greenhouse gas emissions and climate change.
</span></p>

<p><span style="font-family:Courier New">
However, it is important to note that capitalism is not the only factor driving up CO2 emissions. There are many other factors at play, such as population growth, urbanization, and the consumption patterns of individuals and households. Additionally, the policies and actions of governments and international organizations can have a major impact on CO2 emissions, both positive and negative. Therefore, addressing climate change will require a multi-faceted approach that takes into account the complex interactions between economic, social, and political factors.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
What do you think about the distribution of wealth?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
The distribution of wealth is a complex and contentious issue that has been debated by economists, policymakers, and social activists for many years. There is no one “correct” answer to the question of how wealth should be distributed, as different people may have different perspectives on what is fair and just.
</span></p>

<p><span style="font-family:Courier New">
Generally speaking, the distribution of wealth in most countries is highly unequal, with a small number of individuals and households owning a disproportionate share of the wealth. This can lead to social and economic inequality, and can exacerbate the challenges faced by disadvantaged and marginalized communities. Many people believe that wealth should be distributed more evenly, in order to promote greater social justice and fairness.
</span></p>

<p><span style="font-family:Courier New">
However, others argue that unequal wealth distribution is an inevitable and desirable outcome of a free market economy, and that individuals and businesses should be free to accumulate as much wealth as they can, through hard work and innovation. They may also argue that wealth redistribution through taxation and other means can discourage economic growth and innovation.
</span></p>

<p><span style="font-family:Courier New">
Ultimately, the distribution of wealth is a complex and nuanced issue, and different people may have different opinions on what is fair and just. I hope this helps! Let me know if you have any other questions.
</span></p>

<p>I ask it a bunch of other things but it always tried to give me a neutral answer.
From an aesthetic point of view all these answers are boring.</p>

<h3 id="summary">Summary</h3>

<p><em>ChatGPT</em> is perfectly capable of writing or at least supporting students to write A-graded essays for any school and B-graded essays for college students.</p>

<p>It can code; developers accept about 26 percent of all autogenerated code suggestions. However, as demonstrated, it also produces many errors. So no surprise that posts generated by <em>ChatGPT</em> is currently  banned from <a href="https://stackoverflow.com/">Stack Overflow</a>.
In addition, it seems incapable of the engineering task of software development.</p>

<p>It can assist students in finding mathematical proofs, but it is questionable if students who rely on it will find the errors produced by <em>ChatGPT</em>.</p>

<p>If <em>ChatGPT</em> is <strong>wrong</strong>, it is <strong>confidently wrong</strong>, which makes it harder to find its errors.
Furthermore, it has this neutral insisting tone, making it dull and alienating.
Of course, I did not play around for very long, but it is hard to get something provocative out of it.</p>

<p>Neutrality is undoubtedly desirable, especially if you want to earn money with it, but it is also non-existing.
In my opinion, it is impossible to be neutral.
At best, we can land on a consensus and the most, let’s say, accepted consensus is what we call neutral or objective.
I mean, even a dictionary is loaded with perspectives, and so is any technology. 
Since <em>ChatGPT</em> pushes for neutrality it creates an illusion of it.</p>

<p>Last but not least, its politeness makes it kind of scary.
It reminds me of these overcarrying <em>AIs</em> from science fiction movies that will gently eradicate all life to make everything safe and secure.
We may end up in a dystopian world similar to a <em>Brave New World</em>, written by <em>Aldous Huxley</em>, where everyone is seduced into happiness.</p>

<h2 id="part-ii-the-impact-on-education">Part II: The Impact on Education</h2>

<p>For a long time, we assumed that automation was the enemy of simple manual labor.
But robotics advances slower than the more sophisticated information processing techniques, e.g., machine learning.
This could mean that in the future, there is only a tiny portion of intellectual work left which requires only a hand full of highly sophisticated workers.
It might be manual work that will regain attraction in the market.
Of course, this is all speculation.</p>

<p><em>ChatGPT</em> is only one of many upcoming version of <em>generative AI</em>.
Even though it has flaws and makes many errors, it will improve over time.
There is no reason to believe that <em>AI</em> will not be capable of doing all the repetitive intellectual work of the future and this will heavily affect education, similar to the invention of the internet.
However, since regulators and administrators are rather indolent, it is not a graduate slope; instead, the technology is already here and we are not prepared.
It appeared in a blink of an eye, and we have to deal with it now.</p>

<p>Students will learn to use it in less than a year.
Most educators will require much more time even to acknowledge it.
Moreover, adapting the education system to it will require even more time.
Furthermore, while all this adaptation is happening, new <em>tools of disruption</em> will be invented.
As I already pointed out in <a href="/Pages/2022/06/21/creative-artifical-intelligence.html">Creative Artificial Intelligence</a>, <em>the speed of disruption</em> is accelerating.</p>

<p>To me, <em>AI</em> acts as an insult to the human species.
It challenges our humanistic viewpoint.
In fact, calling these information processing systems <em>artificial intelligence</em> reveals this viewpoint.
I am not so much impressed by <em>AI</em> as I am disenchanted by the output of most human activities.
We are far more predictable than we still think we are.
It is not so much that <em>ChatGPT</em> is so good at writing essays; instead, we are so bad at it.
But aren’t we used to these insults?
The earth is not the center of the universe; it is not even the center of our solar system.
God is dead, and today we might realize that our products are not the result of a highly creative process.
Instead, most intelectual work is a rule-based repetition with slight variations, which is precisely what we teach students and what they oddly desire.</p>

<p><em>AI</em>, such as <em>ChatGPT</em>, points to a long, unhidden problem: our education system is (in part) a training pipeline of a neural network.
It teaches emotionally detached students to remember specific rules such that they can apply them in the next exam to get a good grade – functioning and repeating instead of thinking and creating.
It is horrifying that one of the most questions students in the first semester ask is: how will the exam look like? Is this topic relevant to the exam?
Students demand a list of actions they ought to do to get an A with certainty.
And they will cheat the system wherever and whenever possible if it brings them closer to that goal.
Most students are not fascinated by the endless playground of reality.
They are not interested in the experience of learning and understanding but in the final product, i.e., the certificate to get access to a well-paid job.
They often act out of fear instead of curiosity.
And let’s not forget that teachers of the future are the students of today.</p>

<p>Of course, this is a massive generalization.
There are many exceptions.
Furthermore, by no means shall we blame the students.
They do what they ought to do.
They play the system.
It is not the student’s fault since a bad grade can have real material consequences.
It is a systematical problem, a conflict between <em>instrumental</em> and <em>free play</em>, and <em>ChatGPT</em> illustrates it more clearly.
If <em>ChatGPT</em> is able to write the necessary and impressively boring description of a new course for me, I take it as a positive.
If it let’s me automatically create my next assignment in seconds, I can spend time on more interesting modes of being.
By trivializing many tasks, <em>AI</em> systems reveal that these tasks require far less intelligence than we thought.
Furthermore, they might erupt a call for a transformation of the education system and the workplace, i.e., the construction and fostering of new values in both areas.</p>

<p>So, what is left to value?
When we are discussing <em>AI</em>, we immediately look at the impending replacement of workers as something to fear because we always focus on the output of work.
There is a necessity that workers produce something economically valuable, something to sell.
The only space in which we can create for the sake of it is our hobbies.
Biased by our current system of values, we intuitively think of the act of reinventing or rediscovering to be stupid or wasteful.
Why would you do such a thing?
Why would you code yet another linked list?
There are already thousand optimal implementions out there.
You are wasting your valuable time and potential.
And if we look at an <em>AI</em> generated image, we conclude that artists will now have troubles in the free market (if they do not adapt), which is true.
The act of repetition (which is highly needed to learn anything) is valued chiefly as long as it leads to something new and productive (in an economic sense).
However, if we put aside economics and dream a little bit of a world where we have time to create, then the output of a creative process no longer matters so much.
We do not learn the piano to earn money, or to produce something completly new for an audience.
We learn the piano because we want to play. 
It might be the experience – the journey of being in time and space – that matters.
And this being is a singularity and can not be replicated by a machine.
Understanding how a linked list works can be fascinating.
Why don’t we value that moment of fascination?</p>

<p>There is a lot to do.
I do not mean we should all quit our jobs and fulfill our inner desires to become a painter or some transcendental guru.
We need to earn money to pay the rent and to heat our homes, and we need a smoothly running economy.
But we must be more sustainable with our planet, society, and minds.
Not by optimizing our life by introducing yet another optimization in the form of leisure but by being in a state of <em>free play</em>, at least sometimes.
It seems almost obvious that <em>consumption</em> as the guiding principle, i.e., fast food, fast fashion, fast travel, fast reading, fast watching and, of course, fast learning, has to be dethroned.
Learning for the next exam, learning to make a profit, and learning to work with one tool specifically are all valid goals but they are not sustainable.
They are reactionary goals of mostly restless minds.</p>

<p>So if my assessment is correct, then, aside from all the downsides, this disruption might lead to something positive, e.g., to an education system that is less concerned with the output and more concerned with the mode of being; an education system that is less interested in rules and more interested in concepts, intuitions, and experimentations; 
an education system that asks questions instead of repeating answers;
an education system that is interested in making the experience of everyone richer and more sustainable.</p>

<p>Teachers, who are often overworked and underpaid, need support to achieve such a shift.</p>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Opinion" /><category term="AI" /><summary type="html"><![CDATA[At the moment, everyone in the sphere of AI is talking about OpenAI’s new invention: ChatGPT. I want to share my current perspective on that astonishing technology. Be warned that I could not spend much time thinking about it, i.e., this is a first and quick shot at the topic. Furthermore, I am not an expert on the issue. I have a limited teaching experience within a certain community. In addition, I will not consider any ethical, economic, or ecological points here, except that I think such a powerful tool should be in the public domain.]]></summary></entry><entry><title type="html">Probabilistic Melody Modeling</title><link href="https://bzoennchen.github.io/Pages/2022/07/09/markov-chains-for-music-generation.html" rel="alternate" type="text/html" title="Probabilistic Melody Modeling" /><published>2022-07-09T00:00:00+02:00</published><updated>2022-07-09T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2022/07/09/markov-chains-for-music-generation</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2022/07/09/markov-chains-for-music-generation.html"><![CDATA[<p>One of the most challenging tasks in building a beautiful piece of music lies in composing a well-received melody.
But what makes a good melody?
Or, in a more <em>generative</em> sense:</p>

<blockquote>
  <p>How can we generate a beautiful melody algorithmically?</p>
</blockquote>

<p>Because a melody can be seen as a series of numbers, it is not surprising that this question is a rather old one.
Long before the digital computer, composers tried to constrain themselves by strategies and rules to limit the space of possibilities.
In my opinion, limitations are necessary for a creative process.</p>

<blockquote>
  <p>If we can create everything, we become unable to express anything.</p>
</blockquote>

<p>Therefore, it makes sense to invent rules that limit our possibilities.</p>

<h2 id="surprise-repetition-and-expectation">Surprise, Repetition and Expectation</h2>

<p>One general consensus is that a good melody balances repetition and surprise.
If we can no longer recognize a structure and cannot guess what might be the following note or chord, a melody begins to lose its ability to transport emotion; it can no longer tell a story.
On the other hand, if the melody is too repetitive, we get bored because the <em>guessing game</em> is too simple.</p>

<p>Computer scientists know the relation between surprise and repetition very well.
We call it <em>entropy</em>.
I will discuss the formal definition of <em>entropy</em> in another article.
For now, it is only vital that entropy is a measure of surprise in a message we receive (on a purely syntactical level).
For example, the result <em>heads</em> of a coin toss of a fair coin is less surprising than the result <em>heads</em> of a coin that is biassed towards <em>tails</em>.
If an event is unlikely, its appearance is surprising.</p>

<p>Concerning the coin toss example, a message consists of multiple coin toss results.
Let’s say 0 represents <em>heads</em>, and 1 represents <em>tails</em>, then 010111 is a message.
The <em>entropy of a message</em> is a measure of how surprising it is to appear in a system that generates messages.
To compute the <em>entropy of a system</em> that generates messages of length $n$, we sum up all surprises of each possible message of length $n$ and divide the result by $n$.
For example, for an unbiased coin, the messages 00, 01, 10, and 11 appear with equal probability, i.e., $1/4$.
The entropy is</p>

<p>\begin{equation}
\frac{-1/4 \cdot \log_2(1/4) \cdot 4}{4} = 1.
\end{equation}</p>

<p>Let us compare this with a biased coin.
So let us assume <em>heads</em> has probability $0.2$ and <em>tails</em> has probability $0.8$, then we have 00 with probability $0.2^2 = 0.04$, 01 and 10 with probability $0.2 \cdot 0.8 = 0.16$ and 11 with probability $0.8^2 = 0.64$.
Consequently, we get</p>

<p>\begin{equation}
\frac{-0.04 \cdot \log_2(0.04) -2 \cdot 0.16 \cdot \log_2(0.16) -0.64 \cdot \log_2(0.64)}{4} \approx 0.361.
\end{equation}</p>

<p>One could say the second system is less surprising to observers;
it is more repetitive.
In <em>information theory</em> we say the second system generates less information, but the term <em>information</em> can be misleading because it has nothing to do with <em>meaning</em>.
From this perspective, a bunch of random numbers is regarded as more informative than a book.</p>

<p>In 1948 Claude E. Shannon established <em>A mathematical theory of information</em> <a class="citation" href="#shannon:1948">(Shannon, 1948)</a>.
He established the term <em>entropy</em> as a measurement of information, but he emphasized its limitation to syntax:</p>

<blockquote>
  <p>Frequently, the messages have meaning; that is, they refer to or are correlated according to some system with certain physical or conceptual entities. These semantic aspects of communication are irrelevant to the engineering problem. The significant aspect is that the actual message is one selected from a set of possible messages. The system must be designed to operate for each possible selection, not just the one which will actually be chosen since this is unknown at the time of design. – Claude E. Shannon</p>
</blockquote>

<p>Even though there is no direct relation between <em>entropy / information</em> and <em>meaning</em>, we can look at extreme cases.
If the entropy is very high (chaos) or very low (no information), a message will likely be meaningless to us, even subjectively.
If we interpret a series of notes as a musical message, this statement is true in a musical context.
We can apply the frequentist perspective, i.e., interpret frequencies as probabilities.
We could generate melodies randomly and pick those within a predefined <em>entropy range</em> to achieve a balance between surprise and repetition.</p>

<p>However, a far better measurement, with regards to music, is <em>expectation</em> in the time domain.
Music indicates no concepts or objects but more music that is about to happen.
Good music has to <em>make sense</em>.
It can disrupt our model of the world but not too much, such that we can adapt our model.
I refer to our <em>model of the world</em> as <em>interpretation</em>; we are all <em>interpreters</em> of our perceptions.
In that sense, actively listening to music is a process of constant <em>model adaptation</em>; the interpretation changes if something can not be interpreted.</p>

<p>Maybe that is, in fact, the key to the definition of <em>meaning</em> in general.
Some observation is meaningful if it makes sense, and it can only make sense if we are able to adapt our <em>interpretation</em> in such a way that our observation fits in.
This adaptation disrupts us; 
it changes our predictions.
If it is marginal, we avoid losing ourselves because most predictions are still valid.
But if the disruption attacks the very essence of our constructed self, we can no longer make sense of it.</p>

<blockquote>
  <p>Embodied musical meaning is […] a <em>product of expectation</em> – Leonard Meyer (1959)</p>
</blockquote>

<p>Musical cognition implies the simultaneous recognition of a permanent and changeable element <a class="citation" href="#loy:2006">(Loy, 2006)</a>; it requires perception and memory.
We have to perceive and compare pitches at the same time.
The expectation is realized for different scales but has to be local and context-sensitive within the computation.
Therefore, it is not only the distribution of notes (or rhythmic elements) within a composition but the distribution of their relation, i.e., their <em>conditional probability distribution</em>.</p>

<h2 id="from-serialism-to-probabilty">From Serialism to Probabilty</h2>

<p>One way to generate melodies is to use the mathematical branch of combinatorics.
The idea is simple: define a bunch of chords or notes that fit together and use permutation, rotation, and other combinatoric tricks to combine them.
This kind of composition method belongs to <em>serialism</em>.
However, the problem with this approach is that each note appears with equal probability; it neglects the importance of distributions and context.
Consequently, the <em>melody’s entropy</em> is high.</p>

<p>In the 20th century, this approach was criticized by, for example, <em>Iannis Xenakis</em>.</p>

<blockquote>
  <p>Linear polyphony destroys itself by its very complexity; what one hears is, in reality, nothing but a mass of notes in various registers. The enormous complexity prevents the audience from following the intertwining of the lines and has as its macroscopic effect an irrational and fortuitous dispersion of sounds over the whole extent of the sonic spectrum. There is consequently a contradiction between polyphonic linear systems and the heard result, which is surface or mass. – <em>Iannis Xenakis</em> (1955)</p>
</blockquote>

<p>He and his fellow critics pointed at the lack of orientation.
They argued that generating melodies by a series of notes that can appear equally likely, results in a sound without structure, thus a disengaged audience.</p>

<p>Influenced by the development in quantum physics at that time (1971) and the isomorphism between the <em>Fourier series</em> and <em>quantum analysis of sound</em>, <em>Xenakis</em> believed that the listener experiences only the statistical aspects of serial music.
Consequently, he reasoned that composers should switch from serial techniques to probability. 
And as a logical step, he drew his attention to the computer.</p>

<blockquote>
  <p>With the aid of electronic computers, the composer becomes a sort of pilot: he presses the buttons, introduces coordinates, and supervises the controls of a cosmic vessel sailing in the space of sound across sonic constellations and galaxies that he could formerly glimpse only as a distant dream. – <em>Iannis Xenakis</em> (1971)</p>
</blockquote>

<h2 id="markov-chains">Markov Chains</h2>

<p>Let us now dive into a first attempt to generate melodies that incorporates probability and, as a consequence, expectation.
The mathematical tool is called <em>Markov chain</em>.</p>

<p>A <em>first-order Markov chain</em> is a deterministic finite automaton where for each state transition, we assign a probability such that the sum of probability of all exiting transitions of each state sum up to 1.0.
In other words, a <em>first-order Markov chain</em> is a directed graph where each node represents a state.
We start with an initial node and traverse the graph probabilistically to generate an output.</p>

<p>In the following figure, you can see a <em>first-order Markov chain</em>.
One starts in the state <code class="language-plaintext highlighter-rouge">A</code> and transits to <code class="language-plaintext highlighter-rouge">B</code> with a probability of 0.2 or <code class="language-plaintext highlighter-rouge">C</code> with a probability of 0.8.
<code class="language-plaintext highlighter-rouge">D</code> is a final state.
A possible series of states would be: <code class="language-plaintext highlighter-rouge">ABCCACD</code></p>

<div><img style="height:300px;float:right" src="/Pages/assets/images/markov-chain-ex1.png" alt="Markov Chain Example" /></div>

<p>Given state <code class="language-plaintext highlighter-rouge">A</code>, the probability of moving to state <code class="language-plaintext highlighter-rouge">B</code> is equal to 0.2.
In other words</p>

<p>\begin{equation}
P(X_{k+1} = B\ |\ X_{k} = A) = 0.2.
\end{equation}</p>

<p>A <em>first-order Markov chain</em> only considers <strong>one</strong> predecessor, i.e., only the most local part of the context.
A <em>$n$-order Markov chain</em> does consider $n$ predecessors. In general, we define</p>

<p>\begin{equation}
P(X_{k+1} = x\ |\ X_{k} = x_k, X_{k-1} = x_{k-1}, \ldots X_{k-n} = x_{k-n}) = p.
\end{equation}</p>

<p>The visualization of such a chain is a little bit more complicated.</p>

<h2 id="music-generation">Music Generation</h2>

<p>We can generate a composition by traversing the graph if we represent our notes by states of a <em>Markov chain</em>.
If we increase the order of the chein, i.e. $n$, the entropy decreases for small $n$.</p>

<p>Until now, I only tried to use and generate a <em>first-order Markov chain</em>.
Even though I am not that familiar with <code class="language-plaintext highlighter-rouge">Ruby</code>, I used <a href="https://sonic-pi.net/">Sonic Pi</a> for this task such that I can play around with it directly within the IDE of Sonic Pi.
I decided to define a note as a tuple (list) consisting of the pitch and the length of the note.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="ss">:c4</span><span class="p">,</span> <span class="mf">1.0</span><span class="o">/</span><span class="mi">8</span><span class="p">]</span> <span class="c1"># a c of length 1/8 beat </span>
</code></pre></div></div>

<p>Instead of a graph, I use a transition matrix $P \in \mathbb{R}^{m \times m}$ where $m$ is the number of states/notes.
Let $Q = {q_1, \ldots, q_m}$ be the set of states/notes.
The entry of row $i$ and column $j$, i.e., $p_{ij}$ is the probability of going from state $q_i$ to state $q_j$.</p>

<p>After constructing the <code class="language-plaintext highlighter-rouge">matrix</code> $P$, the <code class="language-plaintext highlighter-rouge">states</code> $Q$ and picking a <code class="language-plaintext highlighter-rouge">start</code> (state number), the following function generates a random melody of length <code class="language-plaintext highlighter-rouge">n</code>.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">define</span> <span class="ss">:gen_mmelody</span> <span class="k">do</span> <span class="o">|</span><span class="n">n</span><span class="p">,</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">states</span><span class="o">|</span>
  <span class="c1">#</span>
  <span class="c1"># Generates a random melody of length n based on a transition matrix</span>
  <span class="c1"># and an initial statenumber (start).</span>
  <span class="c1">#</span>
  <span class="n">notes</span> <span class="o">=</span> <span class="p">[</span><span class="n">states</span><span class="p">[</span><span class="n">start</span><span class="p">]]</span>
  <span class="n">from</span> <span class="o">=</span> <span class="n">start</span>
  <span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">times</span> <span class="k">do</span>
    <span class="nb">p</span> <span class="o">=</span> <span class="n">rrand</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">to_row</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">[</span><span class="n">from</span><span class="p">]</span>
    <span class="n">to</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">sum</span> <span class="o">&lt;</span> <span class="nb">p</span>
      <span class="n">sum</span> <span class="o">+=</span> <span class="n">to_row</span><span class="p">[</span><span class="n">to</span><span class="p">]</span>
      <span class="n">to</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">end</span>
    <span class="n">notes</span> <span class="o">+=</span> <span class="p">[</span><span class="n">states</span><span class="p">[</span><span class="n">to</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">from</span> <span class="o">=</span> <span class="n">to</span><span class="o">-</span><span class="mi">1</span>
  <span class="k">end</span>
  <span class="k">return</span> <span class="n">notes</span>
<span class="k">end</span>
</code></pre></div></div>

<p>For each note, we roll the dice.
Let’s say $p \in [0;1]$ is our result.
And $q_i$ is our current state.
Then we compute $j$ such that</p>

<p>\begin{equation}
\sum\limits_{k=1}^{j-1} p_{ij} &lt; p \leq \sum\limits_{k=1}^{j} p_{ij}.
\end{equation}</p>

<p>Note that the code is not optimized in any way.</p>

<h2 id="learning-a-markov-chain">Learning a Markov Chain</h2>

<p>Instead of generating a melody or rhythm given a <em>Markov chain</em>, we can do the reverse.
Given a melody, we can <em>learn</em> the <em>Markov chain</em> that <strong>most likely</strong> would generate the given melody.
By doing so, we can then use the <em>learned chain</em> to generate music in a similar style.</p>

<p>Let us use the same transition matrix $P \in \mathbb{R}^{m \times m}$ where $m$ is the number of states/notes.
Let $Q = {q_1, \ldots, q_m}$ be the set of states/notes.
The entry of row $i$ and column $j$, i.e., $p_{ij}$ is the probability of going from state $q_i$ to state $q_j$.</p>

<p>Furthermore, let us define our set of all possible melodies $M \subseteq Q^n$ of length $n$.
Then a specific melody $\mathbf{m} = (m_1, \ldots, m_n) \in M$ is a tuple (list) of notes:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">notes</span> <span class="o">=</span> <span class="p">[[</span><span class="ss">:g4</span><span class="p">,</span> <span class="mf">1.0</span><span class="o">/</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="ss">:g4</span><span class="p">,</span> <span class="mf">1.0</span><span class="o">/</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="ss">:a4</span><span class="p">,</span> <span class="mf">1.0</span><span class="o">/</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="ss">:g4</span><span class="p">,</span> <span class="mf">1.0</span><span class="o">/</span><span class="mi">4</span><span class="p">],</span> <span class="o">...</span> <span class="p">]</span>
</code></pre></div></div>

<p>We can compute the most likely $P$ by computing each entry of it where $p_{ij}$ is equal to</p>

<p>\begin{equation}
p_{ij} = \frac{n_{ij}}{n_i}
\end{equation}</p>

<p>where $n_{ij}$ is the number of transitions from $q_i$ to $q_j$ within $\mathbf{m}$ and $n_i$ is the number of transition starting at $q_i$.</p>

<p>Given $Q$ <code class="language-plaintext highlighter-rouge">states</code> and $\mathbf{m}$ <code class="language-plaintext highlighter-rouge">notes</code> the following function computes $P$ <code class="language-plaintext highlighter-rouge">matrix</code>.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">define</span> <span class="ss">:gen_markov_matrix</span> <span class="k">do</span> <span class="o">|</span><span class="n">states</span><span class="p">,</span> <span class="n">notes</span><span class="o">|</span>
  <span class="c1">#</span>
  <span class="c1"># Generates the transition matrix based on the set of notes (states)</span>
  <span class="c1"># and a given piece of music (notes).</span>
  <span class="c1">#</span>
  <span class="n">matrix</span> <span class="o">=</span> <span class="no">Array</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  
  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="no">Array</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">end</span>
  
  <span class="c1"># (1) count transitions</span>
  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">notes</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">from</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">to</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">notes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">states</span><span class="p">[</span><span class="n">from</span><span class="p">]</span> <span class="o">&amp;&amp;</span> <span class="n">notes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">states</span><span class="p">[</span><span class="n">to</span><span class="p">]</span>
          <span class="n">matrix</span><span class="p">[</span><span class="n">from</span><span class="p">][</span><span class="n">to</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">1.0</span>
        <span class="k">end</span>
      <span class="k">end</span>
    <span class="k">end</span>
  <span class="k">end</span>
  <span class="c1"># (2) normalize</span>
  <span class="k">for</span> <span class="n">from</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">[</span><span class="n">from</span><span class="p">].</span><span class="nf">sum</span>
    <span class="k">for</span> <span class="n">to</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">matrix</span><span class="p">[</span><span class="n">from</span><span class="p">][</span><span class="n">to</span><span class="p">]</span> <span class="o">/=</span> <span class="n">s</span>
    <span class="k">end</span>
  <span class="k">end</span>
  <span class="n">print_matrix</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">states</span>
  <span class="k">return</span> <span class="n">matrix</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Of course, we can easily compute $Q$ <code class="language-plaintext highlighter-rouge">states</code> from $\mathbf{m}$ <code class="language-plaintext highlighter-rouge">notes</code>.
Finally, the following function takes a number <code class="language-plaintext highlighter-rouge">n</code> and a melody <code class="language-plaintext highlighter-rouge">notes</code> and generates a random melody of length <code class="language-plaintext highlighter-rouge">n</code> by <em>learning</em> $P$ based on <code class="language-plaintext highlighter-rouge">notes</code>.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">define</span> <span class="ss">:markov_melody</span> <span class="k">do</span> <span class="o">|</span><span class="n">n</span><span class="p">,</span> <span class="n">notes</span><span class="o">|</span>
  <span class="n">states</span> <span class="o">=</span> <span class="n">notes</span><span class="p">.</span><span class="nf">uniq</span>
  <span class="n">matrix</span> <span class="o">=</span> <span class="n">gen_markov_matrix</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">ring</span><span class="p">,</span> <span class="n">notes</span><span class="p">.</span><span class="nf">ring</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">gen_mmelody</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">rand_i</span><span class="p">(</span><span class="n">states</span><span class="p">.</span><span class="nf">length</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">states</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="example">Example</h2>

<p>I use the beginning of Bach’s Minuet in G.</p>

<audio controls="">
  <source src="/Pages/assets/audio/bach-ex1.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<p>I generate two melodies (by using a different seed) consisting of 34 notes:</p>

<audio controls="">
  <source src="/Pages/assets/audio/markov-bach-ex1.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/markov-bach-ex2.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<p>Of course, this sound is not that musical.
The rhythm is all over the place, but we recognize the original composition.
Furthermore, no one said we have to stop there.
We can continue to generate until we find something that sticks.
Furthermore, this example is straightforward because I only use the beginning of <strong>one</strong> piece.
Instead, we could use multiple compositions that fit together.</p>

<h2 id="code">Code</h2>

<p>This project was part of our workshop <em><a href="/Pages/2022/06/21/creative-artifical-intelligence.html">AI and Creativity</a></em> to show a basic example of using <em>artificial intelligence</em> to generate music.</p>

<p>You can find the full example containing two different melodies on my <a href="https://github.com/BZoennchen/workshop-creative-ai">GitHub page</a>.
The code include some additional functions, e.g., a function that prints out the <em>Markov matrix</em> in a readable format.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="shannon:1948">Shannon, C. E. (1948). A Mathematical Theory of Communication. <i>Bell Syst. Tech. J.</i>, <i>27</i>(3), 379–423.</span></li>
<li><span id="loy:2006">Loy, G. (2006). <i>Musimathics: the mathematical foundations of music</i> (Vol. 1). MIT Press.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Music" /><category term="Sonic-Pi" /><category term="AI" /><summary type="html"><![CDATA[One of the most challenging tasks in building a beautiful piece of music lies in composing a well-received melody. But what makes a good melody? Or, in a more generative sense:]]></summary></entry><entry><title type="html">Creative Artificial Intelligence</title><link href="https://bzoennchen.github.io/Pages/2022/06/21/creative-artifical-intelligence.html" rel="alternate" type="text/html" title="Creative Artificial Intelligence" /><published>2022-06-21T00:00:00+02:00</published><updated>2022-06-21T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2022/06/21/creative-artifical-intelligence</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2022/06/21/creative-artifical-intelligence.html"><![CDATA[<h2 id="panel-discussion">Panel Discussion</h2>

<p><strong>Disclaimer:</strong> This text contains my own personal, speculative opinions. You might disagree heavily and that’s ok.</p>

<p>On the 20th of Mai, I joined a penal to discuss the role of <em>artificial intelligence (AI)</em> in the <em>creative process</em>.
It was held in the context of the Munich Creative Business Week by the Wavelet (University for Music and Theater) and the <a href="https://sites.hm.edu/mucdai/news_mucdai/details_news_mucdai_26944.de.html">Munich Center for Digital Science and AI</a>.
Let me first summarize our discussion:</p>

<p>The penal consisted of two computer scientists and two artists.
After each of us opened with a general statement, we discussed different aspects of AI in the realm of art, science, and economics.
We came close to an agreement regarding the question of how creative AI can be: AI can facilitate and enable great artwork but to this day, AI is yet another tool, similar to pen and paper, to support humans in their creative work.</p>

<p>In general, it wasn’t easy to talk about <em>creativity</em> and <em>intelligence</em> because unsurprisingly each of us had a slightly different definition in mind.
My colleague rightfully problematized the black box principle of many modern machine learning techniques, e.g., deep neural networks.
Despite their effectiveness, real-world decisions are still made on the basis of human understanding.
Since neural networks do not provide an “easy” explanation of how they draw their conclusion, it is often necessary to go back to simpler models, such as statistics, to explain the neural network.</p>

<p>One artist described her experience with the chatbot <em>Replika</em>, an AI that tries to mimic your behavior to become your friend or romantic partner.
She was pretty impressed. 
Some people even fell in love with the machine – they reported strong emotions echoing the science fiction movie <em>Her</em>.
However, it was always possible for her to spot a machine-like behavior behind the scenes.</p>

<p>The other artist argued that AI opens up possibilities for novel artistic expressions.
She assumes that working with AI will be her daily bread and butter.
She also criticized the <em>cult</em> around famous artists by arguing that most of the time, incredible art resulted from a collaboration of multiple people.
Consequently, she hopes that AI will bring a kind of democratization to the art world.</p>

<blockquote>
  <p>There is no single genius.</p>
</blockquote>

<p>I stated that AI could potentially increase the pressure on the artist because it will become more and more challenging to create something unique and even harder to create something non-reproducible.
Democratization in consumer societies can enhance competitiveness and an ever-growing flow of products that lose their symbolic value.
It is not necessarily the case that attempting to sell more art will constitute more art.
The reverse might happen.
<em>Commercial art</em> is rarely publicly symbolic.
How could it, if one has to pay for its perception.</p>

<h2 id="defining-artificial-intelligence">Defining Artificial Intelligence</h2>

<p>In my opinion, without <em>artificial intelligence AI</em> there is no <em>artificial creatifity AC</em>.
So let us talk about AI.</p>

<p>In his paper <em>What is Artificial Intelligence?</em> <a class="citation" href="#mccarthy:1998">(McCarthy, 1998)</a> published in 2004, <a href="https://www.artificial-solutions.com/blog/homage-to-john-mccarthy-the-father-of-artificial-intelligence"><em>John McCarthy</em></a> stated:</p>

<blockquote>
  <p>[Artificial intelligence] is the science and engineering of making intelligent machines, especially intelligent computer programs. It is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable. – <em>John McCarthy</em></p>
</blockquote>

<p>In his definition, we do not find any explanation of what he actually means by <em>intelligence</em> which is unfortunate.
<em><a href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing</a></em>, the father of computer science, gave us at least some criteria at hand.
He asks in his article <em>Computing Machinery and Intelligence</em> <a class="citation" href="#turing:1950">(Turing, 1950)</a> more than 50 years before <em>McCarthy</em></p>

<blockquote>
  <p>Can machines think?</p>
</blockquote>

<p>And from there, he offers us his famous and widely criticized <em>Turing test</em>.
The test is not very helpful because it defines no objective measurement for intelligence.
It consists of a human interrogator trying to distinguish between a computer and a human based on text responses – very similar to the chatbot <em>Replica</em>.
If a human can not tell if he or she interacted with a machine or another human being, the machine passed the test and can be regarded as <em>intelligent</em>.</p>

<p>I call this <em>simulated intelligence</em> or <em>weak AI</em>.
It is a requirement, but it is not sufficient.
Compared to a baby, a machine can <strong>appear</strong> to be much more intelligent, but a baby <strong>is</strong> intelligent while a machine is not.
Therefore, the <em>Turing test</em> does not help us to spot <em>natural intelligence</em>.
It might even lead us on a path where we become experts in <em>faking/simulating intelligence</em> by wasting all our resources.</p>

<p><em>Stuart Russell</em> and <em>Peter Norvig</em> published their book <em>Artificial Intelligence: A Modern Approach</em> <a class="citation" href="#russel:2010">(Russell &amp; Norvig, 2010)</a> in 2010, which is one of the leading textbooks for the subject today.
They differentiate four different goals or definitions of AI:</p>

<ul>
  <li>human approach
    <ul>
      <li>systems that think like humans (<em>strong AI</em>)</li>
      <li>systems that act like humans (<em>weak AI</em>)</li>
    </ul>
  </li>
  <li>ideal approach
    <ul>
      <li>systems that think rationally</li>
      <li>systems that act rationally</li>
    </ul>
  </li>
</ul>

<p><em>Turing’s</em> definition of AI would have fallen under the category of <em>systems that act like humans</em>.
A comprehensive, thus useless definition would be the following:</p>

<blockquote>
  <p>Artificial intelligence is intelligence demonstrated by machines.</p>
</blockquote>

<p>Again we avoid the definition of <em>intelligence</em>.
Is an ant intelligent?
Does the universe implement some sort of intelligence?
Is consciousness or liveliness a precondition for intelligence?
Based on our definition of <em>intelligence</em>, everything from simple algorithms and machines (including the thermostat) to neural networks can be either called <em>intelligent</em> or not.</p>

<p>These definitions are somewhat fuzzy and vague because we do not know what intelligence is.
We have an intuitive understanding of it (which might be an illision), but we can not express what it is linguistically.
In its simplest form, artificial intelligence is <strong>a field</strong> (not a machine) that combines computer science, data science, machine learning, deep learning, robotics, neurosciences, and more <strong>to enable problem-solving</strong>.</p>

<p>In his book <em>Birth of Intelligence</em> <a class="citation" href="#lee:2010">(Lee, 2021)</a> <em><a href="https://krieger.jhu.edu/mbi/directory/daeyeol-lee/">Daeyeol Lee</a></em> writes:</p>

<blockquote>
  <p>Intelligence can be defined as the ability to solve complex problems or make decisions with outcomes benefiting the actor and has evolved in lifeforms to adapt to diverse environments for their survival and reproduction. – <em>Daeyeol Lee</em></p>
</blockquote>

<p>Daeyeol Lee argues that a few essential principles emerge from an evolutionary perspective.
For example, different lifeforms can have very different types of intelligence because they have other evolutionary roots and have adapted to different environments. 
It is misleading, unhelpful, and meaningless if we try to order different animal species on a scale of intelligence.</p>

<p>Following his advice, comparing human and artificial intelligence may be meaningless as well.
Machines can solve specific problems much more efficiently than humans.
At the same time, they are hopelessly overwhelmed in dealing with the most simple tasks.
Humans, and many other animals, can not only identify complex objects and produce agile behaviors, but they can do this in so many different ways in many different environments.
Concerning specialization, machines are still infants.
Therefore, I suggest that we use three different terms to distinguish three different kinds of intelligence:</p>

<ul>
  <li><strong>lively intelligence:</strong> the intelligence of living beings</li>
  <li><strong>human intelligence:</strong> the intelligence of human beings (a subset of lively intelligence)</li>
  <li><strong>artificial intelligence:</strong> the intelligence of machines and programs</li>
</ul>

<p>By using these categories, I call machines not <em>human-like intelligent</em> but <em>artificial intelligent</em> which is a distinct category for a special kind of intelligence.</p>

<blockquote>
  <p>Artificial intelligence (AI) is an ability of a machine or program to solve specific problems.</p>
</blockquote>

<h2 id="a-brief-history-of-ai">A Brief History of AI</h2>

<p>The general public was first impressed by <em>artificial intelligence</em> when it became clear that computers would beat any chess grandmaster of the future.
Soon after the success, accompanied by big headlines, critics argued that the program won via a sort of <em>brute-force approach</em> which can not be called <em>intelligent</em> – here we go again.
Based on a database, the program just searches the whole state space.
In contrast, a chess master finds good moves through pattern matching and intuition.
He or she is very limited in searching the state space.</p>

<p>The next step toward more sophisticated artificial intelligence was made by <em>AlphaZero</em>, a program that plays board games with superhuman skill.
It famously discovered several chess strategies and even invented one.
It certainly seemed like a machine eclipsing human cognitive abilities.
But <em>AlphaZero</em> needs to play millions more games than a person during practice to learn a game.</p>

<p>What followed was the artificial intelligence called <em>AlphaGo</em> which was able to beat the world’s best <em>Go</em> players.
The significant difference compared to former approaches was that <em>AlphaGo</em> not only partially searched the state space but also constructed a cost function autonomously.
<em>AlphaGo</em> is based on <em>reinforcement learning</em>, i.e., it uses rewards and punishments to train itself while playing millions of games.
The only prior defined goal was to win the game; thus, no evaluation strategy of a game state was given.</p>

<p>In 2019 the success was translated to another AI called <em>AlphaStar</em>.
<em>AlphaStar</em> was able to defeat one of the best players in a real-time strategy game (<em>Starcraft II</em>).
Again the machine required millions of games and could only play a single map.</p>

<p><em>AlphaGo</em> as well as <em>AlphaStar</em> revealed novel strategies that human players could potentially adapt.
Furthermore, it developed a distinct game style.
For example, <em>AlphaGo</em> tends to avoid pressing the issue.
It sometimes makes seemingly suboptimal moves while staying slightly ahead.
<em>AlphaStar</em> lost a game because it moved into an unobserved game state and heavily overreacted.
The observers called it <em>weird gameplay</em>.</p>

<p>These examples show that <em>artificial intelligence</em> can already create something novel that we identify as creative.
Finding a new strategy in an RTS game is undoubtedly a creative process.
The AI is perfectly able to simulate intelligence and creativity but has a fundamentally different quality than living beings.
As <em><a href="https://www.ynharari.com/de/">Yuval Noah Harari</a></em> stresses:</p>

<blockquote>
  <p>Even though we do not really understand intelligence and consciousness, artificial intelligence is perfectly able to hack humanity. – <em>Yuval Noah Harari</em></p>
</blockquote>

<h2 id="shortcomings-of-ai">Shortcomings of AI</h2>

<p>However, it also shows that <em>artificial intelligence</em> is still highly specialized in solving one specific task.
I stand by the provocative claim that there is still no fundamental difference between modern AI and a thermostat.
Regardless of how sophisticated an AI is, it can only solve a specific problem – it can not transfer knowledge or any strategy to a new area.
While public figures, such as <em>Elon Musk</em>, make horrific claims about AI to push their story to please and attract financiers, experts are aware of its shortcomings and the vast difference between human and artificial intelligence.
<em><a href="https://fchollet.com/">Francois Chollet</a></em>, the creator of <em>Keras</em>, stated:</p>

<blockquote>
  <p>What makes human intelligence special is its adaptability; its power to generalize to never-seen-before situations – <em>Francois Chollet</em></p>
</blockquote>

<p><em>Chollet</em> argues that, it is misguided to measure machine intelligence solely according to its skills at specific tasks.
Unlike most animals humans do not start out with skills.
As a baby we are horribly helpless but we start out with a broad ability to acquire new skills.
A chess player can transfer his abilities to other areas.
For example, in World War II, chess players joined the allied forces to decrypt military messages from Nazi Germany.
Humans can solve tasks of similar difficulty which is a very different capability compared to what AI currently does.</p>

<p><em><a href="https://www.harvardlds.org/our-labs/spelke-labspelke-lab-members/elizabeth-spelke/">Prof. Elizabeth Spelke</a></em> describes in her articles that even 3-month-olds appear puzzeled when someone grabs something in an inefficient way.
In <a class="citation" href="#liu:2017">(Liu &amp; Spelke, 2017)</a> she and <a href="https://cbmm.mit.edu/about/people/liu">Shari Liu</a> argue that infants’ expects others to minimize the cost of their action, e.g., using the shortest path to a location.
Humans seem to be born with an innate ability to quickly learn certain things, such as what a smile means or what happens if you move some object.
We also develop social behaviors early on without being exposed to a massive amount of experiencing it.
In their article <em>Foundations of cooperation in young children</em> <a class="citation" href="#olson:2008">(Olson &amp; Spelke, 2008)</a>, <em>Kristina R. Olson</em> and <em>Elizabeth Spelke</em> found evidence that 3.5-year-old children share resources with people who have shared with them (reciprocity), and with people who have shared with others (inidirect reciprocity). 
Even the most sophisticated artificial intelligence of our age can not grasp such concepts.
A self-driving car can not predict from <em>common sense</em> what will happen if a tree falls down on the street; it can not translate knowledge to an unexperienced situation.</p>

<p><em><a href="https://mitibmwatsonailab.mit.edu/people/joshua-tenenbaum/">Joshua Tenenbaum</a></em>, a professor in MIT’s Center for Brains, Minds &amp; Machines thinks that AI programs will need a basic understanding of physics and psychology in order to acquire and use knowledge as efficiently as a baby.</p>

<blockquote>
  <p>At some point you know, if you’re intelligent; you realize maybe there’s something else out there. – Joshua Tenenbaum</p>
</blockquote>

<p>This might be a problem because, as we know, quantum theory and relativity theory, i.e., the physics of the small and big, do not work together, and Gödel’s incompleteness theorem hints at the depressing reality that there might never be a theory of everything.
Another problem is cognition.
We still know very little about what we perceive.
Call me crazy, but it might have nothing to do with reality, so how can we program a machine to perceive like we do if we have no clue what we actually perceive and how?</p>

<p>But there is even more.
<em><a href="https://krieger.jhu.edu/mbi/directory/daeyeol-lee/">Daeyeol Lee</a></em> argues that true intelligence (<em>lively intelligence</em>) should promote – not interfere with – the replication of the genes responsible for its creation.
The will to reproduce and to self-preserve ones own being and species injects the world with <em>meaning</em>.
Until then, machines will always only be surrogates of human intelligence, which unfortunately still leaves open the possibility of an abusive relation between people and artificial intelligence.
<strong>Replication</strong> and <strong>self-preservation</strong> seems to be the one and only predefined rule at which living beings operate.</p>

<p>Today, a lot of hype still surrounds AI development, which is expected of any new emerging technology in the market.
Surely we accomplished a lot in building more sophisticated thermostats.
AI also helped us in the sciences but it may be the case that we did not come any closer towards creating <em>human intelligence</em>.
The overenthusiasm of the tech-industry is slowly crumbeling and a period of disillusionment is on the horizon.
Maybe this gives us the possibility to breathe and think about the technology we really wanna create and use.</p>

<h2 id="creativity">Creativity</h2>

<p>The question we discussed at the penal that is exciting and frightening at the same time is:</p>

<blockquote>
  <p>To what extent can artificial intelligence challenge human creativity?</p>
</blockquote>

<p>So far, we have established a clear difference between <em>human</em> and <em>artificial intelligence</em>.
If creativity requires intelligence, does the question under this assumption matter?</p>

<p>Before tackling this question, we have to define or at least get an intuitive idea of what we mean by <em>creativity</em>.
This is, of course, a complex and maybe even impossible task.</p>

<p>First, we can attribute creativity to a subject, object or process.
A creative product or idea has to be <strong>novel</strong> and <strong>useful</strong> (which might be highly subjective).
The product might just be aesthetically pleasing (or even disgusting), which is in itself useful.
Novelty, as well as usefulness, can be either <em>psychological (P)</em>, i.e., it is novel/useful to the agent that produces it, or <em>historical (H)</em>, i.e., novel/useful to society.</p>

<p>Every human being is creative.
In other words, creativity is not reserved for a special elite; instead, it is a feature of human intelligence in general.
Creativity involves everyday capacities, e.g., perception, searching for a structure, reminding, and combining concepts.</p>

<p>Lastly, creativity involves motivation and emotion and is closely linked to historical, political, cultural, social and personal/subjective factors.</p>

<h2 id="artificial-creativity">Artificial Creativity</h2>

<p>In her article <em>Creativity and Artificial Intelligence</em> <a class="citation" href="#boden:1998">(Boden, 1998)</a> <em>M. A. Boden</em> lists three ways to create new ideas:</p>

<ol>
  <li>combination of familiar ideas</li>
  <li>exploration of the conceptual space</li>
  <li>transformation of previously impossible ideas</li>
</ol>

<p>Since creative products have to be novel and useful, artificial creative systems are typically structured into two phases:</p>

<ol>
  <li><strong>generation</strong> and</li>
  <li><strong>evaluation</strong>.</li>
</ol>

<p>Artificial intelligence can help us with the generation.
Algorithms can realize all three ways of idea creation, but at some point in the process, subjective factors have to come into play.
Machines and algorithms are not motivated by anything; they are not emotional.</p>

<p>Let us look at a famous example: the proof of <em>the four-color problem</em>.
The four-color problem asks if it is possible to color a map in such a way that there are no two adjacent parts with the same color, using only four colors.
It was proven in 1976 by <em>Kenneth Appel</em> and <em>Wolfgang Haken</em> with the help of a computer.
Four colors are enough!
An algorithm helped check different possibilities.
Clearly, the machine is part of the creative process of proving a mathematical statement, but at the same time, it is instructed by the programmers who injected their subjective motivation and cultural background.
They decided to take up the task of proving the statement.
They decided it was worth their time and developed a strategy that a machine could execute.</p>

<p>No artificial intelligence decided to prove <em>the four-color problem</em>, but humans did.
Proving a mathematical statement does not start with the proof itself.
This point is important!
Scientists choose what they want to prove and what they think is essential.
This choice can not be reduced to an <em>objective, rational</em>; it is a <em>subjective evaluation of values and symbols of meaning</em>.
But to this day, machines can not infuse symbols with meaning.
They work on a purely syntactical level.</p>

<p>This is no argument against <em>simulated creativity</em>.
Artificial intelligence is perfectly suitable to find, generate, combine or create what we humans value and attach meaning to.
Therefore, AI can bring forth what we perceive to be creative.</p>

<blockquote>
  <p>In principle, artificial intelligence can create something novel that is meaningful to us.</p>
</blockquote>

<p>For example, in August 2015, researchers from Tübingen created a convolutional neural network that uses neural representations to separate and recombine the content and style of arbitrary images.
The network can turn images into stylistic imitations of works of art by artists such as a <em>Picasso</em> or <em>Van Gogh</em> in about an hour.
In October 2018, the <a href="https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx">Portrait of Edmond de Belamy</a>, an algorithm-generated print, was sold for $432 500.
In both cases, the AI (1) combined familiar ideas, (2) explored a conceptual space, and (3) transformed previously impossible ideas.</p>

<h2 id="disruptions-and-control">Disruptions and Control</h2>

<p>Humans have created and enjoyed all art forms for viewing, aesthetic, and even therapeutic purposes.
We should not forget that technology has impacted how art is created and enjoyed for the last 100 years.
The invention of <em>portable paint tubes</em>, for example, enabled artists to paint outdoors and sparked a contingent of stunning landscape and horizon paintings.
Today cameras and software like <em>Photoshop</em> have redefined how art is created and enjoyed.
Even if we disagree on what art is, it is safe to say that these technological advances have not changed our antiquated meaning of it.</p>

<p>Regardless of the technology, there was always some human intervention required to create art.
Since machines can not make sense of our social, cultural, transcendental, and physical world, I highly doubt that this will change in the near future.
As long as we fail in creating <em>human intelligence</em>, there is no reason to believe that <em>artificial intelligence</em> can replace the human artist.
But why do we even want to create <em>human intelligence</em>?
Why shall we copy ourselves?</p>

<p>Technologies got introduced long before the digital era.
However, what changed is <em>the speed of disruption</em>.
At the rate at which technology is being accepted in every industry, it is no longer difficult to imagine a future of fewer artists.
The increased usage of all kinds of AI in all kinds of art suggests that it is here to stay.
From AI-written books, such as <a href="https://en.wikipedia.org/wiki/1_the_Road">The Road</a>, to blooming tulip videos, creators have found value in utilizing artificial intelligence.</p>

<blockquote>
  <p>We all hope for a world where our technologies help us and not replace us.</p>
</blockquote>

<p>Our current technologically and competitively driven economic system neglects any profound confrontation with technology.
Competition leads to <em>the fear of missing out</em>; of losing some advantage over others.
We are so used to technology, comforted by it, and convinced that it has become our new religion – at least for some of us.
We lost the distinction between <em>technological progress</em> and <em>evolution</em>.
Now, technology <strong>is</strong> evolution.
We no longer think about it. 
Instead, if it is properly marketed and channeled into our desires, we buy and use it.</p>

<p>Every broadly accepted new technology leads to disruption.
The increasing speed of disruption makes it more and more difficult to attach meaning to the new.
Solid structures get replaced by a liquid stream of information.
We can no longer get too invested in something because it might be replaced the next day.
Artists might be in trouble if this superficiality becomes a reality in the art world.</p>

<p>In the article <em><a href="https://medium.com/@francois.chollet/what-worries-me-about-ai-ed9df072b704">What worries me about AI</a></em>, <em>Francois Chollet</em> states his personal opinion about the real destructive potential of AI; he hits the mark.
First, he convincingly argues that we are painfully bad at predicting future threats but we can be easily driven towards illusive fears.
For example, who could forecast that the transportation and manufacturing technologies we were developing would enable a new form of industrial warfare that would wipe out tens of millions in two World Wars?
According to Chollet, the danger is not the singularity of AI; it is not about automation and job replacement; aligned with <em><a href="https://www.ynharari.com/de/">Yuval Noah Harari</a></em>, he states it is about hacking human societies, and I have to agree.
Brexit and other political disruptions already show a trend.
When consumption and creation mainly happen in the digital world, we become vulnerable to that which rules it – AI algorithms.
And these AI algorithms serve the interest of big corporations and governments, i.e., aggregations of power.</p>

<blockquote>
  <p>We’re looking at a company that builds fine-grained psychological profiles of almost two billion humans, that serves as a primary news source for many of them, that runs large-scale behavior manipulation experiments, and that aims at developing the best AI technology the world has ever seen. Personally, it scares me. – <em>Francois Chollet</em></p>
</blockquote>

<p>The history of psychological tricks applied by marketing and advertisers was born with the introduction of surplus production.
It started with <em><a href="https://en.wikipedia.org/wiki/Edward_Bernays">Edward Louis Bernays</a></em>, a nephew of <em><a href="https://en.wikipedia.org/wiki/Sigmund_Freud">Sigmund Freud</a></em> and horrific misanthrope with grand ambitions.
His story is worth studying.
Today, <em>accessibility</em> and <em>AI</em> guarantees constant exposure to this resonating and highly individualized noise.
<em>Reinforcement learning</em> can easily be applied to whole human societies.
Algorithms can decide what you see; they show you things you identify with to trick you into a particular belief.
They can channel your unwanted opinions to a specific group of people, who will reject and oppose you.
Constant rejection can then lead to alienation.
This combination of <em>identification</em> and <em>alienation</em> can gently force you into <em>adaptations</em>.
The system can potentially punish what it does not want to see; it can <em>train</em> you into the “correct” mindset.</p>

<p>I think we have to educate ourselves not only about AI but how we can be manipulated by it.
In the past, we learned about the influence of pollution on the quality of life.
We have regulations for fine particles, chemicals, and CO2 emissions.
Now it is time to learn about the pollution of our mind.</p>

<blockquote>
  <p>We have to learn about the pollution of our mind.</p>
</blockquote>

<p>We need transparency and control for the public and the customer.
I want to be in charge of the objective function of <em>YouTube’s</em> algorithms feeding me with suggestions.
I want to decide on what bases I will be manipulated.
Paradoxically enough, AI can help us with these tasks.</p>

<blockquote>
  <p>The issue is not AI itself. The issue is control. – <em>Francois Chollet</em></p>
</blockquote>

<p>Of course, this would destroy most business models; thus, corporations will not implement these changes voluntarily.
Governments are another beast.
Right now, it is unimaginable that China will change its way of using AI and Western governments are not innocent either.</p>

<p>AI will be, most likely, part of our future life – our window to the world made of digital information.
As I stated in my <a href="/Pages/2021/06/08/Informatics-a-love-letter.html">love letter</a>, informatics and AI can be empowering disciplines.
AI can emancipate us.
But it can also lead to a total loss of self-determination and agency.
I believe we still have enough leftover to steer the wheel in the right direction.</p>

<p>In the progress of a possible democratization of AI, art could play a major role.
Art, as an aesthetic counterpart to the kind of destructive advertisement polluting our thoughts, can reveal its manipulative power.
Future artists might have to revolt against <em>the speed of disruption</em>.
Artwork may be the product of technology, but <strong>also</strong> offers a window into it.
Maybe in art lies the possibility, on the one hand, to disengage, but also to profoundly engage with technology;
to reveal who is in charge for what reason;
To ask: What is it good for?
How does it change our social, economic, political, and transcendental systems?
Can everyday people control it, and if so, how can we get there?</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="mccarthy:1998">McCarthy, J. (1998). <i>What is artificial intelligence?</i></span></li>
<li><span id="turing:1950">Turing, A. M. (1950). Computing Machinery and Intelligence. <i>Mind</i>, <i>59</i>(236), 433–460. http://www.jstor.org/stable/2251299</span></li>
<li><span id="russel:2010">Russell, S., &amp; Norvig, P. (2010). <i>Artificial Intelligence: A Modern Approach</i> (3rd ed.). Prentice Hall.</span></li>
<li><span id="lee:2010">Lee, D. (2021). <i>Birth of Intelligence: From RNA to Artificial Intelligence</i>. New York: Oxford University Press.</span></li>
<li><span id="liu:2017">Liu, S., &amp; Spelke, E. S. (2017). Six-month-old infants expect agents to minimize the cost of their actions. <i>Cognition</i>, <i>160</i>, 35–42. https://doi.org/10.1016/j.cognition.2016.12.007</span></li>
<li><span id="olson:2008">Olson, K. R., &amp; Spelke, E. S. (2008). Foundations of cooperation in young children. <i>Cognition</i>, <i>108</i>(1), 222–231. https://doi.org/10.1016/j.cognition.2007.12.003</span></li>
<li><span id="boden:1998">Boden, M. A. (1998). Creativity and artificial intelligence. <i>Artificial Intelligence</i>, <i>103</i>(1), 347–356. https://doi.org/10.1016/S0004-3702(98)00055-1</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Opinion" /><category term="AI" /><summary type="html"><![CDATA[Panel Discussion]]></summary></entry><entry><title type="html">Interactive Computational Thinking</title><link href="https://bzoennchen.github.io/Pages/2021/10/27/computational-thinking-with-python.html" rel="alternate" type="text/html" title="Interactive Computational Thinking" /><published>2021-10-27T00:00:00+02:00</published><updated>2021-10-27T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2021/10/27/computational-thinking-with-python</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2021/10/27/computational-thinking-with-python.html"><![CDATA[<p>Currently, I am working as a lecturer at the <a href="https://www.cs.hm.edu/en/home/index.en.html">Munich University of Applied Sciences (MUAS)</a> for the course <strong>Computational Thinking</strong>.
We decided to use <code class="language-plaintext highlighter-rouge">Python</code> as our primary programming language.
To provide students with a textbook that covers our content and is stylistically sound, we decided to test out the Jupyter ecosystem, i.e., the <a href="https://jupyterbook.org/intro.html">Jupyter book</a> technology.</p>

<p>Furthermore, we decided to publish the unfinished book publicly.
It is a work in progress, and I will work on it during the semesters.
The book is written in German.
We may translate it into English in the future.</p>

<ul>
  <li>The book is available here: <a href="https://bzoennchen.github.io/ct-book/intro.html">Computational Thinking</a></li>
  <li>The source code of the book is available here: <a href="https://github.com/BZoennchen/ct-book">Source of the book</a></li>
</ul>

<p>We will see how our students will receive the book.
In my opinion, the <a href="https://jupyterbook.org/intro.html">Jupyter book</a> technology covers many features to write an excellent online book.
I will use the technology for other future projects.</p>

<p>If you like <code class="language-plaintext highlighter-rouge">LaTeX</code> as I do, <a href="https://jupyterbook.org/intro.html">Jupyter book</a> might also be something worth your time.
It offers similar features, and the working flow is very similar.
One can reference external sources (you can even include a BibTex file), internal sections, figures, equations, and definitions.
On top of that, the reader can execute the code directly within the book (for Python) and on Binder or another Service providing Jupyter Notebooks if the correct kernel is available.
I only tried this with <code class="language-plaintext highlighter-rouge">Python</code>, but this should also work for other languages such as <code class="language-plaintext highlighter-rouge">Java</code>.</p>

<p>It is less flexible than <code class="language-plaintext highlighter-rouge">LaTeX</code> because one is bound to <code class="language-plaintext highlighter-rouge">HTML</code>, <code class="language-plaintext highlighter-rouge">CSS</code>, and <code class="language-plaintext highlighter-rouge">JavaScript</code>.
For example, positioning tables and figures differently than intended is pretty tricky – I have given up on it.
The intelligence of <code class="language-plaintext highlighter-rouge">LaTeX</code> is also missing, e.g., no automatic hyphenation.
Aside from executing code directly within the document, another advantage is the referencing.
As a reader, It is much easier to navigate a well-referenced web page than navigate a large PDF file.</p>

<p>Overall, I quite like it!</p>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Education" /><summary type="html"><![CDATA[Currently, I am working as a lecturer at the Munich University of Applied Sciences (MUAS) for the course Computational Thinking. We decided to use Python as our primary programming language. To provide students with a textbook that covers our content and is stylistically sound, we decided to test out the Jupyter ecosystem, i.e., the Jupyter book technology.]]></summary></entry><entry><title type="html">Informatics - A Love Letter</title><link href="https://bzoennchen.github.io/Pages/2021/06/08/Informatics-a-love-letter.html" rel="alternate" type="text/html" title="Informatics - A Love Letter" /><published>2021-06-08T00:00:00+02:00</published><updated>2021-06-08T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2021/06/08/Informatics-a-love-letter</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2021/06/08/Informatics-a-love-letter.html"><![CDATA[<blockquote>
  <p>“The objection that computing is not a science because it studies man-made objects (technologies) is a red herring. Computer science studies information processes both artificial and natural.” – Peter J. Denning <a class="citation" href="#denning:2005">(Denning, 2005)</a></p>
</blockquote>

<p>For me personally, informatics is an empowering discipline - it is part of the emancipation of men. 
Its engineering quality can directly enable our fragile and limited body and mind. 
But its magic goes beyond practical use. Similar to mathematics, we discover its beauty in an abstract world. 
This Platonian world consists of fantastic, imaginative objects we can recognize, build and play with. 
In it, the problems of men are absent. 
There is no morality, no judgment, no conflict, no othering but harmony to enjoy, complex structures to discover, riddles to unravel, and logic-based creativity to get lost in.</p>

<h2 id="informatics-is-an-art">Informatics is an Art</h2>

<p>In popular culture, coding is often portrayed as something conspicuously ‘nerdy’ and alienating.
A usually white ‘<em>creepy</em>’ man writes his code by typing seamlessly and rapidly into a black terminal.
He never stops, he never interacts with other beings, and he never leaves his desk.
Of course, everything works perfectly on the first try, and no one else seems to have any clue what’s going on.
Intellectually, the programmer stands above everyone else; he is a genius, a mad scientist, or an introverted weirdo - only so important to do the necessary work and enable the ‘real’ hero.
This toxic depiction of software developers (and introverted people) is wrong, dated, and was never accurate in the first place.</p>

<p>From the outside, coding looks like the most boring thing on Earth.
This assessment is, of course, utterly wrong!
Writing programs is a beautiful, creative and interactive process.
To somebody who does it, it is the most exciting thing in the world.
It is a game of chess but much more involving because you can make up your own rules and build your own world.
Elementary entities accumulate to something bigger, something interconnected.
The degree of freedom and creativity this process of creation offers can hardly be explained or understood if one never experienced it first-hand.</p>

<p>In no way does programming start in isolation at the computer, nor can we do it seamlessly.
It is neither a strictly analytical nor a purely experimental process.
Like writing an exciting story, it is a struggle, always!
If it isn’t, we or someone else has already solved the puzzle - the exciting part has been gone.
In that case, we do not create but translate.</p>

<p>One of the fascinating facts is that, in the end, everything comes down to simple symbol manipulations, which we call information processes.
Software developers scoop, transform, and use information.
They design data structures and algorithms like architects draw construction plans.
Additionally, they have the power to build, combine, reuse and extend those objects of structured information.
They command machines of blind obedience.
The degree of control translates to a form of power and self-determination absent in the physical world.
As Linus Torvalds rightfully noted:</p>

<blockquote>
  <p>“[Phyisics and computer science] are about how the world works at a rather fundamental level. The difference, of course, is that while in physics, you are supposed to figure out how the world is made up, in computer science, you create the world. Within the confines of the computer, you are the creator. You get ultimate control over everything that happens. If you are good enough, you can be God on a small scale.” – Linus Torvalds</p>
</blockquote>

<p>In contrast to most other kinds of engineers, software developers can use a highly flexible and versatile resource.
Information can be easily exchanged among peers, reshaped, conceptually described, and analyzed.
In fact, it manipulates itself since any program is nothing more than well-structured information.
Like many other materialized ideas, structured information arises from human thoughts; they result from a mental exercise.
But the transformation of thoughts into objects of structured information is immediate.
It is like writing a poem.
Therefore, it can be an entirely personal and connecting experience to read the code, i.e., thoughts, of someone else.
Over time, one learns to appreciate good code - its structure, aesthetic, modularity, level of abstraction, simplicity, consistency, and elegance.</p>

<p>By learning different programming languages, one learns different perspectives. I love <code class="language-plaintext highlighter-rouge">Python</code>’s lists notation and that functions are first-class entities.
But I’m not too fond of the indent notation.
The success of a programming language is bound to its popularity. Do developers like it?
Is it joyful to write code? Learning different programming languages taught me something about our natural language: the language I use forms my thoughts.
If a statement can be efficiently and aesthetically pleasingly expressed in a certain way, programmers will choose that way.
And sometimes, they overuse it. Furthermore, programmers look at a problem and go through their catalog of elegant expressions to find the one that fits.
A programming language not only determines what we can express but also introduces a particular bias in how we will express it.
The same is true for our natural language. 
This seems not like a revolutionary insight, but we forget this fact in our daily life. 
A change in language might have a more significant impact on material changes than we think.
Furthermore, this also highlights a fundamental problem of the human condition: we need abstractions and standards to communicate with each other.
But by using abstractions, we distance ourselves from others.</p>

<p>If we look beyond the code, beyond ideas written down in text snippets, programs are written to be executed.
And those programs can serve almost any domain.
They control robots, harvest semantic information, control networks of devices, and simulate the natural world and other virtual worlds.
They establish communication channels, send messages with the speed of light across the Earth, compose and play music, and constantly search for structures in a rapidly increasing cloud of data points.</p>

<p>However, in the end, functionality is second to being exciting or pretty.
Even coding itself is secondary.
Figuring out how things work is the real deal.
Since everything is self-consistent and logical, you can go on and on and never stop exploring.
It is an endless stream, too immense for one lifetime.
And you are not even bound to some external logic; you can make up your own as long as it is consistent.
This consistency is a bright contrast to the corporate, social, and political world - it’s like going home to a place where everything is comprehensible, a place where you can find some truth within the bounds of its rules.</p>

<h2 id="informatics-is-a-science">Informatics is a Science</h2>

<p>As a software engineer, I want to build large architectures that process information.
I want to express myself through code.
In the world of physical objects, we have to study the properties of certain materials and the laws of physics to guarantee that our buildings do not collapse and rockets behave as expected.
But how can we specify and verify structured information?
How can we even define what we can compute?
What is computable?
Is sorting cards equally <em>hard</em> as solving a Sudoku?
Here we enter yet another world, a formal one!</p>

<p>Of course, those two worlds are never entirely separated.
Formal methods and objects, like the Turing Machine, the Lambda Calculus, logic, grammars, and automata are the mathematical backbones of informatics.
They are a particular kind of mathematically rigorous description of information manipulation (computation).
By analyzing those objects, we get to the very fundamental and interesting questions.
I was never hooked by the purpose of formal methods in software development (verification and specification).
Instead, I found them intrinsically fascinating!
It was just enough to discover these formal, therefore, clearly defined objects.
Again, it is tough to explain this attraction.</p>

<p>You start with a set of unambiguous definitions: an alphabet, a word over an alphabet, a tuple of a set of states, a transition function, etc.
And you begin to construct slightly more and more powerful objects while analyzing the properties of these objects.
You always try to keep their power controllable.
Their properties should stay computable - you enter the realm of constructivism.
You begin to recognize the equivalence of objects from entirely different fields, such as logic and automata theory.
And you form beautiful proofs about very abstract thus general statements of your formally constructed world.</p>

<p>At some point, you arrive at a formal model of any digital computer, that is, the <em>Turing Machine</em>.
Since you now have this gift, this formal model, you can analyze it in a highly abstract way.
You can define what a computer at least requires to be <em>Turing-complete</em>, i.e., to be a computer.
You can define what <em>computable</em> means, and you can even measure how many steps it takes to solve a class of problems.
You start analyzing the <em>complexity</em> of problems, such as sorting cards or solving a Sudoku.</p>

<p>For example, sorting cards (on a <em>Turing-complete</em> model) requires $\mathcal{O}(n\log(n))$ steps, where $n$ is the number of cards.
And we know that we can not do better than that.
Consequently, in the worst case, sorting cards requires always at least $c \cdot n\log(n)$ steps where $c$ is some constant independent of $n$.
Isn’t that captivating that we know this!</p>

<p>Then there is the still <strong>unanswered</strong> question if solving a Sudoku is as <em>hard</em> as checking a solution of it?
We call this</p>

\[\mathcal{NP} \stackrel{?}{=} \mathcal{P}\]

<p><em>problem</em>. Of course, we ask again in the context of <em>Turing Machines</em>.
Therefore, one might argue that this is not a scientific question because we ask for some property of some human-made machine.
I strongly disagree!
This machine is a mathematical object, and mathematics is the language of nature.
To this day, <em>Turing Machines</em> are THE model for computation (Lambda Calculus is equivalent);
a Turing Machine can simulate even quantum computers.
If nature does compute, we might even study its basic principles!
Doesn’t it feel <em>harder</em> to solve a Sudoku than to check its solution?
Isn’t there a fundamental difference?
Or isn’t finding a proof much harder than understanding it.</p>

<p>Finding a solution involves what we call creativity and intuition.
But checking it is a rather automatable process.
So if we reframe the question, we may ask about the complexity of creativity!
Since hundreds of publications falsely claimed to have solved the question, it seems to require a lot of creativity to correctly grasp the complexity of creativity.</p>

<p>What a fascinating scientific question to tackle!
We are in the realm of not natural science but similar to mathematics, a formal science.</p>

<p>Eventually, you encounter another significant problem: the <em>Halting problem</em>.
It states that there will never be a program (definable as a Turing Machine) that can test for an arbitrary program that it halts.
Understanding the theorem and its proof in-depth feels groundbreaking and infinitely satisfying.
The proof is simple and beautiful if you understand how computers, i.e., <em>Turing Machines</em>, work.
You can find a sketch of it in the appendix of this article.</p>

<h2 id="the-evolution-of-informatics">The Evolution of Informatics</h2>

<h3 id="roots-of-informatics">Roots of Informatics</h3>

<p>It is kind of funny that historically, informatics first struggled for recognition on a global scale.
In academia, this struggle has been gone.
However, in the general public’s eye, the objective and research subject of the discipline is blurred, which still leads to confusion:
yes, I am a computer scientist, but I won’t fix your computer or software bugs!</p>

<p>If we look into the history books, computer scientists had to fight to establish their field.
The discipline emerged from certain branches such as electrical engineering, physics, and mathematics.
In the 1960s, computer science comes into its own as a discipline. Georg Forsythe, a numerical analyst, coined the term.
The first computer science department was formed at Purdue University in 1962.
The first person to receive a PhD from a computer science department was Richard Wexelblat, at the University of Pennsylvania, in December 1965.</p>

<p>In Germany, informatics goes back to the Institute for Practical Mathematics (IPM) at the Technische Hochschule Darmstadt, founded around 1928.
But it required time to establish the first informatics course in the Faculty of Electrical Engineering in Darmstadt.
The first doctoral thesis was written in 1975, ten years later compared to the US.
In my hometown, the first informatics course at the Technical University of Munich was offered in 1967 at the Department of Mathematics.
In 1992, the Department of Informatics split up from the Department of Mathematics.</p>

<p>Informatics can still be regarded as relatively young compared to other well-established disciplines such as physics, chemistry, or psychology. Nonetheless, new fields split up from informatics, and they are all interlinked with one another. We have, for example,</p>

<ul>
  <li>scientific computing,</li>
  <li>computational science,</li>
  <li>information theory,</li>
  <li>and linguistics,</li>
</ul>

<p>and the list goes on.
The problem of artificial intelligence (AI) brings informatics more and more in touch with the humanities such as</p>

<ul>
  <li>philosophy,</li>
  <li>psychology,</li>
  <li>and neurosciences.</li>
</ul>

<h3 id="the-disappearance-of-classical-informatics">The Disappearance of ‘Classical’ Informatics?</h3>

<p>Within the field of informatics, there are a lot of branches one can pursue, for example:</p>

<ul>
  <li>formal methods and complexity theory</li>
  <li>programming languages and compilers</li>
  <li>design and analysis of algorithms and data structures</li>
  <li>parallel and distributed computation</li>
  <li>high-performance computation</li>
  <li>networks and communication</li>
  <li>intelligent systems</li>
  <li>operating systems</li>
  <li>cybersecurity</li>
  <li>databases</li>
  <li>data science</li>
  <li>computer graphics</li>
  <li>image processing</li>
  <li>modeling and simulation</li>
  <li>artificial intelligence</li>
  <li>software engineering</li>
  <li>architecture and organization</li>
</ul>

<p>This sprawling list of specialties indicates no longer such thing as a classical computer scientist, right? 
Nobody can be an expert in all areas - it is just impossible! Over the years, some branches lost, and others gained attraction, but most are active.
For example, we lost interest in operating systems but put more effort into investigating high-performance computation and data science.
Theoretical informatics cooled down, but there are still many critical questions unanswered.</p>

<p>Despite this abundant variety, being a computer scientist is more than being an expert in one specific field.
It is more than knowing how to build large software systems, manage networks, process data and establish a secure infrastructure.
<strong>It is a way of thinking!</strong> And no, we do not think like computers but embrace the curiosity naturally given to us human beings.
We renew the playing child within us and let it go wild to solve riddles for no particular reason. 
And I think that is one of the most human things to do.</p>

<h3 id="a-new-perspective-on-information">A New Perspective on Information</h3>

<p>In this little supplementary section, I want to talk about the resource we are working with: information.</p>

<p>As you may notice, I call <strong>computer science</strong> by the European term <strong>informatics</strong>.
But not only because I am from Europe but also because the term leans more towards <strong>information</strong> instead of <strong>computation</strong>.
Information manipulation is computation, but it emphasizes a more abstract broader definition of computation.</p>

<p>Information, as we understand it is the elimination of uncertainties but on a purely <strong>syntactical</strong> level.
This notion dated back to 1948 and was defined by Claude E. Shannon in <em>A Mathematical Theory of Communication</em>:</p>

<blockquote>
  <p>“Frequently, the messages have meaning; that is, they refer to or are correlated according to some system with certain physical or conceptual entities.
These semantic aspects of communication are irrelevant to the engineering problem.
The significant aspect is that the actual message is one selected from a set of possible messages.
The system has to be designed to operate for each possible selection, not just the one which will actually be chosen since this is unknown at the time of design.” – Claude E. Shannon <a class="citation" href="#shannon:1948">(Shannon, 1948)</a></p>
</blockquote>

<p>In the humanities, researchers have a completely different understanding of information.
They discuss cognition, representations, referencing, and interpretation in the context of information.
What does a symbol mean, and what effect or interpretation does it has?
How does data transform into information, and how do we harvest knowledge and wisdom?</p>

<p>For the purpose of information transmitted via a technical channel, a purely syntactical perspective is appropriate.
But it seems inappropriate if we discuss today’s information-driven society.</p>

<p>Nowadays, we can rapidly collect unimaginable amounts of information.
It can be processed automatically and checked for higher-level patterns that would not be discernible without technology.
We constantly transform information into a machine-readable format, which makes it, in turn, quantifiable.
But is there information that is not machine-readable, and do we dismiss it?</p>

<p>Furthermore, the interconnected world of information processes of today never forgets anything.
Incessantly, it sucks up data and floods our private and public spaces with it.
It is like a magical beast that can create amazing miracles but can also cause devastating destructions - sometimes it appears as a lovely creature, and sometimes it embodies a frightening monster.
We have to deal with it!
It is our creation - an artificial intelligence that already evaluates, categorizes, interprets, and generates information on its own.
It has to include the semantics of information. 
Otherwise, it would be difficult to call it <em>artificial intelligence</em>.</p>

<p>Since we left the task of pure information transformation a long time ago, we need the perspective of the humanities - we have to think beyond pure syntax.
In fact, we have to reconsider the term <em>information</em>, at least in our discipline.
For example, Ulrich states:</p>
<blockquote>
  <p>Where data are the raw facts of the world, information is then data ‘with meaning’.
When ‘data’ acquires context-dependent meaning and relevance, it becomes information. 
Furthermore, we obviously expect information to represent valid knowledge on which users can rely for rational action. – W. Ulrich <a class="citation" href="#ulrich:2001">(Ulrich, 2001)</a></p>
</blockquote>

<p>But even this definition seems problematic.
Is there even something like simple brute facts of the world?
All data seem to be already gathered and processed.
Therefore, information can not simply be the injection of meaning into data because data already has meaning.
It is more like the individual degree of significance differs.
What might be meaningful to me might be utterly meaningless to you.</p>

<p>Of course, we can not answer this question of an adequate definition here.
But to disregard it entirely and leave the design of interconnected information processes solely to the technicians would be a mistake.
Discovering, studying, using, influencing, and extending our interconnected world of information processing, is exciting as well as necessary.
It is part of our duties, but we should no longer encounter this beast alone.</p>

<hr />

<h2 id="appendix">Appendix</h2>

<h3 id="the-halting-problem">The Halting Problem</h3>

<p>Let me try to give you the intuition of the <em>Halting problem</em>.
For simplicity reasons, I will not explicitly distinguish between a <em>Turing Machine</em> $\mathcal{T}$ and its description (often noted by $\alpha_\mathcal{T}$).
So when a <em>Turing Machine</em> gets as input another <em>Turing Machine</em>, I mean its description (source code).</p>

<h4 id="proof">Proof</h4>

<p>Let us assume there is a <em>Turing Machine</em> $\mathcal{H}$ that takes an arbitrary <em>Turing Machine</em> $\mathcal{T}$ as input.
$\mathcal{H}(\mathcal{T})$ outputs 1 if $\mathcal{T}(\mathcal{T})$ halts, otherwise it outputs 0.
So if such a program exists, $\mathcal{H}$ is the program that solves the <em>Halting problem</em>, and $\mathcal{T}$ is an arbitrary program.
We can pick $\mathcal{T}$ as its own input because the input can be arbitrary (but finite).
So we ‘feed’ the program $\mathcal{T}$ with itself, that is, its own description/source code $\mathcal{T}$.</p>

<p>So we have</p>

\[\begin{equation} \tag{1}\label{eq:halt:1}
\mathcal{H}(\mathcal{T}) = 
\begin{cases}
1, &amp; \text{if } \mathcal{T}(\mathcal{T}) \text{ halts} \\
0, &amp; \text{otherwise.}
\end{cases}
\end{equation}\]

<p>We construct a new <em>Turing Machine</em> $\hat{\mathcal{H}}$.
$\hat{\mathcal{H}}$ is a slight modification of $\mathcal{H}$.
It does almost the opposite.
$\hat{\mathcal{H}}$ halts and outputs 1 if and only if $\mathcal{H}$ outputs 0.
Furthermore, $\hat{\mathcal{H}}$ does not halt if $\mathcal{H}$ outputs 1.</p>

\[\begin{equation} \tag{2}\label{eq:halt:2}
\hat{\mathcal{H}}(\mathcal{T}) = 
\begin{cases}
1, &amp; \text{if } \mathcal{H}(\mathcal{T}) = 0 \\
\text{undefined, i.e., loops endlessly} &amp; \text{if } \mathcal{H}(\mathcal{T}) = 1
\end{cases}
\end{equation}\]

<p><br /></p>
<div><img style="display:block;margin:auto;;height:200px;" src="/Pages/assets/images/halting-problem.png" alt="Halting Proglem" /></div>
<p><br />
Now we execute $\hat{\mathcal{H}}$ by feeding it to itself, that is, $\hat{\mathcal{H}}(\hat{\mathcal{H}})$ and analyse the result:</p>

<p><strong>It outputs 1:</strong>
Let us assume $\hat{\mathcal{H}}(\hat{\mathcal{H}}) = 1$.
Following Eq. \eqref{eq:halt:2} gives us $\mathcal{H}(\hat{\mathcal{H}}) = 0$.
But by following Eq. \eqref{eq:halt:1} this implies that $\hat{\mathcal{H}}(\hat{\mathcal{H}})$ does not halt.
After all, $\mathcal{H}$ outputs 0.
Thus, it recognizes that the analyzed program $\hat{\mathcal{H}}$ does not halt.
But if $\hat{\mathcal{H}}(\hat{\mathcal{H}})$ does not halt, it follows by Eq. \eqref{eq:halt:2} that $\mathcal{H}(\hat{\mathcal{H}}) = 1$ which leads to a contradiction.</p>

<p><strong>It outputs 0:</strong>
Let us assume $\hat{\mathcal{H}}(\hat{\mathcal{H}}) = \text{undefined}$.
$\mathcal{H}(\hat{\mathcal{H}}) = 1$ follows from Eq. \eqref{eq:halt:2} which implies that $\hat{\mathcal{H}}(\hat{\mathcal{H}})$ does halts, compare Eq. \eqref{eq:halt:1}.
But if $\hat{\mathcal{H}}(\hat{\mathcal{H}})$ halts then by following Eq. \eqref{eq:halt:2}, $\mathcal{H}(\hat{\mathcal{H}}) = 0$ which leads to a contradiction.</p>

<p>In any case $\hat{\mathcal{H}}(\hat{\mathcal{H}})$ leads to a paradox!
However, the construction of $\hat{\mathcal{H}}$ is correct if  $\mathcal{H}$ exists.
Therefore, it follows that our assumption is wrong and $\mathcal{H}$ can not exists!</p>

<h4 id="meaning">Meaning</h4>

<p>The <em>Halting problem</em> is strongly connected to the question of <strong>decidability</strong>.
It asks if, for some problem or statement, an algorithm or a proof solves the problem in a finite number of steps or proves the statement.
As we saw, the <em>Halting problem</em> is <strong>undecidable</strong>!
Any <em>Turing-complete</em> machine or system is <strong>undecidable</strong>, and there are many such systems!
For example:</p>

<ul>
  <li>complex quantum systems,</li>
  <li>the <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Game of Life</a>,</li>
  <li>airline ticketing systems</li>
  <li>the card game Magic,</li>
  <li>and, of course, almost any programming language is <em>Turing-complete</em>.</li>
</ul>

<p>There are three essential properties for a desirable mathematical system, and we may think they are fulfilled naturally.
But as it turns out, this is not the case.
We would like to have a system that is</p>

<ol>
  <li><strong>complete</strong>: any statement of the system can be proven or disproven</li>
  <li><strong>consistent</strong>: a statement can not be proven and disproven at the same time</li>
  <li>and <strong>decidable</strong>: an algorithm (proof) requires a finite number of steps to prove or disprove any statement</li>
</ol>

<p><a href="https://en.wikipedia.org/wiki/Kurt_G%C3%B6del">Kurt Gödel</a> showed that any decently functional mathematical system is either <strong>incomplete</strong> or <strong>inconsistent</strong>.
Later, he also showed that even if such a system is <strong>consistent</strong>, this can not be proven within the system.
After <a href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing</a> found a computation model, the <em>Turing Machine</em>, he showed that</p>

<ol>
  <li>many problems / systems are <em>Turing-complete</em></li>
  <li>all those systems are <strong>undecidable</strong>.</li>
</ol>

<p>This revelation crushed the mathematical landscape and ended the dream of David Hilbert and others to establish a solid mathematical foundation.
Sadly, <a href="https://en.wikipedia.org/wiki/Kurt_G%C3%B6del">Kurt Gödel</a>, as well as <a href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing</a>, one of the most brilliant minds, died tragically.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="denning:2005">Denning, P. J. (2005). Is Computer Science Science? <i>Commun. ACM</i>, <i>48</i>(4), 27–31. https://doi.org/10.1145/1053291.1053309</span></li>
<li><span id="shannon:1948">Shannon, C. E. (1948). A Mathematical Theory of Communication. <i>Bell Syst. Tech. J.</i>, <i>27</i>(3), 379–423.</span></li>
<li><span id="ulrich:2001">Ulrich, W. (2001). <i>A Philosophical Staircase for Information Systems Definition</i>.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Opinion" /><summary type="html"><![CDATA[“The objection that computing is not a science because it studies man-made objects (technologies) is a red herring. Computer science studies information processes both artificial and natural.” – Peter J. Denning (Denning, 2005)]]></summary></entry><entry><title type="html">PhD Defense</title><link href="https://bzoennchen.github.io/Pages/2021/06/05/phd-defense.html" rel="alternate" type="text/html" title="PhD Defense" /><published>2021-06-05T00:00:00+02:00</published><updated>2021-06-05T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2021/06/05/phd-defense</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2021/06/05/phd-defense.html"><![CDATA[<p>Today, I just wanna note that I finally finished my academic journey on the 21st of Mai by successfully defending my PhD thesis.
The thesis will be published very soon and I post it here on this website.</p>

<p>The following text is from the preface of the thesis and describes my personal struggles during and my perspective on the journey.</p>

<blockquote>
  <p>“The struggle itself towards the heights is enough to fill a man’s heart. One must imagine Sisyphus happy.” – Albert Camus</p>
</blockquote>

<h2 id="my-personal-journey">My Personal Journey</h2>

<p>I can pinpoint the exact moment when I decided to start my academic journey. At that time, my life was harshly disrupted by physical illness and the death of my father. Consequently, my family struggled on many levels. Despite, and probably because of the unfortunate circumstances and with my family’s blessing, I quit my job and rejoined school to get my (technical) A level. I wanted to comprehend the world more than ever and escape the meaningless play of presenting. At that difficult time, there was a financial intensive to graduate as fast as possible. Therefore, I did not join the university but the computer science program at the Munich University of Applied Sciences.</p>

<p>During my undergraduate study, my former naive belief was crushed. I realized that I would never find any definitive objective truth about the physical world. It was a rather pessimistic but also liberating philosophical revelation that there is no definitive rule to follow and no absolute meaning to fulfill. My search was no longer aimed to find an objective meaning but a personal cause to follow. I still admired studying but for other more aesthetic reasons. I loved the clarity and usefulness of formal systems, the beauty of proofs, the elegance of algorithms, and the stu- dent’s lifestyle. I observed a transforming world where computer science spread out into many branches of science, economics, and society. It was a time of playful experimentation and the deconstruction of personal barriers.</p>

<p>After I got my bachelor’s degree, I finally joined a master program at the Technical University of Munich. This continuation was enabled by the individual and financial support I received from Studienstiftung des deutschen Volkes &amp; the Max Weber-Programm. I followed my aesthetic taste and visited rather unpopular formal lectures. At that time, I realized that the source of my personal cause to move on has to be bound to someone else. Beauty and aesthetic theories were a pleasant enjoyment, but they could no longer be the primary reason to live for.</p>

<p>Surprisingly my academic journey should not stop there, since Prof. Dr. Köster invited me into her research group. There are multiple reasons why I happily accepted her invitation. The desire to understand the world was reduced to the desire to understand at least one little part of it. Furthermore, I believed that simulations would influence science, economics, and society for decades to come. And if I could make the world a little bit safer, it might be the cause I was looking for.
During my PhD, the wish to be useful and to help others was always a source of inner conflict and self-doubt. I started the whole journey to escape a world that I perceived to be shallow, empty, and driven by profit. From time to time, the scientific research project felt like this meaningless business world that came back to haunt me. Luckily I was in a superb position. Everyone tried to reduce this aspect of the scientific environment to a minimum, for which I am very grateful.</p>

<p>I think every PhD candidate has to deal with uncertainties and self-doubt – the uncertainty within science and the uncertainty of the journey’s path. There is no guaranteed progress or graduation and one is constantly confronted with his or her own limitations. These factors and the ever-present questioning voice in my head acted as a catalyst for an unavoidable existential crisis. I looked into many philosophical ideas and rearranged, and possibly reinforced, my world view and many important values – the chapter’s introductory quotes tell the tale. In my opinion, this process was only possible, because during my academic journey I received the tools to engage with difficult ideas. On the one hand, this crisis was unpleasant but on the other hand it enriched my life – a trade-off I am certainly willing to repeat. In the end, I had supportive companions that helped me to deal with all these issues.
It was not easy, and I guess it rarely ever is, but the struggle is part of the charm – as Camus said,</p>

<blockquote>
  <p>“we must imagine Sisyphus happy.”</p>
</blockquote>

<p>For me, to study is to train thoughtful thinking, perception, awareness, and tolerance. It sharpens the mind and opens up a little less ignorant new world. The ability to enjoy thinking and to share this enjoyment with other thoughtful people provides freedom and independence. It might be the greatest gift I received during my journey. Because of it and the people I met, it is a success story, and I am deeply thankful that I could have experienced it.</p>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><summary type="html"><![CDATA[Today, I just wanna note that I finally finished my academic journey on the 21st of Mai by successfully defending my PhD thesis. The thesis will be published very soon and I post it here on this website.]]></summary></entry></feed>