<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://bzoennchen.github.io/Pages/feed.xml" rel="self" type="application/atom+xml" /><link href="https://bzoennchen.github.io/Pages/" rel="alternate" type="text/html" /><updated>2024-11-23T16:13:00+01:00</updated><id>https://bzoennchen.github.io/Pages/feed.xml</id><title type="html">Bene’s Blog</title><subtitle>A blog dedicated to computer science, education, music, philosophy and technology</subtitle><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><entry><title type="html">Crises of Communication: Sustainability and Trumpism</title><link href="https://bzoennchen.github.io/Pages/2024/10/30/a-crisis-of-non-communication.html" rel="alternate" type="text/html" title="Crises of Communication: Sustainability and Trumpism" /><published>2024-10-30T00:00:00+01:00</published><updated>2024-10-30T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2024/10/30/a-crisis-of-non-communication</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2024/10/30/a-crisis-of-non-communication.html"><![CDATA[<p>I have to admit, I’m somewhat addicted to thinking about <em>social systems theory</em>, particularly the version developed by the German sociologist Niklas Luhmann (1927–1998). 
But this addiction isn’t driven by pure fascination—it’s more of a love-hate relationship. 
On one hand, seeing the world through a Luhmannian lens doesn’t make it more just or fantastic, but it does make it comprehensible. 
The chaotic state of global affairs—the crazyness of U.S. elections, the brutal devastation in the Middle East, the war in Europe, and the looming tensions brought by the climate crisis—appears senseless at times, even apocalyptic.
And yet, <em>systems theory</em> offers a framework that, paradoxically, brings coherence to this apparent madness, showing us how these outcomes emerge from the logic of <em>functionally differentiated systems</em>.</p>

<p>Faced with such overwhelming disorder, how can anyone retain a sense of sanity? 
We can protest, advocate for change, and try to amplify ‘reasonable’ voices, but as we’ll see, whether these efforts have the desired effect is largely out of our hands.
One might speculate that a Trump victory would worsen the Middle East conflict (and the conflict in Ukraine), but, as citizens of the world, we have no ballot for de-escalating global tensions.
People outside the U.S. cannot vote in American elections, and even if Kamala Harris were to win, there’s little reason to assume that U.S. policy would suddenly prioritize humanitarian investment in preserving lives and infrastructure abroad—the very foundations of a decent existence.</p>

<p>The other option is to try to make sense of the seemingly senseless, not to justify what’s happening but to deepen our understanding and foster empathy, even with those we might otherwise label as perpetrators of harm. 
To ease tensions one has to move beyond simplistic judgments of good and evil. 
Strangely enough, Luhmann’s <em>anti-humanistic</em> theory might aid in this endeavor, as it places individuals outside the bounds of society, such that we can shift our blame from <em>souls to systems</em>.
In Luhmann’s view, social dynamics operate autonomously, driven by complex systems that rarely align with individual intentions.
In many ways, Luhmann’s thinking aligns with the ideas of several twentieth-century French theorists, such as Baudrillard, Foucault, Deleuze, and Derrida.
However, his approach is less dramatic and, in a stereotypically German way, more detached and methodical.
While he shares many of the French theorists’ insights into power, society, and structural dynamics, he refrains from moral interpretations, neither labeling these dynamics as inherently good nor bad. Instead, he offers a distant, almost clinical description of society—a detached analysis that seeks to understand social mechanisms without prescribing judgment.
His perspective allows us to look past personal blame, seeing <em>dysfunction</em> not as a failure of character but as a product of systemic logic that no one person controls.</p>

<h2 id="beyond-good-and-evil">Beyond Good and Evil</h2>

<p>Clearly, attempting to make sense of complex issues should not be mistaken for rationalization.
This is an easy trap to fall into, particularly when the topic is heavily charged with moral language, where any effort to explain events can be (willingly) misinterpreted as either justification or condemnation. 
The framework within which sense-making occurs in such cases often defaults to the age-old binary of good versus evil—arguably the most effective, yet oversimplified, way to reduce complexity.
This moral framing gives us a manageable lens through which to view the world, but it also makes us blind for a more nuanced perspective, risks obscuring deeper systemic dynamics and can hinder genuine understanding of the complex interactions at play.
As a German comedian once said:</p>

<blockquote>
  <p>If you know who is the devil, your day is already well-structured.</p>
</blockquote>

<p>Most would agree that this binary division of good versus evil is overly simplistic and, at times, dangerous.
Yet, when we look toward the U.S. election or the languge used in the current horrific conflict in the Middle East, we see a striking example of this polarization in action—a place where the framing of social and political conflicts as battles between absolute good and evil has become more pronounced than ever.
Especially the situation in Palestine is extremely hard to swallow without being overwhelmed by emotions and breaking down in tears.
Here the moral dichotomy shows its face and its power.
It is so dangerous because to defeat absolute evil everything is permitted.</p>

<p>I have the luxury to shift my perspective from judging individuals as good or evil to evaluating systems as either <em>functional</em> or <em>dysfunctional</em>.
Instead of moralizing, I can try to focus on understanding the underlying structures and processes that contribute to societal challenges.
Someone directly affected by these conflicts probably cannot.</p>

<p>Thinking in terms of systems brings a certain relief from the confusion and frustration of modern life.
It helps to lessen anger and bewilderment about why our <em>life-world</em> and the decisions made within it often seem so irrational or even absurd.
Systems theory sheds light on why, even in an era where nearly everyone can participate in media production, we have neither reduced manipulation nor fostered a more reasonable dialogue. 
In many ways, the Enlightenment’s aspirations for rational discourse and universal truth have not materialized as hoped. 
The ideal of ‘Truth’—which Plato connected to the ‘Good’—has, it seems, drifted into obscurity and we are left with a spectacular hyperreality; it seems we have been fallen deep into the cave of shadows.</p>

<p>In a typcial postmodern move, Luhmann’s conclusion to the ‘lost Truth’—understood as singular objective truth—is (similar to Baudriallard) that it never existed in the first place.
As a constructivist, he avoids Plato’s concept of ‘the Truth’ and shifts his attention to the <em>production of sense</em> via different systems.
If we take Luhmann’s theory seriously, we must recognize that controlled, predictable change within society is extremely limited because each (social) system constructs its own reality.
There is no agreement on what is true or real.
Fundamentally, many problems arise from <strong>the difficulty of communication</strong>.
Adopting this perspective introduces a sense of helplessness because even with well-intentioned or radical actions, there is no guarantee that the outcomes will align with the respective intentions.
As individuals, we find ourselves positioned outside the social systems that coevolve with their environment according to their own complex dynamics.
This view is both awe-inspiring and disquieting: I admire the explanatory power of Luhmann’s theory, yet I feel a deep urge to challenge or even disprove it.
It confronts us with the unsettling notion that society evolves autonomously, beyond our direct influence, regardless of our individual ideals and aspirations.</p>

<p>I first encountered Luhmann’s theory while preparing a lecture on sustainable artificial intelligance. 
In researching future competencies, including sustainability competencies <a class="citation" href="#Brundiers2020">(Brundiers et al., 2020)</a>, I noted that systems thinking is emphasized as a fundamental skill for addressing complex issues. 
However, I doubt that Luhmann’s work appears on the reading lists or syllabi of most courses on sustainability.
Outside of Germany, he remains relatively unknown for a few reasons. His writing, e.g.,</p>

<ul>
  <li>Die Wissenschaft der Gesellschaft (The Science of Society) <a class="citation" href="#luhmann:1992">(Luhmann, 1992)</a></li>
  <li>Die Wirtschaft der Gesellschaft (The Economy of Society) <a class="citation" href="#luhmann:1994">(Luhmann, 1994)</a></li>
  <li>Die Kunst der Gesellschaft (The Art of Society) <a class="citation" href="#luhmann:1997">(Luhmann, 1997)</a></li>
  <li>Die Politik der Gesllschaft (The Politics of Society) <a class="citation" href="#luhmann:2002">(Luhmann, 2002)</a></li>
  <li>Die Gesllschaft der Gesellschaft (The Society of Society) <a class="citation" href="#luhmann:1998">(Luhmann, 1998)</a></li>
</ul>

<p>is notoriously technical and repetitive, and his theory clashes with the Western concept of the <em>sovereign individual</em> <a class="citation" href="#moeller:2011">(Möller, 2011)</a>.
Note that each title has a double meaning, e.g. <em>The Science of Society</em> discusses the social system called science but it is also a specific description written by society, hinting at the fact that there is no perspective from outside.
Consequently, <em>The Society of Society</em> is a self-description of society.</p>

<p>Additionally, Luhmann sidesteps moral language and offers no prescriptive or normative framework.
Those looking to his theory for answers on what to do will likely be disappointed.</p>

<p>Today, <em>systems thinking</em> is widely discussed as a method to grasp the complexity of global issues by focusing on wholes and relationships rather than dissecting problems into isolated parts. 
It seeks to move beyond Cartesian reductionism and the Newtonian view of linear cause-and-effect, proposing instead an anti-reductionist approach that emphasizes interdependencies, especially crucial in fields like climate science. 
Here, we are not dealing with a computable universe but with complex and chaotic systems, where non-linearity and feedback loops disrupt straightforward causal relationships. 
However, we should remind ourselves that chaos is different from randomness. 
Chaotic systems can exhibit intricate structures, yet the slightest change in initial conditions can drastically alter future outcomes, as we see with weather systems—a classic examples of chaotic behavior.
While accurate short-term predictions are challenging due to the chaotic nature of weather, long-term averages, such as the global average temperature, can be predicted with reasonable accuracy.
Unlike weather, which is highly sensitive to initial conditions, climate trends respond more predictably to persistent external drivers like greenhouse gas concentrations and solar radiation. 
However, when we consider societal factors, the picture becomes more complex, as human activities and policy decisions can significantly influence these long-term climate trends.</p>

<p>In essence, <em>systems thinking</em> itself is a kind of <em>technology</em>, and many hope it will equip us to address the <em>climate crisis</em>.
However, I believe there are distinct schools of thought within <em>systems thinking</em>, each relying on different levels of abstraction, and they are not necessarily compatible.
If systems thinking is indeed essential for tackling the <em>climate crisis</em>—a hypothesis I support—then it stands to reason that we should understand the social dimensions of the climate crisis and other global issues through the lens of one of sociology’s most sophisticated systems thinkers, that is arguable, Niklas Luhmann. His framework provides a unique approach to examining the complex, interdependent nature of social systems that underlie and influence our responses to the <em>climate crisis</em>.</p>

<h2 id="so-what-is-a-system">So what is a System?</h2>

<p>The highly abstract term <em>system</em> is so loose and overused in so many contexts and in our daily language that it has hardly any specific meaning.
We can talk about computer systems, a system of linear or differential equations, a system of thinking, systems of oppression, ecosystems and political systems.</p>

<blockquote>
  <p>[So] what is a system? 
A system is a set of things […] interconnected in such a way that they produce their own pattern of behavior over time. […] 
[T]he system’s repsonse to these forces is characteristic of itself, and that repsonses is seldom simple in the real world. – <a class="citation" href="#meadows:2008">(Meadows, 2008)</a></p>
</blockquote>

<p>For the environmental scientist Donella Meadows (1941–2001) a system is basically <strong>an interconnected set of elements that is coherently organized in a way that achieves something</strong>.
A system is characterized by three key components:</p>

<ol>
  <li><strong>Elements</strong>: The parts or components of the system, such as individual actors, objects, or variables.</li>
  <li><strong>Interconnections</strong>: The relationships or interactions between the elements, often in the form of flows of information, energy, or material.</li>
  <li><strong>Purpose or Function</strong>: The overarching goal or behavior that the system is organized to achieve.</li>
</ol>

<p>But here the trouble begins because Luhmann defines a system very differently.
It seems to me that Meadows’ definition still relies on the subject-object destinction which Luhmann wants to sublime.
He thinks in interdependent but operationally closed processes instead of things and he very much dislike the concept of an externally given ‘purpose’.
For Luhmann</p>

<blockquote>
  <p>A system is a self-referential, self-organizing set of operations that differentiates itself from its environment.</p>
</blockquote>

<p>This requires some explanation:</p>

<ol>
  <li><strong>Self-Referential</strong>: Systems create their own elements through their own operations. In fact, they are operations. In social systems, these elements are not people but <em>communications</em>. Each communication refers back to the system, reaffirming its boundaries and identity.</li>
  <li><strong>Autopoiesis</strong>: Systems are autopoietic, meaning they are self-producing. They continuously reproduce the <em>communications</em> that sustain them, distinguishing themselves from their environment. This process enables a system to maintain coherence and adapt to changes.</li>
  <li><strong>Environment and Differentiation</strong>: Systems are defined by the distinction between themselves and their environment. Luhmann stresses that the environment is everything that the system excludes, setting clear boundaries. This differentiation allows the system to maintain its <em>identity</em> while interacting with, but remaining distinct from, external influences.</li>
  <li><strong>Social Systems as Sense Making Networks</strong>: Luhmann focuses on social systems—such as organizations, institutions, the economy, the political system, and the mass media—as networks of meaning/sense making (‘<em>Sinn machen</em>’ in German). In these systems, communication itself is the fundamental element, and these <em>communications</em> build the system’s reality.</li>
</ol>

<p>In essence, Luhmann views a system as a closed network of <em>communications</em> that operates independently of external elements and functions primarily by sustaining itself through self-generated, meaningful <em>communications</em>.
If we want to be accurate we can not speak of a system without its environment because <strong>a system is the process that differentiates itself from its environment</strong> which is a circular definition—a paradox—that keeps the system (the system-environment differentiation) going.
This definition contrasts sharply with definitions based on tangible components and external goals, focusing instead on processes of <em>sense-making</em>, self-production and self-maintenance.</p>

<p>Luhmann read a lot of interdisciplinary material and borrowed from mathematics, classical systems theory, biology, cybernetics and other disciplines.
For example, he took the concept of <em>autopoiesis</em> <a class="citation" href="#maturana:1987">(Maturana &amp; Varela, 1987)</a> from biology, the concept of <em>feedback loops</em> and <em>second-order observation</em> from cybernetics and of <em>re-entry</em> and the fundamental operation of <em>differentiation</em> and <em>indication</em> from the mathematician Spancer-Brown <a class="citation" href="#brown:1969">(Spence-Brown, 1969)</a>.</p>

<p>For Luhmann, systems are <em>operationally closed</em> meaning that no system can interfer in the operation of another system.
For example, the economic system communicates via payments and there is almost no way that the political system can interfer in it.
Of course, the political system can observe these payments and can try to regulate them but only indirectly.
It can pass laws which the legal processes.
The economic system will observe this—it will ‘digest’ it—and evolve with its environment (which contains the political system).
Therefore, systems are <em>cognitively open</em> meaning that they can observe (based on their own logic) their environment which contains all the other systems.
They take everything in what they are able to digest and use it to continue their opertions, that is, their <em>autopoiesis</em>.
An analogy is a human body that takes in food and digist it in the way it is able to.
Neither does the food determine how the body is affected nor does the body can make anything it wants from the food.
The process is contingent.</p>

<p>To reduce complexity social systems work on simple <em>binary codes</em> under which they <em>differentiate</em>.
The legal system interprets actions as legal or illegal but doesn’t engage with the healthy/unhealthy distinctions from the health system.
The following table shows more of these codes:</p>

<table>
  <thead>
    <tr>
      <th><strong>Social System</strong></th>
      <th><strong>Binary Code</strong></th>
      <th><strong>Description</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Economy</strong></td>
      <td>Payment / Non-payment</td>
      <td>Decisions are guided by whether a transaction involves payment, focusing on economic exchanges.</td>
    </tr>
    <tr>
      <td><strong>Politics</strong></td>
      <td>Power / Non-power</td>
      <td>Concerned with the distribution and exercise of power, focusing on who has authority and control.</td>
    </tr>
    <tr>
      <td><strong>Law</strong></td>
      <td>Legal / Illegal</td>
      <td>Operates on legality, determining if actions or behaviors align with established legal norms.</td>
    </tr>
    <tr>
      <td><strong>Science</strong></td>
      <td>Truth / Falsehood</td>
      <td>Guided by the pursuit of truth, evaluating claims based on their validity and scientific evidence.</td>
    </tr>
    <tr>
      <td><strong>Religion</strong></td>
      <td>Immanence / Transcendence</td>
      <td>Focuses on distinctions between the sacred (transcendent) and the profane (immanent).</td>
    </tr>
    <tr>
      <td><strong>Education</strong></td>
      <td>Success / Failure</td>
      <td>Concerned with the effectiveness of learning and teaching, evaluated by success in achieving educational goals.</td>
    </tr>
    <tr>
      <td><strong>Health</strong></td>
      <td>Healthy / Unhealthy</td>
      <td>Operates based on the state of health, determining whether a body or behavior is healthy.</td>
    </tr>
    <tr>
      <td><strong>Mass Media</strong></td>
      <td>Information / Non-information</td>
      <td>Distinguishes between what is considered newsworthy (informative) versus uninformative content.</td>
    </tr>
    <tr>
      <td><strong>Art</strong></td>
      <td>Fitting / Unfitting</td>
      <td>Focused on e.g. aesthetic value, distinguishing what is perceived as beautiful or aesthetically valuable.</td>
    </tr>
  </tbody>
</table>

<p>The specific code a system operates under is less important than the fact that each code differentiates one system from others.
For instance, Luhmann struggled to pinpoint a definitive code for the art system, as its operations are complex and multifaceted.
He proposed several possibilities, including beautiful/ugly, coherent/incoherent, new/old, and fitting/unfitting.</p>

<p>Each code of a system gives the system its ‘character’ and consequently its operational specificity and functional closure.
The <em>exclusivity</em> of the <em>binary code</em> ensures that each system maintains its autonomy and operates independently, even when interacting with other systems.
<em>Operational closure</em> means that each system can only process information according to its own internal logic, thus keeping it <em>closed</em> to other systems’ codes and distinctions.</p>

<p>Of course, further distinctions within a system are possible.
For example <em>reputation</em> is an important distinction within science.
While not a binary code in Luhmann’s strict sense, it is significant within the scientific community as it affects how research and findings are perceived, valued, and disseminated.
Reputation can influence which scientists’ work is taken seriously, whose research is funded, and which publications are more widely read and cited.
However, it does not drive the core distinction of truth/falsehood; rather, it shapes the social hierarchy, credibility, and visibility within the scientific community.</p>

<p>Luhmann’s concept of <em>re-entry</em> (borrowed from <a class="citation" href="#brown:1969">(Spence-Brown, 1969)</a>) is a mechanism, allowing a system to reflect on itself by reintroducing its primary binary code within its own operations. 
Thus, this is an inherently recursive relation.
<em>Re-entry</em> enables a system to apply its guiding binary distinction not only outwardly (to its environment or other systems) but also inwardly, to its own internal processes and <em>communications</em>. 
This is crucial in complex systems, like science, where re-entry enables self-reference and internal differentiation.
Science can use the truth/falsehood distinction to evaluate not only external hypotheses but also its own standards, research paradigms, and accepted theories.
Another more familiar example is the media which reports on itself.</p>

<p>Another important Luhmannian concept that is stronlgy connected to <em>re-entry</em> and orignated from Heinz von Foerster (1911–2002) and Margaret Mead (1901–1978) <a class="citation" href="#foerster:2003">(von Foerster, 2003)</a> is <em>second-order observation</em>.
<em>Second-order observation</em> is facilitated by re-entry, as it allows the scientific system to reintroduce its primary distinction, i.e. truth/falsehood, internally.
It refers to observing observations rather than simply observing objects or phenomena directly.
This concept is crucial for complex systems as it allows them to recognize and reflect on how they construct their own distinctions and interpretations.
In science, second-order observation enables scientists to observe not only external phenomena but also the methods, theories, and interpretations of other scientists.
This includes observing how truths are constructed within the scientific community and scrutinizing the frameworks, biases, and assumptions underlying those constructions.
But it also includes how a specific scientist or science lab is being observerd.
In this context, <em>reputation</em> is effectivly a measure of how a scientist is seen by other scientists.
It furhter reduces complexity by accumulating the observation of others.
I do not have to read and carefully analyse every paper of a specific researcher to find out if his or her research is trustworthy, i.e. if it is good research under the truth/falshood code.
In complex environments, <em>second-order observation</em> helps systems like science to deal with uncertainty and complexity.
Rather than aiming for <strong>absolute certainty</strong>, science can adapt by recognizing different observational frameworks, revisiting previously accepted truths, and acknowledging limitations in current knowledge. 
This adaptive flexibility, achieved through <em>second-order observation</em>, is vital for science’s resilience and continued evolution.
Today, second-order observation is everywhere, be it in the form of the housing or stock market, the social phenomena of <em>reaction videos</em> or the fact that we are all invested in our profiles, that is, <strong>we are invested in how we are seen/observed by an anonymous peer</strong> <a class="citation" href="#moeller:2021">(Möller &amp; D’Ambrosio, 2021)</a>.</p>

<p>In the mode of authentic identity construction, second-order observation appears as the production of ‘fake’ because the focus shifts from who one <strong>is</strong> to how one <strong>is observed</strong>.
Paradoxically, as we transition from <em>authentic</em> to <em>profilitic</em> identity construction, the most important goal becomes to be observed as authentic.
This phenomenon is evident in the behavior of streamers, social media influencers (including figures like Trump and Musk), as well as companies and even institutions such as universities.
All of these entities are heavily invested in how they are observed, striving to appear authentic and real, rather than fake.
However, if we ask the existentialist question—<em>What is your ‘true self,’ your ‘authentic being’?</em>—we encounter paradoxes and articulation problems.
Luhmann provides an uncanny response to this authenticity problem, reminiscent of Kant: What one is, is always already a description or observation of a system, and therefore, a selection or differentiation—choosing one thing over another.
This includes self-observation, which is itself a re-entry of the system. In this case, the psychic system re-enters itself.
Through Luhmann’s perspective, we are left with the impossibility of being truly authentic. In some sense, we (and other systems) are always already pretending.
However, Luhmann crucially does not view this as inherently negative. There is nothing—especially morally—wrong with being invested in how one is observed.
The problem arises when this focus on appearence no longer aligns with the system’s function.
For example, when the pursuit of appearing as a trustworthy scientist contradicts the truth/falsehood distinction that underpins the operation of science.</p>

<p>But what exactly is <em>observation</em>?
For Luhmann, every act of <em>observation</em> has two essential steps: <strong>distinction</strong> and <strong>indication</strong> (also borrowed from <a class="citation" href="#brown:1969">(Spence-Brown, 1969)</a>).
The system first creates a <em>distinction</em> (e.g., legal/illegal in the legal system) and then <em>indicates</em> one side of that distinction. 
This act of <em>indicating</em> one side of a <em>distinction</em> allows the system to focus on what it deems relevant or meaningful while leaving out what is not.
For instance, the economic system distinguishes between payment and non-payment and then indicates whether a transaction falls into one category or the other.</p>

<p>Luhmann also uses <em>feedback loops</em> but in a more complex, indirect way to explain self-referential and <em>autopoietic</em> (self-producing) processes within social systems.
<em>Feedback loops</em> enable systems to observe and respond to their own operations and their environment without sacrificing their internal logic or autonomy.
A system produces <em>communications</em> and then feeds those back into itself as input, creating a recursive process. 
For instance, the scientific system continually generates new research findings that become part of its ongoing discourse, which shapes further research questions and methods.
This recursive process enables a system to build on its own operations and maintain continuity over time.
<em>Feedback loops</em> help systems to learn from past operations and adjust future <em>communications</em>. 
However, instead of direct feedback that leads to specific, immediate corrections (as in a thermostat, for instance), feedback in Luhmann’s theory involves observing patterns over time and <em>adjusting structurally</em>.
For instance, the legal system may notice shifts in societal values based on case outcomes or public reactions and eventually adjust interpretations of the law, but it does so in a way that remains consistent with its legal/illegal <em>binary code</em>.
Through <em>repeated feedback</em>, systems can detect trends in their environment (e.g., shifts in public opinion or technological advances) and adapt their operations in response, but only when those trends become relevant within the system’s own code.
Despite the use of <em>feedback loops</em>, systems remain <em>operationally closed</em>.
Feedback is processed in terms of the system’s unique code, meaning that only information relevant to that code is taken in. 
For instance, if the economic system receives feedback from the political system, it only integrates that feedback if it pertains to the payment/non-payment distinctions. 
This allows each system to interact with its environment while preserving its autonomy and self-referential logic.
Feedback loops help systems manage the complexity of their environments by selectively processing information.
Each system filters out what is irrelevant to its operations, thereby creating <em>blind spots</em>.</p>

<p>Luhmann’s concept of <em>structural coupling</em> (borrowed from <a class="citation" href="#maturana:1987">(Maturana &amp; Varela, 1987)</a>) describes how different social systems develop stable, interdependent relationships with their environment or other systems without losing their <em>operational closure</em> or <em>autonomy</em>.
<em>Structural coupling</em> is essential for maintaining a productive relationship with various other systems.
For example, science and politics are structurally coupled when scientific research informs policy decisions, while political priorities influence the direction and funding of scientific research. 
Despite this interaction, both systems remain <em>operationally closed</em>: science focuses on truth/falsehood, and politics operates on power/non-power.
Another example: the economic system and the political system may engage in <em>structural coupling</em>, where economic data (like inflation) affects political decisions (like interest rate changes). 
<em>Feedback loops</em> are crucial for <em>structural coupling</em> since they allow each system to remain sensitive to changes in the other system without changing its fundamental operations or logic.</p>

<p>The last term we have to discuss is the term maybe most important, and that is <em>communication</em>.
As a computer scientist I understand communcation using Shannon’s framework <a class="citation" href="#shannon:1948">(Shannon, 1948)</a>, that is, a transfer of information over a error-prone or noisy channel.
But this is not what Luhmann understands as <em>communication</em>.
For him, <em>communication</em> is not merely the transfer of information between individuals (or machines). 
Instead, it is a self-contained social process that occurs within and is produced by social systems, with <strong>individuals seen as part of the environment rather than as agents within the system</strong>.
According to Luhmann, it is a three-part process of three interdependent elements:</p>

<ol>
  <li><strong>Information</strong>: The content or ‘<strong>what</strong>’ of communication, which could be new data, knowledge, or ideas relevant to the system.</li>
  <li><strong>Utterance</strong>: The ‘<strong>how</strong>’ of communication, which includes the form, manner, or medium through which information is expressed. This could be spoken language, writing, or nonverbal cues, depending on the medium and context. E.g. a payment is a communication.</li>
  <li><strong>Understanding</strong>: The receiver’s interpretation of both the information and the utterance. Understanding is crucial, as it determines whether and how the communication is taken up within the system. It is the <strong>differentiation between information and utterance</strong>.</li>
</ol>

<p>For Luhmann, communication only ‘happens’ if all three elements are present. It’s not just about sending information; it’s about how information is expressed and then understood within a particular context.
<em>Communication</em> is not generated by individuals but by the system and is itself autopoietic, meaning it is self-producing and self-sustaining.
<em>Communication</em> is inherently selective; it involves making choices about what information to include, how to present it, and how to interpret it. 
This selectivity creates <em>blind spots</em>, as each communication inherently excludes other possible meanings.
It is based on the concept of <em>double contingency</em>—the idea that each party in a communication anticipates and adjusts to the other’s responses.
Social systems manage this <em>contingency</em> through established expectations.
For example, in the legal system, there is an expectation that communications follow the legal/illegal code, which guides interactions between lawyers, judges, and citizens and maintains coherence in legal decisions.
Or take the education system.
If I start singing in my lecture students would be quite confused.
Since in Luhmann’s framework every system operates by its unique logic, <em>communication</em> can <strong>not</strong> be about transferring <strong>objective</strong> information; it is about processing meaning/sense which depends on the ‘processor’, i.e. the system. 
Each <em>communication</em> within a system adds to the meaning that the system produces.
For instance, in the scientific system, each new theory or finding creates meaning within the context of the truth/falsehood code and is interpreted within that framework.
<strong>Systems thus continuously build their own specific reality</strong>, shaped by the types of meaning they process through communication.</p>

<p>Consequently, if we take Luhmann serious, we arrive at the revelation that there is not one ‘really real and objective reality’ but that there is a <strong>plurality of realities</strong>;
that there is not one controlling system that steers all the others but that there is anarchy in society;
that we are not in control but that society is <strong>out of control</strong>;
that there is not one objective truth but systemic interpretations;
and maybe most importantly: that there is no outside of society, no view at the whole because <strong>any indication of something requires a distinction from something else</strong>.</p>

<h2 id="part-i-a-crisis-of-non-communication">Part I: A Crisis of Non-Communication</h2>

<p>One area where Luhmann’s theory seems to make unsettlingly accurate sense is the <em>climate crisis</em>—that is, the accelerating destabilization of the climate system.
We see how Luhmann’s framework reveals the challenges of a complex, multi-systemic problem. 
Each social system—politics, economy, science, and media—observes the climate crisis from within its own operations and distinctions.
Science operates on a truth/falsehood basis, producing reports on climate change’s reality and projections, while politics, operating on power/non-power, assesses climate issues according to political priorities, public opinion, and election cycles. 
The economic system, structured by payment/non-payment, may respond to climate science only insofar as it impacts financial markets, investments, or regulatory demands.</p>

<p>The <em>climate crisis</em>, however, does not ‘belong’ to any one system.
Instead it spans across systems but is refracted through each one’s unique code.
No single system can comprehensively address the crisis because its complexity exceeds the logic of any one system’s operations.
The climate crisis is precisely so problematic for the communication network we call society because each system deals with its environment by reducing the environment’s complexity.
Furthermore, there is essentailly no <em>climate communcation</em> ‘happening’, because (to the best of my knowledge) there is no <em>social system</em> that operates on a code that leads to the observation of the climate or the earth’s ecosystem.
One might step in and argue that science certainly observes the climate but that is not really the case if we use Luhmann’s definiton of observation and communication.
Science, despite its close engagement with ecological and climate issues, operates on a fundamentally different basis than a (hypothetical) climate-focused system.
While many scientists care very much about the climate and the survival of human beings, science operates under the truth/falshood distinction.
Its observation of the climate does not directly lead to climate or political activism, or an economic transformation but to more truth/falshood distinction;
to research and funding opportunities and the building up of reputation.
In fact, some scientist such as Ulf Büntgen are concerned about scholars who are at the same time activists because they might damage the operation of science <a class="citation" href="#buentgen:2024">(Büntgen, 2024)</a>, others argue against these worries <a class="citation" href="#eck:2024">(van Eck et al., 2024)</a>.
From a system’s viewpoint, we should not attribute to much influence to the individual since, again, there is no individual within society.
Science can ‘use’ the respective psychic system as well as activism.
At the same time, while activsim cannot steer science, science digest/observes activism by its own operations to preserve its operating.</p>

<p>Similarly, the political system interprets the <em>climate crisis</em> through its own operational code of power/non-power, using it as an opportunity to gain influence and public support. 
For example, in Germany, the Green Party views the climate crisis as a platform to expand its political reach.
They advocate for environmental policies that resonate with their voter base.
However, they (as a system, not as individuals) do this to gain power and not to solve the climate crisis.
Other parties may leverage the crisis in the opposite direction, appealing to constituents who prioritize economic stability over environmental reform.
Yet, even if the Green Party succeeds in passing policies aimed at accelerating economic transformation, it cannot directly control whether the economic system will fully implement these changes. 
This limitation arises because each system—politics and the economy—operates autonomously according to its own logic.
For politics to dictate economic outcomes would imply that the political system could override the economy’s fundamental payment/non-payment distinction, which, according to Luhmann, is structurally impossible.
Note that this is not a critique of the members of the Green Party which might very much care and belief in the values they display—they might be honestly invested in how they are being observed.
I do not consider individuals or people but systems.</p>

<p>The climate crisis illustrates how <em>structurally coupled</em> systems face limits in their coordination.
Each system’s response to climate issues is conditioned by its own operations, preventing unified action despite the existential threat posed by the destabilizing climate.
As Luhmann’s theory reveals, social systems are inherently self-referential and cannot simply ‘combine’ their functions. 
Thus, the climate crisis may persist without cohesive action precisely because <strong>no system is structured to address an issue that transcends its operational boundaries</strong>.
In fact, if systems cross boundaries, we call it corruption, for example when the economy system pays for a football goal or for a law or if a scientist makes false claims to strengthen a certain political ideology.</p>

<p>This fragmentation of responsibility means that no single system is inherently designed to address global, cross-cutting issues like the climate crisis.
Each system approaches climate issues only insofar as they relate to its own logic:</p>

<ul>
  <li><strong>Science</strong> seeks truth and thus investigates the mechanisms, causes, and projected impacts of climate change.</li>
  <li><strong>Politics</strong> operates on power/non-power, framing climate policies in terms of public support, regulatory reach, and political gain or loss.</li>
  <li><strong>Economy</strong> focuses on payment/non-payment, assessing climate initiatives based on profitability and market viability.</li>
  <li><strong>Media</strong> works with information/non-information, spotlighting climate issues based on newsworthiness rather than scientific rigor or policy relevance.</li>
</ul>

<p>Systems only engage with climate issues when these issues align with their internal priorities.
Science can produce overwhelming evidence of climate risks, but if political decisions are driven by short-term voter approval, economic costs, or geopolitical interests, the full implications of scientific knowledge may not translate into concrete action.
Political decisions are often informed by scientific findings but are ultimately filtered through the political logic of power/non-power.
Economies can adopt sustainable practices, but often only when such practices promise financial returns.
This misalignment is evident in the delays or dilution of climate policies, where political and economic interests often override scientific findings.</p>

<p>Luhmann’s theory suggests that issues of this magnitude may require a dedicated system with its own <em>binary code</em>—such as ‘sustainable/unsustainable’ or ‘ecologically balanced/unbalanced’—to assess and act on climate issues directly. 
Social systems are so immensly effective (with respect to their function) because they reduce complexity by operating under a rather simple binary code.
A new <em>sustainable system</em> could facilitate large enough irritations that resonate within other systems such that standards, goals, and measures across all systems are implemented (by themselves) in such a way that align with ecological stability and sustainability.
Although hypothetical, this system would prioritize ecological concerns by constructing ‘sustainable communication’.
Of course, the problem is: How can such a communication be possible without interferring in, e.g. economic communication?</p>

<p>Howsoever, the time is up and I have almost no hope that such a system will suddenly emerge.
If it does it should happen via the seperation by operational closure similar to how, for example, art was able to separate itself from religion.
The only other option, using Luhmann’s framework, is to try to align all the systems in such a way that if they operate according to their logic, they also operate (at least close) to the logic of such a hypothetical <em>sustainable system</em>.
Caring about the earth’s ecosystem and the climate has to be financially profitable;
it has to lead to power for politicians;
it has to lead to funding and furhter research in science;
and it has to be a spectacle for the media to cover;</p>

<p>Naturally, we might see it as hypocritical when a company adopts sustainable practices primarily to increase profits rather than out of genuine concern for the environment.
We are back to the <em>authenticity problem</em> mentioned earlier.
And, indeed, companies may choose to appear sustainable rather than enact substantive changes if it proves more profitable.
This dynamic holds for other issues as well, such as diversity and inclusion—and deep inside we all know it.
However, from a systems theory perspective, it may be more productive to move beyond <em>moral judgments</em> about individuals, pointing to them as being hypocritical, virtuous, or evil and instead to focus on  <em>systemic realities</em>.</p>

<p>In the economic system, sustainability, diversity, and other social values are interpreted through the code of payment/non-payment; the system evaluates decisions based on profitability rather than intrinsic ethical value.
We may not like it but that’s the <em>reality of the economic system</em>.
For example, instead of hoping for an <em>humanistic turn</em> of the economic system, it might be more effective to achieve social progress for disabled people by letting the economic system ‘know’ how these people are financially important.
While individuals within a company might personally care deeply about these issues, this personal commitment does not translate into the company’s operations, as employees are part of the system’s environment, not its core functions.
People care, systems observe and operate on their own terms.</p>

<p>In this light, <em>truthfully pretending</em>—adopting sustainability practices for economic gains—can still yield positive outcomes.
From the perspective of systems theory, the motivations behind these actions matter less than the fact that they result in more sustainable practices, which in itself contributes to broader societal goals.
This does not imply that public outrage about the state of affairs is misguided.
On the contrary, if outrage <em>irritates</em> systems in ways that make sustainable practices more profitable for companies, it can drive meaningful change.
However, outrage can also produce unintended effects.
For instance, the media, which constructs a shared reference reality that shapes public discourse, may find it more sensational to focus on the ‘unlawfulness’ of protesters.
This framing can prompt the political system to respond by mobilizing power against the protests, potentially reinforcing the very practices that climate advocates aim to change.
Especially when a system’s ability to continue its autopoietic operations is threatened, a strong reaction can be expected.</p>

<p>These nonlinear and indirect effects, often amplified through feedback loops, illustrate the unpredictable and uncontrollable nature of systemic interactions. 
In Luhmann’s terms, feedback loops create complex dynamics within and between systems, making it difficult to foresee or control the outcomes of public reactions, even when intentions are clear.</p>

<h2 id="part-ii-a-crisis-of-over-communication">Part II: A Crisis of Over-Communication</h2>

<p>Luhmann does not oppose elections, but he challenges the common assumption that they express <em>the will of the people</em>. 
This skepticism follows directly from his understanding of society as an uncontrollable network of interdependent social systems, each operating according to its own logic. 
Society, in Luhmann’s view, evolves organically—like a self-reproducing system—and cannot be directly steered or micromanaged by politics.</p>

<p>Politics, in this context, plays a specific role: it makes collectively binding decisions.
Yet these decisions must then be processed and implemented by other systems.
For instance, the legal system creates laws to enforce political decisions, while the economy and even religion may shape how these decisions are interpreted and realized in practice.</p>

<p>Consider the example of childbirth. 
How do different social systems contribute to this event? 
The political system might legislate that abortion is legal.
Religious beliefs may influence whether a person opts for or against it. 
Socio-economic conditions affect whether one can afford to raise a child, and the health system plays a crucial role in medical support. 
Political decisions matter, but they exist within a web of other systems, each with its own influence, sometimes more decisive than politics itself.</p>

<p>The popular narrative around elections is that they make ‘the people’ the foundation of all political power. 
After the election, politicians—servants of the people—are supposed to put the will of the people into action. 
However, according to Luhmann, the idea that the people are the source of all power in a liberal democracy is a myth. 
Instead, the people function more as an audience, much like in a talent show, where they get to elect a winner at specific, pre-determined moments, but do not control the larger system. 
The ‘show’ of politics is a much larger, self-sustaining system, where politicians, the state, and the voters all play their roles and influence one another, but the system ultimately serves itself.</p>

<p>In democratic politics, the state, politicians, and voters are mutually interdependent, each contributing to the reproduction of the political system. 
Elections, therefore, are <em>symbolic procedures</em> in Luhmann’s view.
They confer legitimacy on the political system by symbolically invoking <em>the will of the people</em>, but in reality, such a unified will does not exist.
For example, many people abstain from voting, and a significant portion of the population may not be eligible to vote at all.
Moreover, election outcomes are shaped by arbitrary rules—they are contigent.
In the U.S., for example, the popular vote does not directly determine the outcome; instead, the electoral college decides the presidency, often making a few swing states the key deciders. 
In Germany, government coalitions are typically formed after elections, yet no single voter casts a ballot for the specific coalition that ends up governing.
These complexities highlight how elections, while significant, are far from a straightforward expression of a unified popular will.</p>

<blockquote>
  <p>How did we vote? But did we really vote, or did the people just roll the dice? […] What individuals actually think, if anything at all, when they mark ballots, remains unknown. This alone suffice not to […] conceive of public opinion as the general expression of the opinions of individuals. – <a class="citation" href="#luhmann:2002">(Luhmann, 2002)</a></p>
</blockquote>

<p>Elections seem to achieve the impossible: merging the diverse, individual wills of the people into a singular, cohesive ‘general will’.
For Luhmann, this process is almost magical, as it provides the symbolic foundation upon which liberal democracy rests.
Elections create the <em>illusion of unity and consensus</em>, giving legitimacy to political decisions that, in reality, are based on a highly fragmented and complex societal landscape.
However, as previously mentioned, Luhmann has no problem with this illusion. 
In his view, <em>the miracle of democratic elections</em> is perfectly acceptable—provided it functions effectively for all involved and helps stabilize the political system.</p>

<p>In fact, the <em>symbolic power of elections</em> is essential to maintaining social order, as it grants politics a legitimate mandate without requiring every individual’s direct influence on policy decisions. 
This symbolic function of elections allows the political system to operate independently, without collapsing under the weight of countless individual preferences.
Elections serve to renew the legitimacy of the political system periodically, preventing it from stagnating, while also setting boundaries within which political decisions are accepted, even by those who disagree with the outcomes.</p>

<p>For Luhmann, it is less important that elections genuinely express a collective will, which he considers a fiction, and more important that they fulfill their function: they create a momentary sense of unity and provide a mechanism for the orderly transition of power seemingly melting the individual will of ‘the people’ into the general will. 
As long as elections maintain public confidence in the political process and prevent <em>systemic breakdown</em>, they serve their purpose, not by conveying truth but by ensuring continuity. 
In this sense, elections are not a search for truth but a pragmatic solution to the challenge of political legitimacy in a complex, functionally differentiated society.</p>

<p>Viewing the election as a performance—or as Baudrillard might call it, <em>hyperreality</em>—feels particularly fitting for the spectacle that Americans witness during the election weeks. 
Do these debates between Trump and Biden, or Trump and Harris, genuinely convey new insights or substantive ‘truths’? 
Or are Americans, in many ways, simply the audience to a grand show, swept up in the drama, spectacle, and narrative arcs that these events offer?</p>

<p>There is, however, something distinct and potentially perilous about the American context.
In the U.S., the problem for the political system seems to lie in the crumbling of the illusion of unity and consensus.
The illusion is increasingly undermined by escalating economic and social inequalities.
As living conditions deteriorate for many, regardless of who they vote for, it becomes glaringly apparent that there is no singular ‘general will’ guiding political outcomes. 
The democratic promise that elections merge the will of the people into collective decisions feels hollow when so many are left feeling unrepresented and disillusioned.</p>

<p>This breakdown makes it clear that those voting for Donald Trump are not simply misguided or irrational. 
Many voters feel disconnected from a political system they perceive as indifferent to their realities and struggles.
As one interviewee put it:</p>

<blockquote>
  <p>I agree that Trump is from the billionaire class and that’s all he’s going to work for.
It basically comes down to the lesser of the two evils right now.
I think about the four years he was president.
In my opinion he’s the world’s best crime boss.
And then you see people posting ‘in the arms of Jesus’ like ‘I was persecuted too’, and I think what a bunch of bullcrap.
The system is so captured that you need a crime boss to get out of it.
If it wasn’t Trump I would love to have a working familiy candidate who stands up for the little guy.
The middle class, from day one of this United States, has built the United States, and we are the ones that always get shit on.</p>
</blockquote>

<p>But there’s a second factor at play: a candidate who is so absurd, so obscene, that he disrupts the expected script of political ‘producers’.
Because Trump is taken seriously he (unconsciously) discloses the reality of elections and the political system.
From a systems theory perspective, a showman does what one shouldn’t do: making the big show, the big stage visible and dismanteling one myth but also replacing it with another, far more dangerous one: <em>the deep state</em>.
While the <em>illusion of unity and consensus</em> gives the system stability, Trump’s <em>deep state myth</em> does the opposite and that is the reason why he is dangerous for the political system and probably for the functional differentiated society.</p>

<p>As the interviewee described, Trump is perceived as a <em>red button</em>—a tool voters can press to create enough disturbance within the system that it is forced to respond.
Perceived <em>as the world’s best crime boss</em> any accusation or scandal only feeds into Trump’s persona. 
Trump clearly wants to cross systems’ boundaries.
The interviewee’s perception might not be far from the truth, howerver, if such an irritation is desirable is very questionable.
The level of desperation in the U.S. has become so acute that many are willing to risk an extreme disruption, effectively pushing for an ‘over-irritation’ of the system, hoping it will provoke meaningful change or even a systemic collapse.</p>

<p>In this way, Trump embodies what Luhmann might call an agent of second-order observation—someone who leverages his own media persona to observe and exploit the expectations of the political system, creating feedback loops that intensify rather than stabilize.
While Luhmann argued that elections are primarily a symbolic show, the outcomes of this particular show may indeed carry existential significance.
The stakes are high, and the effects of a Trump victory or defeat could trigger unpredictable reactions. 
What we are witnessing is both dangerous and volatile, and it exemplifies how systemic irritations—if strong enough—can shake the foundations of even the most stable-seeming structures.</p>

<h2 id="criticism-of-luhmanns-theory">Criticism of Luhmann’s Theory</h2>

<p>Luhmann’s theory is not immune to criticism, and, by its own logic, it necessarily contains blind spots. 
One of the most common criticisms is that his theory removes individuals from the core of social analysis.
By focusing on self-referential systems rather than human actors, Luhmann places individuals in the environment of society, not within it.
Human agency, emotions, and individual motivations are neglected and the role of intentional human actions and collective decision-making in shaping societal evolution is minimized.</p>

<p>In addition, its theory lacks a normative direction or ethical foundation.
By avoiding moral or ethical judgments, Luhmann’s systems theory does not offer guidance on what should be done, especially concerning social justice, inequality, or human rights.
His theory seems to be indifferent to power imbalances and fails to address issues of accountability and responsibility within social systems.</p>

<p>Also Luhmann’s concept of <em>operational closure</em> has been criticized for overemphasizing system autonomy.
According to those critics, his perspective ignores the deep interdependencies and interconnectedness of social, economic, and political systems.
They contend that while systems may have unique operations, they are often influenced by each other in ways that Luhmann’s model underestimates.
Marxist thinkers argue that although Luhmann includes the economic system as one of society’s core functional systems, he does not give sufficient attention to the economic forces shaping society, especially those tied to capitalism.
By focusing primarily on the communication logic of payment/non-payment, Luhmann’s theory fails to address the structural inequalities and exploitative dynamics inherent in modern economic systems.</p>

<p>Because Luhmann’s theory emphasizes the self-reproduction of systems, it suggests that systems are largely resistant to intentional change from within.
This perspective might downplay the role of social movements, activism, and democratic engagement as forces that can drive systemic transformation.
Futhermore, by treating power as a form of communication (very different from Foucault’s approach) within the political system rather than a force that operates across systems, critics argue that his approach obscures how power dynamics influence interactions between systems and shape societal outcomes.</p>

<p>My current opinion is that Luhmann’s theory is excellent for the sense-making of society.
It can even clear the fog for making better intentional decisions but it can not provide us with suggestions of what we should do.
But if people want to change oppressive systems, they should know and understand their ‘adversary’.</p>

<h2 id="treatment-of-an-illness">Treatment of an Illness</h2>

<p>In their book <em>The Tree of Knowledge</em> <a class="citation" href="#maturana:1987">(Maturana &amp; Varela, 1987)</a> Maturana and Varela very briefly discuss society.
They think that, unlike cells serving the whole organism, a functioning society should prioritize the needs and well-being of the individual—the orientation should be reversed.
I totally agree.
But can we bring their humanistic viewpoint in line with Luhmann’s <em>anti-humanistic</em> theory?
That would be nice but is probably not in the spirit of the author.
While both views address the organization of society, Maturana and Varela focus on an ideal in which society exists for the benefit of individuals, whereas Luhmann’s theory suggests that society, as a system, operates independently of individual well-being.
We could evaluate societies (across time and space) according to the degree they served individual well-being and then learn from the lessons to irritate our society in such a way that it becomes more <em>functional</em>, in Maturana’s and Varela’s sense of the word.
However, operationalizing this perspective would face challenges within Luhmann’s framework.</p>

<p>As a scientific theory communicated by the science system, it is a theory of society that society produced about itself—a quintessential example of second-order observation.
The individual—the person, psychic system, and living body—we identify as Luhmann existed only as part of the environment of the social systems he studied.
According to his own theory, his view, as every view, cannot be the objectively correct description of society.
Therefore, I think, we should not take his ideas as absolutes but as irritations and sense-making foundation.</p>

<p>If the individual is not the center of social structures and dynamics, the impossibility of controlled action might give some relief on an individual/personal level.
It emphasizes that individual human beings are observers of a greater force acting on them and since society is out of control, we are also out of control.
We can observe society critically from an <em>ironic distance</em>, being <em>carefree</em> without being <em>careless</em> (as individuals) and without being fully subsumed by it, a perspective that may be worth remembering—illuminating neither hope nor fear.
We can look at us and our fellow human beings as beings thrown into fabric of society.
By pointing to the limits of the individual we can rediscovering a sense of innocence and grace of the human being.</p>

<p>One of Luhmann’s most influential critics, Jürgen Habermas, famously remarked of Luhmann’s work:</p>

<blockquote>
  <p>It’s all wrong, but of high quality.</p>
</blockquote>

<p>Habermas labeled Luhmann’s theory <em>metabiological</em>, drawing a comparison to metaphysics and suggesting it extends beyond empirical sociology into abstract structures that make it detached from human agency.
This comparison is spot on: Luhmann’s theory views society not as a product of individuals’ intentions but as an autonomous, complex system very similar to an organism.
From this perspective, if we are to learn anything valuable from Luhmann, it might be that we should avoid treating society—and, by extension, the climate crisis—either as an engineering problem, i.e. as something to be ‘solved’ with a clear-cut plan or a knowledge problem, i.e. something that can be solved if deniers just accept ‘the Truth’.
Instead, we might approach it more like a chronic condition or complex illness, where we, as doctors, explore, probe, and apply potential treatments without assuming a one-size-fits-all solution. 
This approach requires continuous adjustment, sensitivity to feedback, and a readiness to adapt to the unexpected outcomes of our actions, reflecting the complex, interdependent nature of the systems we inhabit.
But, of course, <strong>we are not in control</strong> and there is no single medical doctor controlling the medication plan.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="Brundiers2020">Brundiers, K., Barth, M., Cebrián, G., Cohen, M., Diaz, L., Doucette-Remington, S., Dripps, W., Habron, G., Harré, N., Jarchow, M., Losch, K., Michel, J., Mochizuki, Y., Rieckmann, M., Parnell, R., Walker, P., &amp; Zint, M. (2020). Key competencies in sustainability in higher education—toward an agreed-upon reference framework. <i>Sustainability Science</i>, <i>16</i>(1), 13–29. https://doi.org/10.1007/s11625-020-00838-2</span></li>
<li><span id="luhmann:1992">Luhmann, N. (1992). <i>Die Wissenschaft der Gesellschaft</i> (p. 732). Suhrkamp.</span></li>
<li><span id="luhmann:1994">Luhmann, N. (1994). <i>Die Wirtschft der Gesellschaft</i> (p. 356). Suhrkamp.</span></li>
<li><span id="luhmann:1997">Luhmann, N. (1997). <i>Die Kunst der Gesellschaft</i> (p. 517). Suhrkamp.</span></li>
<li><span id="luhmann:2002">Luhmann, N. (2002). <i>Die Politik der Gesellschaft</i> (p. 444). Suhrkamp.</span></li>
<li><span id="luhmann:1998">Luhmann, N. (1998). <i>Die Gesellschaft der Gesellschaft</i> (p. 1164). Suhrkamp.</span></li>
<li><span id="moeller:2011">Möller, H.-G. (2011). <i>The Radical Luhmann</i> (p. 184). Columbia University Press.</span></li>
<li><span id="meadows:2008">Meadows, D. H. (2008). <i>Thinking in Systems: A Primer</i> (p. 240). Chelsea Green Publishing.</span></li>
<li><span id="maturana:1987">Maturana, H. R., &amp; Varela, F. J. (1987). <i>The Tree of Knowledge</i>. Shambhala.</span></li>
<li><span id="brown:1969">Spence-Brown, G. (1969). <i>Laws of Form</i>. London: Allen and Unwin.</span></li>
<li><span id="foerster:2003">von Foerster, H. (2003). Cybernetics of Cybernetics. In <i>Understanding understanding: Essays on cybernetics and cognition</i> (pp. 283–286). Springer New York. https://doi.org/10.1007/0-387-21722-3_13</span></li>
<li><span id="moeller:2021">Möller, H.-G., &amp; D’Ambrosio, P. J. (2021). <i>You and Your Profile: Identity After Authenticity</i>. Columbia University Press.</span></li>
<li><span id="shannon:1948">Shannon, C. E. (1948). A mathematical theory of communication. <i>Bell Syst. Tech. J.</i>, <i>27</i>(3), 379–423.</span></li>
<li><span id="buentgen:2024">Büntgen, U. (2024). The importance of distinguishing climate science from climate activism. <i>Npj Climate Action</i>, <i>36</i>(3), 2731–9814. https://doi.org/10.1038/s44168-024-00126-0</span></li>
<li><span id="eck:2024">van Eck, C. W., Messling, L., &amp; Hayhoe, K. (2024). Challenging the neutrality myth in climate science and activism. <i>Npj Climate Action</i>, <i>81</i>(3), 2731–9814. https://doi.org/10.1038/s44168-024-00171-9</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Sustainability" /><category term="Social Systems Theory" /><category term="Politics" /><summary type="html"><![CDATA[I have to admit, I’m somewhat addicted to thinking about social systems theory, particularly the version developed by the German sociologist Niklas Luhmann (1927–1998). But this addiction isn’t driven by pure fascination—it’s more of a love-hate relationship. On one hand, seeing the world through a Luhmannian lens doesn’t make it more just or fantastic, but it does make it comprehensible. The chaotic state of global affairs—the crazyness of U.S. elections, the brutal devastation in the Middle East, the war in Europe, and the looming tensions brought by the climate crisis—appears senseless at times, even apocalyptic. And yet, systems theory offers a framework that, paradoxically, brings coherence to this apparent madness, showing us how these outcomes emerge from the logic of functionally differentiated systems.]]></summary></entry><entry><title type="html">Musical Interrogation IV - Transformer</title><link href="https://bzoennchen.github.io/Pages/2024/02/03/musical-interrogation-IV.html" rel="alternate" type="text/html" title="Musical Interrogation IV - Transformer" /><published>2024-02-03T00:00:00+01:00</published><updated>2024-02-03T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2024/02/03/musical-interrogation-IV</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2024/02/03/musical-interrogation-IV.html"><![CDATA[<blockquote>
  <p>Recurrent models trained in practice are effectively feed-forward.
This could happen either because truncated backpropagation through time cannot learn patterns significantly longer than k steps, or, more provocatively, because models trainable by gradient descent cannot have long-term memory. – John Miller</p>
</blockquote>

<p>This time in the series we use the most famous model architecture for generative purposes: the <strong>transformer</strong> <a class="citation" href="#vaswani:2017">(Vaswani et al., 2017)</a>.
Transformers were initially targeted at natural language processing (NLP) problems, where the network input is a series of high-dimensional embeddings representing words or word fragments.
Transformers were introduced in 2017 by the authors of <em>Attention Is All You Need</em> <a class="citation" href="#vaswani:2017">(Vaswani et al., 2017)</a> to basically replace <em>recurrency</em> with <em>attention</em>.</p>

<p>One of the problems with RNNs is that they can forget information that is further back in the sequence.
While more sophisticated architectures, such as LSTMs <a class="citation" href="#hochreiter:1997">(Hochreiter &amp; Schmidhuber, 1997)</a> and <em>gated recurrent units</em> (GRUs) <a class="citation" href="#chung2014">(Chung et al., 2014)</a> partially, addressed this problem, they still struggle with long term dependecies.
The idea that intermediate representations in the RNN should be exploited to produce the output led to the <em>attention mechanism</em> <a class="citation" href="#bahdanau:2014">(Bahdanau et al., 2014)</a> and, in the end, to the transformer architecture <a class="citation" href="#vaswani:2017">(Vaswani et al., 2017)</a>.
The transformer avoids the problem of vanishing or exploding gradients by avoiding recurrency, that is, by utilizing the whole sequence in parallel.</p>

<p>Today, all successful large language model (LLMs) utilize the transformer architecture.
It brought us ChatGPT (based on GPT-3 <a class="citation" href="#brown:2020">(Brown et al., 2020)</a> and GPT-4 <a class="citation" href="#openai:2023">(OpenAI, 2023; Bubeck et al., 2023)</a>), LLaMA <a class="citation" href="#touvron:2023">(Touvron et al., 2023)</a>, LLaMA 2 <a class="citation" href="#touvron:2023b">(Touvron et al., 2023)</a>, BERT <a class="citation" href="#devlin:2019">(Devlin et al., 2019)</a> and many fine-tuned derivates such as Codex <a class="citation" href="#chen:2021">(Chen et al., 2021)</a> .
In the domain of symbolic music, transformers where also employed.
Examples are the Music Transformer <a class="citation" href="#huang:2018">(Huang et al., 2018)</a>, the Pop Music Transformer <a class="citation" href="#huang:2020">(Huang &amp; Yang, 2020)</a>, multi-track music generation <a class="citation" href="#ens:2020">(Ens &amp; Pasquier, 2020)</a>, piano inpainting <a class="citation" href="#hadjeres:2021">(Hadjeres &amp; Crestel, 2021)</a>, Theme Transformer <a class="citation" href="#shih:2022">(Shih et al., 2022)</a> and more.
Furthermore there are transformers, such as MusicGen <a class="citation" href="#copet:2023">(Copet et al., 2023)</a> that generate audio output directly.</p>

<p>While there is an intuitive explanation of the attention mechanism, it is still unclear why exaclty the transformer is so effective—there is no rigorous mathematical proof.
It is well-known how their components work and what mathematical operations are performed, but it is very hard to interpret the seemingly emerging power when all the small parts work together.
One source of their effectiveness is that they relate tokens to other tokens more directly (without a hidden state which washes away the information) and the independence of multiple execution paths make them especially suitable for the exploitation of multicore processors such as GPUs and TPUs.
However, looking at the whole sequence at once comes at a cost: computation and memory complexity!
Therefore, to train transformers you require GPUs with a lot of memory which is concerning for artists who might want to utilize transformers independently from proprietary cloud services.</p>

<p>Original transformers where introduced for natural language processing.
However, since language datasets share some of the characteristics of musical notations, transformers achieve good results in learning the structure of symbolic pieces.
In music as well as in language the number of input variables can be very large, and the statistics are similar at every position; it’s not sensible to re-learn the meaning of the word <em>dog</em> at every possible position in a body of text.
Language datasets and music datasets have the complication that their sequences vary in length.</p>

<p>However, we also have to remember that there are also differences between the two domains.
The alphabet of musical notations has more than 26 symbols and there is a strong relation between certain symbols.
For example, there is a strong relation between the C’s of each octave or a whole and half note in the same pitch class.
Furthermore, shifting all the letters in a text changes the meaning of that text dramatically while in the case of music this is most often not the case.</p>

<h2 id="attention-in-encoder-decoder-rnns">Attention in Encoder-Decoder RNNs</h2>

<p>What is the idea behind the attention mechanism?
Attention was introduced to bidirectional recurrent neural networks (RNNs) in 2014 <a class="citation" href="#bahdanau:2014">(Bahdanau et al., 2014)</a> for language translation, that is, for an <em>encoder-decoder architecture</em>.
In this scenario we want to translate a sentence from e.g. English into e.g. German.
The attention mechanism helps the decoder part of the RNN to focus on different parts of the encoders ouput (representations of the English words) differently.
Therefore, it helps to preserve long term dependencies.</p>

<p>The <strong>encoder’s</strong> input is a sequence of tokens, let’s say words for simplicity, i.e. a sequence</p>

\[\mathbf{x}_{0}, \ldots \mathbf{x}_{n-1}.\]

<p>For each word \(\mathbf{x}_{i}\) it computes some output \(\mathbf{y}_{i}\).
The assumption is that the probability for \(\mathbf{x}_{i}\) depends on \(\mathbf{x}_{j}\).
Since we have the whole sentence given, we can use a <em>bidirectional RNN</em> and look into the future.
Thus, with respect to dependency, the probability for token \(i\) can depend on the probability for token \(j\) and vice versa.</p>

<p>The <strong>decoder’s</strong> input is the <strong>whole</strong> sequence computed by the <strong>encoder</strong> but as a weighted sum.
The output is a sequence of German words, let’s say</p>

\[\mathbf{y'}_{0}, \ldots \mathbf{y'}_{n-1}.\]

<p>This time however, the <strong>decoder</strong> RNN is unidirectional.
It can not look into the future and computes each German word strictly from left to right.
To compute the weights or attenion scores of \(\mathbf{y'}_{i}\), an <strong>alignment model</strong> receives the hidden state \(\mathbf{h'}_{i-1}\) and the outputs of the encode as input.
First a simple dot product is comuted:</p>

\[e_{i,j} = \mathbf{h'}_{i}^\top \mathbf{y}_{j} \quad \text{ for } j = 0, \ldots, i-1.\]

<p>Later it was suggested to us an additional linear transformation on the output:</p>

\[e_{i,j} = \mathbf{h'}_{i}^\top (\mathbf{W}\mathbf{y}_{j}) \quad \text{ for } j = 0, \ldots, i-1.\]

<p>where \(\mathbf{W}\) is learned.
All these scores are normalized by the softmax function giving us \(n\) weights:</p>

\[\alpha_{i,j} = \frac{\exp\left( e_{i,j} \right)}{\sum\limits_{k=0}^{n-1} \exp\left( e_{i, k}\right)}.\]

<p>Then the <strong>decoder’s</strong> ‘real’ input is computed by a weighted sum of the <strong>encoder’s</strong> output:</p>

\[\hat{\mathbf{h}}_i = \sum_j \alpha_{i,j} \mathbf{y}_j.\]

<p>The weights determine how “strong” the information of the input will be utilized, i.e., how much attention is spent on each previous output of the model.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:90%;" src="/Pages/assets/images/rnn-attention.png" alt="RNN with attention" />
<div style="display: table;margin: 0 auto;">Figure 1: RNN with self-attention.</div>
</div>
<p><br /></p>

<p>In case of a decoder, this results in a quadratic complexity of \(\mathcal{O}(n^2)\) because for each of the \(n\) tokens, we want to decode, we have \(n\) weights.</p>

<h2 id="the-transformer-architecture">The Transformer Architecture</h2>

<p>The original transformer was introduced for the task of machine translation thus it was an encoder-decoder architecture.
In Fig. 2 you see a slightly modified version where the addition (residual connections) and the layer norm are in front of the attention layer.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:90%;" src="/Pages/assets/images/transformer.png" alt="RNN with attention" />
<div style="display: table;margin: 0 auto;">Figure 2: The slightly modified transformer.</div>
</div>
<p><br /></p>

<p>Let’s consider a scenario in which we have an English sentence that we want to translate into French. 
In this process, the encoder plays a crucial role by transforming the English sentence into a highly compressed and information-rich representation.</p>

<p>Subsequently, the decoder comes into play, generating the French translation word by word. 
It relies on the previously computed French words to predict and produce the next one. 
It’s important to note that the input provided to the decoder is a partial translation, essentially a shifted version of what it is currently working on. 
This is because the decoder should lack the ability to see into the future; it only has access to the portion of the translation it has computed up to that point—otherwise it would cheat while training which would hurt the learning process.</p>

<p>To address this limitation, the decoder employs a masked version of the multi-head attention layer. 
This mechanism ensures that the decoder focuses on the relevant information without peeking ahead.</p>

<p>Furthermore, the utilization of residual connections and layer normalization over a mini-batch (layer norm) serves as a valuable tool to combat the issue of vanishing gradients in deep neural networks, ensuring the efficient training and optimization of the translation model.</p>

<p>In our case we do not acutally want to translate a sentence but we want to generate musical notes from a sequence of given notes.
Therfore, we have no encoded information and there is no encoding envolved.
We only need the decoder part.
Furthermore, I only use one (masked) multi-head attention layer in each block.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:40%;" src="/Pages/assets/images/decoder.png" alt="Decoder-only transformer" />
<div style="display: table;margin: 0 auto;">Figure 3: Our decoder-only transformer.</div>
</div>
<p><br /></p>

<p>Ok, but how does this really works?
What is going on here?
Well, the key to understand transformers is to understand the self-attention mechanism which I try to explain below.</p>

<h2 id="self-attention">Self-Attention</h2>

<p>The idea of the transformer is to just rely on (self-)attention thus remove recurrency.
This means that the model “sees” \(n\) tokens to generate the \((n+1)^\text{th}\) token.
Simple RNNs for predicting the next tokens only see the previous token and the hidden state which represents all the tokens before.
But, as I discussed in previous articles, the information of the hidden state gets washed away over time and without attention there seem to be little control over the importance of certain tokens of the sequence.</p>

<p>The fundamental operation of the transformer, i.e. the attention mechanism, is implemented in its <code class="language-plaintext highlighter-rouge">Head</code>.
Let \(\mathbf{x}_0, \ldots, \mathbf{x}_{n-1} \in \mathbb{R}^{D \times 1}\) be the \(n\) tokens of a sequence.
A standard neural network layer \(f(\cdot)\), takes a \(D \times 1\) input and applies a linear transformation followed by an activation function like a \(\text{ReLU}\):</p>

\[f(\mathbf{x}) = \text{ReLU}\left( \mathbf{W}\mathbf{x} + \mathbf{b }\right),\]

<p>where \(\mathbf{b}\) contains the biases, and \(\mathbf{W}\) contains the weights.</p>

<p>A self-attention \(\mathbf{sa}(\cdot)\) block takes all the \(n\) inputs, each of dimension \(D \times 1\), and returns \(n\) output vectors of the same size.
Note that in our case each input represents a musical note or event.
First, a set of <strong>values</strong> is computed for each input:</p>

\[\mathbf{v}_i = \mathbf{b}_v + \mathbf{W}_v \mathbf{x}_i, \quad \text{ (value)}\]

<p>where \(\mathbf{b}_v \in \mathbb{R}^D \text{ and } \mathbf{W}_v \in \mathbb{R}^{D \times D}\) represent biases and weights, respectively (<strong>for all inputs</strong>). 
The \(j^\text{th}\) output \(\mathbf{sa}_j(\mathbf{x}_0, \ldots, \mathbf{x}_{n-1})\) is a weighted sum of all the values \(\mathbf{v}_i, i = 0, \ldots n-1\) where the weight each weight depends on \(\mathbf{x}_j\):</p>

\[\mathbf{sa}_j(\mathbf{x}_0, \ldots, \mathbf{x}_{n-1}) = \sum_{i=0}^{n-1} \alpha(\mathbf{x}_i, \mathbf{x}_j) \mathbf{v}_i.\]

<p>The scalar weight \(\alpha(\mathbf{x}_i, \mathbf{x}_j)\) is the <strong>attention</strong> that the \(j^\text{th}\) output pays to the input \(\mathbf{x}_i\).
The \(n\) weights \(\alpha(\cdot, \mathbf{x}_j)\) are non-negative and sum to one.
Hence, self-attention can be thought of as <em>routing</em> the values in different proportions to create each output.</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:35%;" src="/Pages/assets/images/routing.png" alt="Routing principle" />
<div style="display: table;margin: 0 auto;">Figure 4: Routing principle.</div>
</div>
<p><br /></p>

<p>To compute the attention, we apply two more linear transformations to the inputs:</p>

\[\begin{aligned}
\mathbf{q}_j &amp;= \mathbf{b}_q + \mathbf{W}_q \mathbf{x}_j \quad \text{ (query)}\\
\mathbf{k}_i &amp;= \mathbf{b}_k + \mathbf{W}_k \mathbf{x}_i \quad \text{ (key).}
\end{aligned}\]

<p>The <strong>dot product</strong> of two vectors \(\mathbf{q}_j\), \(\mathbf{k}_i\) is a measurement of their similarity.
In the special case where both vectors are unit vectors, the dot product is the cosine of the angle between the two.
In general, this relationship is expressed by the following equation:</p>

\[\mathbf{q}_j \circ \mathbf{k}_i = \mathbf{q}_j^\top  \mathbf{k}_i = \Vert \mathbf{q}_j \Vert \cdot \Vert \mathbf{k}_i \Vert \cos(\beta),\]

<p>where \(\beta\) is the angle between the two verctors.
Computing the <em>dot product</em> between queries and keys gives us the similarities we desire.
To normalize, we then pass the result through a <em>softmax</em> function:</p>

\[\alpha(\mathbf{x}_i, \mathbf{x}_j) = \frac{\exp(\mathbf{q}_j^\top \mathbf{k}_i \sqrt{D_q})}{\sum\limits_{r=0}^{n-1} \exp(\mathbf{q}_j^\top \mathbf{k}_r \sqrt{D_q})},\]

<p>where \(D_q\) is the dimension of the queries and keys (i.e., the number of rows in \(\mathbf{W}_q\) and \(\mathbf{W}_k\), which must be the same).
You can think of the <em>key</em> of what is offered and the <em>query</em> of what is searched.
If \(\mathbf{X}\), \(\mathbf{K}\), \(\mathbf{Q}\), and \(\mathbf{V}\) contain all the inputs, keys, queries and values then we can compute the self-attention by</p>

\[\mathbf{Sa}(\mathbf{X}) = \mathbf{V} \cdot \text{Softmax}\left( \frac{\mathbf{K}^\top \mathbf{Q}}{\sqrt{D_q} }\right).\]

<p>The overall computation is illustrated in Figure 5.</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:90%;" src="/Pages/assets/images/self-attention.png" alt="Self-attention in matrix-form" />
<div style="display: table;margin: 0 auto;">Figure 5: Self-attention in matrix-form.</div>
</div>
<p><br /></p>

<h2 id="masking-attention-head">Masking Attention Head</h2>

<p>Since our transformer should not look into the future, because when we use it in the prediction mode it also can not look ahead of the token it predicts, we have to mask entries in</p>

\[\text{Softmax}\left(\frac{\mathbf{K}^\top \mathbf{Q}}{\sqrt{D}_q}\right).\]

<p>If you look into the code, I did this by setting the respective values in \(\mathbf{K}^\top \mathbf{Q}\) to negative infinite before computing the softmax.</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:60%;" src="/Pages/assets/images/transformer-head.png" alt="Transformer head" />
<div style="display: table;margin: 0 auto;">Figure 6: Transformer head for a sequence length equal to 5.</div>
</div>
<p><br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Head</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">""" one head of self-attention """</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>   <span class="c1"># key embedding
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># query embedding
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># value embedding
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s">'tril'</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">sequence_len</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">)))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span> <span class="c1"># to avoid overfitting
</span>        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">B</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">C</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># B, T, head_size, compute all keys
</span>        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># B, T, head_size, compute all queries
</span>        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">head_size</span> <span class="o">=</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span>
        
         <span class="c1"># B, T, head_size @ B, head_size, 
</span>        <span class="n">wei</span> <span class="o">=</span> <span class="n">q</span> <span class="o">@</span> <span class="n">k</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">head_size</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">))</span> <span class="c1"># T =&gt; B, T, T
</span>
        <span class="c1"># because we can not look into the future 
</span>        <span class="n">wei</span> <span class="o">=</span> <span class="n">wei</span><span class="p">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">tril</span><span class="p">[:</span><span class="n">T</span><span class="p">,</span> <span class="p">:</span><span class="n">T</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s">'-inf'</span><span class="p">))</span>
        <span class="n">wei</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">wei</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">wei</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">wei</span><span class="p">)</span>

        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># B, T, head_size
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">wei</span> <span class="o">@</span> <span class="n">v</span> <span class="c1"># T, T @ B, T, head_size =&gt; B, T, head_size
</span>        <span class="k">return</span> <span class="n">out</span>
<span class="p">...</span>
</code></pre></div></div>

<p>The multi-head attention layer consists of multiple heads.
Note that apart from <strong>masked</strong> <strong>self-attention</strong>, the head also applys a <strong>dropout</strong> which helps with regularization.</p>

<h2 id="stacked-multi-head-attention">Stacked Multi-Head Attention</h2>

<p>Instead of using only one <code class="language-plaintext highlighter-rouge">Head</code> it is usually a good idea to use multiple ones.
To do this we transform the input into a <code class="language-plaintext highlighter-rouge">head_size</code>-dimensional space.
Suppose we use 4 heads than <code class="language-plaintext highlighter-rouge">head_size * 4</code> should be equal to the rows of \(\mathbf{W}_0\) (compare Fig. 7) of the multi-head attention layer.
Since I add the input to the output of <code class="language-plaintext highlighter-rouge">MultiHeadAttention</code> (via residual connections), the columns of \(\mathbf{W}_0\) should be equal to the dimension of the input of the <code class="language-plaintext highlighter-rouge">MultiHeadAttention</code>.
In my case this is <code class="language-plaintext highlighter-rouge">n_embd</code>, i.e. the dimension of our embedded tokens.</p>

<p>\(\mathbf{W}_0\) transforms the concatenated results of the heads back to the dimension equal to <code class="language-plaintext highlighter-rouge">n_embd</code>. 
This is needed to stack <code class="language-plaintext highlighter-rouge">Block</code>s (each consisting of a <code class="language-plaintext highlighter-rouge">MultiHeadAttention</code>) on top of each other.
The output of <code class="language-plaintext highlighter-rouge">Block</code> \(i\) has to fit into block \(i+1\).</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:90%;" src="/Pages/assets/images/multi-head.png" alt="Multi-head attention" />
<div style="display: table;margin: 0 auto;">Figure 7: Multi-head attention.</div>
</div>
<p><br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">Head</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_heads</span><span class="p">)]</span>
        <span class="p">)</span>

        <span class="c1"># W_0
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">W0</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">head_size</span> <span class="o">*</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">)</span> 

        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># concatenation of the results of each head
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">head</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">heads</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> 

        <span class="c1"># Figure 7
</span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">W0</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
<span class="p">...</span>
</code></pre></div></div>

<p>The hope is that each <code class="language-plaintext highlighter-rouge">Head</code> concentrates on different parts of the structure we want to learn.</p>

<h2 id="transformer-block">Transformer Block</h2>

<p>A <code class="language-plaintext highlighter-rouge">Block</code> consists of a <code class="language-plaintext highlighter-rouge">MultiHeadAttention</code>-layer and a relatively simple FFN-layer followed by two <code class="language-plaintext highlighter-rouge">LayerNorm</code> which applies <em>layer normalization</em> over a mini-batch of inputs.
This helps the gradients to stay in a “good” range.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="c1"># head_size could be defined differently
</span>        <span class="n">head_size</span> <span class="o">=</span> <span class="n">n_embd</span> <span class="o">//</span> <span class="n">n_heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">sa</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ffwd</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ln1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">n_embd</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ln2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">n_embd</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">sa</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ln1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c1"># residual connection
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">ffwd</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ln2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c1"># residual connection
</span>        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">n_embd</span><span class="p">),</span> 
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="p">...</span>
</code></pre></div></div>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:40%;" src="/Pages/assets/images/block.png" alt="Transformer block" />
<div style="display: table;margin: 0 auto;">Figure 8: Our decoder transformer block with only one (masked) multi-head attention layer.</div>
</div>

<h2 id="positional-encoding">Positional Encoding</h2>

<p>The Transformer has no more hidden state.
Therefore, instead of processing token by token trying to memorize important information via the hidden state, it processes all \(n\) tokens at in parallel, which is good for parallel computation but increases the time and space complexity from \(\mathcal{O}(n)\) (LSTM) to \(\mathcal{O}(n^2)\).</p>

<p>Furthermore, we have to encode the position of the tokens into \(\mathbf{x}\) because we lost the implicit order of computation.
In the original paper <a class="citation" href="#vaswani:2017">(Vaswani et al., 2017)</a> the authors utilized a embdding that involved sine and cosine functions.
Their embedding is a very clever use of peridoic functions but I will not go into details here.
Instead of using a fixed embedding, I let the transformer learn the positional embedding.</p>

<p>Therefore, I transform the input <code class="language-plaintext highlighter-rouge">idx</code> into two vectors <strong>positional embedding</strong> and <strong>token embedding</strong>, which are <strong>added</strong> together.
Note that our input <code class="language-plaintext highlighter-rouge">idx</code> is an array of numbers each representing the id of the token.
Each number will be transformed into a specific vector (i.e. its embedding).
The embedding will be learned.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">n_blocks</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="c1"># vocab_size is the size of our alphabet
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">token_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">)</span>

        <span class="c1"># sequence_len is equal to n
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">position_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">sequence_len</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">Block</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">sequence_len</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_blocks</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">idx</span><span class="p">.</span><span class="n">shape</span>
        
        <span class="c1"># token embedding. B, T, n_embd
</span>        <span class="n">token_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">token_embedding_table</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> 

        <span class="c1"># positional embedding. T, n_embd 
</span>        <span class="n">pos_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">position_embedding_table</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span> 

        <span class="n">x</span> <span class="o">=</span> <span class="n">token_emb</span> <span class="o">+</span> <span class="n">pos_emb</span> <span class="c1"># B, T, n_embd + T, n_embd =&gt; B, T, n_embd
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># B, T, head_size
</span>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># B, T, vocab_size
</span>        <span class="k">return</span> <span class="n">logits</span>

<span class="p">...</span>
</code></pre></div></div>

<p>By increasing the dimension of the embedding, the sequence length, the number of heads within a block and the number of blocks we can drastically increase the size and power of our decoder-only transformer.
However, this will rapidly increase the memory requirements and training time.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:40%;" src="/Pages/assets/images/decoder.png" alt="Decoder-only transformer" />
<div style="display: table;margin: 0 auto;">Figure 9: Our simplified decoder-only transformer.</div>
</div>
<p><br /></p>

<p>Futhermore, it is very important to understand that what really matters is a <strong>high-quality training dataset</strong>!
Of course, your model achitecture matters too, but your model can not learn what is not there.
Additionally, the <strong>musical representation</strong> you feed into the transformer matters as well.
In our case this representation, using basically piano rolls, is very simple.
It does not contain any high level information such as the end of a bar, section, phrase or musical theme.
We just hope that the transformer will eventually learn all these concepts.
It is a active research question what impact a good musical representation has on the result the trained transformer generates.</p>

<h2 id="relative-positional-self-attention">Relative Positional Self-Attention</h2>

<p>So far our positional encoding was just a sequence of natural numbers \(0, 1, \ldots, n-1\) and we used an embbedding which was added to the input, that is, the embedding of \(i\) was added to the embedding of \(\mathbf{x}_i\) of the input sequence.
However, this encoding might not be optimal in the context of music where we tones, phrases, musical ideas and themes reapeat frequently.
A relative position representation to allow attention to be informed by how far two positions are apart in a sequence might be much more effective.</p>

<p>So, instead of learning the index of a token within a sequence we want the mode to learn relative distances between tokens.
In other words, instead of learning the attention spent by token with index \(j\) on \(i\), that is, \(\alpha(\mathbf{x}_i, \mathbf{x}_j)\) we want to compute an attention score based on the (directed) distance \(i-j\).
This concept was introduced by <a class="citation" href="#shaw:2018">(Shaw et al., 2018)</a>.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:60%;" src="/Pages/assets/images/relative-attention.png" alt="Relative positional encoding" />
<div style="display: table;margin: 0 auto;">Figure 10: Relative positional encoding.</div>
</div>
<p><br /></p>

<p>Note that if there are \(\mathcal{O}(n)\) absolute positions \(0, 1, \ldots, n-1\) then there are \(\mathcal{O}(n)\) relative positions \(-(n-1), \ldots, -1, 0, 1,\ldots, n-1\).
The authors also introduce a maximal distance \(k\) such that they only learn weights</p>

\[\mathbf{w}^{V}_{\text{clip}(i-j,k)} \text{ with } \text{clip}(x,k) = \max(-k, \min(k,x))\]

<p>Therefore, they learn relative position representations for the keys \(\mathbf{w}^K_{-k}, \ldots, \mathbf{w}^K_{k}\) and for the values \(\mathbf{w}^V_{-k}, \ldots, \mathbf{w}^V_{k}\).
They introduce the relative position between \(\mathbf{x}_i\) and \(\mathbf{x}_j\) to be</p>

\[\mathbf{a}_{ij} = \mathbf{w}_{\text{clip}(i-j,k)}\]

<p>Thus there are \(\mathcal{O}(n^2)\) different such vectors but many share the same value.
Of course, they drop the absolute positional encoding.
And they adapt the <strong>self-attention comuputation</strong> from</p>

\[\mathbf{sa}_j(\mathbf{x}_0, \ldots, \mathbf{x}_{n-1}) = \sum_{i=0}^{n-1} \alpha(\mathbf{x}_i, \mathbf{x}_j) \mathbf{v}_i.\]

<p>to</p>

\[\mathbf{sa}_j(\mathbf{x}_0, \ldots, \mathbf{x}_{n-1}) = \sum_{i=0}^{n-1} \alpha(\mathbf{x}_i, \mathbf{x}_j) (\mathbf{v}_i + \mathbf{a}^V_{ij}).\]

<p>and the computation of the similarity between <strong>query</strong> and <strong>key</strong> from</p>

\[\frac{(\mathbf{W}_q \mathbf{x}_i)^\top (\mathbf{W}_k \mathbf{x}_j)}{\sqrt{D_q}}\]

<p>to</p>

\[\frac{(\mathbf{W}_q \mathbf{x}_i)^\top (\mathbf{W}_k \mathbf{x}_j + \mathbf{a}^K_{ij})}{\sqrt{D_q}}.\]

<p>Computation-wise the first manipulation can be easily achieved by adding a matrx \(\mathbf{A}\) to \(\mathbf{V}\).
However, the second manipulation destroys parallelism, i.e. the possibility to compute everything by matrix-matrix multiplications.
This can be mitigated by splitting the computation into two parts:</p>

\[\frac{(\mathbf{W}_q \mathbf{x}_i)^\top (\mathbf{W}_k \mathbf{x}_j + \mathbf{a}^K_{ij})}{\sqrt{D_q}} = \frac{(\mathbf{W}_q \mathbf{x}_i)^\top (\mathbf{W}_k \mathbf{x}_j) + (\mathbf{W}_q \mathbf{x}_i)^\top \mathbf{a}^K_{ij}}{\sqrt{D_q}}\]

<p>Assuming that \(\mathbf{S}\) contains all the relative attention scores, that is,</p>

\[\mathbf{S}_{ij} = (\mathbf{W}_q \mathbf{x}_i)^\top \mathbf{a}^K_{ij},\]

<p>then we can go back to the matrix form which gives us</p>

\[\mathbf{Sa}(\mathbf{X}) = (\mathbf{V} + \mathbf{A}^V) \cdot \text{Softmax}\left( \frac{\mathbf{K}^\top \mathbf{Q} + \mathbf{S}}{\sqrt{D_q} }\right).\]

<p>To compute \(\mathbf{S}\) <a class="citation" href="#shaw:2018">(Shaw et al., 2018)</a> instantiate an intermediate tensor \(\mathbf{R} \in \mathbf{R}^{k \times k \times D_q},\) containing the embeddings that correspond to the relative distance between all keys and queries.
\(\mathbf{Q}\) is then reshaped to an \((k, 1, D_q)\) tensor, and \(\mathbf{S} = \mathbf{Q} \mathbf{R}^\top.\)
This incurs a total space complexity of \(\mathcal{O}(k^2 D_q)\).</p>

<h2 id="the-music-transformer">The Music Transformer</h2>

<p>The Music Transformer <a class="citation" href="#huang:2018">(Huang et al., 2018)</a> was one of the first transformer utilized to generate symbolic music.
Even if it was introduced five years ago (which is like a century in the AI-world) it is worth studying it.
In the paper you find two different datasets</p>

<ol>
  <li><a href="https://github.com/czhuang/JSB-Chorales-dataset">J.S. Bach chorales dataset</a></li>
  <li><a href="https://www.piano-e-competition.com/">Piano-e-Competition dataset</a></li>
</ol>

<p>and they used an impressive sequence length of <strong>2048-tokens</strong>!
They used GPUs for the training.
With such a large number of token, one question arises: How did they manage to put 2000-tokens and all the respective matrices in the GPUs’ memory?</p>

<p>The authors correctly identify the space complexity of \(\mathcal{O}(k^2 D_q)\) to be problematic for GPU computation and they reduce the complexity to \(\mathcal{O}(k D_q)\) by exchanging space for re-computation.
This is possible due to the structure of the tensor \(\mathbf{R}\) which contains many equal values.</p>

<p>To handly very long sequences, the authors use local attention <a class="citation" href="#liu:2018">(Liu et al., 2018)</a> by chunking the input sequence into non-overlapping blocks.
Each block then attends to itself and the one before.</p>

<h2 id="attention-free-transformer">Attention-Free Transformer</h2>

<p>Basically, the attention mechanism, regardless of the specifics, solves a routing problem, that it, which information is transported to the next layer of the neural network.
Thus, it has a quadratic time and space complexity of \(\mathcal{O}(n^2)\) where \(n\) is our sequence length.
Therefore, if you have limited ressources, it is hard to scale it to larger sequences.
As with the local attention and other techniques, like the Linformer <a class="citation" href="#wang:2020">(Wang et al., 2020)</a>, Longformer <a class="citation" href="#"></a>, Reformer <a class="citation" href="#kitaev:2020">(Kitaev et al., 2020)</a>, and Synthesizer <a class="citation" href="#tay:2021">(Tay et al., 2021)</a>, and Performer <a class="citation" href="#choromanski:2022">(Choromanski et al., 2022)</a> there are ways to improve this but in principle the complexity will bite us eventually.</p>

<p>Now we enter in an era in deep learning where we question if we actually need the attention layers in the transformer!
This was proposed in 2022.
Instead of computing attention, <em>FNet</em> <a class="citation" href="#leethorp:2022">(Lee-Thorp et al., 2022)</a> just mixes tokens according to the discrete Fourier transformation (DFT).
First, a 1D transformation is computed with respect to the embedding and then another with respect to time.
Amazingly even though there is no parameter to learn within the <code class="language-plaintext highlighter-rouge">Fourier</code>-layer (which replaces the <code class="language-plaintext highlighter-rouge">Head</code>) this strategy seems to work almost as good as the far more computational expensive task of learning all the required attention scores.</p>

<p>The Fourier transform decomposes a function (in our case a discrete signal) into its constituent frequencies.
Given a sequence \(x_0, \ldots, x_{N-1}\), the discrete Fourier transform (DFT) is defined by</p>

\[X_k = \sum\limits_{n=0}^{N-1} x_n \exp\left( - \frac{2\pi i}{N} nk \right), \quad 0 \leq k \leq N-1.\]

<p>\(X_k\) encodes the <strong>phase</strong> and <strong>power</strong> of frequency \(k\) within the signal.</p>

<p><em>FNet</em> consists of a Fourier <strong>mixing sublayer</strong> followed by a feed-forward sublayer.
Essentially, the self-attention sublayer of each transformer decoder layer is replaced with a <strong>Fourier sublayer</strong> which applies a 2D DFT to its</p>

\[(\text{sequence length} \times \text{hidden dimension})\]

<p>embedding input.
This can be achieved using two 1D DFTs—one 1D DFT along the sequence dimension, \(\mathcal{F}_\text{seq}\), and one 1D DFT along the hidden dimension, \(\mathcal{F}_\text{h}\):</p>

\[y = \text{Real}\left( \mathcal{F}_\text{seq} \left( \mathcal{F}_\text{h}(\mathbf{x}) \right) \right)\]

<p>The authors only consider the real part of the DFT.</p>

<p>Now, as emphasized by the title of their paper, the Fourier transform is probably not the important part.
It is just a special case of how you can mix tokens.
Important is the mixing itself which allows information to flow from one token to all the other tokens and the Fourier transform happens to be a nice why of mixing.
The paper indicate that it might not be so important to let the model learn how exaclty information flows around.
It might be just enough if information flows at all (to all tokens).
In other words, the exact routing might be less important than we thought.</p>

<p>Now, the results of the paper are not better than using a traditional transformer.
But one trades accuracy for resources thus longer sequence length and a faster computation.</p>

<p>To the best of my knowledge, I have not seen this tried out for symbolic music generation.
But when I have time, I play around with it.
Futhermore, one might think about a special mixing which is effective for our specific task.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="vaswani:2017">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017). attention is all you need. <i>CoRR</i>, <i>abs/1706.03762</i>. http://arxiv.org/abs/1706.03762</span></li>
<li><span id="hochreiter:1997">Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. <i>Neural Computation</i>, <i>9</i>(8), 1735–1780. https://doi.org/10.1162/neco.1997.9.8.1735</span></li>
<li><span id="chung2014">Chung, J., Gulcehre, C., Cho, K. H., &amp; Bengio, Y. (2014). <i>Empirical evaluation of gated recurrent neural networks on sequence modeling</i>.</span></li>
<li><span id="bahdanau:2014">Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. <i>CoRR</i>, <i>abs/1409.0473</i>.</span></li>
<li><span id="brown:2020">Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., … Amodei, D. (2020). <i>Language models are few-shot learners</i>.</span></li>
<li><span id="openai:2023">OpenAI. (2023). <i>GPT-4 rechnical report</i>.</span></li>
<li><span id="bubeck:2023">Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S., Nori, H., Palangi, H., Ribeiro, M. T., &amp; Zhang, Y. (2023). <i>Sparks of artificial general intelligence: Early experiments with GPT-4</i>.</span></li>
<li><span id="touvron:2023">Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., &amp; Lample, G. (2023). <i>LLaMA: Open and efficient foundation language models</i>.</span></li>
<li><span id="touvron:2023b">Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., … Scialom, T. (2023). <i>LlaMA 2: Open foundation and fine-tuned chat models</i>.</span></li>
<li><span id="devlin:2019">Devlin, J., Chang, M.-W., Lee, K., &amp; Toutanova, K. (2019). <i>BERT: Pre-training of deep bidirectional transformers for language understanding</i>.</span></li>
<li><span id="chen:2021">Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., … Zaremba, W. (2021). <i>Evaluating large language models trained on code</i>.</span></li>
<li><span id="huang:2018">Huang, C.-Z. A., Vaswani, A., Uszkoreit, J., Shazeer, N., Hawthorne, C., Dai, A. M., Hoffman, M. D., &amp; Eck, D. (2018). Music Transformer: Generating music with long-term structure. <i>ArXiv Preprint ArXiv:1809.04281</i>.</span></li>
<li><span id="huang:2020">Huang, Y.-S., &amp; Yang, Y.-H. (2020). <i>Pop Music Transformer: Beat-based modeling and generation of expressive pop piano compositions</i>.</span></li>
<li><span id="ens:2020">Ens, J., &amp; Pasquier, P. (2020). <i>MMM: Exploring conditional multi-track music generation with the transformer</i>.</span></li>
<li><span id="hadjeres:2021">Hadjeres, G., &amp; Crestel, L. (2021). <i>The piano inpainting application</i>.</span></li>
<li><span id="shih:2022">Shih, Y.-J., Wu, S.-L., Zalkow, F., Müller, M., &amp; Yang, Y.-H. (2022). <i>Theme Transformer: Symbolic music generation with theme-conditioned transformer</i>.</span></li>
<li><span id="copet:2023">Copet, J., Kreuk, F., Gat, I., Remez, T., Kant, D., Synnaeve, G., Adi, Y., &amp; Défossez, A. (2023). <i>Simple and controllable music generation</i>.</span></li>
<li><span id="shaw:2018">Shaw, P., Uszkoreit, J., &amp; Vaswani, A. (2018). Self-attention with relative position representations. <i>CoRR</i>, <i>abs/1803.02155</i>. http://arxiv.org/abs/1803.02155</span></li>
<li><span id="liu:2018">Liu, P. J., Saleh, M., Pot, E., Goodrich, B., Sepassi, R., Kaiser, L., &amp; Shazeer, N. (2018). Generating Wikipedia by summarizing long sequences. <i>International Conference on Learning Representations</i>. https://openreview.net/forum?id=Hyg0vbWC-</span></li>
<li><span id="wang:2020">Wang, S., Li, B. Z., Khabsa, M., Fang, H., &amp; Ma, H. (2020). <i>Linformer: Self-Attention with linear complexity</i>.</span></li>
<li><span id="kitaev:2020">Kitaev, N., Kaiser, Ł., &amp; Levskaya, A. (2020). <i>Reformer: The Efficient Transformer</i>.</span></li>
<li><span id="tay:2021">Tay, Y., Bahri, D., Metzler, D., Juan, D.-C., Zhao, Z., &amp; Zheng, C. (2021). <i>Synthesizer: Rethinking self-attention in transformer models</i>.</span></li>
<li><span id="choromanski:2022">Choromanski, K., Likhosherstov, V., Dohan, D., Song, X., Gane, A., Sarlos, T., Hawkins, P., Davis, J., Mohiuddin, A., Kaiser, L., Belanger, D., Colwell, L., &amp; Weller, A. (2022). <i>Rethinking Attention with Performers</i>. https://arxiv.org/abs/2009.14794</span></li>
<li><span id="leethorp:2022">Lee-Thorp, J., Ainslie, J., Eckstein, I., &amp; Ontanon, S. (2022). <i>FNet: Mixing tokens with Fourier transforms</i>.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Music" /><category term="ML" /><category term="Transformer" /><summary type="html"><![CDATA[Recurrent models trained in practice are effectively feed-forward. This could happen either because truncated backpropagation through time cannot learn patterns significantly longer than k steps, or, more provocatively, because models trainable by gradient descent cannot have long-term memory. – John Miller]]></summary></entry><entry><title type="html">Escaping the Reality of the Climate Crisis?</title><link href="https://bzoennchen.github.io/Pages/2024/01/02/conspiracy.html" rel="alternate" type="text/html" title="Escaping the Reality of the Climate Crisis?" /><published>2024-01-02T00:00:00+01:00</published><updated>2024-01-02T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2024/01/02/conspiracy</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2024/01/02/conspiracy.html"><![CDATA[<p>Diverging from my area of expertise is always a risky endeavor, but since this is a blog and not a scientific journal, I’m giving myself the liberty to explore and have fun with different ideas (even if the topic is depressing). 
Often writing helps in transforming the mess into a structured and coherent concept.
The process of rethinking and reflecting can be invaluable.
It helps to make ones thought <em>anschlussfähig</em> which literally means <em>to be capable for connections</em> and in this context means <em>enabling the continuation of communication</em>.</p>

<p>In this piece, I aim to explore various aspects by linking the movie <em>The Matrix</em>, Plato’s <em>Allegory of the Cave</em>, <em>myths</em>, and <em>conspiracy theories</em>.
Additionally, delve into the understandable yet problematic skepticism surrounding <em>second-order observation</em>.
I will relate this skepticism to the notions of <em>complexity</em> and <em>hyperreality</em>, and discuss why we rely on <em>second-order observation</em> to address the <em>climate crisis</em>. 
Some parts of this text will escape a clear interpretation, especially when I offer my interpretation of Baudrillard’s writings.
Some parts might even be contradictory.
But this is the point: enduring or even enjoying ambiguity!</p>

<p>Overall, I hope to give good reasons for the emergence of conspiracy theories and our state of inaction in the face of disaster; reasons that do not rely on a good and evil dichotomy of individuals.
I will argue that our perception of reality makes effective communication between each other improbable and that complex systems follow their own stabalizing dynamic.
In the end, conspiracy theorist will appear as anti-authoritarian rebels that fight against the power of knowledge using the same source of authority, that is, knowledge.</p>

<p>Before we start, let us agree on a definition of conspiracy theories:</p>

<blockquote>
  <p>By conspiracy theory, I mean an explanation of historical, ongoing, or future events that cites as a main causal factor a group of powerful persons, the conspirators, acting in secret for their own benefit against the common good. – Joseph E. Uscinski</p>
</blockquote>

<h2 id="mythologies-science-and-conspiracy-theories">Mythologies, Science and Conspiracy Theories</h2>

<p>The phenomena of conspiracy theories hunts and intrigues me since the terror attacks of 9/11 happened back when I was a child.
I remember watching the <em>Zeitgeist series</em>, which linked various conspiracy theories involving religion, the September 11 attacks and the financial sector.
During that time, even German TV occasionally presented documentaries that portrayed certain events in a conspiratorial light.
The shock and uncertainty that the Western world experienced after these events, combined with a sense of lack of control, created a fertile ground for such theories. 
These ‘documentaries’ were not only entertaining, but they also sparked my interest in geopolitics, the history of religion, history in general, and even philosophy. 
They managed to make historical events captivating, and I often wished that my history classes were similarly engaging.
Fortunately, I never embraced the logic presented in these films; for me, they remained within the realm of entertainment but I could see how easy it is to fall for them on an emotional level.
Interestingly, years later, when a real plot unfolded to deceive the public (and other nations) into supporting the war against Iraq, there was no corresponding emergence of conspiracy theories like those seen previously.</p>

<p>During the pandemic, I observed a repetition of history in the form of similar documentaries emerging, and I became interested in how they were designed and how they relate to the conspiratorial ‘documentaries’ I encountered in my childhood. Indeed, they bore striking similarities.</p>

<p>Apart from the obvious parallels, such as misrepresentation and drawing connections between completely unrelated events, there were also more bizarre links.
For instance, these documentaries often incorporate some form of spiritual concept, promising a return to or discovery of a ‘true self’, an ‘inner peace’ or a ‘forgotten innocence’. 
For example, the <em>Zeitgeist series</em> uses a speech from the Indian philosopher Jiddu Krishnamurti (1895 – 1986) but only as an emotional device:</p>

<blockquote>
  <p>We will see how very important it is to bring about in the human mind the radical revolution.
The crisis is a crisis in consciousness, a crisis that cannot anymore accept the old norms, the old patterns, the ancient traditions.
And considering what the world is now with all the misery, conflict, destructive brutality, aggresion, and so on, man is still as he was, is still brutal, violent, aggressive, competitive and has built a society along these lines. – Jiddu Krishnamurti</p>
</blockquote>

<p>In my interpretation, this reflects a lost connection to the wholeness of the universe. 
At the extreme end, I experience sometimes two contradictory moods. 
First, there is this feeling of alienation in an absurd world, which Albert Camus described best in his book <em>The Stranger</em>.
For me, the absurdity of the world reveals itself when I am out in the city, observing people rushing through their lives, participating in the acceleration towards a promised utopia that no longer exists, not even in their imaginations.
It is also connected to the realization that I was thrown into this world, culture, mess; this contradiction; this meaningless rat race.
The second mood arises from a profound connection with the world.
It feels as if we are the world, as if there is no separation between myself and my environment, between myself and the universe.
Yet, at the same time, I sense a process that is not only mysterious but overwhelmingly greater than I can ever comprehend; a force beyond my intellect.
Such feelings arise, for example, in nature.
When we stand atop a mountain, not thinking but simply being present in the world, or even feeling as if we are the world.
Such a feeling can also arise when we are completely immersed in an activity, like a drummer who dissolves entirely into the act of drumming.
This state of existence requires a quiet mind and a cessation of thought.</p>

<p>Consequently, it was no surprise to me that at the protests against COVID-19 restrictions and at QAnon gatherings, there was a peculiar blend of people, including everyone from far right-wingers to faith healers.
Of course, one has to be careful with such categorization since such protests are often captured by extreme parties.
Anyways, this mix reflects the broad, albeit unusual, appeal of such conspiratorial narratives and the desire for an effective (post-truth) narrator, e.g. Donald Trump, who provides a myth that carries emotional weight rather than the difficulty and uncertainty of a complex world—a <em>myth</em> one can live by.
However, <em>ignorance</em> is too simple of an explanation.
The MAGA cult is not disingaged in communication or the production of knowledge.
Instead they (ab)use communication to construct quite imaginative but also inconsistant <em>alternative facts</em> effectively.</p>

<p>On the basis of knowledge, it is easy to make fun of people believing in mythologies.
Scienficially speaking, myths are either inconsistent or unfalsifiable.
However, socially they can be very useful and powerful.
They explain experience and reduce complexity.
A myth is ment to answer questions and offer solutions to quell the anxieties of the present through stories.
They can serve a useful purpose, particularly in politics.
They create visions, unities and identities among groups such that they can work together towards a meaningful goal—a mission greater than oneself.
Here, a shadow of spirituality plays an important role, be it in the form of <em>the Light of God</em>, <em>Siegfried the Dragonslayer</em>, <em>Achilleus the Greatest of All the Greek Warriors</em> or <em>Donald Trump the Warrior King</em>.</p>

<p>Later I will argue that we should keep the source for spirituality, that is, imagination, ambiguity, and contradictions alive and that science can be abused for a <em>Crusade Against Ambiguity</em>.
In my view, spirituality and science can harmonize with quite well.
Religion, as a subset of spirituality, should be criticised especially if it becomes dogmatic, that is, if it starts a crusade against ambiguity.
But it is a narrow perspective to scientifically dispute the existence of a divine entity, just as it is misguided to interpret religious scriptures in a strictly literal sense.
Religion needs ambiguity.
Therefore, it is peculiar to witness esteemed intellectuals like Richard Dawkins engage in debates concerning the divine, overlooking the potential for a creator amidst the universe’s intricate complexity.</p>

<blockquote>
  <p>We have a working theory, which we know is true, which explains how you can go from great simplicity to prodigious complexity.
And finally to the sort of complexity which is capable of designing things, of creating things, of working out how to do things.
If you suddenly going to insert a designing machine, a creator, an intelligence at the root of the universe you have just undermined your entire enterprise because your entire enterprise has been to explain how you get to something complicated enough to do design. – Richard Dawkins</p>
</blockquote>

<p>When Dawkins discusses evolution, it is easy to agree with him from a scientific perspective.
I want him to defend his theory.
However, he often speaks in absolutes, using the language of dogmatic religion that he himself criticizes.
From a systems theory point of view, can resolve this paradox by re-entering itself, that is, by communicating about itself on its own terms—a sort of self-reflection.</p>

<p>Dawkins and similar critics overlook a crucial point: the pursuit of absolute truth is elusive.
Even Dawkins’ assertion that “the theory is true” misrepresents the nature of scientific inquiry, which he is undoubtedly aware of.
Science provides models that explain phenomena until new evidence suggests otherwise.
It mosty works on the basis of <em>falsifiability</em> for <em>demarcation</em>, a concept introduced by Karl Popper (a critic of the inductive theory of science).</p>

<blockquote>
  <p>The problem of finding a criterion which would enable us to distinguish between the empirical sciences on the one hand, and mathematics and logic as well as ‘metaphysical’ systems on the other, I call the problem of demarcation. – <a class="citation" href="#popper:1934">(Popper, 1934)</a></p>
</blockquote>

<p>A statement or system of statements (theory) is falsifiable if it is capable of conflicting with possible, or conceivable observation;
The theory must be able to fail when tested against reality.
Build on rigor and the combination of theory bound by empiricism makes scientific method incredibly useful, and according to philosophers like Markus Gabriel, brings us closer to the Truth.
In contrast, others, such as Richard Rorty, completely reject the notion of absolute Truth and instead emphasize the practical usefulness of the scientific method.</p>

<p>The question of ontology remains unanswered even if most of us operate on the assumption of some sort of <em>naturalism</em>. 
It is the principle by which science operates and by which people in well-developed countries often live.
Some define it as “the idea that only natural laws and forces operate in the universe”.
The philosopher Quine described naturalism as “the position that there is no higher tribunal for truth than natural science itself”.
Quine’s more humble and pragmatic definition allows space for profound questions regarding the existence of time, space, causality, and our place within this framework—questions that lie beyond the scope of scientific inquiry.
For him and many others, these are absolute unknowns that can be considered within the realm of spirituality.
These unanswerable questions delve into the <em>essence of being</em> and the universe, inviting a spiritual exploration alongside scientific understanding.</p>

<p>Dawkins seems also to be unaware of the usefulness of ambiguity.
People can hold contradictory beliefs without being irrational or anti-science.
For example, it is unlikely that individuals with a non-dogmatic spiritual outlook adhere to a literal interpretation of the Earth’s creation in seven days or dismiss evolutionary theory but, at the same time, they might believe in a creator.
They can operate in different social systems with different rationals.
This is neither good or bad but a sign of diversity.
I mean how many mathematicians still believe that math has something to do with a divine entity or realm?
Such contradictions only become problematic if systems interfere in the other’s operations, e.g., if religion operates in science or science in religion.</p>

<p>But why can spirituality lead to the descent into the rabbit hole of conspiracy theories?
First of all, there is a strong relation between philosophy, religion, and spirituality, e.g., between Platonism and Christianity.
Monolithic religions offer a rather rigorous explanation of why things are as they are, based on the presumption of a creator.
Especially, non-believers sometimes misunderstand that religious people dislike logic when, in fact, it was Thomas Aquinas who attempted to synthesize Aristotelian philosophy (and logic) with the principles of Christianity.
He produced a vast body of precise, detailed, and systematic philosophical writings, in which he integrated Aristotle’s encyclopedic work and medieval Christian theology into a seamless whole.
The dark side of this was that any contradiction by future scientists would necessarily have to be seen as heresy.
Philosopher Bertrand Russell pointed out that Aquinas started by already knowing the truth in the form of the Catholic faith.
Aquinas used logic to strengthen his belief system and not to question it.
Note that postmodern thinkers argue that philosophers, who practiced metaphysics, did basically the same but in a more clever way.
Famous is Nietzsche’s suspicion of Kant’s categorical imperative, which is, after all, categorical.
Kant, however, pointed to the source of the problem which is not logic or rational thinking but a lack of empirical evidence; a lack of outwardness; of asking nature.</p>

<p>From this perspective, one might say that conspiracists are in the business of doing metaphyics poorly.
It is certainly the case that there are similarities in doing metaphysics and constructing a grand conspiratorial theory (or myth) that attempts to explain everything.
And like Aquinas, theorists of a conspiracy try to establish a kind of system, synthesizing the world into one big theory.
But there are also differences.
Metaphysicians (as well as many religious texts) at least try to be consistent, while conspiracy theorists are liberated from such limitations.
They openly replace rationality with mythology.
By constructing and emphasizing mythological symbols, conspiracy theories provide a shortcut into our soul, psyche, mind, or the unconscious.
They can switch seamlessly from one theory to another.</p>

<p>Myths can be very dangerous.
They misconstrue associations, destroy nuances and advance subconscious theses without the necessary burden of evidence.
Instead of delivering arguments, they short-circuit the entire argumentative process.
Myths do not make logical claims but significations <a class="citation" href="#barthes:1973">(Barthes, 1973)</a>.
For example, calling someone <em>a snake</em> is not a logical conclusion but signifies deceptive behaviour.
Real snakes, of course, are not significantly more or less deceptive than any other animal.
But mythological snakes often are and calling someone a snake can be a powerful gesture in our culture.</p>

<blockquote>
  <p>Poetry feeds and waters the passions instead of drying them up; she lets them rule, although they ought to be controlled, if mankind are ever to increase in happiness and virtue. – Socrates</p>
</blockquote>

<p>If Trump speaks of <em>America</em> or our radical right-wingers speak of Germany, they do not mean literal countries.
They signify a mythological symbol.
An effective myth is a self-contained world of signs were everything has a marked position, making it very hard to signify otherwise with a believer.
To critique their definition as being racist, irrational, exclusive, inhumane, or disastrous only demontrates to them that you are of ‘the them’ (das Man); that you are jealous that they won.
Any contrary narrative is spun by false prophets which conspire against the ‘chosen ones’.</p>

<h2 id="taking-the-wrong-pill">Taking the Wrong Pill</h2>

<p><em>The Matrix</em> is one of my all-time favorite movies, which increased my interest in computer science and philosophy.
As a child, I fantasized about being <em>The One</em>, akin to the hacker Neo, who could hack the matrix. 
Interestingly, the movie is inspired by French philosopher and theorist of postmodern media and culture, Jean Baudrillard (1929 – 2007), especially by his book <em>Simulacra and Simulation</em> <a class="citation" href="#baudrillard:1983">(Baudrillard, 1983)</a>.
The book even makes an appearance (as an empty prop) at the beginning of the film when Neo gives a disc to his clients.
The actors were even reportedly required to read it.</p>

<p>Baudrillard—the prophet of post-truth—focused on analyzing what can be termed <em>postmodern media</em>, although postmodernity is challenging to define.
Thinkers in the field of postmodern theory frequently hold different opinions but there is one core agreement: there are no all encompassing meta-narratives.
For some, such as Niklas Luhmann (1927–1998), the concept of postmodernity itself is contentious, with Luhmann believing it never truly existed <a class="citation" href="#luhmann:2000">(Luhmann, 2000)</a>. 
But back to Baudrillard.</p>

<p>He was an interesting figure but not taken very seriously by the academic community.
His writing style is polemical and his worldview extremely cynical. 
Despite this, his texts are intriguing and thought-provoking, capturing a sentiment that resonates with many facets of our society today.
In many sense, he was ahead of his time and highly influencial in the media and culture he studied.</p>

<p>What particularly makes <em>The Matrix</em> fascinating in connection with Baudrillard is how the film embodies the type of pop-cultural phenomenon he often discussed in his philosophy.
The movie not only reflects his ideas but might be able to bring them to life in a way that is accessible to a broader audience.
Furthermore, Baudrillard was still alive when the movie hit the theatre.
So, did it succeed in bringing his theory to the big screen?</p>

<h3 id="the-simulacrum-is-true">The Simulacrum is True</h3>

<p>When we first meet Neo, his computer is active, processing something, with the screen reflecting on his face. 
He listens to music through headphones while lying on his desk, asleep. 
This scene introduces the difficulty of distinguishing between a dream and reality or more precisely, the problem of informational overload and sensory input that, according to Baudrillard, leads to passivity.
The abundance of disjointed information and excessive transparency makes it nearly impossible to organize the world and assign meaning to it—faces transform into screens or terminals that passively absorb.</p>

<p>In his early career, Baudrillard aimed to merge (post-)Marxism with (post-)structuralism but eventually abandoned the former.
He applied structuralism in his analysis of <em>The System of Objects</em> <a class="citation" href="#baudrillard:1968">(Baudrillard, 1968)</a>. 
Baudrillard theorized that the significance of commodities stems not primarily from their use or exchange value, but rather from their sign value. 
In structuralism, the meaning of elements, such as words, doesn’t derive from what they represent. 
For instance, teaching a child the word ‘tree’ isn’t as simple as pointing to one and stating, “Look, this is a tree!”
The child wouldn’t know if ‘tree’ refers to that specific tree, its leaves, or a category of trees. 
Understanding the word ‘tree’ requires knowledge of many other words and examining their relationships to ‘tree’—their difference.
Baudrillard argues that in a postmodern society, any cultural idea, image, sign, or symbol is apt to be pulled out of its social context and used (or abused) for advertisement and marketing.
The individual is placed in the position of a consumer.
As these signs are lifted out of the social, they lose all possibility of stable reference.
They may be used for anything, for any purpose.
All that remains is a yawning abyss of meaninglessness—a placeless surface that is incapable of holding personal identity, self, or society.</p>

<p>Baudrillard believed that in a postmodern society, the meaning and value of an object are primarily defined by its relationship to other objects. 
Apple products serve as a pertinent example. 
They appear overpriced when considering solely their use value.
However, their value arises from what they signify in relation to other objects which leads to the demishing of <em>symbolic values</em>.
For example, a pen given to you for your graduation, has probably a high symbolic value to you.
Symbolic values are assigned by a subject in relation to another subject.
Sign value, on the other hand, is the object’s value within a system of objects signifying, for example, social status.</p>

<p>Baudrillard, known for his cynical views, also believed that objects essentially have triumphed over subjects. 
He posited that just as money has become a universal medium that renders everything comparable and thus exchangeable, <em>the code</em> has made every sign integratable thus also exchangeable.
It is not that subjects or objects stand no longer for something ‘real’ but that the imagined referent, that does not exist, disappeared.
For example, in the Renaissance people or objects appear to stand for an imagined referent, for instance, royalty, nobility, holiness, etc.
A sign like Iron Man, stands for nothing other than itself in a network of other meaningless signs, i.e. the Marvel universe.
It can be repackaged into a toy or a specific McDonalds meal because it has no sacred connection to the world.
According to Baudrillard, instead of disimulating something, now signs dissimulate that there is nothing.</p>

<blockquote>
  <p>The transition from signs which dissimulate something to signs which dissimulate that there is nothing, marks the decisive turning point. 
The first implies a theology of truth and secrecy (to which the notion of ideology still belongs). 
The second inaugurates an age of simulacra and simulation, in which there is no longer any God to recognize his own, nor any last judgment to separate truth from false, the real from its artificial resurrection, since everything is already dead and risen in advance. – Jean Baudrillard</p>
</blockquote>

<p>This leads to a kind of dissolution of the ‘real’ meaning behind objects.
Accroding to Baudrillard, in the postmodern world, simulacra (e.g. images) have replaced the reality they once represented.
In other words, our current reality is dominated by these simulacra—representations, images, and signs—that no longer have any connection to any real/imagined object or event they might have originally represented.
Importantly, the simulacrum is not just covering up the truth or reality; it’s not a mask over something real!
In fact, it is quite the opposite.
What we perceive as truth or reality is actually just a construct (the simulacrum) that conceals the fact that there is no underlying, original reality; we enter simulation.
In other words, what we consider ‘real’ is just a construct of our perceptions and societal agreement.
In our current postmodern state, the simulacrum has become the truth for us, because there is no other reality against which to measure it.</p>

<blockquote>
  <p>The simulacrum is never what hides the truth—it is the truth that hides the fact that there is none.
The simularcum is true. – Jean Baudrillard</p>
</blockquote>

<p>Following Baudrillard’s perspective, experiences such as a teenager’s first kiss are no longer real in a sense that they express ‘true love’;
instead, they are mere simulations of a Hollywood love story because these stories are the truth!
Imaginations are not destroyed by hiding the truth but by showing it overtly naked, like pornography rips us of the imaginative allure of sexuality and intimacy.
Life imitates advertisement.
This does not mean that there is no more love.
However, there is nothing behind the ‘Hollywood love story’—it is true as it is.</p>

<p>We are compelled to reproduce these images and to participate, even if we know or suspect that it is all a simulation.
Critically, the problem (if it is in fact one) is not a virtualized reality that hides the truth, but that the truth is simulation.
People are fake but they are turthfully fake because being fake is the truth.</p>

<blockquote>
  <p>[…] pretending […] leaves the principle of reality intact: the difference is always clear, it is simply masked, whereas simulation threatens the difference between the ‘true’ and the ‘false’, the ‘real’ and the ‘imaginary’. – Jean Baudrillard</p>
</blockquote>

<p>When more and more simulacra transform into simulation we enter the matrix.
Pictures of ourselves no longer represent us, or us pretending to be someone else, but they are a simulation of some specific and often stereotypical fantasy that has no reference to something real other than different parts of the code.
That is the depressing and cynical viewpoint of Baudrillard.</p>

<h3 id="platos-allegory-of-the-cave">Plato’s Allegory of the Cave</h3>

<p>I love <em>The Matrix</em> but I have to assess that it did not succeed in capturing Baudrillard’s main themes.
The main problem is a clear line between simulation and reality; between the matrix and Zion.
The matrix clearly is not the truth but hides it.
Rather than exploring the new problem of simulation, the movie falls back on the <em>Allegory of the Cave</em> presented in Plato’s <em>Republic</em>.
Instead of investigating further questions, it postulates a true world behind the simulation by re-introducing religion.
Thus <em>The Matrix</em> brings us back where it all started but, according to Baudrillard, this is no longer possible.
In Baudrillard’s framework, the movie is itself the truth that hides the fact that there is none and therefore distracts the audience from acknowledging <em>hyperreality</em>.</p>

<p>The <em>Allegory of the Cave</em> is a metaphor for exploring the nature of knowledge and reality.
Plato imagined a group of people who lived their entire live chained inside a dark cave.
The only thing they can see are the shadows projected on the wall of the cave by objects passing in front of a fire behind them. 
These shadows are the only reality they know.
The cave dwellers believe the shadows to be the real objects, not knowing that these are mere reflections. 
Their knowledge and understanding of the world are based solely on this limited perspective.
One day, a prisoner breaks free. 
He struggles to adjust to the light outside the cave, but eventually, he sees and understands the true nature of reality. 
He realizes that the sun illuminates the world and that what he saw in the cave were just shadows of real objects.
The freed prisoner returns to the cave to enlighten the others. 
However, his eyes have adjusted to the sunlight, so the cave is now blindingly dark to him. 
The other prisoners, unable to understand his experiences and seeing his blindness in the dark, refuse to believe him. 
They cling to their old beliefs about the shadows being the real objects.</p>

<p>In Plato’s metaphysics, the form (true essence of things) are more real than their physical representations.
The shadows represent the physical world, while the objects outside the cave symbolize the forms.
Plato also emphasizes that education is not just a matter of transferring information, but a transformative experience that leads to understanding, or to the seeing of a different world that opens up.
Of course, it is the philosopher that seeks the truth (outside the cave) and then attempts to bring this knowledge back to the people (inside the cave).</p>

<p>We can draw a neat parallel between Plato’s <em>Allegory of the Cave</em> and the film <em>The Matrix</em> by replacing the <em>cave</em> with <em>the matrix</em> and the philosopher with the character Morpheus. 
In this parallel, Morpheus takes on the role of guiding Neo (and others) out of the matrix—similar to leading prisoners out of the cave. 
Neo learns to understand and manipulate the matrix on his terms, which parallels the ability to manipulate the shadows on the cave walls.</p>

<p>In <em>The Matrix</em>, Neo is confronted with a crucial binary decision, symbolized by the choice between a red and a blue pill. 
As revealed in the sequels, this choice is, in itself, a part of a predetermined simulation—a much more Baudrillardian take.
Morpheus presents Neo with this decision and advises him to trust his instinct that something is fundamentally wrong with the world. 
This guidance emphasizes the importance of an emotional rather than a logical conclusion, steering Neo to follow his feelings in making this pivotal choice.</p>

<p>Once Neo makes his choice, the distinction between the matrix and reality is clear to him; it is a clear binary: reality and simulation.
True love is still possible outside and even inside the matrix, even if it is predetermined.
According to Baudrillard reality is a simulation echoing Kant, who does not grant us the access to the <em>thing-in-itself</em>, and of course Nietzsche, who tells us that there are only <em>constructed</em> values.
Simualation is nothing bad or something to fear.
It was always already there but the simulacrum (e.g. cave paintings, images) changed towards its own gravity; towards its own perfection.
What Baudrillard feared is a world akin to the movie <em>Minority Report</em>.
A world without <em>reversability</em> where everything is already decided in advance; a world without <em>ambiguity</em>.
In a sense, Baudrillard feared the modern project that started with Plato by looking for some absolut truth or perfect idea.
The perfect simulation gets rid of illusions and imaginations; it is too real; it is <em>hyperreal</em>;
Therefore, Baudrillard did not fear the loss of reality but an exzess of it which would lead to the destruction of illusions and imaginations like the ‘technical perfection of sex’, i.e. pornography, leads to the removal of sexuality and intimacy.</p>

<blockquote>
  <p>Reality and simulation aren’t opposed to one another. 
There are two sides of the same coin. – <a class="citation" href="#baudrillard:2008">(Baudrillard, 2008)</a></p>
</blockquote>

<p>With this in mind, if we reexamine <em>The Matrix</em> it becomes clear that Baudrillard would describe it to be a pretty good simulation of the matrix.
In a sense, the sign of simulation is re-integrated into the simulation itself.
This re-integration highlights the film’s exploration of reality, perception, and the nature of choice, themes that resonate with Plato’s allegory but not with <em>Simulacra and Simulation</em>.
Thus Baudrillard concluded:</p>

<blockquote>
  <p>The radical illusion of the world is a problem faced by all great cultures, which they have solved through art and symbolization.
What we have invented, in order to support this suffering, is a simulated real, which henceforth supplants the real and is its final solution, a virtual universe from which everything dangerous and negative has ben expelled.
And The Matrix is undeniably part of that.
Everything belonging to the order of dream, utopia and phantasm is given expression, ‘realized’.
We are in the uncut transparency.
The Matrix is surely the kind of film about the matrix that the matrix would have been albe to produce. – Jean Baudrillard</p>
</blockquote>

<h2 id="a-hunger-for-certainty-and-definitude">A Hunger for Certainty and Definitude</h2>

<p>Now, what has this to do with <em>conspiracy theories</em>?
Well, other than Baudrillard’s theory of a reality that is simulation, I claim that the <em>cave allegory</em> offers a theoretical justification for doubting established institutions, which are likened to ‘the matrix’.
One might discover that parts of reality, e.g. institutions, norms, moral judgements, ideologies, is constructed and that there has to be something real behind it.
This suspicion of a matrix is not unfounded, however, believing in some <em>absolut point</em> of view behind it, opens the door to confusion.
We are in a cave but going outside might only lead to another cave.
Importantly, this does not mean that any cave is as useful or functional!
Although not all interpretations of a text are equally meaningful, a good text offers numerous interesting and valuable interpretations and the same seems to be true of our <em>lifeworld</em>.</p>

<p>Doubting parts of reality—a known or presented world—is the starting point of any conspiracy theory.
The perspective is compelling because it feeds the allure of knowing a secret, akin to Neo’s experience in the matrix.
Such knowledge is seen as something that sets an individual apart from ‘the herd’, giving them a sense of being special or enlightened.
It is similar to <em>New Age</em> beliefs in some sort of special knowledge about the universe presented in movies like <em>The Secret</em>.</p>

<p>Belief in conspiracy theories appears to be driven by motives that can be characterized as epistemic (understanding one’s environment), existential (being safe and in control of one’s environment), and social (maintaining a positive image of the self and the social group) <a class="citation" href="#douglas:2017">(Douglas et al., 2017)</a>.
One important facet of conspiracy theories that often goes without much notice is that they are notions about power: who has it and how are they using it?
Conspiracy theories accuse an implicitly powerful group of conspiring.
Usually that group is already powerful—even if that power is a fantasy—i.e., the president, a legislative body, industries or corporations, foreign countries, multinational groups, etc. 
Powerless groups are rarely accused of conspiring <a class="citation" href="#uscinski:2018">(Uscinski, 2018)</a>.
This also reflects the plot of <em>The Matrix</em> where agents of the matrix are much more powerful than ‘enlightened’ humans.</p>

<p>Studies show that some people are more prone to believing in conspiracy theories than others.
Some people will believe in any conspiracy theory even on light evidence while others, at the opposite end of the spectrum, are naive and will deny the existence of conspiracies even on accumulating evidence <a class="citation" href="#uscinski:2018">(Uscinski, 2018)</a>.
According to Jan-Willem Prooijen, conspiracy theories orginate through the same cognitive process that produce other types of belief (e.g. spirituality), they reflect a desire to protect one’s own group against a potentially hostile outgroup, and they are often grounded in strong ideologies.
They are a natural defensive reaction to feelings of uncertainty and fear <a class="citation" href="#prooijen:2018">(Prooijen, 2018)</a>.</p>

<p>Interestingly, in studies, individuals who perceive patterns in abstract paintings, random dots, or coin tosses were more inclined to believe in conspiracy theories, paranormal phenomena, and hold religious beliefs. 
Belief in conspiracies also tends to rise during natural disasters when people feel a lack of control. 
Due to their tendency to seek patterns, conspiracy theorists tend to categorize everything neatly into a framework of good versus evil.
Even though the world that is constructed is miserable, it is without uncertainty.</p>

<p>We are risk calculating creatures, always on the watch for new dangerous patterns.
This is evolutionary advantageous.</p>

<blockquote>
  <p>Conspiracy is a stubborn creed because humans are pattern-seeking animals.
Show us a sky full of stars, and we will arrange them into animals and giant spoons.
Show us a world full of random misery, and we will use the same trick to connect the dots into secret conspiracies. – Jonathan Kay <a class="citation" href="#kay:2011">(Kay, 2011)</a>.</p>
</blockquote>

<p>Perceiving patterns is the opposite of perceiving randomness, and randomness cannot be the basis for making sense. 
Of course, quite often, events occur randomly, without any discernible purpose or meaning. 
Sometimes, foolish mistakes simply happen unintentionally.</p>

<p>Research indicates that education reduces the likelihood of believing in conspiracy theories (with exceptions). 
This may initially appear counterintuitive because education encourages skepticism toward received wisdom. 
Shouldn’t skepticism lead one to think that there might be something hidden behind the scenes?
Well, skepticism is only one aspect of the equation. Education teaches individuals to scrutinize the evidence and seek primary sources, or more precisely, to consider <strong>all</strong> available evidence.
Under such scrutiny conspiracy theories fall apart.
Moreover, having a greater understanding tends to foster humility since individuals become increasingly aware of the vast expanse of knowledge that remains beyond their grasp.</p>

<p>Scrutiny is built into our institutions.
In the context of academic publishing, one must demonstrate a comprehensive understanding of the relevant literature and show how experiments can be reproduced to validate the published findings.
A peer review process by experts in the field checks for the soundness of the work and identifies possible errors. 
While this system is not flawless, makes mistakes, overemphasis the number instead of the value of publications, can be biased, and often favours the middle to upper class, it remains open to critique and has propelled us a long way.
Science is a discourse.
Theories are never absolute true but are seen as true as long as there is no evidence or proof that gives rise to different conclusions.
Mistakes have been made and will continue to be made in the future, but the system is self-correcting, self-preserving, and has advanced our knowledge considerably.</p>

<p>Conspiracy theories are also fueled by our cognitive biases. 
For instance, the <strong>proportionality bias</strong> tends to make us believe that a substantial effect must have a significant cause. 
Consider a scenario where either a neighbor or the President of the United States dies randomly; which one is more likely to trigger a conspiracy theory?
Studies have revealed that when people are informed about the assassination of a president, they are more inclined to believe in a conspiracy theory if it coincides with the outbreak of a subsequent civil war <a class="citation" href="#prooijen:2018">(Prooijen, 2018)</a>.
<strong>Tribalism</strong> encourages us to protect our own ingroup and establish a clear division between ‘us vs. them’, often framing it as a battle between good and evil.
The <strong>intentionality bias</strong> leads us to believe that negative consequences of our actions are unintentional, while attributing intentionality to others when they cause harm. 
For example, we may view bankers as evil, but perceive our own pension fund as a necessary institution.</p>

<p>Seeing patterns everywhere is the need for control <a class="citation" href="#shermer:2022">(Shermer, 2022)</a>.</p>

<blockquote>
  <p>The economy is not this crazy patchwork of supply and demand laws, market forces, interest rate changes, tax policies, business cycles, boom-and-bust fluctuations, recessions and upwings, bull and bear markets, and the like.
Instead, it is a conspiracy of a handful of powerful people variously identified as the Illuminati, the Bilderberger group, the Council on Foreign Relations, the Trilateral Commission, the Rockefellers and Rothshields.
[…] Conspiracists believe that the complex and messy world of politics, economics, and culture can all be explained by a single conspiracy and conspiratorial event that downplays chance and attributes everything to this final end of history. – Michael Shermer</p>
</blockquote>

<p><a class="citation" href="#landau:2015">(Landau et al., 2015)</a> show that people compensate for perceived loss of control by trying to restore control themselves by</p>

<blockquote>
  <p>bolstering personal agency, affiliating with external systems perceived to be acting on the self’s behalf, and affirming clear contingencies between actions and outcomes [… and] seeking out and preferring simple, clear, and consistent interpretations of the social and physical environments.</p>
</blockquote>

<p><strong>Narcissism</strong>, characterized by a belief in one’s superiority and the desire for special treatment, strongly correlates with a tendency to believe in conspiracy theories. 
Narcissists also exhibit heightened sensitivity to perceived threats <a class="citation" href="#cichocka:2022">(Cichocka et al., 2022)</a>.
Within the realm of narcissism, grandiose narcissists seek admiration by bolstering their egos through a sense of uniqueness, charm, and grandiose fantasies. 
It’s worth noting that narcissists often display naivety and are less likely to engage in <strong>cognitive reflection</strong>.
Surprisingly, studies have uncovered evidence suggesting that, contrary to expectations, education increases the likelihood of narcissists adopting conspiracy beliefs <a class="citation" href="#cosgrove:2023">(Cosgrove &amp; Murphy, 2023)</a>. 
This underscores the critical role of cognitive reflection as one of the most, if not the most, essential abilities to guard against narcissistic tendencies towards conspiracy beliefs.</p>

<blockquote>
  <p>[Conspiracy believers] are relatively untrusting, ideologically eccentric, concerned about personal safety, and prone to perceiving agency in action – <a class="citation" href="#hart:2015">(Hart &amp; Graether, 2015)</a></p>
</blockquote>

<p>Similar to the experience of emerging from the cave in Plato’s allegory, delving into a conspiracy theory is not merely a transfer of knowledge, but a transformative experience. 
It involves a world being shattered and a new one being constructed in its place.
This process signifies a profound shift in perception and understanding, where previously accepted realities are dismantled and replaced with an entirely different framework of belief and interpretation.</p>

<p>Like Morpheus’ emphasis on trusting one’s instincts in <em>The Matrix</em>, conspiracy theories often accurately capture the emotional aspects of a person’s situation. 
These theories provide compelling descriptions of emotional states but tend to offer simplistic and reactionary explanations for complex situations. 
Additionally, much like the concept of the matrix, they seek an all-encompassing explanation for everything.
Essentially, these theories represent a futile effort to eliminate contingency and the future’s uncertainty. 
They attempt to provide a sense of certainty and understanding in a world that (hopefully) is still inherently open, contingent, unpredictable and complex. 
This desire for comprehensive explanations reflects a deep-seated human need for order and predictability in an increasingly fatal looking world.</p>

<h2 id="escaping-the-simulation">Escaping the Simulation?</h2>

<p>The incorporation of expressions like ‘escaping the matrix’ and ‘being red-pilled’ into the vocabulary of conspiracy theory groups as metaphorical language is unsurprising.
These terms, which originated from <em>The Matrix</em>, are used metaphorically to describe the experience of awakening to a hidden or suppressed truth.
This desire might increase with the suspicion that there is none.
Specifically, ‘escaping the matrix’ denotes the recognition and liberation from a controlling system or an illusionary world, while ‘being red-pilled’ represents a moment of profound revelation or enlightenment, often regarding societal structures or purported conspiracies.
These metaphors have gained traction within certain groups as a way to express their beliefs in uncovering what they perceive as hidden truths within society.
They believe to be the philosophers of our age, teaching us how real man behave and how ‘the system’ keeps them weak and small.</p>

<p>Contrary to the common belief that ignorance fuels the acceptance of a matrix-like reality, it is curiosity that often propels this belief. 
People are attracted to the notion of discovering hidden truths and understanding the world in ways that differ from the majority’s perspective.
The group forms, in a manner reminiscent of a cult, and establishes easily comprehensible guidelines, resembling the revolutionaries from another pop-cultural and frequently misunderstood film—<em>Fight Club</em>.
The theme of ‘stepping out of the dark’ is central to Plato’s cave allegory, <em>The Matrix</em>, and various conspiracy theories. 
Such curiosity ignites a desire to investigate and question conventional narratives, leading some individuals to adopt alternative interpretations of reality.</p>

<p>Interestingly, critical thinking and intelligence do not necessarily prevent one from falling into this rabbit hole.
As described above, these attributes can sometimes drive narcissits deeper into exploring and accepting these alternate realities—the problem is a lack of reflection.
The quest for understanding and the allure of uncovering hidden knowledge can be so compelling that even the most critical and intelligent minds are susceptible to these alternate explanations.
Take the following speech performed by the actor James Caviezel (an actor I once admired for his role in <em>The Thin Red Line</em>) at the end of <em>Sound of Freedom</em>, a conspitorial movie about child trafficking:</p>

<blockquote>
  <p>While watching this movie, I guess some of you were feeling sad, maybe overwhelmed, or even feel a sense of fear, which is understandable. But living in <strong>fear</strong> isn’t how we solve this problem. It’s living in <strong>hope</strong>. It’s <strong>believing that we can make a difference</strong> because we can.
I want to make one thing clear: this movie you just watched isn’t about me or Tim Ballard. 
It’s about those kids. This film was actually made five years ago. 
It wasn’t released until now, with every roadblock you can imagine being tossed in our way. [The powerful do not want you to see it, believe me]. 
And the names you see here, on the screen, <strong>took a stand</strong>! They made sure that this story could be shown to all of you. Now, all of you have the opportunity to continue <strong>telling this story</strong>; [the Truth].
We don’t have big studio money to market this movie [(we only have Fox News, one of the biggest network in the country)], but we have <strong>you</strong>. The baton has now been passed to <strong>you</strong>. <strong>You</strong> are the storytellers who can get people to come see this film in theaters. Together, we have a chance to make these two kids and the countless children they represent the most powerful people in the world by telling their story in a way only cinema can.
For a couple of months, while Sound of Freedom is in theaters, these kids can be more powerful than the cartel kingpins, presidents, congressmen, or even tech billionaires. We believe this movie has the power to be a huge step forward toward ending child trafficking, but it will only have that effect if <strong>millions of people see it</strong>.
We don’t want finances to be the reason someone doesn’t see this movie, so Angel Studios has set up a forward program where you can pay for someone else’s ticket who might not otherwise see it. If you’re able, we invite you to pay it forward by buying a ticket for someone else, or if your budget is tight, share the already available free ticket with as many friends as you can.
Join us and millions of others as we ring Sound of Freedom and hope throughout the world. And just remember this: <strong>God’s children are not for sale</strong>.</p>
</blockquote>

<p>During the speech a QR Code and the text “Give an Share Tickets / ANGLE.COM/freedom” is displayed.</p>

<p>This speech is filled with pathos, it is shamelessly manipulative, moralistic, heroistic and serves a narcissist desire to ‘wake up’, spread the word of Truth or God and become the hero; a soldier of Freedom; an angle of God; a righteous martyred that saves us all.
It is also conspiratorial.
Of course, in the same breath Caviezel tells us to buy tickets to end child trafficking which is not only irrational but flat out unethical and morally dubious.
It is so obviously a scam that it becomes an interesting field of study why people buy into it.
Does the deeply religious actor James Caviezel believe what he is saying? I think he does on some level.
He explained at a promotion event for the movie that billionaires capture children to extract adrenalin out of their blood when they are scared of death, which is a famous QAnon conspiracy theory.</p>

<blockquote>
  <p>These people that do it; there will be no mercy for them! – James Caviezel</p>
</blockquote>

<p>The speech is also kind of Baudrillardian in that sense that even the fight for the Good is just a struggle to buy that god damn ticket; even God’s angles are reduced to passive consumers.
At the same time it is not about the kids but a much more sacred war of Good against Evil—a mystic war in a very <strong>angry</strong> United States of America!
A country that is at the brink of an inwardly directed outburst.
Everyone in the media is so angry all the time.
This angry speech and movie, that abuses religion, confirms my believe that I should not fear the people who name themselves after the Devil but those who name themselves after a righteous God.
Nietzsche was right about that.</p>

<p>Now, it is a fact that people do engage in conspiracies (and that child trafficking is a big problem).
A brief examination of history reveals numerous instances of conspiracies, some of which have even led to wars between nations. 
However, in retrospect, these conspiracies can often be explained without assuming the involvement of thousands of people. 
The complexity and impact of these historical events do not necessarily require large-scale collusion; often, they can be understood through the actions and decisions of a relatively small number of individuals or groups and through a systemic rationality. 
This understanding helps differentiate between plausible historical conspiracies and the more elaborate, less credible theories that claim widespread secret collaboration.
If it exists, the matrix is not a planned construction of anybody but a Baudrillardian process beyond anyones control.</p>

<p>In addition, it’s important to recognize that the world is inherently unjust. 
Justice is a human concept, one that evolves over time as we make what we call progress. 
However, in the realm of nature, there is no concept of justice at least none I am aware of;
nature operates outside of morality.
Absolute justice remains elusive and if we seek an explanation for the world’s injustice, conspiracy theories provide a sense of comfort.</p>

<p>It appears to me that the belief in having escaped the matrix or emerged from the cave is a strong indication of someone having entrenched themselves deeply in their own perspective—failing to see that their perspective also relies on some sort of <em>second-order observation</em>; a following of the herd, or in Baudrillard’s viewpoint, the false assumption that there is something true behind the simulation.
This belief offers comfort by addressing various uncertainties and the realization of one’s own ignorance. 
No one desires to be ignorant and no one wants to rely on some sort of authority, yet in many ways, we all are.
In our complex world, this is an unavoidable reality. 
Conspiracy theories provide a sense of understanding and control in a world where complete knowledge is unattainable, helping individuals cope with the inherent limitations of human understanding.</p>

<p>Therefore, I believe that individuals who are particularly uncomfortable with uncertainty, who seek control over their life, and who are actively aware of their lack of control, are more susceptible to falling into these rabbit holes of alternate realities. 
Additionally, a certain degree of narcissism may be necessary to believe in the premise that one possesses a superior ability to understand complex matters better than trained experts and to assume that the media consisting of hundred of thousand of journalists is a monolith.
This combination of a need for control, discomfort with uncertainty, and a self-perceived exceptional understanding can lead individuals to embrace alternative explanations that offer a sense of clarity and personal significance in a complex world.</p>

<p>If we contemplate the matrix envisioned by Baudrillard, then attempting to escape it through the immersion in an alternate version of reality, fostered by extensive consumption of social media and digital content, appears absurd. 
Perhaps a more appropriate approach to disengaging from the machinery of simulation and countering the sensation that reality seems increasingly tenuous is to simply disconnect from it all (from time to time).
When advertisements, repetitive media, individuals transformed into brands, and an incessant stream of content seize our attention, the signal overflow—the noise—overshadows a more tangible reality. 
In a scenario where there may be no external escape from the simulation, it could be valuable, from time to time, to focus on what is immediately before us: to experience, touch, smell, listen to our bodies, engage with physical sensations, concentrate, savor awareness, and relinquish the illusion of the “real” by re-connecting to a spiritual world.</p>

<p>We are not superheroes; we are composed of the same fundamental elements as everything else. 
While it might feel like we inhabit a sort of matrix, it’s essential to acknowledge that this is a choice we make. 
From childhood, we develop self-conceptions and fantasies, but this doesn’t negate the existence of the world itself. 
Fantasies are constructs, and doubting the existence of the world presupposes a profound level of experience and knowledge of that world—a world where we learn to eat, walk, dance, and understand the nuances of correct and incorrect language usage.
Doubting it requires a distance from it and that might be what social media does: it shrinks the world but increases the distance to it.
We often employ our habits so routinely that we forget we are employing them, and in doing so, we forget that the world—our home—is still there. 
The central question here is what is more reasonable to doubt: the world we intimately grew up in or our doubts about doubting it?</p>

<h2 id="our-dependence-on-second-order-observation">Our Dependence on Second-order Observation</h2>

<p>Thinking critically and maintaining a sense of curiosity are attributes that I certainly hope everyone possesses.
It is crucial that institutions, including large media operations, research institutions, and particularly governments, are consistently challenged and kept under close scrutiny.
Conspiracy theories can serve as a force to encourage the prevention of corruption.
I would be quite suspicious if there were no conspiracy theories present!</p>

<p>Simultaneously, these theories have the potential to divert attention from genuine issues. 
The public should advocate for accountability and transparency, cultivating a healthy and well-informed society in which decisions and policies undergo scrutiny and improvement through public discourse and critical examination.</p>

<p>However, as the current state of affairs stands, the notion that everyone can participate in the <em>marketplace of ideas</em> and engage in public discourse seems somewhat impractical and utopian. 
This dream may appear overly optimistic, excessively humanistic, and excessively individualistic. 
Instead, according to Luhmann, there exists an interdependent network of social systems that co-evolve together—not individual souls but interconnected systems.</p>

<p>Similarily we demand the media should try to be as objective as they can be but it is naive to think that they are able to present reality as it is.
Here I agree with Luhmann:</p>

<blockquote>
  <p>It is impossible to understand the reality of the mass media if you assume it is their job to provide correct information on the world and then assess how they fail, distort reality, and manipulate opinion—as if they could do otherwise. – Niklas Luhmann</p>
</blockquote>

<p>Basically, Luhmann observed something very similar to the <em>Manufacturing Consent</em> <a class="citation" href="#herman:1988">(Herman &amp; Chomsky, 1988)</a> but explains it slightly differently without the need for a <em>propaganda model</em>.
If one anticipates that the primary purpose of the media is to deliver accurate information or facts, they are likely to encounter inconsistencies that raise significant doubts about the credibility of the mass media apparatus. 
The media is inherently self-preserving.
It functions in a manner that constructs and sustains itself. 
While it is certainly beneficial for the media to provide accurate information, this is not its foremost objective.
The media provides <em>what is known to be known</em>.
It irritates politics, our economy and the scientific system while bing irritated by all these systems.
<strong>The media makes society restless</strong>.</p>

<p>The view that the media presents ‘the Truth’ contributes to the proliferation of conspiracy theories, since it portrays the entire system as corrupt.
If the media presents objective facts and these facts are inconsistent, distorted, incomplete and open for interpretation then it is disfunctional or corrupt.
Instead of recognizing the various shortcomings (which serve the internal logic of the system) within the media (of which there are many), one tends to assume a broad conspiracy aimed at deliberately deceiving the public.
This leads to a pervasive distrust, particularly directed towards well-established media outlets.
As a consequence, consumers may turn to ‘alternative’ media sources, even though these alternatives often inadvertently rely on established media institutions for their information. 
Reporting, conducting on-site investigations, collecting information, and managing extensive archives are expensive endeavors that only large institutions can effectively undertake. 
These institutions are essential if we are to have any hope to share a world that is at least partly commonly known.</p>

<p>The core issue lies in our reliance on what Niklas Luhmann refers to as <em>second-order observation</em> and is consequently a trust issue.
In modern society, directly observing reality is increasingly challenging. 
To stay informed about various aspects such as the state of the economy, job market trends, recent fashion styles, developments in one’s favorite sports league, or new scientific inventions and studies, it is impractical to personally verify these facets. 
Instead, we depend on the observations made by others and, of course, machines.
This means we have to engage with various forms of reporting and analysis: reading reports about the GDP, considering the opinions of fashion critics, watching sports programs, and reviewing scientific papers.
In science, we write review papers about review papers.
We track how often papers are cited, i.e. how these papers are being observed.
This reliance on second-hand information shapes our understanding of the world, as we depend on external observers to provide us with insights and knowledge about various domains that we cannot directly experience or verify ourselves.</p>

<p>We are frequently depend on multiple layers of <em>second-order observations</em> or various levels of abstraction.
Scientific papers serve as a prime example. 
These papers are typically not intended for a general audience but are meant for peers within the specific field of research. 
As a result, the average person often finds them inaccessible.
Consequently, we turn to science communicators and mass media to distill and present scientific information. 
These intermediaries play a crucial role in interpreting and translating complex scientific data and studies into ‘facts’ that are understandable and relevant to the general public. 
This reliance on filtered and simplified interpretations highlights our dependence on external sources to understand and engage with specialized knowledge areas.</p>

<p>At the core of our society is the notion of the individual as a subject capable of making their own decisions and drawing sound conclusions. 
However, it’s evident that our understanding of the numerous processes occurring around us is limited. 
The complexity of the modern world might only be manageable through <em>functional differentiation</em> and <em>second-order observation</em>. 
We are heavily dependent on specialists and experts, and our understanding is largely shaped by observing their observations.</p>

<p>Conspiracy theorists seemingly reject <em>second-order observation</em>, viewing it as a form of manipulation akin to the matrix. 
However, this rejection is a perilous illusion.
There is no position outside of second-order observation, no external vantage point from which to objectively assess ‘reality’ as it is, separate from the interpretations and understandings provided by others.
This perspective underscores the intricate and interconnected nature of knowledge and understanding in contemporary society.</p>

<p>Philosophers ranging from Plato, Fichte, and Kierkegaard to Russell, Kant, and Heidegger have provided insights that prompt us to question the application of second-order observation.
These philosophical teachings encourage us to contemplate whether we should exercise independent thinking and challenge the prevailing mainstream narrative.
This concept is epitomized in Heidegger’s notion of avoiding assimilation into <em>das Man</em> (the they), Kierkegaard’s emphasis on distancing oneself from the public, or Fichte’s focus on the ego. 
The stories goes like this: There exists an inner truth within us, and we should search within our <em>authentic</em> selves to discover it. 
As sovereign individuals in a libertarian society, we should not solely rely on the opinions, or observations, of others. 
As Kant famously articulated, we should have the courage to employ our own intellect (Verstand). 
I align with Kant with a caveat: we should also have the courage to acknowledge our own ignorance and cultivate the ability to rectify it.
By utilizing second-order observation wisely, we can develop a <em>cultural intelligence</em> more akin to Hegel’s concept of the world spirit than Kant’s emphasis on the individual.</p>

<h2 id="conviction-under-constructivism">Conviction under Constructivism</h2>

<p>Biologists Humberto Maturana, Francisco Varela, Samy Frenk, and Gabriela Uribe made a significant discovery regarding our understanding of color perception.
Rather than focusing solely on the correlation between the physical source of color and the retina’s response, they emphasized another more important correlation: the one between the retina and subjective color perception. 
In this context, the external source of color functions as a trigger, not the sole determinant.</p>

<p>This structure of subjective color perception effectively maintains the perception of colors under various objective conditions, even when there are substantial discrepancies between the perceived and ‘emitted’ color, as seen in deception experiments. 
Maturana and Varela extended this insight to introduce the concept of autopoesis, integral to the biological theory of cognition <a class="citation" href="#maturana:1987">(Maturana &amp; Varela, 1987)</a>.</p>

<p>In line with their constructivist theory, every individual constructs their own cognition and, by extension, their reality.
In fact, for Maturana cognition is living.
His theory seems not far from Kant’s and to an extend Fichte’s understanding of cognition.
Constructivism does not imply an absence of a single reality or a state of complete subjectivity, but rather, it leads to some noteworthy conclusions:</p>

<ol>
  <li>An absolute system of values and knowledge cannot exist because personal experience forms an unshakable foundation.</li>
  <li>Convincing someone can only succeed when they develop their own system of conviction.</li>
  <li>Humans, capable of observing their cognitive actions and recognizing the relativity of their seemingly valid knowledge, face the responsibility of choosing and adhering to their own value system.</li>
</ol>

<p>These conclusions have significant relevance to our current discussion. 
Maturana’s framework explains the challenge of debunking conspiracy theories and how individuals can inhabit vastly different realities. 
It also underscores our responsibility to acknowledge our inherently constructed perspective on reality and the value system we embrace.</p>

<p>Now, I should mention that there are numerous critics of constructivism, including Markus Gabriel, who advocates for what he refers to as <em>new realism</em>.
In his book <em>Der Sinn des Denkens</em> (English: <em>The Sense of Thinking</em>) <a class="citation" href="#gabriel:2018">(Gabriel, 2018)</a>, he writes:</p>

<blockquote>
  <p>Constructivism is incorrect. New realism asserts that we can perceive reality as it is, without there being precisely one world or reality that encompasses all objects or facts that exist. – Markus Gabriel</p>
</blockquote>

<p>I read his book with the expectation of finding a plausible justification for why this should be the case, but I couldn’t find any consistent argument. 
Admittedly, this might be unfair as the book is a popular science book and doesn’t aim to provide a rigorous theory. 
Nevertheless, Gabriel often labels assertions as obvious without offering a reasonable explanation. 
Based on what I’ve encountered and also observed in my own life, I lean toward believing in constructivism.</p>

<p>Certainly, this form of relativism raises several pressing issues. 
For instance, how can we justify the actions of individuals whose worldviews may vastly differ from our own?
Additionally, how can international bodies like the United Nations apply pressure on nations that violate human rights if their value systems diverge significantly from a Western dominated notion of values?
Richard Rorty has an intreresting take on that question.
If we want universal acceptance of and respect for human rights, we shouldn’t try to argue about it. 
We shouldn’t attempt to work out rational justifications of human rights, or arguments that will convince people that human rights are a good thing. 
Instead, according to Rorty, we would achieve better results if we try to influence people’s feelings instead of their minds—philosophy as poetry <a class="citation" href="#rorty:2016">(Rorty, 2016)</a>!
Rational justifying human rights is an abstract and philosophical way—something that, according to Rorty, isn’t possible anyway.
In a sense, Rorty suggest that, instead of arguing rationally against mythologies, we should imagine, construct and present better ones.
He does not believe in a second enlightenment—in which logic and rationality will triumph over evil.
It is worth noting that similar challenges and questions arise when we consider the concept of <em>free will</em>, which is itself a highly contentious notion, compare for example <a class="citation" href="#sapolsky:2023">(Sapolsky, 2023)</a>.</p>

<p>In a world with no singular perspective, there are multiple viewpoints coexisting and each has its inherent blind spots. 
According to Luhmann, this principle applies to any observing system, whether it’s a psychological system, like the human mind, or a social system.
The diversity of perspectives inherently limits each view, preventing it from fully encompassing all facets of a situation or concept. 
Observation is blind to its own conditions.
When I observe a tree I can not (at the same time) observe myself observing the tree.
This inherent limitation in observation highlights the intricate and multifaceted nature of comprehending and interpreting the world around us.</p>

<p>The diversity of perspectives among individuals often complicates accurate communication because each of us essentially speaks a slightly different language.
Communication, in itself, can be seen as improbable. 
In addition, language is not something we use to describe reality accurately but a technique we employ to get things done.
Nevertheless, communication remains a crucial element as it plays a central role in stabilizing the chaos and connecting psychic and social systems.
Interestingly, it can be effective even when we don’t fully comprehend each other. 
A prime example of this is ChatGPT, which may not understand as humans do but still manages to communicate effectively.</p>

<p>So, can we embrace and navigate this diversity of perspectives?
Can or should we tolerate the uncanny sensation of numerous distinct realities coexisting? 
Is it possible for us to, to some extent, accept that others may inhabit a differently constructed world while simultaneously acknowledging the existence of something that persists, even if we cease to believe in it.
After all, our constructions do not follow our beliefs—we can not dream the problem away.</p>

<h2 id="the-reality-of-the-climate-crisis">The Reality of the Climate Crisis</h2>

<p>The COVID-19 pandemic had a measurable positive effect on pollution levels—which did not last for long.
However, one could argue that it also had a negative impact on trust levels in institutions, especially scientific ones.
This erosion of trust may ultimately hinder efforts to address the climate crisis.
The ongoing debate regarding climate change’s origins and the necessity of curbing CO2 and equivalent gas emissions continues to persist even if the scientific community is clear on the matter—a conviction I have established via <em>second-order observation</em>.</p>

<p>It appears to me that COVID, combined with the rapid and highly polarizing consumption of “news” on social media, has fractured our social discourse. 
The culture of dialogue has suffered, forcing individuals to align with one of two extreme sides. 
It now seems impossible to critique one party without facing accusations of working for the other.
The language we employ has become more <strong>moralizing</strong>. 
Instead of characterizing people as simply incompetent, misled, misguided, or influenced by flawed incentives within a system, they are often labeled as <strong>evil</strong>. 
This focus on the individual impedes progress in reforming social systems, which are in need of change to provide alternative incentives that prioritize social, ecological, and economic measures for all inhabitants of the planet.
Part of the reality of the climate crisis is that we need trusted institutions that need to be aligned in a way that dealing with the crisis becomes possible.</p>

<p>Emissions are not the only problems on our hand.
Many ecological systems are on the bringe of collapse.
Our agriculture is under threat.
Water shortages are on the horizon.
Increased carbon dioxide absorption by oceans leads to ocean acidification, which can harm marine life, especially coral reefs and shellfish.
Climate change can exacerbate health issues by increasing the spread of diseases, heat-related illnesses, and air quality problems due to wildfires and increased pollen levels.
Changing weather patterns and more frequent extreme events can disrupt agriculture and water supplies, potentially leading to food shortages and conflicts over resources.
As climate impacts worsen, there will be never-seen increased migration and displacement of populations, both within and across borders, as people seek refuge from areas affected by climate-related hazards.
Climate change is very likely to intensify extreme weather events such as hurricanes, droughts, heatwaves, and heavy rainfall. 
These events can lead to increased property damage, displacement of populations, and economic losses.
Sea levels are expected to continue rising, posing a threat to coastal communities, infrastructure, and ecosystems. 
Flooding and saltwater intrusion into freshwater sources may become more common.
I imagine that, at some point, borders of certain countries will be closed, dividing the world in a <em>real</em> and a <em>hyperreal</em> one.</p>

<p>Considering all the points I discussed, the resistance to transitioning away from fossil fuels is expected, given the various parties involved. 
It would be a relief if we were in a simulated reality, where everything could be dismissed as a bad dream.
However, we are faced with the pressing need to convince everyone that climate change is a real problem that demands immediate action.
And that it is worth to sacrifice for the unknown other.
Individuals who have limited information may be persuaded through sound arguments and credible sources. 
However, those who actively reject the mainstream narrative may ultimately question the legitimacy of <em>second-order observation</em>.</p>

<p>An example of this dynamic in action was during a BBC News panel where Brian Cox (physics professor and science communicator) clashed with skeptic Malcolm Roberts (politician). 
Roberts insisted on <em>empirical evidence</em> and rejected <em>appeals to authority</em>. 
All seemed well and logical, but when Cox presented a graph as evidence, Roberts dismissed it, alleging that the data had been corrupted by NASA.
At this juncture, a discussion is no longer possible because there are no external empirical evidence available beyond that produced by scientific institutions.</p>

<p>Undeniable empirical evidence, including temperature records, ice melt data, and rising sea levels, serves as a compelling testament to the tangible effects of climate change. 
To promote a more informed perspective, it is advisable to encourage individuals to explore and critically evaluate reputable, peer-reviewed scientific sources, rather than relying on fringe or biased information.
So, let’s delve into a tiny selection of influential contributions from the scientific community that have shaped our understanding of climate change.
Note that this is only a tiny selection from the whole corpus:</p>

<p>As early as 1896, Svante Arrhenius published a groundbreaking paper on the greenhouse effect, demonstrating how rising concentrations of greenhouse gases lead to an increase in global average surface temperatures <a class="citation" href="#arrhenius:1896">(Arrhenius, 1896)</a>.
Another significant milestone occurred in 1967 when Manabe and Wetherald published the first paper that incorporated the fundamental elements of Earth’s climate into a computer model, exploring the implications of doubling carbon dioxide levels for global temperatures <a class="citation" href="#manabe:1967">(Manabe &amp; Wetherald, 1967)</a>. 
Remarkably, the results of their work remain valid today, according to Prof. Forster.
In 1976, Charles D. Keeling and his team documented a pivotal moment by revealing the sharp rise in carbon dioxide levels at the Mauna Loa observatory in Hawaii <a class="citation" href="#keeling:1976">(Keeling et al., 1976)</a>. 
This paper highlighted the observable increase in atmospheric CO2 resulting from the combustion of carbon, petroleum, and natural gas.
Fast-forwarding to 2006, Held and Soden advanced the concept known as <em>wet-get-wetter, dry-get-drier</em> precipitation in the context of global warming <a class="citation" href="#held:2006">(Held &amp; Soden, 2006)</a>. 
This idea, though occasionally misunderstood and misapplied, remains the first and perhaps the only systematic conclusion regarding regional precipitation and global warming based on a robust physical understanding of the atmosphere.
Additionally, the <em>Intergovernmental Panel on Climate Change</em> (IPCC) reports have played an integral role in consolidating and disseminating crucial climate science findings, further enhancing our collective comprehension of climate change.
If one is convinced that there may be some shadiness going on, I encourage the reader to delve into the extensive history of climate change science, for example <em>The Discovery of Global Warming</em> <a class="citation" href="#weart:2009">(Weart, 2008)</a>.</p>

<p>Additional, one can highlight the overwhelming consensus among climate scientists and scientific organizations that climate change is real and largely caused by human activities, compare <a class="citation" href="#myers:2021">(Myers et al., 2021; Lynas et al., 2021; Cook et al., 2016; Cook et al., 2013; Doran &amp; Zimmerman, 2009)</a>.
Of course, if we only rely on those papers we have to trust an even <em>higher-order observation</em>!
In addition, one can argue that there is no plausible alternative theory apart from the effects humans caused by polluting the planet.</p>

<p>But if an individual has lost trust in institutions, all these efforts will be fruitless.
Therefore, it is so deeply important that our scientific institutions as well as the media defend and improve their reputation.
Without the trust in <em>the other</em>, I see great danger on the horizon, especially if things become increasingly difficult.
The challenge lies in persuading individuals who harbor skepticism, particularly toward what climate change deniers label as <em>mainstream science</em>.</p>

<p>According to Maturana, convincing someone can only happen when they develop <strong>their own system of conviction</strong>. 
This aspect is especially crucial to consider. 
Therefore, engagement must be respectful. 
It’s essential to take the worries, fears, and arguments of deniers seriously, even when they appear unreasonable.
However, it is also important to remember that while we encourage others to develop their convictions, we should also acknowledge our own unique and potentially flawed convictions and remain true to them if we are not convinced otherwise.</p>

<blockquote>
  <p>I think I do it always through stories, never through direct confrontation.
Because if you directly confront somebody who’s thinking polar opposite to you, they don’t really listen.
They are thinking of arguments to refute to. […]
The first thing is to listen to them because maybe they’ve got a point, maybe they’re doing something you never thought about.
But if you still feel that you’re right, then you must have the courage of your conviction. – Jane Goodall</p>
</blockquote>

<p>There is another more systemic problem at hand: There is an entire self-producing industry centered around climate denial. 
Our society has fostered an army of lobbyists whose primary aim is to actively sabotage progress in addressing climate issues. 
In contrast to these ‘knowledgable’ deniers, scientists are required to rigorously justify every aspect of their research repeatedly and tend to be cautious about offering concrete advice. 
Conversely, climate deniers merely need to sow seeds of doubt; their strategy revolves around raising questions rather than providing evidence-based answers. 
This asymmetry in approach creates a challenging environment for advancing scientific understanding and consensus on climate change.</p>

<h2 id="rebels-of-authority">Rebels of Authority</h2>

<p>Apart from ignorance, selfish interests and plain stupidity, I have not yet pointed to the root problem.
I cited papers that suggest that there is a link between pattern matching skills, narcissism and believing in conspiracy theory.
Stupid people elect stupid and corrupt politicians, right?
But that is too easy of an explanation.
Whenever I have to fall back on stupidity or evilness, I get the feeling that I am missing something.
Most of the time peope are not evil or stupid.
Similar to conspiracy theories, such a rational is too simple, too individualistic and also too dangerous.
So what is the systemic reason why people reject actions required to keep the planet sustainable for us all?</p>

<p>Of course, there are many complex reasons but I want to focus on one that fits the meat of this article.
I more or less successfully tried to problematize the search for an absolute objective truth by pointing out that those who believe in stepping out of the cave go probably deeper into it.
And I pointed to Baudrillard’s imagined eradication of imagination leading to a <em>true simulacra</em> that no longer stands for anything but itself—a description of <em>hyperreality</em> that hits me emotionally.
Now, let us imagine that conspiracy theorists rightly point to a problem they might not really understand rationally but feel intuitively.
What might it be?</p>

<p>If we want to describe our modern Western society, I think it’s fair to say that we are a <em>knowledge-based society</em>.
Since Foucault’s historical analysis, we know that knowledge and power are linked. 
In our daily life, most of our decisions are informed by some scientifically produced piece of knowledge.
For example, our diet is informed by scientific research that gives us guidance to stay healthy.
How often or for what reason we go to the doctor is informed by science.
In fact, we wittness a whole industry of self-optimization that claims to be scientific.
There are cults trying to establish a ‘science’ of finding a breeding mate.
Or take this article.
My goal and strategy of achieving it is similar: I employ knowledge and second-order observation by citing scientific papers.
In that sense, I fall into the same trap, that is, I try to convince my opponents by displaying superious knowledge.
Since Foucault</p>

<p>In such a society, we tend to search for the <em>perfect algorithm</em> that can make the best decisions for any situation.
In fact, many decisions are already made by algorithms based on the observation of large amounts of data.
Even policies are crafted by utilizing artificial intelligence.
The idea is simple: instead of shouting at each other about the right course of action, let <em>objective reality</em> be the final judge; let ‘the Truth’ decide—let science guide us through the mess.
This is the dream born out of the Enlightenment and it sparked many ideologies that promised to fulfill this utopian harmony.
It is supported by the <em>mechanistic view</em> on the universe suggesting that we can eventually understand all causal relations going back to some final cause we might call God;
In its current interpretation, I call it <strong>algocracy</strong> <a class="citation" href="#danaher:2016">(Danaher, 2016)</a>, i.e., <em>rule by algorithms</em>.</p>

<p>Interstingly, most conspiracy theorist argue within this framework, that is, they argue not in terms of values but in terms of better knowledge.
At the same time they rebel against the authority of such algorithmic rigor.
Therefore, on the one hand, they believe in a complete understanding of reality or at least a big and very complex chunk of it.
Consequently, they also buy the idea that politics is basically determined by the most powerful authority: the truth.
On the other hand, they rebel against this doctrine by using its own logic.
I think here lies a great danger because <strong>the system harms itself by its own operation</strong>.
The system enters a process of selfdestruction.</p>

<p>Like Pippi Longstocking, conspiracy theorists create their world or imagine it based on an alternative system of turth.
In the case of Pippi Longstocking, we find this antiauthoritarian attitude charming, creative, and imaginative, but in the case of conspiracy theorists, many find it dangerous, idiotic, and ignorant—an inconsistency worth investigating.</p>

<p>According to the sociologist Alexander Bogner an overdose of  antiauthoritarian attitude becomes problematic if we no longer agree on any foundation making any conflict impossible since there is nothing to argue about.
One of such foundation is the belief in an objective truth.
He pragmatically argues that:</p>

<blockquote>
  <p>For libaral democracies, the idea of objective truth is a necessary fiction. – <a class="citation" href="#bogner:2021">(Bogner, 2021)</a></p>
</blockquote>

<p>This statement seems reasonable but I will problematize it later.
Bogner points out that a liberal democratic society requires conflicts grounded in dissent.
However, dissent is only possible if there is at least a shared foundation and also an alternative to think about.
Overall, I think Bogner’s essay aligns closely with the constructivists viewpoint shared by e.g. Luhmann even if he criticizes the theory for attacking the idea of an objective truth.
For example, he argues in a Luhmannian manner about the root problem of conspiracy theories, or what many call the <em>post-truth society</em>, pointing out the crossing of boundaries between two interdependent but operationally closed systems:
<strong>science</strong> and <strong>politics</strong>.</p>

<p>Due to the <em>functional differentiation</em> of modern societies, politics communicates about <strong>values</strong> and science communicates about <strong>facts</strong>.
Bogner argues that today this distinction is blurred leading to dysfunctional systems.
Nowadays, politics communicates about facts but is still guided by values.
This makes <em>productive dissent</em> difficult because different value systems no longer compete within the boundary of values but hide behind the battle for better knowledge.
Values are no longer up for debate.
Instead we argue for superior facts.
In this context, <em>fake news</em> take part in a new <em>language game</em> that is born out from the lack of alternatives.
Fake news do not attack values but knowledge itself.</p>

<blockquote>
  <p>This could also be observed during the coronavirus crisis: 
Due to the high pressure of scientification, the will for fundamental opposition in some places was discharged through the spread of ‘alternative facts’.
[…] It was directed against a (supposedly) authoritative instance that claimed to determine what is real, rational, and politically necessary through superior rationality.
From the perspective of this protest, political emancipation could only be an emancipation from the facts.
Alternative facts are evidently in vogue when politics (due to its alignment with science) appears to be without alternatives. – <a class="citation" href="#bogner:2021">(Bogner, 2021)</a></p>
</blockquote>

<p>Bogner correclty points out that scientific knowledge can be dangerous for politics because it dismantles or defuses the discourse.
It is also attractive if one wants to surrender responsibility because in science it is far easier to agree on statements since it follows a strict true-false distinction.
In this sense, science is authoritarian.</p>

<p>Take a simple example such as health.
Before talking about it, we already share certain values.
For example, most people probably assume that a long healthy life is preferable over a short or unhealthy life.
This seems reaonable.
However, even this seemingly simple assumption can not be proven.
It is a value and values are mutually constructed.
I can, for example, easily argue that it is better to live to the fullest even if this means that my life expectancy drops.</p>

<p>In politics we argue about values and try to find some common ground.
This requires some degree of cohesion.
It goes against our more and more individualistc togetherness.
Bogner points out that people are considerably constrained in their expression of dissent if scientific truth is translated into a politic that knows no alternative.
His statement resonates with the relation between the belief in conspiracy theory and narcism.
He writes:</p>

<blockquote>
  <p>The struggle against science and experts can thus be understood as a struggle against determinations that were not chosen by oneself.
For such determinations must appear as an impudent imposition to the individualized, modern person, who is increasingly called upon today as a self-responsible shaper of their destiny, as a self-entrepreneur or ‘Me Inc’. 
Therefore, the struggle against facts is, not least, a struggle for autonomy.
From this perspective, science denial appears as a critique that is in tune with the times, insofar as it derives its plausibility from the current conditions of subjectification.
In the protest against established knowledge, the disappointed hope of the highly individualized, activated subject for complete sovereignty and a fully comprehensible, decision-open world is discharged. – <a class="citation" href="#bogner:2021">(Bogner, 2021)</a></p>
</blockquote>

<p>If politicians give knowledge absolute authority over political decisions, and these decisions realize certain values, the only way to fight for different values is to fight a different truth.
Using Bogner’s perspective, fake news are not the cause of the problem but a symptom of a society that feels impotent because certain values are always already presupposed to be the right values.
Therefore, what Bogner calls <em>productive dissent</em> becomes impossible.</p>

<blockquote>
  <p>The rebellion of the knowledge deniers can overall be understood as a covert appeal directed against a (looming) colonization of politics by expert consensus, 
regardless of how reasonable the expert recommendations may be in individual cases. – <a class="citation" href="#bogner:2021">(Bogner, 2021)</a></p>
</blockquote>

<p>I agree with Bogner that a culture needs a common foundation, a reference world, which, according to Luhmann, should be provided by the media.
And we also need a more flexible and ambiguous reference world on a global scale, see <a class="citation" href="#bauer:2018">(Bauer, 2018)</a>.
Furthermore, I agree that science cannot and should not realize politics and that better knowledge does not automatically lead to better politics.
Science should continue to operate on the true-false distinction, while politics should use a different code that differentiates values.</p>

<p>In case of climate activism, it might be a far more effective strategy to demand the values people want to be realized instead of discussing the facts they believe in.
Instead of calling people deniers, it might be healthier to find and employ strategies that reveal their value system and how this value system supports certain actions.
We should reinvigorate the discourse about values since it is save to say that more and better facts alone cannot move a society towards change.</p>

<p>However, I do not agree with Bogner’s claim that we need to agree that there is an <em>objective truth</em> to be found. 
I even suspect he does not fully believe this himself, as he refers to the <strong>idea of an objective truth as a necessary fantasy</strong>, akin to <em>Plato’s noble lie</em>—a myth knowingly propagated by an elite to maintain social harmony.
I reject this in favor of an embracing uncertainty because, as I argued above, I think it drives the individual deeper into the cave. 
As the philosopher Slavoj Žižek argues—contrary to Dostoevsky and many others—–that the belief in God enables us to commit horrific crimes, believing in an objectively accessible truth can serve the same purpose.
If we no longer live in the same world, society might break, but this does not diminish the great value of doubt and uncertainty in restraining our tendency for megalomania.</p>

<p>On this matter, I lean more towards Rorty, believing that we are mature enough to handle the pragmatist view that it is socially more useful to reject the idea of an objective truth (in the Platonist sense).
According to Rorty, Pippi Longstocking should be allowed to argue for her position, and we should accept her position to be true if it emerges out of the struggle for truth.
The American pragmatist rejects the Platonist’s notion of truth, considering it unintelligible and meaningless.</p>

<blockquote>
  <p>For the idea of a liberal society, it is of central importance that everything is allowed as long as it pertains to words as opposed to actions, to persuasion as opposed to violence. 
This openness should not be maintained because, as the Bible says, the truth is great and will prevail, nor because, as Milton believes, in a free and open fight, the Truth will always win. A society is liberal when it is content to call ‘true’ whatever emerges as the result of such struggles. – <a class="citation" href="#rorty:1989">(Rorty, 1098)</a></p>
</blockquote>

<p>Many, including Bogner, believe that such an attitude leads to <strong>indifference</strong>. 
He argues that if we take Rorty’s comment literally, we would bury both the idea of <em>objective truth</em> and our <em>liberal democracy</em>, since the realization of individual freedom through social change requires productive dissent.
I think Bogner, like many others, misinterprets Rorty or at least applies his statement to the wrong level of society—the wrong reality, so to speak. 
The implication that we end up in a sort of absolute relativism or complete indifference if we stop believing in an objective truth remains unfounded. 
It’s a huge leap.
Even if we reject the idea of an objective truth, empirical evidence is still valuable for discussions.</p>

<p>Rejecting the belief in an objective truth does not mean that we lose the ground for productive dissent.
On the contrary, it allows for a more pragmatic approach to dialogue and disagreement.
When we drop this belief, we recognize that our conversations and disagreements are grounded in our contingent vocabularies and cultural practices.
This recognition does not lead to indifference but rather to a greater appreciation of the diversity of perspectives.
It encourages us to engage with others’ values and beliefs not because they correspond to an objective reality, but because they are part of the <strong>shared human experience</strong>.
Productive dissent arises from the acknowledgment that our beliefs and values are fallible and open to revision through conversation.
It promotes a kind of solidarity where we strive to understand and negotiate our differences rather than impose a supposed objective truth.
This process fosters mutual respect and a more inclusive society, where different viewpoints can coexist and contribute to a richer, more nuanced understanding of the world.
By focusing on the practical consequences of our beliefs and actions, we can still engage in meaningful debates about what kind of society we want to create.
This pragmatic approach encourages us to find common ground and work together to address shared problems, rather than being paralyzed by the quest for an elusive objective truth.</p>

<h2 id="conclusion">Conclusion</h2>

<p>What I wanted to emphasize is the idea that we are existing within a subjective and distorted world of a reality that we can not directly access.
We are always already in a simulation, relying on second-order observation.
What I call <em>angry media</em> outlets, many of which take part in spreading misinformation and conspiracy theories, use more and more frequently phrases like <em>literally</em>, <em>this is simply the truth</em>, <em>they all know it</em>, <em>its a fact</em>.
They fight against ambiguity dragging anything into a culture war such that it has to be defined using one of two perspectives.
Thus the root cause of descending into the rabbit hole may not be a detachment from reality but rather an <strong>attachment to certainty</strong>. 
Perhaps Baudrillard is correct in asserting that we are entering a <em>hyperreality</em> that is no longer contradictory and dissolves all illusions, imaginations, and mysteries.
According to him, what we are trying to do is to purge the world of all mysteries, illusions and imaginations.
But certainty exists only in a pure form of simulation. 
In a constructivist sense, we cannot access the absolute true reality (Kant’s <em>the thing in itself</em>) because it is always already mediated.
If we cannot accept this fundamental ambiguity of our reality (by which Baudrillard does not mean physical reality but that which is intelligible via signs), we run the risk of constructing the one and only reality, i.e., hegemony.
Since this realm does not allow contradictions, it tends to integrate everything, including disasters, into it.</p>

<p>Contradictions form the very foundation of our environment. 
We perceive the reality of nature when it manifests as a non-human force of destruction, such as a natural disaster or a pandemic. 
What occurs is incomprehensible. 
In hyperreality, nature ceases to be a conflicting force and becomes merely an element within the simulation—a floating sign. 
Destruction transforms into a calculated event.
Repeatedly displaying graphs of death tolls gives us the illusion of control.
It can be seen as an attempt to reintegrate death (arguably the greatest contradiction of all) into the simulation.
The negative, along with contradictions, is either integrated or discriminated against.
Wars, natural disasters, and pandemics metamorphose into a spectacle on the television screen, a tourist attraction for our theme park, and are more disastrous than the disaster, more natural than nature—in short, a perfect simulation that surpasses and supplants reality.</p>

<p>In a postmodern society, the absence of any central value system and firm, objective evaluative guides tends to create a demand for substitutes. 
These substitutes are symbolically created rather than being actual or socially produced. 
The need for these symbolic group tokens results in tribal politics and defines self-constructing practices that are collectivized but not socially produced. 
These neo-tribes function solely as imagined communities and, unlike their premodern namesake, exist only in symbolic form through the commitment of individual ‘members’ to the idea of an identity. 
They exist as imagined communities through a multitude of agent acts of self-identification and endure solely because people use them as vehicles of self-definition; as an identity technology termed <em>profilicaty</em>.</p>

<p>I have no intention of passing moral judgment on conspiracy theorists.
They often risk a significant amount of social capital, leading to alienation from their relatives and friends.
Being a conspiracy theorist is generally not an enjoyable experience.
As I said, they rebel against authority via the same use of authority—a conflict of knowledge against ‘better’ knowledge in the realm of politics.
This is dangerous.
It points to a deeper problem of a violation of the <em>operational clousure</em> of social systems which we should take serious if our goal is to preserve these systems.
One might even argue that conspiracy theorists perceive cracks in the simulation but mistakenly believe in a way out of it, which, and this misinterprets <em>The Matrix</em> as well, serves as the perfect cover-up for our reality as always partly simulated.</p>

<p>Baudrillard famously argued that Disneyland does not hide the fact that it is a simulation, but rather conceals the fact that America is a simulation too. 
Disneyland is more real than America.
Conspiracy theories operate similarly; they are pure simulations and, in this regard, true. 
The outsider is convinced of his or her reality, and the contradictory nature of these theories is not contradictory for him or her. 
Instead, (obvious) contradictions are necessary to make the theory hyperreal. 
The suspicion of the theorists is not unreasonable, but their conclusion is fatal—they demand a simple metanarrative and cannot see that this can only be another far more harmful simulation.</p>

<p>Several factors contribute to the prevalence of conspiracy theories, including information overload, the perception of a reality that is becoming ‘less real’, the sensation of living in a quasi-simulated reality, natural disasters, ongoing conflicts, and the rapid pace of our society. 
Our modern world is so complex that it is virtually impossible for any single individual to comprehensively make sense of all that occurs.
As a result, we heavily rely on the concept of second-order observation, and there is no shame in acknowledging this fact.
Turning to experts and authorities, provided that their authority is derived from genuine competence, is necessary. 
However, it’s crucial to subject these authorities to scrutiny and verification and to be aware that their observation has always a blind spot.</p>

<p>Nothing in what I’ve stated here should be misconstrued as a defense of the political system. 
Lobbyism, which is sometimes indistinguishable from outright corruption, represents a significant issue. 
The consistent failure to fulfill promises, whether they be pledges for a transaction tax, the cessation of subsidies that actively contribute to global warming, or the numerous ‘conferences’ like COP that, at this point, are merely part of a <em>hope economy</em>—offering a false and pacifying sense of hope—that fuels the distrust in institutions.</p>

<p>In my view, COP28 proved to be a disaster for the majority of the world’s population. 
There was essentially no consensus on even the most basic measures. 
No accord on phasing out fossil fuels, and not even a genuine commitment to promoting renewable energy. 
The decision to have COP led by one of the world’s largest oil and gas companies is, at this point, satirical if it were not true.
In an assessment by journalist Jonathan Watts in The Guardian, the winners of the conference were identified as the oil and gas industry, the United States, China, COP28 President Sultan Al Jaber, the green energy sector, and lobbyists. Conversely, the losers encompassed the climate, small island nations, climate justice, future generations, other species, and scientists.</p>

<p>Nothing in what I’ve said here should be interpreted as a defense of the media for its issues, nor should it downplay the problem of increasing wealth inequality or any other ecological, social, or economic problems.
Both mass media and the scientific system have their problems, but this doesn’t negate their incredible value.
Moreover, independent media outlets play a crucial role, but we must be under no illusion that the verification of information is becoming increasingly challenging. 
Social media platforms present us with an overwhelming array of viewpoints, claims, and video content. With the ascent of generative artificial intelligence, the task of verifying this deluge of information becomes even more daunting.
The power of the image is indeed huge. 
The blurred line between hyperreality and lower forms of simulations makes it difficult to navigate through the mass of information. In contrast, conspiracy theorists do not bear the burden of a demanding verification process. 
They can simply draw upon fringe and unvalidated stories, presenting them in an entertaining, sensational style akin to news pornography. 
They can use the power of high-order simulacra which are disconnected from the real.</p>

<p>Believing in a conspiracy theory is akin to being the prisoner in Plato’s cave, presuming that everyone else is, in fact, in prison. 
It is the belief in something outside of simulation.
The most effective remedy is to harbor doubts about our own competence, to be skeptical of ourselves, to maintain self-awareness at a metacognitive level, and to be able to live in a contradictory world and recognize those contradictions.
These contradictions live on the borders of hyperreality—in slums, cobalt mines, the streets of New York City, the border of Mexico, the fortress of the European sea, refugee camps, and the ‘ugly’ parts of the world.</p>

<p>I am not sure if I can agree with the cynical viewpoint of Baudrillard. 
His overly dramatic and playful writings are interesting but also contradictory, probably by design.
He would probably be horrified at our attempt to <a href="https://blogs.nvidia.com/blog/earth-2-supercomputer/">simulate the whole earth</a> to predict and control our future. 
But how else can we deal with an open, unpredictable future other than the pursuit of more and more accurate predictions? Esposito asks if this future will still be open <a class="citation" href="#esposito:2024">(Esposito, 2024; Esposito et al., 2023)</a>.</p>

<p>It appears to me that logical reasoning and providing ‘better’ facts alone is not sufficiently compelling.
Science and technology is not enough.
It feels like we lack spiritual growth.
Maybe Rorty is right about the importance of empathic stories.
Maybe science should provide us with that what we call truth and politics should offer us a story that moves us.
But where are these stories?
Are we already as cynical as Baudrillard?
We need storytellers and artists to craft more persuasive mythologies, narratives, and stories that resonate on an emotional level.
I believe this can only be possible if we do not filter out the negative and the ugly part of society.
We have to be serious yet playful and imaginative.
I want a serious vision which is shamelessly emphatic towards all forms of life.
This anti-Platonistic approach, while potentially controversial, could prove more effective in influencing beliefs and behaviors and, in the end, matter more than any rational argument could be.</p>

<p>We have reached an alarming point at which millions of people can no longer discriminate between reality and hyperreality. 
That which cannot be simulated seems to disappear. 
There is a confusion between truth claims grounded in evidence and sound logic and alternative facts inspired by an authoritarian rebellion against the authority of knowledge.
Even in the case of the climate crisis, if we want to preserve a liberal democracy, politics has to discuss alternatives based on the consideration of different values.
We need imagination to draw larger circles and rationalty to make valid moves within these circles.
We have to trust in the scientific method to provide us with good knowledege, politics (not politicians) that is informed by science to provide us with good politics, and spirituality that may spend us wisdom and psychologic stability.</p>

<p>Most importantly, instead of appealing to objective truth, it is more productive to focus on the practical consequences and shared values that can mobilize action.
Instead of arguing that climate change is an objective truth that everyone must accept, we should emphasize the practical and tangible consequences of climate inaction.
By highlighting concrete consequences, we may make a compelling case for action based on the observable and lived experiences of people.
We should frame the argument for climate action in terms of shared values and common interests.
The goal is to find common ground and motivate people to act based on their own interests and values, rather than trying to convince them of an abstract objective truth.
Acknowledging the contingency and fallibility of our beliefs does not mean we cannot act decisively.
We can adopt policies and actions that are based on the best available evidence while remaining open to revising them as new information emerges. 
While rejecting objective truth might complicate the traditional ways of arguing for action, it also opens up new avenues for persuasion and coalition-building.</p>

<p>Sooner or later the reality of the crisis will eventually bleed into hyperreality.
Even if we construct our own perspective on the world, the reality of the climate crisis will not disappear if we stop believing in it.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="popper:1934">Popper, K. (1934). <i>Logik der Forschung</i>.</span></li>
<li><span id="barthes:1973">Barthes, R. (1973). <i>Mythologies</i>. Hill &amp; Wang Pub.</span></li>
<li><span id="baudrillard:1983">Baudrillard, J. (1983). <i>Simulacra and Simulation</i>. Semiotext(e).</span></li>
<li><span id="luhmann:2000">Luhmann, N. (2000). Why does society describe itself as postmodern. In W. Rasch &amp; C. Wolfe (Eds.), <i>Observing complexity: Systems theory and postmodernity</i> (pp. 35–49). University of Minnesota.</span></li>
<li><span id="baudrillard:1968">Baudrillard, J. (1968). <i>System of Objects</i>.</span></li>
<li><span id="baudrillard:2008">Baudrillard, J. (2008). <i>The Perfect Crime</i>. Verso.</span></li>
<li><span id="douglas:2017">Douglas, K. M., Sutton, R. M., &amp; Cichocka, A. (2017). The psychology of conspiracy theories. <i>Current Directions in Psychological Science</i>, <i>26</i>(6), 538–542. https://doi.org/10.1177/0963721417718261</span></li>
<li><span id="uscinski:2018">Uscinski, J. E. (2018). The study of conspiracy theories. <i>Argumenta</i>, 233–245. https://doi.org/10.23811/53.arg2017.usc</span></li>
<li><span id="prooijen:2018">Prooijen, J.-W. (2018). <i>The Psychology of Conspiracy Theories</i>. Taylor &amp; Francis Group. https://doi.org/10.4324/9781315525419</span></li>
<li><span id="kay:2011">Kay, J. (2011). <i>Among the Truthers: A Journey Through America’s Growing Conspiracist Underground</i>. Harper.</span></li>
<li><span id="shermer:2022">Shermer, M. (2022). <i>Conspiracy: Why the Rational Believe the Irrational</i>. Johns Hopkins University Press.</span></li>
<li><span id="landau:2015">Landau, M. J., Kay, A. C., &amp; Whitson, J. A. (2015). Compensatory control and the appeal of a structured world. <i>Psychol Bull</i>. https://doi.org/10.1037/a0038703</span></li>
<li><span id="cichocka:2022">Cichocka, A., Marchlewska, M., &amp; Biddlestone, M. (2022). Why do narcissists find conspiracy theories so appealing? <i>Curr Opin Psychol</i>. https://doi.org/10.1016/j.copsyc.2022.101386</span></li>
<li><span id="cosgrove:2023">Cosgrove, T. J., &amp; Murphy, C. P. (2023). Narcissistic susceptibility to conspiracy beliefs exaggerated by education, reduced by cognitive reflection. <i>Front Psychol</i>. https://doi.org/10.3389/fpsyg.2023.1164725</span></li>
<li><span id="hart:2015">Hart, J., &amp; Graether, M. (2015). Something’s going on here: Psychological predictors of belief in conspiracy theories. <i>Journal of Individual Differences</i>.</span></li>
<li><span id="herman:1988">Herman, E. S., &amp; Chomsky, N. (1988). <i>Manufacturing Consent</i>. Pantheon Books.</span></li>
<li><span id="maturana:1987">Maturana, H. R., &amp; Varela, F. J. (1987). <i>The Tree of Knowledge</i>. Shambhala.</span></li>
<li><span id="gabriel:2018">Gabriel, M. (2018). <i>Der Sinn des Denkens</i>. Ullstein Buchverlag.</span></li>
<li><span id="rorty:2016">Rorty, R. (2016). <i>Philosophy as Poetry</i>. University of Virginia Press.</span></li>
<li><span id="sapolsky:2023">Sapolsky, R. M. (2023). <i>Determined</i>. Bodley Head.</span></li>
<li><span id="arrhenius:1896">Arrhenius, S. (1896). XXXI. On the influence of carbonic acid in the air upon the temperature of the ground. <i>The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</i>, <i>41</i>(251), 237–276. https://doi.org/10.1080/14786449608620846</span></li>
<li><span id="manabe:1967">Manabe, S., &amp; Wetherald, R. T. (1967). Thermal equilibrium of the atmosphere with a given distribution of relative humidity. <i>Journal of Atmospheric Sciences</i>, <i>24</i>(3), 241–259. https://doi.org/10.1175/1520-0469(1967)024&lt;0241:TEOTAW&gt;2.0.CO;2</span></li>
<li><span id="keeling:1976">Keeling, C. D., Bacastow, R. B., Bainbridge, A. E., Ekdahl Jr., C. A., Guenther, P. R., Waterman, L. S., &amp; Chin, J. F. S. (1976). Atmospheric carbon dioxide variations at Mauna Loa Observatory, Hawaii. <i>Tellus</i>, <i>28</i>(6), 538–551. https://doi.org/10.1111/j.2153-3490.1976.tb00701.x</span></li>
<li><span id="held:2006">Held, I. M., &amp; Soden, B. J. (2006). Robust responses of the hydrological cycle to global warming. <i>Journal of Climate</i>, <i>19</i>(21), 5686–5699. https://doi.org/10.1175/JCLI3990.1</span></li>
<li><span id="weart:2009">Weart, S. R. (2008). <i>The Discovery of Global Warming</i>. Harvard University Press.</span></li>
<li><span id="myers:2021">Myers, K. F., Doran, P. T., Cook, J., Kotcher, J. E., &amp; Myers, T. A. (2021). Consensus revisited: quantifying scientific agreement on climate change and climate expertise among Earth scientists 10 years later. <i>Environmental Research Letters</i>, <i>16</i>(10), 104030. https://doi.org/10.1088/1748-9326/ac2774</span></li>
<li><span id="lynas:2021">Lynas, M., Houlton, B. Z., &amp; Perry, S. (2021). Greater than 99% consensus on human caused climate change in the peer-reviewed scientific literature. <i>Environmental Research Letters</i>, <i>16</i>(11), 114005. https://doi.org/10.1088/1748-9326/ac2966</span></li>
<li><span id="cook:2016">Cook, J., Oreskes, N., Doran, P. T., Anderegg, W. R. L., Verheggen, B., Maibach, E. W., Carlton, J. S., Lewandowsky, S., Skuce, A. G., Green, S. A., Nuccitelli, D., Jacobs, P., Richardson, M., Winkler, B., Painting, R., &amp; Rice, K. (2016). Consensus on consensus: a synthesis of consensus estimates on human-caused global warming. <i>Environmental Research Letters</i>, <i>11</i>(4), 048002. https://doi.org/10.1088/1748-9326/11/4/048002</span></li>
<li><span id="cook:2013">Cook, J., Nuccitelli, D., Green, S. A., Richardson, M., Winkler, B., Painting, R., Way, R., Jacobs, P., &amp; Skuce, A. (2013). Quantifying the consensus on anthropogenic global warming in the scientific literature. <i>Environmental Research Letters</i>, <i>8</i>(2), 024024. https://doi.org/10.1088/1748-9326/8/2/024024</span></li>
<li><span id="doran:2009">Doran, P. T., &amp; Zimmerman, M. K. (2009). Examining the scientific consensus on climate change. <i>Eos, Transactions American Geophysical Union</i>, <i>90</i>(3), 22–23. https://doi.org/https://doi.org/10.1029/2009EO030002</span></li>
<li><span id="danaher:2016">Danaher, J. (2016). The Threat of Algocracy: Reality, Resistance and Accommodation. <i>Philosophy &amp; Technology</i>, <i>29</i>, 245–268. https://doi.org/10.1007/s13347-015-0211-1</span></li>
<li><span id="bogner:2021">Bogner, A. (2021). <i>Die Epistemisierung des Politischen</i>. Reclam.</span></li>
<li><span id="bauer:2018">Bauer, T. (2018). <i>Die Vereindeutigung der Welt</i> (p. 104). Reclam.</span></li>
<li><span id="rorty:1989">Rorty, R. (1098). <i>Contingency, Irony, and Solidarity</i> (p. 201). Cambridge University Press.</span></li>
<li><span id="esposito:2024">Esposito, E. (2024). Can we use the open future? Preparedness and innovation in times of self-generated uncertainty. <i>European Journal of Social Theory</i>, <i>0</i>(0). https://doi.org/10.1177/13684310231224546</span></li>
<li><span id="esposito:2023">Esposito, E., Hofmann, D., &amp; Coloni, C. (2023). Can a predicted future still be an open future? Algorithmic forcasts and actionability in the precision medicine. <i>History and Theory</i>. https://doi.org/10.1111/hith.12327</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Social Systems Theory" /><category term="Conspiracy Theories" /><category term="Climate Crisis" /><summary type="html"><![CDATA[Diverging from my area of expertise is always a risky endeavor, but since this is a blog and not a scientific journal, I’m giving myself the liberty to explore and have fun with different ideas (even if the topic is depressing). Often writing helps in transforming the mess into a structured and coherent concept. The process of rethinking and reflecting can be invaluable. It helps to make ones thought anschlussfähig which literally means to be capable for connections and in this context means enabling the continuation of communication.]]></summary></entry><entry><title type="html">Musical Interrogation III - LSTM</title><link href="https://bzoennchen.github.io/Pages/2023/11/19/musical-interrogation-III.html" rel="alternate" type="text/html" title="Musical Interrogation III - LSTM" /><published>2023-11-19T00:00:00+01:00</published><updated>2023-11-19T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2023/11/19/musical-interrogation-III</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/11/19/musical-interrogation-III.html"><![CDATA[<p>This article is the continuation of a series.
It is recommended that you read part I and II first.
This time we use a recurrent neural network (<strong>RNN</strong>), more preceisly an <strong>LSTM</strong>, which I explained a little bit in the <a href="/Pages/2023/04/02/musical-interrogation-I.html">introduction</a>.
An LSTM is a RNN that counteracts the problem of exploding and vanishing gradients.</p>

<p>This article gives some explanation to the code in the following <a href="https://github.com/BZoennchen/musical-interrogation/blob/main/partIII/melody_rnn.ipynb">notebook</a>, which can be executed on <a href="https://colab.research.google.com/?hl=de">Google Colab</a>.
Because our model is now able to learn long-time relations, we can use the <code class="language-plaintext highlighter-rouge">GridEncoder</code>, i.e., a <em>piano roll data representation</em>, which is exaclty what we do.</p>

<h2 id="recurrent-neural-networks">Recurrent Neural Networks</h2>

<p>Prior to the advent of transformers, many cutting-edge natural language processing (NLP) applications relied on recurrent neural networks (RNNs). 
These networks are particularly adept at processing sequences of data, such as words in NLP tasks or notes and musical events in audio processing.</p>

<p>An RNN processes a sequence</p>

\[\mathbf{x}_0, \ldots, \mathbf{x}_{n-1}\]

<p>of inputs one at a time. 
With each new input, the network not only considers this current input but also incorporates a <em>hidden state</em>—a representation of previous inputs—thanks to its recurrent connections.
This hidden state \(\mathbf{h}_t\) is updated at each step, ensuring that the network retains a memory of what it has processed so far.</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/rnn-unfold.png" alt="Sketch of an RNN unfolded in time" />
<div style="display: table;margin: 0 auto;">Figure 1: Sketch of an RNN unfolded in time.</div>
</div>
<p><br /></p>

<p>The unique feature of RNNs is their ability to maintain an internal state that captures information about the sequence they have processed to that point.
As a result, the final output of the RNN is informed by the entire input sequence.</p>

<p>Furthermore, RNNs have been employed in sequence generation or decoding tasks. 
In such applications, the tokens generated by the RNN are fed back into it as inputs. 
This feedback loop allows the RNN to generate sequences where each new token is influenced by the previously generated tokens, making it suitable for tasks like text generation, music composition, and more.</p>

<h2 id="long-short-term-memory-networks">Long Short-Term Memory Networks</h2>

<p>Long short-term memory networks (LSTMs) are a type of RNN that were designed to overcome some of the limitations of vanilla RNNs, particularly in handling long-term dependencies in sequence data.</p>

<p>Vanilla RNNs struggle with learning long-term dependencies due to the <em>vanishing gradient problem</em>. 
As the length of the input sequence increases, the gradients used in the training process can become extremely small, making it difficult for the RNN to learn and retain information from earlier inputs. 
LSTMs address this issue with their unique architecture, which includes <em>memory cells</em> which uses different <em>gates</em>.</p>

<p>A <em>memory cell</em> can maintain information in memory for long periods of time. 
The key components of an such a cell are its gates: the <em>input gate</em>, <em>output gate</em>, and <em>forget gate</em>.
These gates regulate the flow of information into and out of the cell, and they decide what to retain or discard from the cell state.</p>

<ul>
  <li><strong>Update Gate</strong>: Determines how much of the new information to add to the cell state.</li>
  <li><strong>Forget Gate</strong>: Decides what information is no longer needed and removes it from the cell state, helping to prevent the accumulation of irrelevant information.</li>
  <li><strong>Output Gate</strong>: Controls the extent to which the value in the cell is used to compute the output activation of the block.</li>
</ul>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/lstm-cell.png" alt="LSTM cell" />
<div style="display: table;margin: 0 auto;">Figure 2: A sketch of a memory cell.</div>
</div>
<p><br /></p>

<p>Due to their architecture, LSTMs can learn and remember over longer sequences than vanilla RNNs, making them more effective for tasks like language modeling, text generation, speech recognition, and more, where understanding context over a long sequence is crucial.
The gating mechanism helps mitigate the vanishing gradient problem, allowing for more effective training over longer sequences.
This is because the gates allow gradients to flow through the network without being multiplied repeatedly by small numbers (which is what causes the gradients to vanish in vanilla RNNs).</p>

<h2 id="data-preparation">Data Preparation</h2>

<p>Again we use the data from <a href="http://kern.ccarh.org">EsAC</a>. 
The specific dataset I utilized is <a href="https://kern.humdrum.org/cgi-bin/ksdata?l=/essen/europa&amp;format=recursive">Folksongs from the continent of Europe</a> and for the purpose of this work, I will exclusively use the 1700 pieces found in the <code class="language-plaintext highlighter-rouge">./deutschl/erk</code> directory.</p>

<p>We assume that 1/16 is the shortest note in our dataset.
The <code class="language-plaintext highlighter-rouge">GridEncoder</code> automatically filters out pieces that do not fulfill this condition.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">time_step</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">16</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">GridEncoder</span><span class="p">(</span><span class="n">time_step</span><span class="p">)</span>
<span class="n">enc_songs</span><span class="p">,</span> <span class="n">invalid_song_indices</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">encode_songs</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'there are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">enc_songs</span><span class="p">)</span><span class="si">}</span><span class="s"> valid songs and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">invalid_song_indices</span><span class="p">)</span><span class="si">}</span><span class="s"> songs'</span><span class="p">)</span>
</code></pre></div></div>

<p>Let us look at an example encoded of a piece:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>55 _ _ _ 60 _ _ _ 60 _ _ _ 60 _ _ _ 60 _ _ _ 64 _ _ _ 64 _ _ _ r _ _ _ 62 _ 64 _ 65 ...
</code></pre></div></div>

<p>As we discussed in the last article, <code class="language-plaintext highlighter-rouge">55 _ _ _</code> stands for the midinote <code class="language-plaintext highlighter-rouge">55</code> played for 4 beats where one beat is 1/16 note.
Therefore, this is a 1/4 note.
Likewise, <code class="language-plaintext highlighter-rouge">r _ _ _</code> is a 1/4 rest.</p>

<p>Netx the <code class="language-plaintext highlighter-rouge">StringToIntEncoder</code> converts our alphabet of tokens into positive integers.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">string_to_int</span> <span class="o">=</span> <span class="n">StringToIntEncoder</span><span class="p">(</span><span class="n">enc_songs</span><span class="p">)</span>
</code></pre></div></div>

<p>Next, we use <code class="language-plaintext highlighter-rouge">ScoreDataset</code> to arrange our training data.
It requires our encoded songs, the instance of <code class="language-plaintext highlighter-rouge">StringToIntEncoder</code> and a <em>hyperparameter</em> <code class="language-plaintext highlighter-rouge">sequence_len</code> that configures the length of token sequences our model will be trained on.
The longer the sequence, the longer the training will require because the deeper the recurrent neural network will be.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sequence_len</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># this is a hyperparameter!
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">ScoreDataset</span><span class="p">(</span>
    <span class="n">enc_songs</span><span class="o">=</span><span class="n">enc_songs</span><span class="p">,</span> 
    <span class="n">stoi_encoder</span><span class="o">=</span><span class="n">string_to_int</span><span class="p">,</span> 
    <span class="n">sequence_len</span><span class="o">=</span><span class="n">sequence_len</span><span class="p">)</span>
</code></pre></div></div>

<p>It is now possible to split our data into training, validation and test set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_set</span><span class="p">,</span> <span class="n">val_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
</code></pre></div></div>

<h2 id="model-definition">Model Definition</h2>

<p>Firt we define the rest of our <em>hyperparameters</em>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">string_to_int</span><span class="p">)</span> <span class="c1"># size of our alphabet
</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="c1"># can be different
</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span> <span class="c1"># can be different
</span><span class="n">layer_dim</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># can be different
</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="c1"># should not be different
</span><span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="c1"># can be different
</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1"># can be different
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># can be different
</span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># can be different
</span><span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># can be different
</span></code></pre></div></div>

<p>Before explaining every detail, let us look at the model definition first.
The following is the model description of our RNN/LSTM.
To understand what’s going on, look at the forward method.
This sends our data through the network.</p>

<p>The first two lines create the short-term \(\mathbf{h}_0\) and long-term memory \(\mathbf{c}_0\) and fill them with zeros.</p>

<p>Then an embedding takes place: <code class="language-plaintext highlighter-rouge">x = self.embedding(x)</code>.
This is nothing more than what we did with our simple feedforward net in <a href="/Pages/2023/05/31/musical-interrogation-II.html">Part II - FNN</a>: Each element of the input <code class="language-plaintext highlighter-rouge">x</code> is first one-hot encoded and then multiplied by a matrix. 
The result: Each event is represented by the row of a matrix (with learnable parameters).
The matrix has <code class="language-plaintext highlighter-rouge">vocab_size</code> rows and <code class="language-plaintext highlighter-rouge">input_dim</code> columns.</p>

<p>Next, we send our transformed input through our LSTM out, <code class="language-plaintext highlighter-rouge">(ht, ct) = self.lstm(x, (h0, c0))</code>.
This basically computes \(\mathbf{h}_t, \mathbf{c}_t\) based on \(\mathbf{h}_{t-1}, \mathbf{c}_{t-1}\) as indicated in Fig. 2.
We get as many outputs as our sequence is long, i.e., <code class="language-plaintext highlighter-rouge">sequence_len</code> many.
But we are only interested in the last output, which we get by <code class="language-plaintext highlighter-rouge">out[:, -1, :]</code>.
This is a vector with <code class="language-plaintext highlighter-rouge">hidden_dim elements</code>. 
We don’t need <code class="language-plaintext highlighter-rouge">ht</code> and <code class="language-plaintext highlighter-rouge">ct</code>.</p>

<p>Then we send the last output through a dropout layer to counteract <em>overfitting</em>.</p>

<p>In the last step, we transform the <code class="language-plaintext highlighter-rouge">hidden_dim</code>-dimensional vector into an <code class="language-plaintext highlighter-rouge">output_dim</code>-dimensional vector, which is equal to <code class="language-plaintext highlighter-rouge">vocab_size</code>.
This vector is interpreted as a probability distribution.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LSTMModel</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LSTMModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layer_dim</span> <span class="o">=</span> <span class="n">layer_dim</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">layer_dim</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">layer_dim</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># x = B, T, C
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">out</span><span class="p">,</span> <span class="p">(</span><span class="n">ht</span><span class="p">,</span> <span class="n">ct</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span> <span class="c1"># B, C
</span></code></pre></div></div>

<p>Next, we initialize the model:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">LSTMModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># use gpu if possible
</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()))):</span>
    <span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">())[</span><span class="n">i</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<p>We could play with different hyperparameters.
Increasing <code class="language-plaintext highlighter-rouge">hidden_dim</code> basically increases the complexity of the “memory” of the LSTM.
We surely want to increase <code class="language-plaintext highlighter-rouge">n_epochs</code> to increase number of times the LSTM “sees” all training data.</p>

<p>We can visualize the LSTM by utilizing the <code class="language-plaintext highlighter-rouge">draw_graph</code> function from the <code class="language-plaintext highlighter-rouge">torchview</code> package.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># (batch_size, sequence_len)
</span><span class="n">X_vis</span><span class="p">,</span> <span class="n">y_vis</span> <span class="o">=</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'shape of X_vis: </span><span class="si">{</span><span class="n">X_vis</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'shape of y_vis: </span><span class="si">{</span><span class="n">y_vis</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'number of different symbols </span><span class="si">{</span><span class="n">vocab_size</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">X_vis</span><span class="p">,</span> <span class="n">y_vis</span> <span class="o">=</span> <span class="n">X_vis</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_vis</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">model_vis</span> <span class="o">=</span> <span class="n">LSTMModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">model_graph</span> <span class="o">=</span> <span class="n">draw_graph</span><span class="p">(</span><span class="n">model_vis</span><span class="p">,</span> <span class="n">input_data</span><span class="o">=</span><span class="n">X_vis</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">model_graph</span><span class="p">.</span><span class="n">visual_graph</span>
</code></pre></div></div>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:40%;" src="/Pages/assets/images/lstm-model.png" alt="LSTM model" />
<div style="display: table;margin: 0 auto;">Figure 4: The architecture of our LSTM model using a batch size of 64 and a sequence length also equal to 64. The alphabet consists of 38 unique tokens. Each single input is hot-encoded into a vector with 38 components. The LSTM uses a hidden state with 128 components. After the dropout the 128 components of hidden state are reduced to 38 components utilizing a normal linear layer (without an activation function).</div>
</div>
<p><br /></p>

<p>Note that the softmax is part of our loss <code class="language-plaintext highlighter-rouge">criterion</code> i.e. the cross entropy loss <code class="language-plaintext highlighter-rouge">torch.nn.CrossEntropyLoss()</code> which is part of the backpropagation, i.e., the training process.</p>

<h2 id="melody-generation-before-training">Melody Generation (Before Training)</h2>

<p>Given a sequence of arbitrary length, the <code class="language-plaintext highlighter-rouge">generate</code> function is used to generate a new piece of music.
<code class="language-plaintext highlighter-rouge">temperature</code> determines how much the probability distribution learned by the model is considered.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">temperature</code> equal to 1.0 means that sampling is done from the probability distribution.</li>
  <li><code class="language-plaintext highlighter-rouge">temperature</code> approaching infinity means that sampling is done uniformly (more variation).</li>
  <li><code class="language-plaintext highlighter-rouge">temperature</code> approaching 0 means that higher probabilities are emphasized (less variation).</li>
</ul>

<p>We can set a maximum length for the piece and also provide the beginning of a piece.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">next_event_number</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">temperature</span><span class="p">:</span><span class="nb">float</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span> <span class="o">/</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># B, C
</span>        <span class="n">idx_next</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">idx_next</span>

<span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="n">seq</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">max_len</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">temperature</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">generated_encoded_song</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">seq</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="p">[[</span><span class="n">string_to_int</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">char</span><span class="p">)</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">]],</span> 
                <span class="n">device</span><span class="o">=</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">generated_encoded_song</span> <span class="o">=</span> <span class="n">seq</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">string_to_int</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">TERM_SYMBOL</span><span class="p">)]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        
        <span class="k">while</span> <span class="n">max_len</span> <span class="o">==</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">max_len</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">generated_encoded_song</span><span class="p">):</span>
            <span class="n">idx_next</span> <span class="o">=</span> <span class="n">next_event_number</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">temperature</span><span class="p">)</span>
            <span class="n">char</span> <span class="o">=</span> <span class="n">string_to_int</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">idx_next</span><span class="p">.</span><span class="n">item</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">idx_next</span> <span class="o">==</span> <span class="n">string_to_int</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">TERM_SYMBOL</span><span class="p">):</span>
                <span class="k">break</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">idx_next</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># B, T+1, C
</span>            <span class="n">generated_encoded_song</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="n">generated_encoded_song</span>
</code></pre></div></div>

<p>Of course, the results are almost random because the parameters of our model are initialized randomly and we did not train it yet.
The following code snippet generates 5 scores.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># number of songs we want to generate
</span><span class="n">n_scores</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.6</span>
<span class="n">before_new_songs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scores</span><span class="p">):</span>
    <span class="n">encoded_song</span> <span class="o">=</span> <span class="n">generate</span><span class="p">(</span><span class="n">max_len</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span><span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'generated </span><span class="si">{</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span><span class="si">}</span><span class="s"> conisting of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span><span class="si">}</span><span class="s"> notes'</span><span class="p">)</span>
    <span class="n">before_new_songs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s listen to the first one:</p>

<audio controls="">
  <source src="/Pages/assets/audio/before_g_song.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<h2 id="training">Training</h2>

<p>For training, we use something called a <code class="language-plaintext highlighter-rouge">DataLoader</code>. 
This helps us to access our data more easily. 
For example, we shuffle our data before training.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>The code for training seems a bit complicated because we use batches. 
This is due to dealing with a large amount of data, and we don’t send all of it through the network at once (per training step), but only a part of it, namely <code class="language-plaintext highlighter-rouge">batch_size</code> many. 
An <code class="language-plaintext highlighter-rouge">epoch</code> is defined by the fact that all training data have been sent through the network once.</p>

<p>In essence, nothing else happens but:</p>

<ol>
  <li>Send Batch through the network (Forward pass)</li>
  <li>Calculate error/cost</li>
  <li>Propagate gradients of the cost function with respect to the model parameters backwards through the network (Backward pass)</li>
  <li>Update model parameters</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_one_epoch</span><span class="p">(</span><span class="n">epoch_index</span><span class="p">,</span> <span class="n">tb_writer</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">):</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">last_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">all_steps</span> <span class="o">=</span> <span class="n">n_epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">local_X</span><span class="p">,</span> <span class="n">local_y</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">local_X</span><span class="p">,</span> <span class="n">local_y</span> <span class="o">=</span> <span class="n">local_X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">local_y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">local_X</span><span class="p">)</span>
        
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">local_y</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="n">eval_interval</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">last_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="n">eval_interval</span>
            
            <span class="n">steps</span> <span class="o">=</span> <span class="n">epoch_index</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="n">ep_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Epoch [</span><span class="si">{</span><span class="n">epoch_index</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">n_epochs</span><span class="si">}</span><span class="s">]'</span>
            <span class="n">step_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Step [</span><span class="si">{</span><span class="n">steps</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">all_steps</span><span class="si">}</span><span class="s">]'</span>
            <span class="n">loss_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Loss: </span><span class="si">{</span><span class="n">last_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">'</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">ep_str</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">step_str</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">loss_str</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>

            <span class="n">tb_x</span> <span class="o">=</span> <span class="n">epoch_index</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">tb_writer</span><span class="p">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s">'Loss/train'</span><span class="p">,</span> <span class="n">last_loss</span><span class="p">,</span> <span class="n">tb_x</span><span class="p">)</span>
            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.</span>
            
    <span class="k">return</span> <span class="n">last_loss</span>

<span class="c1"># Initializing in a separate cell so we can easily add more epochs to the same run
</span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">,</span><span class="n">respect_val</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">timestamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">().</span><span class="n">strftime</span><span class="p">(</span><span class="s">'%Y%m%d_%H%M%S'</span><span class="p">)</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="s">'runs/fashion_trainer_{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">timestamp</span><span class="p">))</span>
    <span class="n">best_vloss</span> <span class="o">=</span> <span class="mi">1_000_000</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>    
        <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">train_one_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">)</span>
        
        <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">running_vloss</span> <span class="o">=</span> <span class="mf">0.0</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">vdata</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">):</span>
            
            <span class="n">local_X</span><span class="p">,</span> <span class="n">local_y</span> <span class="o">=</span> <span class="n">vdata</span>
            <span class="n">local_X</span><span class="p">,</span> <span class="n">local_y</span> <span class="o">=</span> <span class="n">local_X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">local_y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            
            <span class="n">voutputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">local_X</span><span class="p">)</span>
            <span class="n">vloss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">voutputs</span><span class="p">,</span> <span class="n">local_y</span><span class="p">)</span>
            <span class="n">running_vloss</span> <span class="o">+=</span> <span class="n">vloss</span>
            
        <span class="n">avg_vloss</span> <span class="o">=</span> <span class="n">running_vloss</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">ep_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">n_epochs</span><span class="si">}</span><span class="s">]'</span>
        <span class="n">tloss_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Train-Loss: </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">'</span>
        <span class="n">vloss_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'Val-Loss: </span><span class="si">{</span><span class="n">avg_vloss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">'</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">ep_str</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">tloss_str</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">vloss_str</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        
        <span class="n">writer</span><span class="p">.</span><span class="n">add_scalars</span><span class="p">(</span>
            <span class="s">'Training vs. Validation Loss'</span><span class="p">,</span> 
            <span class="p">{</span><span class="s">'Training'</span><span class="p">:</span> <span class="n">avg_loss</span><span class="p">,</span> <span class="s">'Validation'</span><span class="p">:</span> <span class="n">avg_vloss</span><span class="p">},</span> 
            <span class="n">epoch</span>
        <span class="p">)</span>

        <span class="n">writer</span><span class="p">.</span><span class="n">flush</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">respect_val</span> <span class="ow">or</span> <span class="p">(</span><span class="n">respect_val</span> <span class="ow">and</span> <span class="n">avg_vloss</span> <span class="o">&lt;</span> <span class="n">best_vloss</span><span class="p">):</span>
            <span class="n">best_vloss</span> <span class="o">=</span> <span class="n">avg_vloss</span>
            <span class="n">model_path</span> <span class="o">=</span> <span class="s">'./models/_model_{}_{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">timestamp</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">model_path</span><span class="p">)</span>
</code></pre></div></div>

<p>Calling <code class="language-plaintext highlighter-rouge">train</code> starts the training.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
</code></pre></div></div>

<p>The best model from the training can be found in the folder <code class="language-plaintext highlighter-rouge">./models</code> and can be loaded as follows</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_path</span> <span class="o">=</span> <span class="s">'./models/pretrained_1_128_best_val'</span>

<span class="k">if</span> <span class="n">device</span><span class="p">.</span><span class="nb">type</span> <span class="o">==</span> <span class="s">'cpu'</span><span class="p">:</span>
    <span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">)))</span>
<span class="k">elif</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">mps</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'mps'</span><span class="p">)))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="melody-generation-after-training">Melody Generation (After Training)</h2>

<p>After training or after we load our pretrained model, we generate new pieces:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_scores</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.6</span>
<span class="n">after_new_songs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_scores</span><span class="p">):</span>
    <span class="n">encoded_song</span> <span class="o">=</span> <span class="n">generate</span><span class="p">(</span><span class="n">max_len</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span><span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'generated </span><span class="si">{</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span><span class="si">}</span><span class="s"> conisting of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span><span class="si">}</span><span class="s"> notes'</span><span class="p">)</span>
    <span class="n">after_new_songs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoded_song</span><span class="p">)</span>

<span class="n">after_generated_scores</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">decode_songs</span><span class="p">(</span><span class="n">after_new_songs</span><span class="p">)</span>
<span class="n">Audio</span><span class="p">(</span><span class="n">score_to_wav</span><span class="p">(</span><span class="n">after_generated_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">'a_g_song.wav'</span><span class="p">))</span>
</code></pre></div></div>

<p>We start to hear repetition and some structure within the piece:</p>

<audio controls="">
  <source src="/Pages/assets/audio/a_g_song.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<h2 id="real-world-example">Real World Example</h2>

<p>In the realm of musical innovation, a significant advancement occurred with the development of a sophisticated <strong>LSTM</strong> model designed to create expressive piano roll music. 
This model was introduced in a notable study by <a class="citation" href="#oore:2018">(Oore et al., 2018)</a>. 
The researchers devised a unique discrete-event based representation for piano rolls, encompassing a diverse range of 413 different events. 
The architecture of their model was meticulously structured, comprising three hidden LSTM layers, each equipped with 512 cells. 
This design choice facilitated the processing of a 413-dimensional one-hot vector as input, with the model subsequently generating a categorical distribution over the same dimensional space.</p>

<p>The training process of the model was finely tuned, employing a mini-batch size of 64 and a learning rate of 0.001, alongside the implementation of teacher forcing techniques. 
For those interested in experiencing the model’s capabilities firsthand, a collection of generated music pieces is available for listening at this <a href="https://clyp.it/user/3mdslat4">link</a>. 
However, it’s important to note a primary limitation of this model: its tendency to produce relatively brief musical compositions, typically ranging from 10 to 20 seconds in duration. 
The authors also emphasized the critical role of high-quality data in achieving optimal results with this model.</p>

<p>Following this development, the field witnessed the emergence of the Music Transformer, introduced by <a class="citation" href="#huang:2018">(Huang et al., 2018)</a>.
This model also utilized a similar piano roll representation but marked a significant leap forward by employing the <strong>transformer</strong> architecture. 
This innovative approach enabled the Music Transformer to learn and reproduce longer sequences, demonstrating the capability to capture more extended musical dependencies. 
The transformer architecture and its implications in music generation will be further explored in the next installment of this series.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="oore:2018">Oore, S., Simon, I., Dieleman, S., Eck, D., &amp; Simonyan, K. (2018). <i>This time with feeling: Learning expressive musical performance</i>.</span></li>
<li><span id="huang:2018">Huang, C.-Z. A., Vaswani, A., Uszkoreit, J., Shazeer, N., Hawthorne, C., Dai, A. M., Hoffman, M. D., &amp; Eck, D. (2018). Music Transformer: Generating music with long-term structure. <i>ArXiv Preprint ArXiv:1809.04281</i>.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Music" /><category term="ML" /><category term="LSTM" /><summary type="html"><![CDATA[This article is the continuation of a series. It is recommended that you read part I and II first. This time we use a recurrent neural network (RNN), more preceisly an LSTM, which I explained a little bit in the introduction. An LSTM is a RNN that counteracts the problem of exploding and vanishing gradients.]]></summary></entry><entry><title type="html">Laws of Form</title><link href="https://bzoennchen.github.io/Pages/2023/11/19/laws-of-form.html" rel="alternate" type="text/html" title="Laws of Form" /><published>2023-11-19T00:00:00+01:00</published><updated>2023-11-19T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2023/11/19/laws-of-form</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/11/19/laws-of-form.html"><![CDATA[<p>In my last blog <a href="/Pages/2023/10/07/system-theory-and-ai.html">post</a>, I discussed Niklas Luhmann’s Social Systems Theory and I emphasized that his theory is based on differentiation and seemingly paradox relations.
My general understanding of Luhmann’s radical constructivism in the most reductive sense is that there are no unified and independent objects—there are only differences.
What an observer can identify as an object is a differentiation of a system and its environment, a foreground and its background, an interior and the external.
However, any observer is itself a distinction between system and environment.
I want to further investigate this idea by looking into Luhmann’s inspiration—his muse so to say.
So let me examine the logic of Georg Spencer-Brown presented in his work <em>Laws of Form</em> <a class="citation" href="#brown:1969">(Spence-Brown, 1969)</a>.</p>

<h2 id="the-principle-of-differentiation">The Principle of Differentiation</h2>

<p>As mentioned, Luhmann’s theory is based on paradoxes such as</p>

<blockquote>
  <p>This statement is wrong.</p>
</blockquote>

<p>The statement is logically problematic because it is self-referential. 
If the statement is false, it states that it is in fact true and if the statement is true, it states that it is false.
Another famous paradox is Russell’s antinomy of the naïve set theory:</p>

\[R := \left\{ x \ | \ x \not\in x \right\}.\]

<p>\(R\) is the set of all sets that do not contain themselves which seems to be a well-defined mathematical object.
However, if we introduce the self-referential relation, we run into a paradox:</p>

<p>\begin{equation} 
R \in R \iff R \not\in R
\end{equation}</p>

<p>This paradox is related to the barber that shaves everyone that does not shave themselves.
If that is the case, does the barber shave themselves?</p>

<p>Another example involves the the proof of the <a href="/Pages/2021/06/08/Informatics-a-love-letter.html">Halting Problem</a>.
To prove it, one can establish a self-referential relation between a machine that presumable solves the Halting Problem.
The machine does not halt if the machine it checks halts, and it halts if the machine it checks does not halt.
Via the self-referential relation, that is, by letting the machine check itself, we get a contradiction.</p>

<p>The idea of Spencer-Brown is to resolve these paradoxes over time.
\(R \in R\) holds at one moment in time and \(R \not\in R\) holds at the next moment.
Note however that he does not resolve Russell’s antinomy <a class="citation" href="#cull:1979">(Cull &amp; Frank, 1979)</a>.
His idea of resolving paradoxes over time is reminiscent of the Hegelian dialectic—a process of self-creation.
The self-referential relation is a paradox if we ignore time and it becomes a generator if we consider time and place.</p>

<p>This led the biologists Huberto R. Maturana and Francisco J. Varela to the concept of <em>autopoiesis</em> <a class="citation" href="#maturana:1987">(Maturana &amp; Varela, 1987)</a>.
Furthermore, the importance of differentiation is inspired by the logic of Spencer-Brown and his work <em>Laws of Form</em> <a class="citation" href="#brown:1969">(Spence-Brown, 1969)</a>.
He resolves the paradox by a similar idea that gave us imaginary numbers, that is, by using what he calls <em>Re-entry</em> which (re-)introduces a system into itself.</p>

<p>Luhmann integrated this idea into his social systems theory.
For example, the media can observe and reintroduce itself into itself. 
It can use its systemic operations on itself, i.e. it can report on itself.</p>

<p>Spencer-Brown begins his work by a quote from Lao-Tse (a stand-in for many different authors) thus begins by philosophical considerations:</p>

<blockquote>
  <p>Wu ming tain di zhi shi. – Loa-Tse</p>
</blockquote>

<p>The sentence has mainly two different meanings.
One is:</p>

<blockquote>
  <p>The beginning of heaven and earth is without a name.</p>
</blockquote>

<p>The other one is:</p>

<blockquote>
  <p>‘Nothing’ is the name of the beginning of heaven and earth.</p>
</blockquote>

<p>A paradox arises: How can Nothing be nothing if we can call it ‘Nothing’?
Furthermore, the quote points to a distinction between heaven and earth.
Can there be heaven without earth—a <em>calling</em> or <em>indication</em> without a <em>distinction</em>?
Spencer-Brown begins by the assumption that there is no such thing:</p>

<blockquote>
  <p>We take the idea of distinction and the idea of indication and that we cannot make an indication without making a distinction as given.
Therefore, we take the form of distinction as the form itself. – Georg Spencer-Brown</p>
</blockquote>

<p>In other words, what we normally identify as object (the form / system) is for Spencer-Brown equal to the distinction (system-environment differentiation).
There is no clear separation between the object or the result of distinction and the process of distinguishing.
Therefore, the process must be integrated into Spencer-Brown’s logic and as we will see, there is no clear separation between objects and operations in Spencer-Browns calculus.
Spencer-Brown thinks that differentiation is a proto-operation that is more fundamental than performing calculations or writing text because to do these activities we have to differentiate beforehand.
I cannot calculate 1 + 1 = 2 without distinguishing between the different symbols and a symbol and ‘nothing’ or the void.</p>

<p>Spencer-Brown uses the mark or cross (result) which at the same time marks (process).
The mark is, calls, and makes a difference.</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/mark.png" alt="The mark." /></div>
<p><br /></p>

<p>There is an interior of the mark and not the interior—the system and its environment.
I can make a distinction again (repetition):</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/calling.png" alt="The calling." /></div>
<p><br /></p>

<p>But making a distinction again does not change the distinction.</p>

<blockquote>
  <p>Calling something back-to-back by its name does not change its name. – Spencer-Brown</p>
</blockquote>

<p>The reverse is also true; therefore, Spencer-Brown introduces the <em>Law of Calling</em>:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/law-of-calling.png" alt="Law of Calling." /></div>
<p><br /></p>

<p>The second transformation called <em>Law of Crossing</em> is less intuitive.
Crossing twice reverses the first crossing.</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/law-of-crossing.png" alt="Law of Crossing." /></div>
<p><br /></p>

<blockquote>
  <p>If a boundary is crossed twice, the original state will be reestablished.
The repetition of the crossing has a different value than the single crossing.
The reason is that in-between the reversal happens.
Crossing changes the side.
Re-crossing reverses this operation. – Spencer-Brown</p>
</blockquote>

<p>With only these two laws, Spencer-Brown established a logic calculus and we can start doing mathematics.
Interestingly, the <em>Law of Crossing</em> and the <em>Law of Calling</em> are implicitly established via the position of the marks.
There is no operator introduced because the result and process, indication and differentiation, the mark and the process of marking are not separated.</p>

<p>Let’s see what we can do with this calculus.
Let \(a, b\) variables, then the following holds:</p>

<p><br /></p>
<div><img style="height:230px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/transformations.png" alt="Transformations." /></div>
<p><br /></p>

<p>Let’s have a look at the last transformation.
Let us assume \(a\) is a <strong>mark</strong>.
Then we get:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/transformation-1.png" alt="First possibility." /></div>
<p><br /></p>

<p>Let \(a\) be <strong>unmarked</strong> instead, then we can follow:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/transformation-2.png" alt="Second possibility." /></div>
<p><br /></p>

<h2 id="the-re-entry">The Re-Entry</h2>

<p>How can we re-introduce the system (here an equation) into itself?
Or in other words: How does the <em>re-entry</em> work?
We can start by a simple self-referential algebraic equation:</p>

<p>\begin{equation}
x^2 = ax + b, \quad a, b \in \mathbb{R}.
\end{equation}</p>

<p>This equation has well-known solutions. 
It is also known that solutions can be imaginary, i.e., \(x\) might be of the for \(r + si\) with \(r, s \in \mathbb{R}$ and $i^2 = -1\).
To see the re-entry, we can rewrite the equation above to get</p>

<p>\begin{equation}
x = a + b/x,
\end{equation}</p>

<p>thus the self-reference is obvious and we solve the equation by the re-entry</p>

<p>\begin{equation}
x = a + b/(a +b/(a+b/(a+b/a+b/(a + \ldots)))).
\end{equation}</p>

<p>Using this infinite formalism it is literally the case that</p>

<p>\begin{equation}
x = a + b/x,
\end{equation}
holds.
Using the same formalism, we can define the imaginary number \(i = -1/i\) as literally</p>

<p>\begin{equation}
i = -1 /(-1 /(-1 / (-1 / \ldots )))
\end{equation}</p>

<p>but what does this mean?
The system is not a number but a process, a generator that generates itself.
\(i\) alternates between 1 and -1.
Interestingly, this is precisely how we use the equal sign in most programming languages.
Writing <code class="language-plaintext highlighter-rouge">i = i / -1</code> in a programming language means</p>

<p>\begin{equation}
i \leftarrow \frac{i}{-1}.
\end{equation}</p>

<p>The next step is to introduce such a re-entry into logic.
Similar to the imaginary number \(i\), Spencer-Brown gives us the following fundamental paradox (<em>The Re-Entry of the Mark</em>):</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/j.png" alt="Imaginary truth value." /></div>
<p><br /></p>

<p>The solution is an alternation between a marked and unmarked state—between true and false.
A state that might seem contradictory in space, makes sense if it is observed in time and space.
Again, time resolves the paradox.
To highlight the re-entry, Spencer-Brown also uses the following notation:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/j-2.png" alt="Notation of the re-entry." /></div>
<p><br /></p>

<p>We could similarily notate \(i\) as</p>

<p><br /></p>
<div><img style="height:35px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/i-2.png" alt="Notation of the re-entry for the imaginary number." /></div>
<p><br /></p>

<p>If we change <strong>all</strong> symbols within a system equally, there is no reason not to calculate with a self-generating process.
For example, we can state the following:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/j-calculations.png" alt="Calculating with the re-entry." /></div>
<p><br /></p>

<p>However, it is forbidden to only change one appearance of \(J\)!
Following this simple rule, no paradox or inconsistency arises.
We can go on and evaluate the following transformation:</p>

<p><br /></p>
<div><img style="height:30px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/wave.png" alt="Wave equation." /></div>
<p><br /></p>

<p>which describes two alternating waves shifted by one cycle resulting in a mark.</p>

<p>Spencer-Brown goes on and defines his <em>Echelon</em>:</p>

<p><br /></p>
<div><img style="height:35px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/echelon.png" alt="Echelon." /></div>
<p><br /></p>

<p>which can be transformed into</p>

<p><br /></p>
<div><img style="height:40px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/echelon-transformation.png" alt="Echelon transformation." /></div>
<p><br /></p>

<p>thus gives us the re-entry</p>

<p><br /></p>
<div><img style="height:40px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/echelon-equation.png" alt="Echelon equation." /></div>
<p><br /></p>

<p>or</p>

<p><br /></p>
<div><img style="height:43px;display:block; margin-left:auto; margin-right:auto; " src="/Pages/assets/images/laws-of-form/echelon-equation-2.png" alt="Echelon equation." /></div>
<p><br /></p>

<h2 id="final-words">Final Words</h2>

<p>In the act of programming there is no problem of using expressions such as</p>

<p>\begin{equation}
i \leftarrow i + 1 \quad  \text{ or } \quad a  \leftarrow f(a)
\end{equation}</p>

<p>but in mathematics—at least since Plato—we assume some sort of eternity.
Of course, we can translate between the static world of “normal” mathematics and Spencer-Brown’s dynamic viewpoint, but it is a different viewpoint which might influence how we observe our environment.
It is like in physics where multiple theories are equivalent but start from very different viewpoints.
It starts by differentiation which gets reintroduced into the system which is constructed by this very same differentiation.
To generate new numbers, such as irrational or transfinite numbers, Spencer-Brown proposes not to use the limit but the whole infinite process that defines such limit.</p>

<p>Spancer-Brown beliefed that to be able to master the transition to new signs, something is necessary for which the previous signs are not sufficient.
To be able to close this gap; to make this leap successfully; to resolve paradoxes; a specific language of one’s own is necessary. 
According to Spancer-Brown this step is accomplished by <strong>thinking</strong> which provides us with its specific imaginations, playful freedom and contradictions.</p>

<p>It is surprising that Spencer-Brown’s <em>Laws of Form</em> plays no role in computer science even though it fits quite neatly in the perspective of programs, processes and computation.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="brown:1969">Spence-Brown, G. (1969). <i>Laws of Form</i>. London: Allen and Unwin.</span></li>
<li><span id="cull:1979">Cull, P., &amp; Frank, W. (1979). flaws of form. <i>International Journal of General Systems</i>, <i>5</i>(4), 201–211. https://doi.org/10.1080/03081077908547450</span></li>
<li><span id="maturana:1987">Maturana, H. R., &amp; Varela, F. J. (1987). <i>The Tree of Knowledge</i>. Shambhala.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Logic" /><category term="Social Systems Theory" /><summary type="html"><![CDATA[In my last blog post, I discussed Niklas Luhmann’s Social Systems Theory and I emphasized that his theory is based on differentiation and seemingly paradox relations. My general understanding of Luhmann’s radical constructivism in the most reductive sense is that there are no unified and independent objects—there are only differences. What an observer can identify as an object is a differentiation of a system and its environment, a foreground and its background, an interior and the external. However, any observer is itself a distinction between system and environment. I want to further investigate this idea by looking into Luhmann’s inspiration—his muse so to say. So let me examine the logic of Georg Spencer-Brown presented in his work Laws of Form (Spence-Brown, 1969).]]></summary></entry><entry><title type="html">Why Machines (Probably) Do Not Think</title><link href="https://bzoennchen.github.io/Pages/2023/10/07/system-theory-and-ai.html" rel="alternate" type="text/html" title="Why Machines (Probably) Do Not Think" /><published>2023-10-07T00:00:00+02:00</published><updated>2023-10-07T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/10/07/system-theory-and-ai</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/10/07/system-theory-and-ai.html"><![CDATA[<p>Generative AI, especially ChatGPT, brought artificial intelligence into the public sphere and sparked a lot of highly speculative claims about <em>machine intelligence</em>.
I’m open for discussions and unafraid of confronting uncomfortable truths. 
Indeed, our imagination and fearless thinking should pave the way for new possibilities. 
Dreams and speculations are valuable, as long as they’re presented as such. 
However, I find it concerning when public figures speak with undue certainty, particularly when making anthropological comparisons between humans and machines.</p>

<h2 id="the-fall-from-human-greatness">The Fall from Human Greatness</h2>

<p>What really hit me was watching Doug Hofstadter expressing his despair about the <em>eclipse of humanity</em>.
As a student, I had been influenced by his renowned book <em>Gödel, Escher, Bach: an Eternal Golden Braid</em>, often referred to as <em>GEB</em> <a class="citation" href="#hofstadter:1979">(Hofstadter, 1979)</a>.
The book delves into how cognition emerges from underlying neurological processes.
Let’s examine Hofstadter’s comments on the state of AI which I gathered from an interview:</p>

<blockquote>
  <p>I never imagined that computer systems would rival or even surpass human intelligence.
It seemed like a goal so far away.
My entire belief system was shaken; it’s a truly traumatic experience when some of your most fundamental beliefs about the world start to collapse.
Particularly, the idea that human beings are soon going to be eclipsed. 
It felt as if not only my belief system was collapsing, but also as if the entire human race was about to be eclipsed and left in the dust soon. 
The accelerating progress has been so unexpected, it stirs a certain kind of terror of an impending tsunami that’s going to catch all of humanity off guard.
It’s unclear whether this signifies the end of humanity, in the sense that the systems we created could destroy us, but it’s certainly conceivable. 
If not, it relegates humanity to a relatively minor phenomenon compared to something else that is far more intelligent and will eventually become as incomprehensible to us as we are to cockroaches.
I find that terrifying. 
I hate it! I think about it almost every single day.
And it overwhelms and depresses me in ways I haven’t experienced in a very long time. […]
It makes me feel diminished; it makes me feel, in some sense, like a very imperfect, flawed structure. 
Compared with these computational systems which have a million or billion times more knowledge than I have, and are a billion times faster, it makes me feel extremely inferior.
It almost feels like we deserve to be eclipsed. 
Unbeknownst to us, all we humans are soon going to be eclipsed and rightly so, because we are so imperfect and fallible. – Doug Hofstadter</p>
</blockquote>

<p>He passionately conveys a sentiment many intuitively feel: The essence of humanism is under siege.
We are fallen from greatness.
Our unique skills are being surpassed, leading to concerns about our relevance.</p>

<p>I perceive Hofstadter’s view as human-centric, stemming from a longstanding tradition where humans are seen as central figures, akin to being God’s creation.
This view encompasses our confidence in determining our fate; the idea of an individual separate from its environment; humans domination over objects; a hierarchy with humans at the pinnacle; the notions of free will, and rational, independent beings arriving at a consensus in public discourse.
Paradoxically, I will try to attack this human-centric view to save myself from his despair.</p>

<p>One could argue that machines are not intelligent since they are just doing statistics by computing some high-dimensional probability distribution <a class="citation" href="#bender:2021">(Bender et al., 2021)</a> and that there is a difference between language processing and language understanding <a class="citation" href="#bender:2020">(Bender &amp; Koller, 2020)</a>. 
However, these arguments seem not convincing for many people.
There always looms a counter argument: Maybe humans do the same?</p>

<p>Instead of going down the technical rabbit hole, I will try to approach Hofstadter’s comments from a distinct and somewhat radical angle by using my <em>observation</em> of Luhmann’s <em>social system theory</em> which builds on <em>radical constructivism</em>.
Along the way, I will not only discuss <em>machine intelligence</em> but also touch on the relation between machines, society and human beings.</p>

<p>I’m not asserting this as the absolute truth but rather as an interesting <em>story</em> that might be useful in some aspects.
In fact, when I started reading Luhmann, I hated it!
It made so much sense but also felt cruel, cold and depressing.
However, like reading Nietzsche’s <em>On the Genealogy of Morality</em>, it has the potential to destroy some deep seeded belief only to bring something new and exciting into existence.
While this theory is nothing more than a theory, it does challenge the confidence behind many claims, including those regarding <em>machine intelligence</em>.</p>

<h2 id="niklas-luhmann">Niklas Luhmann</h2>

<p>Niklas Luhmann (1927-1998) was a largely self-taught sociologist. 
Like postmodern thinkers, he believed that pursuing metaphysics was no longer productive, as there are no ultimate grand narratives that can explain everything. 
Rather than delve into metaphysics, he meticulously developed a comprehensive theory of modern society—–a supertheory that even encompassed itself and its creator.</p>

<p>Luhmann was an avid reader and writer, and he wasn’t hesitant to incorporate valuable concepts from fields like mathematics (Spencer-Brown’s), cybernetics (Wiener and others), and biology (Maturana and Varela).
To encapsulate everything, he employed a high level abstraction and a technical terminology, which can make his writings appear dry, cold and dense. 
Because his work is primarily descriptive—–explaining things as they are and exploring potential reasons for their status—some categorize him as conservative. 
However, I perceive him as an incredibly well-read, sensitive, and discerning observer who wanted a new theory that can help us to transit into a new form of stability, which is a rather progressive attitude.</p>

<p>Even though Luhmann tried to keep a large distance to philosophy, he was well read in it and certainly influenced by it.
In his introductory book <em>From Souls to Systems</em>, Hans-Georg Moeller <a class="citation" href="#moeller:2006">(Möller, 2006)</a> highlights that Luhmann’s work is influenced by several philosophical giants:</p>

<ul>
  <li><strong>Kant</strong>: Luhmann shifts Kant’s focus on cognition to a constructivist perspective <a class="citation" href="#luhmann:1988">(Luhmann, 1988)</a>.</li>
  <li><strong>Hegel</strong>: Luhmann transitions from Hegel’s ideas of unity and dialectic to concepts of multiplicity and from identity to difference. He argues against any essential unity of systems and any general type of cognition, such as Hegel’s spirit.</li>
  <li><strong>Marx</strong>: Luhmann borrows Marx’s view that society isn’t just a byproduct of spirituality, but he disagrees with the idea of one foundational system. Marx focus on economy is too much of a simplification.</li>
  <li><strong>Husserl</strong>: Luhmann adapts Husserl’s work towards constructivism and incorporates many of his terms and ideas.</li>
  <li><strong>Habermas</strong>: Luhmann disputes Habermas’s mission of completing the enlightenment.</li>
  <li><strong>Postmodern thinkers</strong>: Luhmann draws from Deleuze’s radical differentiation, Derrida’s deconstruction, and Lyotard’s rejection of overarching narratives.</li>
</ul>

<p>With respect to his media theory, Luhmann is quite close to the French philosopher Baudrillard but far less dramatic.
While Baudrillard tends to express himself in dramatic metaphors and focuses solely on the media, Luhmann presents a supertheory of society where the mass media is only one of many systems, all administered by their respective codes.
While Baudrillard’s texts are almost poetic, reading Luhmann can cause boredom.</p>

<p>Luhmann believed that the distinction between <em>modernity</em> and <em>postmodernity</em> is largely semantic.
He argued that the last significant structural shift in society occurred in Europe between the sixteenth and eighteenth centuries, transitioning from stratified to functional differentiation. 
To Luhmann, labeling a functionally differentiated society as either ‘modern’ or ‘postmodern’ is inconsequential.</p>

<p>Although his theory can be unsettling, Luhmann was optimistic about the future.
He agreed side-by-side with the postmodern assertion that traditional philosophy had reached its end.
However, he saw this as an opportunity for a rejuvenated, coherent self-description of society and a fresh theoretical framework for a new societal era:</p>

<blockquote>
  <p>Is this, after all, a postmodern theory?
Maybe, but then the adherents of postmodern conceptions will finally know what they are talking about.
The deconstruction of our metaphysical tradition pursued by Nietzsche, Heidegger, and Derrida can be seen as a part of a much larger movement that looses the binding force of tradition and <strong>replaces unity with difference</strong>.
The deconstruction of the ontological presupposition of metaphysics uproots our historical semantics in a most radical way.
This seems to correspond to what I have called the catastrophe of modernity, the transition of one form of stability to another. – <a class="citation" href="#luhmann:1993">(Luhmann, 1993; Luhmann, 2000)</a></p>
</blockquote>

<h2 id="social-systems-theory">Social Systems Theory</h2>

<p>So let me try to give you my incomplete and surface level understanding of his theory:</p>

<p>Luhmann recognised the particular complexity that human beings present for social analysis because they are the bearers of three <em>autopoietic systems</em>: systems of life (cells, brains, organisms), systems of consciousness (mind), and systems of communication (social systems).
As a sociologist he acknowledges but leaves aside the biological systems of human beings and instead focuses on the interactive relationship between their consciousness or psychic system and the social systems with which they interact.
All psychic systems (minds) are in the environment of social systems and vice versa.</p>

<p>He famously argued that communication between psychic systems happens not between (whole) persons or individuals.
This seems counterintuitive but if we spent a little more thought into his claim and clarify some termonology, it makes sense.
Hans-Georg Moeller put it the following way:</p>

<blockquote>
  <p>You cannot communicate with me with your mind or brain, you will have to perform another communicative operation such as writing or speaking. – <a class="citation" href="#moeller:2006">(Möller, 2006)</a></p>
</blockquote>

<p>Luhmann described the mind (the psychic system) as well as social systems as <em>operational closed, structurally coupled, autopoetic systems</em>.
That are a bunch of important terms right away which require some explanation.</p>

<p>In Luhmann’s view, a system is defined by its differentiation with its environment—<strong>differentiation</strong> plays one of the most important roles in his work.
This differentiation is esablished and obtained through the operations of the system.
The system differentiates itself from its environment thus it defines itself.
In other words, the system creates its own functions by its operations (self-creation and self-preservation).
Thinking leads to more thinking and perception leads to more perception.
The economy creates itself by doing economics, the mass media creates itself by its operation of differentiating between information and non-information.</p>

<p>Another <em>theme</em> in Luhmann’s writing is the use of paradoxes which is certainly inspired by Spencer-Brown’s logic presented in <em>Law of Forms</em> <a class="citation" href="#brown:1969">(Spence-Brown, 1969)</a>.
Inspired by imaginary numbers, Spencer-Brown introduced imaginare truth values which are paradoxically in space but the paradox is resolved in time.
Therefore, a paradoxical systems becomes genererative in time.
One prime example is our mind which is capable of self-observation (<em>reentry</em>).
Paradoxically, the oberservation is part of what is observed.
However, in time this gets resolved.
While I am observing myself (second-order observation) I cannot observe my environment (first-order observation).
I can switch to the first-order observation but then I lose track of my oberservation of myself.
In a sense, this back and forth observation and self-observation—this paradox—generates myself.</p>

<p>A psychic or social system is <em>operational closed</em> because its operations can not leave the system.
Mental operations such as thoughts and emotions cannot leave the mind.
An economic transaction, e.g. paying for goods, cannot ‘leave’ the economy.
No mind can interfere with the operations of another mind.
One cannot continue someone else’s mental activities by thinking or feeling for him or her.
It is also impossible to immediatly think what someone else is thinking.</p>

<p>However, systems can observe their environment and act on their terms.
We can hear what others say, see what they express and read what they have written.
Our mind can think about it (using its operations) and we can answer, i.e. communication happens.
We can also see pain or joy on other’s faces, but we cannot literally think or feel what they do.
The economy observes politics, the media, science and gets irritated.
How it will adapt is up to itself and its operations.</p>

<p>Other than <em>allopoietic systems</em>, which produce something other than the system itself, <em>autopoietic systems</em> reproduce themselves.
They are more dynamic than allopoietic systems because they deal with an excess of complicating noise from their environment (too much information that cannot be processed) by changing their structure (increasing internal complexity) to allow in more communications: they have a built-in learning capacity.
In contrast, allopoietic systems theory leads the observer to seek constancy and stability in system functioning because they are intrinsically conservative.</p>

<p>Social systems, like the media, become so efficient because they ‘feed’ the outside into their ‘body’.
A crisis, like a natural disaster or a war, feed the autopoiesis of the media.
It can report on the event and discuss different opinions on the matter.
Strictly speaking, the ‘goal’ of the media is not really to inform or to persuade but to continue its own self-production.</p>

<blockquote>
  <p>It is impossible to understand the reality of the mass media if you assume it is their job to provide correct information on the world and then assess how they fail, distort reality, and manipulate opinion—as if they could do otherwise. – Niklas Luhmann</p>
</blockquote>

<p>Therefore, attention is key.
Informing people or persuading might help to ‘get enough food’ but it is not the media’s ‘goal’ or ‘will’.
The same goes for the economy which trys to commodify everything to further commodify things.
Politics politicizes anything and sciences produces papers with ‘facts’ to get more funding for more papers with ‘facts’.</p>

<p>Even though Luhmann’s termology is close to the termonology of computer science, we have to be careful.
It is more helpful to think of these systems as interdependent organisms feeding on each other and equipped with the will to live than to think of hierarchical or well-structured computer or network systems.</p>

<p>Aside from being <em>autopoetic</em>, social and psychic systems are also <em>symbiotic</em>, that is, their <em>co-evolution</em> is <em>interdependent</em>.
Just as the trees in the forest need water and animals to survive, politics needs money from the economy, attention from the media, and ‘facts’ from science.
Media needs politics or science to produce news, and money to operate.
The economy uses media, politics, and science to make profits.
Science ‘sells’ truth to the economy, politics, and the media.
Academia needs money, attention and power.</p>

<p>Luhmann insists in putting human beings in the environment of social systems and not inside them.
In other words, social systems do not consist of humans but of communication!
This is sometimes seen as an anti-humanistic tendency which is framed negatively.
But one might argue that human beings are better off if their processes are not determined by society.</p>

<p>Luhmann’s theory provokes an <em>amoral</em> view on the state of affairs but it also gives power to the object (systems/processes) thus attacks the domination of objects by subjects.
There are no evil people doing or planing insidious things, instead systems (objects) act on behalf their <em>systemic rational</em> by making sense of their environment on their terms.
What we often identify as hypocratical in a person’s action is a mixture of the operations of <strong>different</strong> systems or the communication between systems.
As a reminder, the person is not part of the system.
Individuals, or better psychic systems, are a necessary condition that social systems can exist (like air has to exist to hear sound) but they belong to the environment of the social system (they do not produce the sound).
If a politician acts immoral and accepts a lot of money for his party to give a certain company an advantage over its competitors, the politician is the mere medium through which the economy communicates with politics.
If a politician of the Green Party goes on vacation by plane and, at the same time, speaks out against air traffic, two different systems are operating: the family and politics.
And the operation of the first does not interfere with the operations of the second.
However, the media make news out of this contradicting behaviour which will irritate politics and probably the family life of the politician.
What the media observes as ‘corruption’ happens if system boundaries are crossed.
It is ok to buy talented football players, but it is not ok to buy goals, i.e. it is not ok that the economy directly operates within the system of a football game.</p>

<p>Psychic and social systems are <em>operationally closed</em> but <em>cognitively open</em>.
They have clear boundaries demacrating them from other systems.
They reproduce themselves by adapting and learning how to cope with external noise by only selecting communication which the system can actively and creatively interpret and <em>understand</em> or make sense of.
Psychic and social systems reduce complexity of their environment through recourse to meaning.
These systems increase inner complexity to deal with the complexity in their environment.</p>

<p>The boundaries of these systems are not defined physically, but by the border of what is meaningful and what is not.
Consequently, each system has its own <em>systemic rationality</em> and view of the world—there is always a blind spot.
If I give a cashier money it is assumed that I paid for something.
This follows from the systemic rationality of the economic system.
It deals with money but it cannot, for example, deal with love or passion which are part of the <em>systemic rationality</em> of relationships.
The cashier does not suspect me that I show him my love with this gesture and if I do, this act is not an operation of the economic system.</p>

<p>The <em>functional differentiation</em> of each system makes it so that only parts of a person is acknowledged by the system.
There is no indivudual—indivisible being—in a system.
The health system understands a person as a patient.
The legal system understands a person as a potential criminal, victim or witness.
In that sense, Marx’s <em>alienation</em> is not limited to the economy.
This differentiation makes systems extremly efficient <strong>with respect to their function</strong>.
But what is ‘good’ for one system is not necessarily ‘good’ for the other system.</p>

<p>Luhmann thinks that this differentiation (Ausdifferenzierung) is a feature of modern society, i.e. it is historical and is an ongoing process.
One example might be the creation of new subjects to study.
Instead of studying computer science, students can enroll in scientific computing, data science, game engineering, information engineering, and more.
One can say computer science is further differentiated.
At the same time, we acknowledge problems stemming from this differentiation and try to find ways to look at problems and society more holistically.
Marignal note: If we follow Luhmann’s theory and we want efficiency (with respect to a systemic rational) we find a strong argument to avoid introducing an interdisciplinary subject such as bioinformatics by simply combining biology with informatics.</p>

<p>The functional differentiation of systems, its effects and our gut reaction to it is nicely depicted in the movie <em>Don’t Loop Up</em>.
What the movie does well is showing us that society consists of functional differientiated systems that follow their own <em>systemic rational</em>.
The main message of the movie is that scientists, who discover a meteor, are unable to communicate this truth to the world.
The movie shows mostly four social systems: politics, media, economy, and science.
It shows how each of these systems functions differently while still being <em>structurally coupled</em> with one another via a <strong>shared medium</strong> (language), as explained above.
But inspite of being coupled, or because of it, they cannot act unitedly.</p>

<p>The effectiveness of functional differentiation to deal with complexity comes at a cost: <em>anarchy</em>, that is, there is no controlling system or governing system—no single rationality that is in charge.
From a reductionist standpoint, the actors of the movie seem completely irrational.
By seeing modern society through the eyes of controllable cause and effect chains one can only come to the conclusion that our society is dysfunctional or worse: immoral.
In the movie, only the scientist, who also represent the perspective of the audience, seem to do the right thing.
But from a systemic view the actions of all actors make sense.</p>

<p>In the end, the narrative of the movie is however a contradiction to the systemic view.
The movie suggest that there is some sort of scientific technological solution that can be used if everyone is thinking and acting properly—if only the government takes proper control, and the media informs everyone correctly then the meteor can simple be nuked.
The movie suggest that there can be some sort of rational self-control if only we would be <em>enlightened</em> enough.
In a sense, it is not much better than the movie <em>Idiocracy</em>.
The dream is that enlightened science can control nature through rational technology, enlightened politics can control society through rational self-government of the people, and enlightened media disseminates knowledge and makes everyone an informed and rational citizen.
Therefore, the movie presents an individualistic solution.
Big tech is greedy, politicians are stupid and hypocritical, and scientists are incapable of being live on TV.
If we fix those issues, we are fine.
If only we ‘look up’ (individually), we will be enlightened and stop being stupid and ignorant and we will solve all our modern problems.
The problem becomes a moral problem of personal responsibility thus it becomes polarizing.
From a systems theory perspective, this individualistic solution is not (or no longer) possible.
Systems function according to their functional differentiation on their terms and individuals are part of their environment.</p>

<p>However, <em>anarchy</em> does not imply the absence of strata or the presence of equality.
It’s evident that systems like the economy can create significant <em>differences</em> between the rich and the poor. 
Luhmann recognized that modern society inherently produces many differences, including those we might disapprove of. 
Every system does this, not just the economy.
However, contrary to a Marxist perspective, Luhmann believed that these societal disparities result more from the operations of multiple systems than from the stratum or class into which people are born. 
That said, an individual’s socioeconomic background, such as whether their parents are rich or poor, does matter. 
For example, in the education system, the ability of one’s parents to afford tuition at prestigious institutions like Stanford plays a significant role due to the interconnectedness of the economic and educational systems.
However, to genuinely understand how systems like education or academia function, one must grasp their unique <em>differentiators</em>. 
The education system is defined by distinctions like good grades versus bad grades, while the academic system differentiates between peer-reviewed and non-peer-reviewed papers.
These differentiations are intrinsic to their respective systems and not solely based on economic factors.
According to Luhmann, while wealth can certainly influence educational outcomes, avoid legal troubles, or facilitate a scientific career, it’s overly simplistic to reduce all systemic distinctions to just ‘money’.
But again, of course it helps a lot if you have money if you want good grades, stay out of prison, or become a scientist.</p>

<p>Luhmann argues that all social systems operate on a binary code determined by their sphere of interest which structures their communication with other systems.
Communication with the legal system is organised by the code legal/illegal through the medium of law;
with the political system by the code government/opposition through the medium of legitimate power;
with the economy through money with the code pay/not pay;
with science by the code true/false through the medium of evidential truth;
with the mass media system by the code information/non-information through the medium of public opinion;
and with the welfare benefits system by the code eligible/not eligible through the medium of citizenship status.</p>

<p>Without their environment systems would cease to exist.
They are <em>structurally coupled</em> with one another.
For example, psychic systems are structurally coupled with social systems—without bodys and minds there is no political system, no economy, no relationship and no family.
Without the economy, the political system would collapse.
However, there is <strong>no causal relationship</strong> between the two;
society does not cause consciousness to occur, neither do people consciously create and manage society.
The relationship between the two is rather one of constant <em>irritation</em> (which may be also translated to <em>confusion</em>) with the one reacting to the other, but always on its own terms.
The dynamics are non-linear and tend to be <em>chaotic</em>.</p>

<p>If the political system enact a new law to steer the economy, it can only try to do so via irritation.
How the economy will react is not up to politics.
If climate activists glue themselves to the ground to generate awareness, they may achive their goal or they may not.
What happens is quite difficult to predict.
How does the media report on the issue if its rational is to further differentiate between information and non-information?
How will politics react based on the assumption that it ‘wants’ to make more politics?
From this point of view, it is hard to see how ‘we’ can ‘make’ cooperations (or individuals) sustainable by referring to morals and virtues.
Moral outbursts and frustrations about the destruction of our livelihood are completely understandable (for my psychic system) but how they irritate the different systems is quite uncertain.</p>

<h2 id="artificial-communication">Artificial Communication</h2>

<p>Niklas Luhmann’s concept of communication offers a useful framework for sidestepping (at least for a moment) the ongoing debate about <em>machine intelligence</em>.
While I personally do not ascribe human-like thinking or understanding to machines, I argue that this does not preclude their participation in communication processes.
Therefore, I agree with <a class="citation" href="#esposito:2022">(Esposito, 2022)</a>.</p>

<p>I think Esposito’s term <em>artificial communication</em> is a very useful contribution to make the discussion of <em>AI</em> (especially of machine learning) more reasonable.
Note that she was a student of Niklas Luhmann.
In an interview she explains why she came up with the term:</p>

<blockquote>
  <p>These algorithms became more and more opaque—not understandable for the users—the idea spread that the activities of machines are not trying to be intelligent; that they are not trying to reproduce, in an artificial way, the process of human thought; they are doing something different.
This is rarely said explicetly but one can find it in many different contexts.
And if we switch away from the idea of intelligence, what can we refer to?
Do we have another metaphor that would fit better into the current situation? – Elena Esposito</p>
</blockquote>

<p>Why do people think that ChatGPT is intelligent?
Well, if we interact with machines, we get information we would not get otherwise and the information cannot be attributed to any human being.
The machine processes the data and produces some information which not only did not exist before but is also a sort of reaction to our request.
The machine does exactly what we do when we communicate with a human being.
We ask something and we get some information we did not had before.
Importantly, this information is <strong>contingent</strong> (the response could be different).</p>

<p>Esposito clarifies that, as a sociologist, it is understandable that we think of these machines as <em>artificial intelligence</em> because we have been communicating with human beings for thousands of years and these beings were ‘intelligent’.
And because of this feature of being able to think, humans were able to produce something which allows us to get new information.
It is our prejudice that lead us to the conclusion that machines are so similar to human beings, i.e., psychic systems.
Therefore, to follow Esposito’s proposal, a more interesting and probably healthier question to ask (also for us computer scientist) is:</p>

<blockquote>
  <p>Why are these machines able to communicate with us inspite of the absence of their intelligence?</p>
</blockquote>

<p>Esposito’s answer is that they are <em>parasitical</em>.
My understanding of her work is that machines make heavy use of <strong>second-order observation</strong>, i.e., the observation of an observer.
The starting point is some mental activity but not the machine’s activity.
The user produces <em>contingent</em> behaviour which the machine can process (or observe) to become itself <em>contingent</em>.</p>

<p>A modern example that might no longer be considered AI is Google’s search algorithm. 
Google’s success stems not from trying to evaluate or calculate the quality of a webpage directly.
They didn’t design an intelligent machine for that purpose. 
Instead, they leveraged <em>second-order observation</em>, essentially tapping into the collective intelligence of their users. 
Rather than determining the value of a webpage themselves, their algorithm observes how users interact with webpages. 
A webpage ranks high if users deem it valuable which can create a feedback loop because highly ranked pages are ranked highly.
The primary task becomes observing users’ observations.</p>

<p>Even if Esposito speaks of switching the metaphor, her work goes deeper.
The word <em>intelligence</em> has two different usage in language which are often confused.
On the one hand, we refer to the operational mode of the mind.
But we have almost no idea what this <em>intelligence</em> exaclty is.
On the other hand, we think of information processing.
Take for example the term ‘Central Intelligence Agency’.
Therefore, the metaphor of <em>artificial intelligence</em> is so problematic which makes it hard to theorize about <em>AI</em> and its impact which leads to these hyper-speculative predictions.
It’s like referring to airplanes as artificial birds.
Just as airplanes succeeded when engineers stopped trying to mimic birds, AI has advanced when researchers moved away from replicating human thought.
By using Luhmann’s theory of communication, we might clear the smoke and find more effective ways to talk about artificial intelligence.</p>

<p>Esposito argues that we—the preachers of machine learning—do not reproduce human intelligence but rather social communication.
Intelligence that emerges from conscious beings might not be needed or might even be an obstacle for the establishment of communication.
Artificial communication (coupling machines and psychic or social systems via language) can be more effective than intelligent communcation (coupling psychic and social systems via language) but it can not be intelligent (referring to the first use of the word).
In other words: That which makes society more intelligent might not necessarily be intelligent.
As described above, social systems have their own <em>systemic rational</em> and we might call them intelligent.</p>

<p>Systems theory is useful because it focusses on communication itself.
Again, Luhmann claims that humans do not communicate, only communication communicates.
Of course, similar to air, humans are a necessary condition for communication but, like air, they do not communicate themselves—we can only hear the ticking of a clock because the air does not tick.</p>

<p>Luhmann diverges from traditional sender-receiver models of communication, such as Shannon’s <a class="citation" href="#shannon:1948">(Shannon, 1948)</a> where the focus is on the transmission of information.
Instead, Luhmann conceptualizes communication as comprising three essential moments: <em>announcement</em>, <em>information</em>, and <em>understanding</em>.
Each component has its unique role in facilitating communication.
An announcement initiates the process.
Whether verbalized, written, or visualized, it serves as the catalyst that triggers communication.
Absence of an announcement, be it from a human or an algorithm, results in the absence of communication altogether.
This announcement must bear some form of informational value, imbuing the text, image, or utterance with meaning.
The final moment, understanding, underscores the necessity of a recipient comprehending the conveyed information.
The efficacy of communication is not solely predicated on accurate understanding, but rather on the act of understanding itself—even if what is understood is incorrect.
As Luhmann notes, understanding is often replete with misunderstandings, but the very act of engaging in a selection of understanding is vital.
Understanding is typically misunderstanding without understanding the ‘mis’ (similarily, misinformation is still information).</p>

<p>In summary, Luhmann’s perspective underscores that effective communication doesn’t necessarily require partners to achieve mutual understanding in the way their respective psychic systems might operate.
I think we can make the same observation in our day to day life.
Partners can perfectly live together even though their understanding is not mutual which, of course, can cause problems in relationships.
However, it can also be a useful feature.
If a third party observe a tense conversation between a couple, the content of the conversation might be quite ordinary but what is communicated can be a conflict within the relationship.
The couple understands the communication much better than the third party.
The conflict, however, is likly caused by the problem of different previous (mis-)understandings.
For the third party, it is like listening to some encrypted communication.
Whether executed by humans or algorithms, the value lies in the process and its constituent parts: announcement, information, and understanding.</p>

<p>In the context of artificial intelligence we can look at the communication of a person and a machine—of ChatGPT and Doug Hofstadter—and we can ask: Why is it so effective or attractive? 
But also: Why is it (probably) not the product of an intelligent thinking system but rather produced social intelligence?</p>

<p>With my shallow understanding of Luhmann’s theory, I imagine that the prerequisites for communication—whether artificial or otherwise—involve <strong>contingency</strong> and <strong>connectivity</strong>.
In social systems theory, the generation of information is not an isolated act; it is attributed to an interactive partner.
While traditionally this partner is human, in the realm of artificial communication, it can very well be a machine.
The focus should be on the nature of the interaction itself: does it exhibit the characteristics of a contingent, autonomous relationship?
And does this interaction spur further communication?</p>

<p>Traditional machines that produce unpredictable outcomes are usually considered faulty rather than creative or original.
Take a pocket calculator, for instance; its primary virtue lies in its predictability.
We do not regard it as a communicative entity because it operates as expected which is desirable.
The calculator is not contingent.
Conversely, when interacting with image-generating algorithms like Stable Diffusion or Midjourney the appeal, I argue, is precisely in the unpredictability of the results.
Chatting with a bot can be exciting preceisly because we do not know the output of the bot or, in general, the outcome of this interaction.
Of course, this does not mean a completely random output would have the same effect.
<em>Contingency</em> should not be confused with randomness or arbitrariness.
The information provided by the bot has to be understandable, in the sense that it can also be misunderstood (like any ‘good’ communication can be).</p>

<p>Despite thinking of this feature as a flaw, this ambiguity is desirable for communication.
Of course, not all possibilities of misunderstanding are desirable.
A chatbot that provides patients with medical or organizational information should give precise and unambiguous answers.
However, in this case, the bot is more like a tool than a real communication partner.
And here we land at an important distinction:
While many argue that irritation caused by <em>generative AI</em> is similar to the invention of photography, I think there is a difference.</p>

<blockquote>
  <p>Cameras do not communicate!</p>
</blockquote>

<p>This does not mean that generative AI can not act as a mere tool in the process of, for example, the production of images.
The more predictable the more tool-like generative AI are and the less communicative they become.
There outputs by themselves become less interesting but at the same time, they are more useful to realize a specific vision of the user or artist.</p>

<p>As Esposito noted: Viewed through the lens of Luhmann’s social system theory, the development of compelling communication partners presents a unique dilemma: 
The challenge lies in engineering machines that exhibit both creativity and control, balancing the production of unexpected outcomes with predictability.
This tension is especially relevant in the field of AI art.
In essence, the paradox that governs the programming of ‘intelligent’ algorithms is the pursuit of controlled unpredictability.</p>

<blockquote>
  <p>The ultimate objective is to achieve a controlled lack of control. – <a class="citation" href="#esposito:2022">(Esposito, 2022)</a></p>
</blockquote>

<p>From a philosophical standpoint, Luhmann transforms the <em>mind-body problem</em> into the <em>mind-communication problem</em>—communication defined by Luhmann as “the operation that society consists of” <a class="citation" href="#moeller:2006">(Möller, 2006)</a>.
If the mind does not communicate but is only in the environment of society (communication)—is merely involved—how does this all work?
Similarily, I think, the question of how <em>artificial communication</em> emerges even if machines are also only in the environment of communicating systems, is one of the most important question to ask if one wants to understand the current state of AI, society and where we are heading at.</p>

<p>Now, if one looks closely to Luhmann’s definition of communication, we find that it is not compatible with Esposito’s concept of <em>artificial communication</em> and she is aware of that.
We might think of communication being really picky, that is, it has a lot of requirenments to occur—there is a lot of <em>structural coupling</em> going on.</p>

<blockquote>
  <p>Communication is improbable. – Luhmann</p>
</blockquote>

<p>Let’s look at some requirements: the physical requirements like temperature and gravity at a certain level, water, air, but also a medium and, according to Luhmann, at least two consciousness entities. 
In a sense, the coupling of these two conscious entities is more strict.
It is an equal operation of the psychic system that has to be devoted to the actual operation of the social system.
That is why they coincide in this event at which communication happens.</p>

<blockquote>
  <p>Empirically, I propse [the concept] because what is going on in the interaction with algorithms is so close to communication that we have to try to find a way to extend [Luhmann’s] concept of communication to include what is going on—it is not exactly the same.
The technique of the communication is similar: production of information which irritates other systems but the algorithm itself is not thinking, is not producing any new communication.
It just sort of conveys something that can produce information somewhere else.
My background is Luhmanian but what I am proposing, without wanting to amend Luhmann, is something different from the standard case of communication  – Elena Esposito</p>
</blockquote>

<h2 id="profilicity-machines">Profilicity Machines</h2>

<p>The philosopher Hans-Georg Moeller adds an interesting point to the machine learning discourse.
He posits that algorithms nowadays are used for profile building—he coined the term <em>profilicity</em> as a new identity technology, which is different from previous modes of identity building, i.e., <em>sincerity</em> and <em>authenticy</em> <a class="citation" href="#moeller:2021">(Möller &amp; D’Ambrosio, 2021)</a>.</p>

<p>Following his thesis, people taking pictures, not (primarily) to preserve memories, but to curate a profile on Facebook, Instagram or LinkedIn.
In that sense, I too build my own profile by writing this text and by curating a personal website, a GitHub repository, and many more profiles.
AI helps us to evaluate our profile(s) within McLuhan’s <em>Global Village</em> <a class="citation" href="#mcluhan:1992">(McLuhan, 1992)</a>.
It makes it possible to get feedback from our peers and to present this evaluation back to the village.
It enables <em>second-order observation</em> which reduces complexity.</p>

<p>Moeller admits that he is—as many of us coming from an age where authenticy was the primary technology to build identity—annoyed by this picture frenzy.
But he stays true to Luhmann and refrains from judging.
He trys not to moralize this phenomenon or classify it as being ‘worse’ or ‘better’ because, in his eye, authenticy was never real in the first place.
Like the other forms of identity building, profilicity comes with its own problems.
Each mode brings its own set of challenges.</p>

<p>He intriguingly describes profile creation as <em>genuinely pretending</em>.
Observing younger generations, this resonates.
Their digital avatars often exude a <em>postmodern irony</em>; they knowingly embrace its constructed nature.
They are fully aware that it is all ‘fake’.
Contrarily, older generations may need reminding that these online images are meticulously curated and often manipulated.
Advising younger folks about the ‘deceptions’ of online portrayals might seem naive.
Their approach is more playful, even inventive, using multiple layers of meta-references to distance themselves from reality as far away as possible.</p>

<p>As Moeller notes, the real tension might arise from the mismatched expectations of older authority figures. 
We—and I include myself here—expect authenticity while most parts of the world of young people operate in the mode of profilicity.
This leads to a contradiction and, because it is about identity building, this contradiction might be psychologically problematic.
Misaligned expectations can cloud the path to self-realization.
Hence, while it’s tempting to solely blame social media for rising mental health issues, the underlying causes, as Luhmann would argue, are multifaceted.</p>

<h2 id="the-revenge-of-objects">The Revenge of Objects</h2>

<p>With the description of society handed over by systems theory, I might have lured you, the reader, into an even greater despair.
My assertion is that we don’t necessarily need AI to challenge Hofstadter’s vision of human greatness; 
the <em>deconstruction</em> might already be underway.
Luhmann’s system theory goes against the honorable belief of Hofstadter which is also expressed by figures like David Graeber or Noam Chomsky.</p>

<blockquote>
  <p>The ultimate, hidden truth of the world is that it is something that we make, and could just as easily make differently. – David Graeber</p>
</blockquote>

<p>I really like the sentiment expressed in the quote.
I want it to be true and to work!
And I admire personalities that keep it alive.</p>

<p>However, objects seem to regain agency and power over us.
When certain philosophers discuss subjects and objects, they often reference commonplace items like chairs and desks.
For instance, a chair might seem like a benign example. 
Here the case seems trivial: Of course a chair has no agency!
We make chairs to sit on them.
We dominate chairs.
They are completely in our control.</p>

<p>But we do not have to look further than <em>Heidegger’s hammer</em> <a class="citation" href="#heidegger:1927">(Heidegger, 1927)</a> to see that things can get tricky very quickly.
Heidegger proposes that before we ponder the essence of a hammer, we use it. 
Before we question its existence, we recognize its utility.
The hammer, in this context, prompts us to act—it, indirectly, has agency.</p>

<p>Or consider more potent examples like opioids, smartphones, the internet, algorithms, images or even movies.
These items influence our behavior, decisions, and perceptions.
The inception of video technology, for example, started with the simple goal of determining if a galloping horse ever had all its hooves off the ground simultaneously.
Now reflect on the vast implications and transformations that this technology has since undergone.
Did we solely shape these inventions, or should we attribute some credit to the inventions themselves?</p>

<p>For Baudrillard there is an uninterrupted production of positivity that has terrifying consequences.
Applying systems theory terminology, he speaks of <em>runaway positive feedback loops</em>.</p>

<blockquote>
  <p>Any structure that hunts down, expels or exorcizes its negative elements risks a catastrophe caused by a thoroughgoing backlash, just as any organism that hunts down and eliminates its germs, bacteria, parasites, or other biological antagonists risks metastasis and cancer—in other words, it is threatened by a voracious posivity of its own cells, or, in the viral context, by the prospect of being devoured by its own antibodies. – <a class="citation" href="#baudrillard:1990">(Baudrillard, 1990)</a></p>
</blockquote>

<p>In other words, runaway positive feedback loops that have no negative, will eventually cause a catastrophe.
A simple technical example of such a feedback is a microphone that picks up the amplified sound output of loudspeakers in the same circuit, then howling and screeching sounds of audio feedback.</p>

<p>Baudrillard thought that the production of images is such a feedback loop.
They are <em>out of control</em> and take over, for example, free democratic politics.
Although we can take a moral stance against certain imagery, such as pornographic content, Baudrillard suggests that positive feedback will ultimately subvert any moral code.
Trump, as an example, may be critiqued from a moral perspective, but because he’s a potent subject for image production, the media engages with him regardless of whether they criticize or praise him.
This cycle of image production can’t be halted simply by creating more images.</p>

<p>Luhmann may have a less bleak view. 
For instance, laws that regulate AI-generated images, can prompt changes in a system’s behavior (indirectly via irritation).
However, reining in runaway positive feedback is challenging, as issues can escalate exponentially.</p>

<p>It might sound unconventional, but to foster our understanding of our world it could be beneficial to acknowledge external influences like reality TV, staged political photos, or conspiratorial content as agents.
Not only in a sense that they affect us but that they have an inner life; a will of their own so to say.
It could be valuable to treat objects like oil with the same reverence and respect as ancient civilizations treated strom and thunder.
Isn’t it the case that in our times oil is more powerful than any ancient god ever was?</p>

<p>Predictive machines can sometimes inadvertently create self-fulfilling prophecies. 
For example, I might be more inclined to buy items from Amazon that appear at the top of a list because of their prominent placement. 
These items are ranked by an algorithm aiming to maximize Amazon’s profits, predicting which items I’m most likely to purchase.
Since I’m inclined to buy items higher up on the list, the algorithm’s prediction is validated, influencing its future predictions and creating a positive feedback loop which consists of me and the algorithm.
Because I rely on algorithms to find items to buy, I believe it’s fair to say that they have influence over me and a sort of agency of their own.</p>

<p>If we don’t attribute agency to objects, then the explanation for the failures of climate agreements likely rests on a dysfunction of the system or on individual failures, e.g. ‘corrupt’ or incompetent politicians.
The idea that our modern society renders us freer and more independent is misconstrued.
A better way to put it is: We are (more) <em>out of control</em>.
While we engage in broader dialogues, express ourselves diversely, and view the world through varied lenses, increasing complexity often amplifies dependency and chaos.
There is more differentiation going on but this does not mean that we are less dependent.
Instead systems are less controlable.
The age-old dynamic of subjects dominating objects could very well be shifting, placing objects alongside us in terms of influence.</p>

<h2 id="artificial-systems">Artificial Systems?</h2>

<p>Systems theory doesn’t assert that society’s evolution is innate or that it will remain unchanged forever.
It simply aims to provide a thorough depiction of modern society. 
Yet, it’s worth exploring the connections between systems theory and artificial intelligence.
This exploration might hint at the concept of an <em>artificial system</em>—–essentially an AI that functions as a system, potentially approaching the capabilities of general artificial ‘intelligence’.</p>

<p>To venture a speculative idea, machines might eventually evolve into these <em>artificial systems</em>.
To thrive in a highly complex modern environment, they might need to exhibit traits similar to psychic and social systems: being <em>autopoietic</em>, <em>structurally coupled</em>, <em>operationally closed</em>, and <em>functionally differentiated</em>.
If we assume this to be true, what implications might it has?</p>

<p>While minds create themselves through mental operations, an <em>artificial system</em> would self-create and self-preserve through computation.
This does not mean that artificial systems have to be in control of their requirements to operate.
The opposite is the case.
The required hardware, programmers, and users of such systems would belong to their environment.
But, as Luhmann writes:</p>

<blockquote>
  <p>The observing and describing itself (cognition), however, always has to be an operation that is capable of autopoiesis, i.e., of the performing of life or actual consciousness or communication, because otherwise it could not reproduce the closure and difference of the cognizing system; it could not take place “in” the system. <a class="citation" href="#luhmann:1988">(Luhmann, 1988)</a></p>
</blockquote>

<p>Computation would probably drive more computation; 
the primary purpose being to continue its computational operations.</p>

<p>Due to their operational closure, a synthesis of thinking and computation—a <em>transhumanist</em> vision—seems unlikely.
Also, their structural coupling suggests they’d be interdependent on psychic systems and other social systems.
Natural language processing might be an important aspect of AI because it potentially makes this coupling possible via the <strong>shared medium of language</strong>.
This implies that the idea of AI overthrowing humanity is also improbable.
It is more likely that our mind, i.e. our thinking/feeling co-evolves with computation/text generation.
Machines will not think for us but they might irritate our thinking because we might need different skills to survive in an environment consisting of such machines.
However, it’s worth noting that psychic systems may not have control over these artificial systems.</p>

<p>The primary function of the psychic system, in Luhmann’s conceptualization, is the processing of meaning. 
Psychic systems generate thoughts, emotions, perceptions, and other mental phenomena. 
They observe, process information, and produce decisions. 
While social systems use communication as their primary medium, psychic systems use consciousness. 
Every individual has their own psychic system, which means their own consciousness and their own way of processing and understanding the world.</p>

<p>Artificial systems, on the other hand, may primarily focus on the production of predictions. 
They would observe and process abstract data and project potential futures. 
But what would ‘motivate’ them? 
To function or to survive, they have to compute, i.e., they have to process abstract data.
Consequently, their <em>systemic rational</em> might prioritize producing predictions that lead to more predictions, rather than producing the most accurate or useful predictions.
While we can see traces of this effect in recommendation algorithms that suggest polarizing content, attributing this behavior to <em>artificial systems</em> and not, or only partly, to the mass media system might be an overreach.</p>

<p>I must admit, I need a deeper understanding of systems theory to consider AI as potential systems in Luhmann’s view.
However, I believe it’s a valuable pursuit.</p>

<h2 id="difference-makes-the-difference">Difference Makes the Difference</h2>

<p>I agree with Hofstadter on the limitations of human greatness, albeit for different reasons and perspectives.
While discussing systems theory, I aimed to challenge his belief that AI diminishes this human greatness. 
I argued that this so-called greatness, or perhaps <em>rational control</em> that comes out of enlightenment, was an illusion from the outset.
Additionally, I’ve raised questions regarding the feasibility of ‘complete’ enlightenment as proposed by the modern project.</p>

<p>Simultaneously, I presented reasons:</p>

<ol>
  <li>for perceiving machines as intelligent, and</li>
  <li>for potentially being misled by this perception.</li>
</ol>

<p>The phenomenon of <em>artificial intelligence</em> is not only interesting because of impressive accomplishments but because it pushes discussions about the ‘human nature’ into many psychic and social systems.
This question leads immediatly to the question of <em>cognition</em>, <em>thinking/feeling</em>, and <em>consciousness</em> because these concepts are so central to the question of <em>machine intelligence</em>.
So, let me elaborate a little bit more on these concepts.</p>

<h3 id="the-mystery-of-consciousness">The Mystery of Consciousness</h3>

<p>First of all, debating if machines possess consciousness or human-like intelligence is premature without a clear understanding of intelligence and consciousness.
Perhaps ‘intelligence’ is just a collective term for several unexplained phenomena.
We do not know yet.</p>

<p>We can identify correlations between mental events and brain activities, implying there’s a physical aspect to consciousness—a sort of carrier.
However, as neuroscientist Giulio Tononi notes, this doesn’t necessarily mean we can pinpoint consciousness within the brain <a class="citation" href="#tononi:2015">(Tononi &amp; Koch, 2015)</a>.</p>

<blockquote>
  <p>[…] what I think I know about my body, about other people, dogs, trees, mountains, and stars, is inferential.
It is a reasonable inference, corroborated first by the beliefs of my fellow humans and then by the intersubjective methods of science.
Yet consciousness—the central fact of existence—still demands a rational explanation. – <a class="citation" href="#tononi:2015">(Tononi &amp; Koch, 2015)</a></p>
</blockquote>

<p>Still <em>physicalism</em>, the view that everything is physical and can be explained by physics, seems to be the natural position, especially in science.
However, this view can be challenged.
In the famous and rather short article <em>What Is It Like to Be a Bat?</em> <a class="citation" href="#nagel:1974">(Nagel, 1974)</a>, the philosopher Thomas Nagel trys to argue against it.
He explains that we can not know what <em>it is like</em> to be a bat.
He chooses bats because they are mammals like us and, presumably, conscious, yet their primary sensory experience—echolocation—is profoundly different from any human sensory experience.
In Luhmann’s words: their environment is very different from ours.
We can imagine flapping our arms like a bat or eating insects like a bat, but we cannot truly imagine what it is like to ‘experience’ the world primarily through echolocation.
Nagel suggests that even if we knew all the physical facts about a bat’s brain while it echolocates, we’d still be missing the subjective experience—the “what it’s like”–—of being a bat.</p>

<p>In the <em>philosopyh of mind</em> there is a broad spectrum of dealing with <em>the hard problem of consciousness</em> ranging from new forms of idealism (the essence of reality is consciousness), naive realism (we have direct awareness of objects as they really are), new realism (accepts that science is not systematically the ultimate measure of truth but realities are first given, not constructed) to panpsychismus (the mind or a mindlike aspect is a fundamental and ubiquitous feature of reality).
There is no agreement on the <em>hard problem of consciousness</em>.
Consequently, consciousness remains enigmatic, with little guidance on where to begin our inquiries.</p>

<h3 id="cognition-as-construction">Cognition as Construction</h3>

<p>Sometimes, to gain a fresh perspective on the world, one must take a completely opposite stance.
For millennia, philosophers have pondered how we can perceive something if we lack direct access to reality.
Luhmann flipped this idea on its head. 
He argued that it’s precisely because we don’t have direct access (due to system/environment distinction and operational closure) that we can perceive.
Cognition can only happen if it is not interrupted which requires operational closure.</p>

<blockquote>
  <p>The tradition of epistemological idealism was about the question of the unity within the difference of cognition and the real object.
The question was: how can cognition take notice of an object outside of itself?
Or: how can it realize that something exists independently of it while anything which it realizes already presupposes cognition and cannot be realized by cognition independently of cognition?
No matter if one preferred solutions of transcendental theory (Kant) or dialectics (Hegel), the problem was: how is cognition possible in spite of having no independent access to reality outside of it.
Radical constructivism, however, begins with the empirical assertion: Cognition is only possible because it has no access to the reality external to it.
A brain, for instance, can only produce information because it is coded indifferently in regard to its environment, i.e. it operates enclosed within the recursive network of its own operations.
Similarly one would have to say: Communication systems (social systems) are only able to produce information because the environment does not interrupt them.
And following all this, the same should be self-evident with respect to the classical “seat” (subject) of epistemology: to consciousness. – <a class="citation" href="#luhmann:1988">(Luhmann, 1988)</a></p>
</blockquote>

<p>I should emphasis and explain how radical this turn is.</p>

<p>Luhmann builds on Kant’s <em>Copernican Turn</em>.
He turned the question of ‘what is the general structure of the world’ into a question of the general structure of cognition: Under which conditions is cognition allowed to operate to conceive the world?
Kant tried to bridge the gap between Hume’s <em>empiricism</em> and German <em>idealism</em>.
He also accepted the skeptical argument that nothing could be realized by cognition independently of cognition.
Kant brought in <em>constructivism</em> into epistemology but he was, in Luhmann’s view, not radical enough because he hold on to some sort of relation to reality.
Luhmann assumes that the realization of reality is not a relating to reality, but that reality basically consists of its own realization and that the key is <em>differentiation</em>.
Therefore, Luhmann drops the idea of a reality that is independent of cognition, i.e. Kant’s <em>Ding an sich</em>.</p>

<p>According to Luhmann, cognition itself becomes a construction based on distinction: Reality emerges as cognition.
This sounds like Hegel’s <em>idealims</em>.
However, the emergence of reality does <strong>not</strong> mean that cognition is <em>ideal</em>—it does not rely on an essence in the form of consiousness.
Cognitive systems construct cognition which is based on the system/environment distinction.
There is no single rule how this can be done.
Cognition can operate materially in the form of biological life, mentally in the form of thoughts, or socially in the form of communication.</p>

<p>Moeller summerizes this shift from <em>Kantian idealism</em> to <em>radical constructivism</em> nicely <a class="citation" href="#moeller:2006">(Möller, 2006)</a>:</p>

<ol>
  <li>Cognition is not <em>per se</em> an act of consciousness. It can take on any operational mode.</li>
  <li>There is no a priori, transscendental structure of cognition; cognition constructs itself on the basis of <em>operational closure</em> and is an <em>empirical</em> process, which varies from system to system.</li>
  <li>No complete description of cognitive structures is possible because these structures are continuously evolving.</li>
  <li>Reality is not singular—there is not one specific reality, but a complex multiplicity of system/environment constellations.</li>
  <li>A description of reality is itself a contingent construction within a system/environment relation.</li>
</ol>

<p>In Luhmann, the subject/object distinction gets replaced with the system/environment distinction and the premise of a common world (the unity of system and environment) gets replaced by a theory of the observation of observing systems (<em>second-order cybernetics</em>).
However, getting to ‘the root’ of cognition—which would lead to some clues about <em>a reality</em>—seems impossible because any such investigations require distinction which is the operation of cognition.
Furthermore, there is no justification for assuming that any adaptation of cognition to reality is happening.
Confronted with this problem how can one start developing a theory of cognition?</p>

<p>In <em>Cognition as Construction</em>, Luhmann recognizes and somewhat addresses this issue by an assumption akin to Decartes and Husserl:</p>

<blockquote>
  <p>We assume that all cognizing systems are real systems within a real environment, or in other words: that they exist.
This is naive—as it is often objected.
But how should one begin if not naively?
A reflection on the beginning cannot be performed at the beginning, but only by the help of a theory that has already established sufficient complexity. – <a class="citation" href="#luhmann:1988">(Luhmann, 1988)</a></p>
</blockquote>

<p>Starting from this assumption, Luhmann reformulates Kant’s question of the possibility of cognition to the question of how systems can <strong>uncouple</strong> themselves from their environment.
For him, closure, i.e. uncoupling, is only possible by a systems’s production of its own operations and by its reproduction within the network of its recursive anticipations and resources.
Thus, cognition is manufactured and is a self-referential process.
It deals with an external world that remains unknown thus cognition has to come to see that it cannot see what it cannot see.
One could say that reality remains as an ineradicable <em>blind spot</em>.
While reality remains unkown, Luhmann speculates that there is some ground for the belief that if reality would be totally entropic, it could not enable any knowledge.
In other words, reality cannot be the object of the knowledge that it makes possible, it serves knowledge merely as a presupposition.
Knowledge can only know itself but it cannot know anything about what it constructs by way of the manipulation of distinctions.</p>

<p>All observing systems are cognitive systems.
They are operationally closed but cognitively open and they make sense of their environment as they experience it.
The mind makes sense in such a way that its construction is valid or functional.
It does not matter if it resembles reality.
In this way, making sense is like finding the right key to open a lock.
The key is useful and <em>functionional</em> but it does not tell us anything about the lock, expect that it fits the lock.
However, how we see the world depends on the cognitive capacities of our eyes and brains to produce images.
Different operations lead to further different operations.
For example, bats are another system/environment distinction than we are.
Therefore, their world most certainly ‘looks’ nothing like ours.</p>

<blockquote>
  <p>To recognize a table and say “This is a table”, I don’t need to have the letters T, A, B, L, E in my brain, nor does a tiny representation of a table (or even the “idea” of the table) need to exist inside me.
However, I do need a structure that calculates the various manifestations of a description for me. – <a class="citation" href="#foerster:1988">(Foerster, 1985)</a></p>
</blockquote>

<p>What our psychic system ‘sees’ does not have anything to do with reality.
In fact, the psychic system cannot ‘see’ reality with ‘its’ eyes because our eyes are in the environment of our psychic system.
Cognition is always a construction by an observing system and there is only irritation and no direct causal relation.</p>

<p>Now, one might ask: If every system constructs itself and reality emerges out of its cognition, how can we find any common ground?
Or, how did we end up believing in an universal and objective reality we actually can access?</p>

<p>Well, only because there is no objective reality does not mean that humans cannot ‘achieve’ social control via social systems.
Importantly, psychic and social systems share a common <em>medium</em>, that is, sense.
It is used in thought as well as in commuincation.
A thought or a gesture is a specific <em>form</em> (strict coupling) that the medium (loose coupling) of sense can take on.
Thus, thinking is like bringing sand (the medium) into a specific form; it can also be defined as a selection within a horizon of what is possible.
By thinking a specific thought, I do not think any other thought that is in my horizon of the thinkable.
Secondly, social and psychic systems are structurally coupled via language.
Language couples psychic and social systems. 
And these social systems make sense in accordance to their <em>systemic rationality</em> irritated by observing their environment.
In a sense, we create a second dimension of ‘reality’ by assuming, through the use of concepts, that our own constructions resemble those of others and by experiencing ourselves as part of a community by assuming and asserting that our own constructions largely correspond to those of others.
The experience of stability and continuity of one’s constructed reality depends not only on the system’s first-order observation but also on the confirmation of this observation by other observers (second-order observation).</p>

<p>From a radical constructivist perspective, a child learns language not as a system of information transmission but as a form of behavioral coordination.
It must learn, through trial-and-error strategies, to connect the multitude of linguistic expressions from adults with desired reactions of its own. 
Therefore, words like “forks/democracy” coordinate our actions with respect to what a person does when dealing with forks/democracy. 
Through the word “forks” and similarly through all other words, information is not transmitted but something specific is triggered in the recipient, which is determined by their structure and, indirectly, by their socialization.</p>

<p>Luhmann’s concept of <em>cognition as construction</em> does not provide an absolute, rigid foundation.
My explanation of it is based on my observation of Luhmann’s observations, and in case of the reader, it relies on your observation of my observation of Luhmann’s observation.
Since my, Luhmann’s and your observation are all constructed and contigent, it is inherently impossible to ‘prove’ the correctness of Luhmann’s theory from outside.
Furthermore, there will be always a blind spot.</p>

<blockquote>
  <p>A supertheory reflects on the fact that it and its validity are its own product—and is therefore absolutely contingent. […]
It is a theoretical endeavor, and there is nothing more to it.
It does little outside of theory. […]
With supertheory, the world does not become morally better, more rational, or spiritually complete.
It only becomes more distinct. – <a class="citation" href="#moeller:2006">(Möller, 2006)</a></p>
</blockquote>

<p>Radical constructivsm is often preceived as a dangerous path because it might lead to the relativization of ‘evil’ actions.
If everything is constructed, anything might be justifiable.
But again, Luhmann does not claim that there is no reality or that one can construct whatever one desires.
If you jump out the window, you will get hurt regardless of what you imagine.
However, acccording to Luhmann (and many others), there is no absolute and I think that this uncertainty makes us more thoughtful than reckless.
If absolute truth is on my side, everything is permitted.</p>

<p>It would be erroneous to claim that the application of social systems theory is justified because it describes society more ‘accurately’ because, according to this very same theory, such claims are impossible.
What we can state is that a theory that makes more sense—culturally and personally—might be useful for effective communication, facilitating a better understanding of one another.
This view aligns with Richard Rorty, another so-called postmodern ‘charlatan’:</p>

<blockquote>
  <p>If we can just drop the distinction between appearance and reality, we should no longer wonder whether the human mind, or human language, is capable of representing reality accurately.
We would stop thinking that some parts of our culture are more in touch with reality than other parts.
[…] we would not say that [our ancestors] were less in touch with reality than we, but that their imaginations were more limited than ours.
We would boast of being able to talk about more things than they could. – <a class="citation" href="#rorty:2016">(Rorty, 2016)</a></p>
</blockquote>

<h3 id="we-are-different">We are Different</h3>

<p>So let me ask: Why should machines (even if they are conscious) ‘live’ in a ‘world’ that is similar to ours?
And why should the bat-workd, my-world, and the machine-world be more true than any other system/environment distinction?
I think it is a mistake to undervalue our mental processes just because machines can communicate, calculate, and display creativity.
I also think it is a mistake to believe that thinking and computing are similar operations.
However, according to systems theory, viewing humans as superior rational entities is misguided as well.</p>

<p>A recurring theme in Luhmann’s writings is the idea of <strong>difference</strong> and <strong>differentiation</strong>.
Neither do we nor does any other system hold an intrinsic superior position in society; existence is <em>contingent</em>.
Observation necessitates selection, i.e. non-observation (a blind spot).
If I observe my cup, I cannot oberserve myself at the same time.
Because of differentiation there is no system that can make absolute sense of some indpendent reality.
The legal system ‘looks’ at a house in legal terms and the economy in economic terms.
There is no view from the top, above or the outside.
A system can only observe in accordance to its <em>systemic rationality</em>.
And as I argued above, bats, human beings, and maybe at some point in future, machines ‘live’ in, or better create, different interdependent ‘worlds’.
We are differnt; neither better nor worse with respect to each other and to other beings/systems.
I think, that should be enough to be fascinated about ourselves and to value us as different as we are.</p>

<p>This multiplicity of ‘worlds’—this functional differentiation—makes communcation so difficult.
It seems like a miracle that we sometimes seem to understand each other.
Luhmann believed that ecological problems are primarily problems of communication.
Different social systems (e.g., politics, science, economics) have different ways of observing and communicating about the environment, which can lead to misunderstandings or contradictions.
So one idea I have in mind is that via <em>artificial communication</em> we might be able to reduce misunderstanding between different systems, including the ecological system.
From a Luhmannian perspective, we need a sort of <em>translation</em> from one <em>systemic rational</em> to the other.
Furthermore, I believe that we need a more strict coupling between the ecological system and psychic as well as social systems.
Maybe artificial communication can establish such a strict structural coupling.</p>

<p>Only because we are not in charge, does not mean that things can not get better.
There seems nothing inherently wrong with biological evolution.
Is social evolution any different?</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="hofstadter:1979">Hofstadter, D. (1979). <i>Gödel, Escher, Bach: An Eternal Golden Braid</i>. Basic Books.</span></li>
<li><span id="bender:2021">Bender, E. M., Gebru, T., McMillan-Major, A., &amp; Shmitchell, S. (2021). On the dangers of stochastic parrots: Can language models be too big? <i>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</i>, 610–623. https://doi.org/10.1145/3442188.3445922</span></li>
<li><span id="bender:2020">Bender, E. M., &amp; Koller, A. (2020). Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data. <i>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</i>, 5185–5198. https://doi.org/10.18653/v1/2020.acl-main.463</span></li>
<li><span id="moeller:2006">Möller, H.-G. (2006). <i>Luhmann Explained: From Souls to Systems</i>. Open Court.</span></li>
<li><span id="luhmann:1988">Luhmann, N. (1988). <i>Erkenntnis als Konstruktion</i>. Bern: Benteli.</span></li>
<li><span id="luhmann:1993">Luhmann, N. (1993). <i>Deconstruction as second-Order observation</i>. New Literary History.</span></li>
<li><span id="luhmann:2000">Luhmann, N. (2000). Why does society describe itself as postmodern. In W. Rasch &amp; C. Wolfe (Eds.), <i>Observing complexity: Systems theory and postmodernity</i> (pp. 35–49). University of Minnesota.</span></li>
<li><span id="brown:1969">Spence-Brown, G. (1969). <i>Laws of Form</i>. London: Allen and Unwin.</span></li>
<li><span id="esposito:2022">Esposito, E. (2022). <i>Artificial Communication</i>. The MIT Press. https://doi.org/10.7551/mitpress/14189.001.0001</span></li>
<li><span id="shannon:1948">Shannon, C. E. (1948). A mathematical theory of communication. <i>Bell Syst. Tech. J.</i>, <i>27</i>(3), 379–423.</span></li>
<li><span id="moeller:2021">Möller, H.-G., &amp; D’Ambrosio, P. J. (2021). <i>You and Your Profile: Identity After Authenticity</i>. Columbia University Press.</span></li>
<li><span id="mcluhan:1992">McLuhan, M. (1992). <i>The Global Village: Transformations in World Life and Media in the 21st Century</i>. Oxford University Press.</span></li>
<li><span id="heidegger:1927">Heidegger, M. (1927). <i>Sein und Zeit</i>.</span></li>
<li><span id="baudrillard:1990">Baudrillard, J. (1990). <i>The Transparency of Evil: Essays in Extreme Phenomena</i>. Verso.</span></li>
<li><span id="tononi:2015">Tononi, G., &amp; Koch, C. (2015). Consciousness: Here, there and everywhere? <i>Philosophical Transactions of the Royal Society B: Biological Sciences</i>, <i>370</i>(1668), 20140167.</span></li>
<li><span id="nagel:1974">Nagel, T. (1974). What is it like to be a bat? <i>Philosophical Review</i>, <i>83</i>(October), 435–450. https://doi.org/10.2307/2183914</span></li>
<li><span id="foerster:1988">Foerster, H. (1985). <i>Sicht und Einsicht</i>. Vieweg.</span></li>
<li><span id="rorty:2016">Rorty, R. (2016). <i>Philosophy as Poetry</i>. University of Virginia Press.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Social Systems Theory" /><category term="AI" /><summary type="html"><![CDATA[Generative AI, especially ChatGPT, brought artificial intelligence into the public sphere and sparked a lot of highly speculative claims about machine intelligence. I’m open for discussions and unafraid of confronting uncomfortable truths. Indeed, our imagination and fearless thinking should pave the way for new possibilities. Dreams and speculations are valuable, as long as they’re presented as such. However, I find it concerning when public figures speak with undue certainty, particularly when making anthropological comparisons between humans and machines.]]></summary></entry><entry><title type="html">Musical Interrogation II - MC and FFN</title><link href="https://bzoennchen.github.io/Pages/2023/05/31/musical-interrogation-II.html" rel="alternate" type="text/html" title="Musical Interrogation II - MC and FFN" /><published>2023-05-31T00:00:00+02:00</published><updated>2023-05-31T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/05/31/musical-interrogation-II</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/05/31/musical-interrogation-II.html"><![CDATA[<p>The code shown here can be found in the following GitHub <a href="https://github.com/BZoennchen/musical-interrogation">repository</a>.
In the second installment of this series, I introduce an initial and arguably the most basic method to generate monophonic melodies. 
This consists of two approaches: (1) A <strong>first-order Markov chain (MC)</strong> and (2) a <strong>feedforward neural network (FNN)</strong></p>

<p>It’s important to note that I will disregard all forms of dynamics within a notated score (or performace), such as loudness, softness, etc.</p>

<p>Despite these two approaches being significantly outdated, I believe their demonstration serves as a valuable exercise for familiarizing oneself with the inherent challenges of the subject matter. 
The inspiration for this work comes from the tutorial series made by <a href="https://www.youtube.com/watch?v=FLr0r-QhqH0&amp;list=PL-wATfeyAMNr0KMutwtbeDCmpwvtul-Xz">Valerio Velardo’s</a> and another series made by <a href="https://www.youtube.com/@AndrejKarpathy">Andrej Karpathy’s</a>.</p>

<p>Although I utilize high-level libraries such as <a href="https://pytorch.org/">PyTorch</a> and take advantage of its <em>computational graph</em> and <em>autograd</em> features, I intend to maintain the model code and training process at a relatively low level.</p>

<h2 id="requirements">Requirements</h2>

<p>The necessary software requirements for this project include:</p>

<ul>
  <li><a href="https://www.python.org/">Python</a></li>
  <li><a href="https://pytorch.org/">PyTorch</a></li>
  <li><a href="http://web.mit.edu/music21/">Music21</a></li>
  <li><a href="https://github.com/BZoennchen/musical-interrogation/blob/main/preprocess.py">preprocessor.py</a> helpler class to deal with <code class="language-plaintext highlighter-rouge">krn</code>-files.</li>
  <li><a href="https://musescore.org/de">MuseScore</a> (optional)</li>
  <li><a href="https://jupyter.org/">Jupyter Notebook Environment</a> (optional)</li>
</ul>

<p>The database required can be found at <a href="http://kern.ccarh.org">EsAC</a>. The specific dataset I utilized is <a href="https://kern.humdrum.org/cgi-bin/ksdata?l=/essen/europa&amp;format=recursive">Folksongs from the continent of Europe</a> and for the purpose of this work, I will exclusively use the 1700 pieces found in the <code class="language-plaintext highlighter-rouge">./deutschl/erk</code> directory.</p>

<p>Let’s listen to one of these pieces:</p>

<audio controls="">
  <source src="/Pages/assets/audio/mel0567.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<h2 id="data-representation">Data Representation</h2>

<p>In <a href="/Pages/2023/04/02/musical-interrogation-I.html">Part I</a> of this series, I alluded to various implementations that utilize different input encodings. Naturally, the information we can leverage depends on the format of our training data. 
For instance, MIDI provides us with attributes such as pitch, duration, and velocity.
In my <a href="">implementation</a>, you will notice two distinct, yet straightforward encoding options available.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">GridEncoder</code> used by Valerio Velardo</li>
  <li><code class="language-plaintext highlighter-rouge">NoteEncoder</code></li>
</ol>

<p>The <code class="language-plaintext highlighter-rouge">GridEncoder</code> utilizes a fixed metrical grid where (a) output is generated for every timestep, and (b) the step size corresponds to a fixed meter (the shortest duration of any note in any score). For instance, if the shortest duration is a quarter note, a whole note of pitch 65 (in MIDI format) would result in the event series:</p>

<p><strong>65-note-on hold hold hold</strong></p>

<p>On the other hand, the <code class="language-plaintext highlighter-rouge">NoteEncoder</code> employs a larger alphabet and encodes one note directly, i.e.,</p>

<p><strong>65-whole</strong></p>

<p>In comparison to <em>note encoding</em>, <em>equitemporal grid encoding</em> relies on a smaller alphabet but needs more tokens for the same score.
This disadvantage is magnified if the score contains notes of vastly differing durations or if we wish to introduce micro-dynamics through an increase in resolution, as done by <a class="citation" href="#oore:2018">(Oore et al., 2018)</a>.</p>

<p>Interestingly, Google’s <a href="https://magenta.tensorflow.org/">Magenta project</a> employs <em>equitemporal grid encoding</em>, specifically the <a href="https://github.com/magenta/note-seq/blob/main/note_seq/melody_encoder_decoder.py">MelodyOneHotEncoding</a> class for their <em>BasicRNN</em>, <em>MonoRNN</em>, and <em>LookbackRNN</em>. 
Since they capture polyphonic scores, they utilize <strong>note-on</strong> and <strong>note-off</strong> events for each MIDI key.</p>

<p>Of course, the chosen representation also depends on the application and the capabilities of the model we use. 
For instance, one might only want to generate the pitches of the melody and manually adjust the duration of each note in post-processing. 
Furthermore, a <em>first-order Markov chain</em> only <em>memorizes</em> the most recent event. 
Therefore, an <em>equitemporal grid encoding</em> would yield unsatisfactory results because the context is lost after a <strong>hold</strong> event occurs.</p>

<p>As a result, in this post, I will focus on the <em>note encoding</em> approach, i.e. <code class="language-plaintext highlighter-rouge">NoteEncoder</code>.</p>

<h2 id="preprocessing">Preprocessing</h2>

<p>The procedure I’m about to present parallels the one detailed in <a href="/Pages/2022/07/09/markov-chains-for-music-generation.html">Probabilistic Melody Modeling</a>. 
The primary differences are that we’ll now be considering 1700 pieces instead of a single one, and we utilize more sophisticated libraries instead of relying solely on <a href="https://sonic-pi.net/">Sonic Pi</a>.</p>

<p>The <a href="http://web.mit.edu/music21/">Music21</a> library significantly simplifies the handling of symbolically notated music in <code class="language-plaintext highlighter-rouge">Python</code>.
I am not so familiar with it but it comes in handy when reading and writing symoblic scores.
It enables us to construct pieces programmatically and to read from or write to various musical score formats.</p>

<p>As an initial step, we need to import all the necessary libraries and functions.
Here I fix the global seed such that you can reproduce the exact same results.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">music21</span> <span class="k">as</span> <span class="n">m21</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">preprocess</span> <span class="kn">import</span> <span class="n">load_songs_in_kern</span><span class="p">,</span> <span class="n">NoteEncoder</span><span class="p">,</span> <span class="n">KERN_DATASET_PATH</span>

<span class="c1"># seed such that we can compare results
</span><span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
</code></pre></div></div>

<p>Then I read all the pieces inside the <code class="language-plaintext highlighter-rouge">./../deutschl/erk</code> directory.
Furthermore, I introduce a special character <code class="language-plaintext highlighter-rouge">TERM_SYMBOL</code> that I use to indicate the beginning and end of a score.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">TERM_SYMBOL</span> <span class="o">=</span> <span class="s">'.'</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">load_songs_in_kern</span><span class="p">(</span><span class="s">'./../deutschl/erk'</span><span class="p">)</span>
</code></pre></div></div>

<p>Now we have to think about our encoding.
As discussed above, I use the <code class="language-plaintext highlighter-rouge">NoteEncoder</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">encoder</span> <span class="o">=</span> <span class="n">NoteEncoder</span><span class="p">()</span>
<span class="n">enc_songs</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">encode_songs</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">enc_songs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<p>The code above prints out:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'55/4 60/4 60/4 60/4 60/4 64/4 64/4 r/4 ... 64/4 60/4 62/4 60/8 r/4'
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">'55/4</code> means MIDI note 55 four timesteps long where the timestep is determined by the shortest note within all scores. 
In our case this means four times 1/4 beat which is one whole beat.</p>

<p>Given that computers cannot process strings directly, I convert these strings into numerical values. 
The first step is to create a set that includes all possible strings. Subsequently, I assign each string a corresponding natural number in sequential order.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">symbols</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">item</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> 
                           <span class="n">enc_songs</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">])))</span>
<span class="n">stoi</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">symbols</span><span class="p">)}</span>
<span class="n">stoi</span><span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">itos</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">s</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">stoi</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'n_symbols: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">itos</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">stoi</code> maps <strong>s</strong>trings <strong>to</strong> <strong>i</strong>ntegers and <code class="language-plaintext highlighter-rouge">itos</code> is its inverse mapping.</p>

<h2 id="discrete-first-order-markov-chain">Discrete First-Order Markov Chain</h2>

<p>To implement a <em>first-order Markov chain</em>, we aim to construct a Markov matrix</p>

\[\mathbf{P} \in [0;1]^{m \times m}\]

<p>where the element at the \(i^{\text{th}}\) row and \(j^{\text{th}}\) column represents the conditional probability</p>

\[P(e_i\ | \ e_j) = p_{ij}.\]

<p>It describes the (conditional) probability of event \(e_i\) (a note or rest of specific length) immediately following event \(e_j\).
For this purpose, I construct a matrix \(\mathbf{N}\) that counts these transitions.</p>

<h3 id="markov-matrix-computation">Markov Matrix Computation</h3>

<p>To accomplish this, I iterate over each score, considering every pair of consecutive events. 
As the first event lacks a predecessor and the last lacks a successor, I append the unique terminal character <code class="language-plaintext highlighter-rouge">TERM_SYMBOL</code> to each score for padding purposes.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">N</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)))</span>
<span class="k">for</span> <span class="n">enc_song</span> <span class="ow">in</span> <span class="n">enc_songs</span><span class="p">:</span>
    <span class="n">chs</span> <span class="o">=</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">+</span> <span class="n">enc_song</span> <span class="o">+</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ch1</span><span class="p">,</span> <span class="n">ch2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chs</span><span class="p">,</span> <span class="n">chs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">ix1</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch1</span><span class="p">]</span>
        <span class="n">ix2</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch2</span><span class="p">]</span>
        <span class="n">N</span><span class="p">[</span><span class="n">ix1</span><span class="p">,</span> <span class="n">ix2</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div>

<p>To construct \(\mathbf{P}\) we have to divide each entry \(n_{ij}\) in \(\mathbf{N}\) by the sum over the row \(i\).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">P</span> <span class="o">=</span> <span class="n">N</span><span class="p">.</span><span class="nb">float</span><span class="p">()</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">P</span> <span class="o">/</span> <span class="n">P</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>In order to compute the sum over a row (instead of a column), i.e., “summing all columns”, we need to specify <code class="language-plaintext highlighter-rouge">dim=1</code> (the default is <code class="language-plaintext highlighter-rouge">dim=0</code>). 
Additionally, to properly exploit broadcasting, it’s necessary to set <code class="language-plaintext highlighter-rouge">keepdim=True</code>. 
This ensures that the sum results in a <code class="language-plaintext highlighter-rouge">(1,m)</code> tensor, as opposed to a <code class="language-plaintext highlighter-rouge">(m,)</code> tensor.</p>

<p>Plotting the probabilities reviels that \(\mathbf{P}\) is a rather sparse matrix containing many zeros.
In fact, only approximately 7.86 percent of the entries are non-zero.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/mc-probs.png" alt="Probabilities" />
<div style="display: table;margin: 0 auto;">Figure 1: Matrix plot of our Markov matrix.</div>
</div>
<p><br /></p>

<h3 id="sampling-of-new-melodies">Sampling of New Melodies</h3>

<p>Given the tensor <code class="language-plaintext highlighter-rouge">P</code>, we can generate new melodies using the function <code class="language-plaintext highlighter-rouge">torch.multinomial</code> which expects a probability (discrete) distribution.
I start with the terminal <code class="language-plaintext highlighter-rouge">TERM_SYMBOL</code> indicating the beginning and, when the second terminal is generated (which indicates the end), I terminate the generation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generated_encoded_song</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">char</span> <span class="o">=</span> <span class="n">TERM_SYMBOL</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">P</span><span class="p">[</span><span class="n">stoi</span><span class="p">[</span><span class="n">char</span><span class="p">]],</span> 
        <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
        <span class="n">replacement</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">item</span><span class="p">()</span>
    <span class="n">char</span> <span class="o">=</span> <span class="n">itos</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">char</span> <span class="o">==</span> <span class="n">TERM_SYMBOL</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">generated_encoded_song</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">generated_encoded_song</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s listen to some of the generated scores:</p>

<audio controls="">
  <source src="/Pages/assets/audio/gen0.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen1.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen2.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen3.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<audio controls="">
  <source src="/Pages/assets/audio/gen4.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<h3 id="negative-log-likelihood-loss">Negative Log Likelihood Loss.</h3>

<p>The outcome is not particularly outstanding, but this is unsurprising given our very simple model. 
To evaluate the quality of our model, we can calculate the likelihood that our generative process produces for a specific training data point \(e_1, e_2, \ldots, e_k\), i.e.,</p>

\[P(e_1) \cdot P(e_2 \ | \ e_1) \cdot \ldots \cdot P(e_{k-1} \ | \ e_k).\]

<p>We can add all the likelihoods (one for each data point) together and divide the sum by the number of data points.
However, it is more convinient to use the <em>negative log-likelihood</em> since one can use addition.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">log_likelyhood</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">enc_songs</span><span class="p">:</span>
    <span class="n">chs</span> <span class="o">=</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">+</span> <span class="n">m</span> <span class="o">+</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ch1</span><span class="p">,</span> <span class="n">ch2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chs</span><span class="p">,</span> <span class="n">chs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">ix1</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch1</span><span class="p">]</span>
        <span class="n">ix2</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch2</span><span class="p">]</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="n">ix1</span><span class="p">,</span> <span class="n">ix2</span><span class="p">]</span>
        <span class="n">logprob</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
        <span class="n">log_likelyhood</span> <span class="o">+=</span> <span class="n">logprob</span>
        <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">log_likelyhood</span><span class="o">=</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">nll</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_likelyhood</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'avg negative log likelyhood: </span><span class="si">{</span><span class="p">(</span><span class="n">nll</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p>This gives us a <em>negative log-likelihood</em> of approximately <code class="language-plaintext highlighter-rouge">2.6756</code>.
The lower this value gets the better it is.
It can be no smaller than 0.</p>

<h2 id="feedforward-neural-network">Feedforward Neural Network</h2>

<p>One method of generating a melody using a <em>feedforward network (FFN)</em> is by addressing a classification task.
Well, strictly speaking we do not even build a FFN, since there will be no activation function involved thus it is a <strong>linear model</strong>.
However, from this starting point we could expand our model into a <em>multi-layer perceptron (MLP)</em>.
By avoiding the activation function, it is easier for me to explain exactly what is going on.</p>

<p>If we think in terms of classification a sequence of note should be classified as some successor note.
So let us assume \(t\) consecutive notes are given then our aim is to identify the note that this sequence “represents”.
For simplicity, I assume we only want to predict the next note given the previous one, that is, \(t=1\) holds.
This stipulation means we won’t require substantial modifications compared to our previous approach.</p>

<p>Since our training process will be more computationally intensive than merely computing frequencies, it’s advisable to use hardware accelerators, if available. 
This can result in faster training and inference times and lower energy costs.
To check if hardware acceleration is available, I employ the following code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">mps</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'mps'</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">)</span>
    
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">device</span><span class="o">=</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p>What we are going to implement is a <em>fully-visible softmax belief network</em> which only predicts the very next note given the previous note.
However, instead of multiplying \(x_1\) to predict \(x_2\) via</p>

\[h_{\theta}(x)_{j=1,\ldots,m} = \left(\alpha_0^{(j)} + \alpha_1^{(j)} \cdot x \right)_{j=1,\ldots,m},\]

<p>we do something similar but not quite the same.
We <em>hot-encode</em> our alphabet \(\mathcal{X}\) of notes into</p>

\[|\mathcal{X}| = m\]

<p>vectors \(\mathbf{x}_j = (x_1, \ldots, x_m)\), \(j=1, \ldots, m\) of length \(m\), such that,</p>

\[h_{\theta}(\mathbf{x}_i)_{j=1,\ldots,m} = \left( w_{1}^{(j)} \cdot x_1 + w_{2}^{(j)} \cdot x_2 + \ldots + w_{m}^{(j)} \cdot x_m \right)_{j=1,\ldots,m} = \left( w_{i}^{(j)} x_i \right)_{j=1,\ldots,m}.\]

<p>In other words, we compute an embedding of our alphabet/domain of notes such that each note is encoded by an \(m\)-dimensional vector.
This vector represents the probabilities of the next note.
To transform these embeddings into probabilities we apply the softmax function.
Our network is depicted in Fig. 2.
Note that we do not use a bias term, i.e., there is no replacement for \(\alpha_0^{(j)}\).</p>

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:75%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:75%;" src="/Pages/assets/images/fvsbn-hot.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 2: Fully-visible softmax belief network (multi-class classification with 4 classes) predicting only the next note utilizing hot-encoding. Only one input node fires 1 all the others fire 0. The illustration indicates that the second input is active while all other inptus are inactive.</div>
</div>
<p><br /></p>

<p>Similar as before, our loss is the empirical mean of the negative log likelyhood</p>

\[-\frac{1}{M} \sum_{i=1,j=y_i}^M \log(\sigma(\mathbf{o})_j),\]

<p>where \(j\) is the \(j^\text{th}\) note in our alphabet and \(y_i\), that is \((\mathbf{x}, y_j)\) is in our training data set.</p>

<h3 id="training-data-construction">Training Data Construction</h3>

<p>Instead of calculating our probability matrix, I am going to generate labeled training data using the variables <code class="language-plaintext highlighter-rouge">xs</code> and <code class="language-plaintext highlighter-rouge">ys</code> (labels).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">ys</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">enc_songs</span><span class="p">:</span>
    <span class="n">chs</span> <span class="o">=</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span> <span class="o">+</span> <span class="n">m</span> <span class="o">+</span> <span class="p">[</span><span class="n">TERM_SYMBOL</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ch1</span><span class="p">,</span> <span class="n">ch2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chs</span><span class="p">,</span> <span class="n">chs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">ix1</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch1</span><span class="p">]</span>
        <span class="n">ix2</span> <span class="o">=</span> <span class="n">stoi</span><span class="p">[</span><span class="n">ch2</span><span class="p">]</span>
        <span class="n">xs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">ix1</span><span class="p">)</span>
        <span class="n">ys</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">ix2</span><span class="p">)</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># one-hot-encoding
</span><span class="n">xenc</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)).</span><span class="nb">float</span><span class="p">()</span>
</code></pre></div></div>

<p>As mentioned, I employ a <em><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html">one-hot encoding</a></em> for the input data.
That is, for encoding \(m\) unique elements one uses \(m\) unique \(m\)-dimensional vectors.
One component of these vectors is set to 1.0 and all others are 0.0.
<code class="language-plaintext highlighter-rouge">F.one_hot</code> assumes that our alphabet consists of whole numbers between 0 and \(m-1\), compare the <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html">documentation</a>.</p>

\[(0, \ldots, 0, 1, 0, \ldots, 0)\]

<p>The \(i^{\text{th}}\) element is represented by a vetor where the \(i^{\text{th}}\) component is 1.0.
Note that our labels <code class="language-plaintext highlighter-rouge">ys</code> are not one-hot encoded.</p>

<h3 id="training">Training</h3>

<p>Next, I initialize a random matrix \(\mathbf{W} \in [-1;1]^{m \times m}\), or tensor, <code class="language-plaintext highlighter-rouge">W</code> with values ranging from -1.0 to 1.0.
This tensor includes our trainable parameters, which represent the single layer of our neural network.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>Our network includes \(m\) inputs and outputs, with the <em><a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a></em> values of the outputs being interpreted as probabilities.
Essentially, our “network” is just one large matrix!</p>

<p>The operation <code class="language-plaintext highlighter-rouge">xenc @ W</code> represents a matrix multiplication where <code class="language-plaintext highlighter-rouge">xenc</code> is an \(1700 \times m\) matrix and <code class="language-plaintext highlighter-rouge">W</code> is our \(m \times m\) matrix.
Here I use the power of parallel computation.
By employing <code class="language-plaintext highlighter-rouge">probs[torch.arange(len(ys), device=device), ys]</code>, I address a single entry for each row.</p>

<p>Please note that <code class="language-plaintext highlighter-rouge">probs[:, ys]</code> does not work; instead of addressing a single entry, it addresses whole columns indexed by <code class="language-plaintext highlighter-rouge">ys</code>!
Also, be aware that I apply an unusually large learning rate.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># training aka gradient decent
</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">2_000</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># forward pass
</span>    <span class="n">logits</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W</span>
    <span class="n">odds</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">odds</span> <span class="o">/</span> <span class="n">odds</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'epoch </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    
    <span class="c1"># backward pass
</span>    <span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># set gradients to zero
</span>    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="c1"># update
</span>    <span class="n">W</span><span class="p">.</span><span class="n">data</span> <span class="o">+=</span> <span class="o">-</span><span class="mf">10.0</span> <span class="o">*</span> <span class="n">W</span><span class="p">.</span><span class="n">grad</span>
</code></pre></div></div>

<p>One iteration of the loop consist of the</p>

<ol>
  <li><em>forward pass</em></li>
  <li><em>backward pass</em> (backwardpropagation) done via <code class="language-plaintext highlighter-rouge">loss.backward()</code> and</li>
  <li>an update of our parameters done via <code class="language-plaintext highlighter-rouge">W.data += -10.0 * W.grad</code>.</li>
</ol>

<p><code class="language-plaintext highlighter-rouge">loss.backward()</code> applies <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> thus computes the gradients and we can update <code class="language-plaintext highlighter-rouge">W</code> by</p>

\[\mathbf{W} \leftarrow \mathbf{W} - \eta \cdot \nabla_\mathbf{W} L\]

<p>where \(\eta = 10\) is the <em>learning rate</em>.</p>

<p>After the initial 2000 epochs the loss is approximately <code class="language-plaintext highlighter-rouge">2.865</code>. 
This performance is somewhat inferior compared to the results achieved by our <em>Markov chain</em>. 
However, by prolonging the training period, I managed to reduce the loss to around <code class="language-plaintext highlighter-rouge">2.707</code>.</p>

<h3 id="what-is-going-on">What is going on?</h3>

<p>Let us assume we have only one sample \(\mathbf{x}\).</p>

<h4 id="forward-pass">Forward Pass:</h4>

<p>The <em>forward pass</em> starts with</p>

\[\mathbf{o} = \mathbf{x} \cdot \mathbf{W}\]

<p>where \(\mathbf{x}\) is a <em>one-hot encoded</em> training data point.
\(\mathbf{o}\) gets interpreted as (component-wise) logarithm of the odds</p>

\[\mathbf{o} = \ln\left(\frac{\mathbf{p}}{\mathbf{1}-\mathbf{p}}\right)\]

<p>which is the <a href="https://en.wikipedia.org/wiki/Logit">logit</a>, i.e., the inverse of the <em>standard logistic function</em> also called <em>sigmoid</em>.
In fact, each data point in \(\mathbf{x}\) selects one row of \(\mathbf{W}\)</p>

\[\mathbf{o} = \mathbf{x} \cdot \mathbf{W} = \begin{bmatrix} o_1 &amp; o_2 &amp; \ldots &amp; o_m \end{bmatrix}.\]

<p>To compute “probabilities” we compute the <em><a href="https://en.wikipedia.org/wiki/Softmax_function">softmax function</a></em> (<code class="language-plaintext highlighter-rouge">probs</code>) of \(\mathbf{o}\), i.e.,</p>

\[\sigma(\mathbf{o}) = \begin{bmatrix} \sigma(\mathbf{o})_1 &amp; \sigma(\mathbf{o})_2 &amp; \ldots &amp; \sigma(\mathbf{o})_m \end{bmatrix}\]

<p>with</p>

\[\sigma(\mathbf{o})_i = \frac{e^{o_i}}{\sum e^{o_j}}.\]

<p>Luckly the <em>softmax</em> has a simple derivative:</p>

\[\frac{\partial \sigma(\mathbf{o})_i}{\partial o_j} =
\begin{cases}
    \sigma(\mathbf{o}_k)_i - \sigma(\mathbf{o})_i^2 &amp; \text{ if } i = j \\
    -\sigma(\mathbf{o}_k)_i \sigma(\mathbf{o})_j &amp; \text{ otherwise.}
\end{cases}\]

<p>We can also compute the full Jacobian of the <em>softmax</em> vector-to-vector operation:</p>

\[\nabla_{\mathbf{o}} \sigma = \mathbf{J}_{\mathbf{o}}(\sigma) =
\begin{bmatrix} 
    \sigma_1 - \sigma_1^2 &amp; -\sigma_1 \sigma_2 &amp; \ldots &amp; - \sigma_1 \sigma_m  \\
    -\sigma_2 \sigma_1 &amp; s_2 - \sigma_2^2 &amp; \ldots &amp; -\sigma_2 \sigma_m \\
    \ldots &amp; \ldots &amp; \ldots &amp; \ldots \\
    -\sigma_m \sigma_1 &amp; -\sigma_m \sigma_2 &amp; \ldots &amp; \sigma_m - \sigma_m^2
\end{bmatrix} = \text{diag}\left(\sigma\right) - \sigma^{\top} \sigma\]

<p>Similar then before, our loss $L$ is the mean <em>negative log likelihood</em>.</p>

\[L(\mathbf{y}, \sigma) = -\sum\limits_{i=1}^{m} \log(s_i) = -\mathbf{y} \log(\sigma)^\top\]

<p>where \(\mathbf{y}\) is the one-hot encoded label vector, i.e.,</p>

<p><code class="language-plaintext highlighter-rouge">loss = -probs[torch.arange(len(ys), device=device), ys].log().mean()</code>.</p>

<p>Note that \(\mathbf{y}\) is a one-hot encoded vector, <code class="language-plaintext highlighter-rouge">ys</code> is not.</p>

<h4 id="backword-pass">Backword Pass:</h4>

<p>For the <em><a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a></em> we need</p>

\[\nabla_{\mathbf{W}} L(\mathbf{y}, \sigma) = \nabla_{\mathbf{o}} L(\mathbf{y}, \sigma) \cdot \nabla_{\mathbf{W}} \mathbf{o}.\]

<p>Here we employ the <em>chain rule</em>.
The sensitivity of cost \(L\) to the input to the softmax layer, \(\mathbf{o}\) is given by a gradient-Jacobian product, each of which we’ve already computed:</p>

\[\begin{align}
    \nabla_{\mathbf{o}} L(\mathbf{y}, \sigma) &amp;= -\nabla_{\mathbf{o}} \mathbf{y} \log(\sigma)^\top \\
    &amp;= -\mathbf{y} \nabla_{\mathbf{o}}\log(\sigma) \\
    &amp;= -\frac{\mathbf{y}}{\sigma} \nabla_{\mathbf{o}} \sigma \\
    &amp;= -\frac{\mathbf{y}}{\sigma} \cdot \mathbf{J}_{\mathbf{o}}(\sigma) \\
    &amp;= -\frac{\mathbf{y}}{\sigma} \cdot \left[ \text{diag}(\sigma) - \sigma^\top \sigma \right] \\
    &amp;= \frac{\mathbf{y}}{\sigma} \sigma^\top \sigma - \frac{\mathbf{y}}{\sigma} \text{diag}(\sigma) \\
    &amp;= \sigma - \mathbf{y}.
\end{align}\]

<p>The \(\log\) and the devision operates component-wise and</p>

\[\text{diag}\left(\sigma\right) =
\begin{bmatrix} 
    \sigma(\mathbf{o})_1 &amp; 0 &amp; \ldots &amp; 0  \\
    0 &amp; \sigma(\mathbf{o})_2 &amp; \ldots &amp; 0 \\
    \ldots &amp; \ldots &amp; \ldots &amp; \ldots \\
    0 &amp; 0 &amp; \ldots &amp; \sigma(\mathbf{o})_m
\end{bmatrix}\]

<p>holds.
We have to apply the <em>chain rule</em> once again to finally get the desired update values for our weight matrix \(\mathbf{W}\):</p>

\[\begin{align}
\nabla_{\mathbf{W}} L(\mathbf{y}, \sigma) &amp;= \nabla_{\mathbf{o}} L(\mathbf{y}, \sigma) \cdot \nabla_{\mathbf{W}} \mathbf{o} \\
&amp;= (\sigma - \mathbf{y}) \cdot \nabla_{\mathbf{W}} (\mathbf{x} \cdot \mathbf{W})\\
&amp;= (\sigma - \mathbf{y}) \cdot \mathbf{x}^{\top}.
\end{align}\]

<p>Given that \(\sigma\) represents probabilities, and \(\mathbf{y}\) contains only zeros except for one instance of 1 at the position of the “correct” probability, the entries of the \(j^\text{th}\) row (\(x_j=1\)) of the gradient is \(p_i\) if the \(i^\text{th}\) probability is deemed “incorrect”, and \((p_i-1)\) otherwise. 
All other entries are zero.
Note also that \(\mathbf{x}\) is also a one-hot encoded vector.
Consequently, if a probability is correct, it gets increased by \(1-p_i\) and decreased by \(p_i-1\) otherwise.
Therefore, probabilities that are more incorrect experience a larger increase or decrease.</p>

<p>We can actually check this result!
Using the following code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># use only 1 data point
</span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># one-hot-encoding
</span><span class="n">xenc</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)).</span><span class="nb">float</span><span class="p">()</span>

<span class="c1"># reinitiate W
</span><span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">logits</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">counts</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>
    
<span class="c1"># backward pass
</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> 
<span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">y</span><span class="p">[</span><span class="n">ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">print</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">))</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">))</span> <span class="c1"># all true
</span></code></pre></div></div>

<h4 id="batching">Batching:</h4>

<p>So far we only considered the math using a single data point \(\mathbf{x}\).
Let us consider a batch of points, i.e.,</p>

\[\mathbf{O} = \mathbf{X}\mathbf{W} = \begin{bmatrix} \mathbf{x}_1 \\ \mathbf{x}_2 \\ \vdots \\ \mathbf{x}_n \end{bmatrix} \mathbf{W}\]

<p>The <em>softmax</em> is still a vector-to-vector transformation, but it’s applied independently to each row of $\mathbf{X}$:</p>

\[\mathbf{S} = \begin{bmatrix} \sigma(\mathbf{o}_1) \\ \sigma(\mathbf{o}_2) \\ \vdots \\ \sigma(\mathbf{o}_n) \end{bmatrix}\]

<p>We can do the exact same steps but I will skip this part.
For the interested reader I refer to <a href="https://mattpetersen.github.io/softmax-with-cross-entropy"></a></p>

<p>Important is that</p>

\[\mathbf{J}_\mathbf{O}(L) = \mathbf{J}_\mathbf{S}(L) \mathbf{J}_\mathbf{O}(S) = \frac{1}{n} \left( \mathbf{S} - \mathbf{Y} \right)\]

<p>and</p>

\[\mathbf{J}_\mathbf{W}(L) = \mathbf{J}_\mathbf{S}(L) \mathbf{J}_\mathbf{O}(S) \mathbf{J}_\mathbf{W}(O) = \frac{1}{n} \left( \mathbf{S} - \mathbf{Y} \right) \mathbf{X}.\]

<p>We can also check this result:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># one-hot-encoding
</span><span class="n">xenc</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)).</span><span class="nb">float</span><span class="p">()</span>

<span class="c1"># reinitiate W
</span><span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> 

<span class="n">logits</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">counts</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>
    
<span class="c1"># backward pass
</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> 
<span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">y</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span><span class="n">ys</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">print</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">))</span> <span class="c1"># same
</span><span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">xenc</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">probs</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">)))</span> <span class="c1"># true
</span></code></pre></div></div>

<h3 id="further-considerations">Further Considerations</h3>

<p>Now, the natural question is: what is the best possible performance we could achieve? 
The answer is that we should aim to match the performance of the <em>Markov chain</em>. 
Indeed, as the process continues, we should expect that the matrix <code class="language-plaintext highlighter-rouge">W</code> will gradually converge towards <code class="language-plaintext highlighter-rouge">P</code>.</p>

<p>Moreover, we should not anticipate surpassing the results achieved by our <em>Markov chain</em> even if we deepen our network, that is, by introducing some <em>hidden layers</em>.
A very good example of useful informations are described in <a class="citation" href="#johnson:2017">(Johnson, 2017)</a>, I discussed in <a href="/Pages/2023/04/02/musical-interrogation-I.html">Part I</a> of this series.
For instance, Johnson adds (compare his interesting <a href="https://www.danieldjohnson.com/2015/08/03/composing-music-with-recurrent-neural-networks/">Blog post</a>)</p>

<ul>
  <li><strong>Positional:</strong> note within the score (that is what we use)</li>
  <li><strong>Pitchclass:</strong> one of the twelve classes</li>
  <li><strong>Previous vicinity:</strong> surrounding notes where played or aticulated last timestep (only useful for polyphonic music)</li>
  <li><strong>Previous context:</strong> the amount of C’s, A’s and so on are played the last timestep (only useful for polyphonic music)</li>
  <li><strong>Beat:</strong> a binary representation of position within the measure</li>
</ul>

<p>However, our expectations may shift if we modify the input, referring to the data that the network processes. 
That being said, we could enhance the training duration.
For instance, introducing a <em>hidden layer</em> results in a loss of <code class="language-plaintext highlighter-rouge">2.693</code> after 2000 epochs.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">W1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">),</span> 
                 <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">stoi</span><span class="p">)),</span> 
                 <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">2_000</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># forward pass
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">xenc</span> <span class="o">@</span> <span class="n">W1</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">W2</span>
    <span class="n">odds</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">exp</span><span class="p">()</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">odds</span> <span class="o">/</span> <span class="n">odds</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">probs</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">ys</span><span class="p">].</span><span class="n">log</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'epoch </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    
    <span class="c1"># backward pass
</span>    <span class="n">W1</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># set gradients to zero
</span>    <span class="n">W2</span><span class="p">.</span><span class="n">grad</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># set gradients to zero
</span>    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="c1"># update
</span>    <span class="n">W1</span><span class="p">.</span><span class="n">data</span> <span class="o">+=</span> <span class="o">-</span><span class="mf">10.0</span> <span class="o">*</span> <span class="n">W1</span><span class="p">.</span><span class="n">grad</span>
    <span class="n">W2</span><span class="p">.</span><span class="n">data</span> <span class="o">+=</span> <span class="o">-</span><span class="mf">10.0</span> <span class="o">*</span> <span class="n">W2</span><span class="p">.</span><span class="n">grad</span>
</code></pre></div></div>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="oore:2018">Oore, S., Simon, I., Dieleman, S., Eck, D., &amp; Simonyan, K. (2018). <i>This time with feeling: Learning expressive musical performance</i>.</span></li>
<li><span id="johnson:2017">Johnson, D. D. (2017). Generating polyphonic music using tied parallel networks. <i>EvoMUSART</i>.</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Music" /><category term="ML" /><category term="FFN" /><category term="MC" /><summary type="html"><![CDATA[The code shown here can be found in the following GitHub repository. In the second installment of this series, I introduce an initial and arguably the most basic method to generate monophonic melodies. This consists of two approaches: (1) A first-order Markov chain (MC) and (2) a feedforward neural network (FNN)]]></summary></entry><entry><title type="html">Replacing Code with ML Models</title><link href="https://bzoennchen.github.io/Pages/2023/04/23/wekinator.html" rel="alternate" type="text/html" title="Replacing Code with ML Models" /><published>2023-04-23T00:00:00+02:00</published><updated>2023-04-23T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/04/23/wekinator</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/04/23/wekinator.html"><![CDATA[<p>This blog post aims to explore how <em>machine learning</em> can empower creative practitioners to bring to life projects that traditionally demanded significant technical expertise, such as programming skills.
To make my case immediately understandable, I will provide a specific example.
However, it’s worth noting that this is just one of countless possible instances.</p>

<p>You can find all the necessary code in my GitHub repo: <a href="https://github.com/BZoennchen/algorithmic-compositions/tree/main/wekinator/firework-example">link</a>.</p>

<p>The example is based on the <a href="http://www.wekinator.org/">Wekinator</a>, which is a powerful, free, and open-source software designed to simplify the process of using <em>machine learning models</em>.
With its user-friendly interface, anyone can easily build new musical instruments, gestural game controllers, computer vision, computer listening systems, and much more. 
Developed by <a href="http://www.doc.gold.ac.uk/~mas01rf/">Rebecca Fiebrink</a>, the software aims to make digital systems more accessible to artists and musicians. 
Although Wekinator’s initial release (version 1.0) dates back to 2009, the software remains relevant today and has aged gracefully.</p>

<p>In her article <a class="citation" href="#fiebrink:2019">(Fiebrink, 2019)</a>, Fiebrink elaborates on her machine learning education practices for creative practitioners and highlights the benefits of using <a href="http://www.wekinator.org/">Wekinator</a>. 
More recently, she has been working on a new tool called <a href="https://interactml.com/">InteractML</a>, which is a more advanced tool for interactive machine learning via visual scripting with <a href="https://unity.com/de">Unity</a> <a class="citation" href="#clarice:2021">(Hilton et al., 2021)</a>. 
<a href="https://interactml.com/">InteractML</a> is a fascinating project that I plan to explore further at a later time. 
It is worth noting that the project is currently in alpha release and may only have limited documentation available.</p>

<p>One of the key advantages of the <a href="http://www.wekinator.org/">Wekinator</a> is its ease of use, making it accessible to a wide range of users.
The software’s versatility is due to its ability to <a href="https://en.wikipedia.org/wiki/Open_Sound_Control">open sound control (OSC)</a> messages, which are supported by numerous applications, especially in the artistic domain.
If other systems can communicate via OSC, they can be integrated (via network) into the larger system. 
For instance, most digital audio workstations (DAWs), <a href="https://processing.org/">Processing</a> (a renowned creative coding environment), <a href="https://derivative.ca/">TouchDesigner</a>, <a href="https://cycling74.com/products/max">Max/MSP</a>, <a href="https://puredata.info/">PureData</a>, <a href="https://supercollider.github.io/">SuperCollider</a> and APIs for popular programming languages support OSC.</p>

<p>To demonstrate the potential of the <a href="http://www.wekinator.org/">Wekinator</a>, I will be using <a href="https://processing.org/">Processing</a> and <a href="https://supercollider.github.io/">SuperCollider</a>, both of which are also free and open-source tools. 
<a href="https://supercollider.github.io/">SuperCollider</a> will be used to generate sound, while <a href="https://processing.org/">Processing</a> will capture human motion. 
The objective is not to showcase elaborate gesture recognition but to provide an overview of the Wekinator’s fundamental workings.</p>

<p>More than just discussing the <a href="http://www.wekinator.org/">Wekinator</a>, my aim is to provide readers with an understanding of how machine learning can supplant traditional programming, enabling non-experts to utilize techniques that were previously inaccessible to them.</p>

<p>We will observe how machine learning can replace coding, albeit with some coding required.
However, the coding required is specific to the task of sending and receiving OSC messages, and the tools utilized, i.e., <a href="https://supercollider.github.io/">SuperCollider</a> and <a href="https://processing.org/">Processing</a> which are both programming environments.
Other tools exist, which allow for sending OSC messages without any coding, and there are tools that produce sound without programming.</p>

<p>The following video demonstrates the final result and all the steps required.</p>

<div class="embed-container">
<iframe src="https://www.youtube.com/embed/lDkeOTQU2Y8" width="800" height="480" frameborder="0" allowfullscreen="true">
</iframe>
</div>

<h2 id="problem-description">Problem Description</h2>

<p>Digital synthesizers are synthetic instruments that generate sound by outputting a stream of floating point numbers.
These synthesizers typically have numerous parameters, such as frequency (pitch), cutoff frequency of a low-pass filter, frequency of the carrier, and several others.
Often these parameters are not <em>interpretable</em>, meaning there is no straightforward connection between a parameter and the sound a synth generates.
Instead, altering multiple parameters concurrently leads to the desired outcome.
In mathematics, we refer to these parameters as residing in a high-dimensional space.</p>

<p>Let’s consider the following scenario: We have a dancer in a rectangular area, such as a room, and we wish to modify the sound generated by a synth based on the dancer’s 2D position.
We aim to alter the synth’s parameters while it is playing (modulation) in response to the dancer’s movements. However, the changes in sound must be smooth and non-random.</p>

<p>Unfortunately, a significant problem arises in this situation. 
The number of parameters exceeds the number of positional values.
We only have two coordinates to work with, and establishing a one-to-one mapping between these coordinates and parameters is not feasible.
We want to avoid merely selecting two parameters and modifying them according to the dancer’s \(x\) and \(y\) coordinates.</p>

<p>In mathematical terms, we are looking for a function that receives \(2\) values (\(x\) and \(y\)) and outputs \(n\) values (one for each parameter), where \(n &gt; 2\).
We want a function</p>

\[f : \mathbb{R}^2 \rightarrow \mathbb{R}^n.\]

<p>Additionally, it is necessary for \(f\) to be smooth and meet our musical preferences. 
As \(f\) maps a lower-dimensional space to a higher-dimensional space and we require a seamless transition, we search for a two-dimensional <em>surface</em> in an \(n\)-dimensional space. 
As the dancer moves in the \(x\) and \(y\) directions, \(f\) translates this motion to a movement on the two-dimensional surface in the \(n\)-dimensional space.</p>

<p>If we have only one coordinate and three parameters, \(f\) represents a curve in the three-dimensional space.
In this case, we can draw it.
Compare Fig. 1.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/3d-curve.png" alt="2-D manifold" />
<div style="display:block; margin-left:auto; margin-right:auto; width:80%;">Figure 1: Sample points and fitted graph of a curve in a three-dimensional space. The length of the curve represents the dancer's single coordinate (let's say x). A point (X,Y,Z) on the curve represents three parameter values.</div>
</div>
<p><br /></p>

<p>This is a complex challenge, and several questions arise: How does \(f\) look like? 
How can we implement it?</p>

<h3 id="reasoning-about-the-world">Reasoning about the World</h3>

<p>Before the advent of machine learning, we would have addressed this problem using the “traditional way” of abstract reasoning and programming to implement the function \(f\) directly via code.
This approach involves roughly six steps:</p>

<ol>
  <li>observer and analyse the system</li>
  <li>construct a falsifiable mathematical model (which is an imperfect generalization)</li>
  <li>implement a numerical model via code</li>
  <li>calibrate the model</li>
  <li>test your assumption via observation until the model approximates reality adequately</li>
  <li>find unobserved phenomena, which the model implies, in the real world</li>
</ol>

<p>Newton’s discoveries serve as a classic example, where he observed reality and reasoned about it, generating laws that are incorrect but sufficiently accurate to travel to the moon. 
He established formulas such as</p>

\[F = m \cdot a,\]

<p>which are falsifiable via experiments.
With these formulas one can predict unknown phenomena that should appear if the model is reliable.</p>

<p>In our case, we would have conducted a comprehensive analysis of the synth to establish how its parameters interact with one another.
This approach would have required a wealth of knowledge across diverse domains such as programming, signal processing, and mathematics.
Furthermore, to achieve our desired sound, we would have needed to understand the impact of parameter changes on various aspects of the sound, such as pitch and timbre.</p>

<p>In essence, we would have aimed to create a model of the synth “world” to enable us to reason about its structures and rules.
We would have then written code to manipulate the \(n\) parameters concurrently, relative to the dancer’s position.</p>

<p>While I value the traditional approach for its ability to provide insights into actual and imaginative structures, it is not the optimal solution for our specific scenario. I believe that creative practitioners do not necessarily avoid analytical work but tend to focus on creation, thereby enabling a more tangible understanding of the problem. I welcome this approach, particularly in the field of machine learning.
In contrast, the traditional approach can be challenging and less accessible, particularly in achieving our artistic objectives.</p>

<h3 id="modelling-without-reasoning">Modelling without Reasoning</h3>

<p>In <em>machine learning</em>, the focus shifts to a <em>data-driven approach</em>.
Rather than constructing a model by hand through reasoning about the world, we enable machines to learn the model by providing them with data, i.e., observations.</p>

<p>In extreme cases when observation is the model, we cannot provide outputs of unobserved inputs.
Therefore, like models constructed manually, machine learning models are an imperfect abstraction of the data on which they are trained.
This is the fundamental idea behind machine learning, albeit an oversimplification.</p>

<p>In our scenario, we replace manual modeling with machine learning by defining what we want and letting the machine learning models provided by the <a href="http://www.wekinator.org/">Wekinator</a> figure out how to achieve it.
We present an algorithm $A$ with examples $D$ that represent our requirements and ask it to “program” a function \(f\) that fulfills our needs.</p>

<p><em>Machine learning</em> involves learning \(f\) from data \(D\) using algorithm \(A\), where \(A\) is essentially just another function that produces functions:</p>

\[A(D) = f\]

<p>The <a href="http://www.wekinator.org/">Wekinator</a> allows us to choose algorithm \(A\) from a list of algorithms and provides a graphical user interface (GUI) for recording \(D\) and feeding it into \(A\) to compute \(f\).
The algorithm \(A\) is predetermined, and \(f\) will be computed.
As a result, we need to provide data/observation \(D\) by recording it, so let’s get started!</p>

<p><strong>Disclaimer:</strong>
Utilizing <em>machine learning</em> does not imply that we cease rationalizing about the world.
However, I selected this thought-provoking title to accentuate the contrast in tendencies.
Moreover, the effectiveness and characteristics of <em>machine learning models</em> are significantly influenced by the quality of the observed data and the choice of algorithm.
Given that our challenge involves a <em>regression task</em>, we will employ a <em>feed-forward neural network</em>.</p>

<h2 id="realization">Realization</h2>

<p>In the following, we have a lot to set up since every part of the system is digital and our own creation.
However, do not worry if you do not understand the <a href="https://supercollider.github.io/">SuperCollider</a> or <a href="https://processing.org/">Processing</a> part.
It is more important to understand the principle of OSC communication and the <a href="http://www.wekinator.org/">Wekinator</a>.
If you are interested in <a href="https://supercollider.github.io/">SuperCollider</a> or <a href="https://processing.org/">Processing</a> I can highly recommend checking them out.</p>

<h3 id="creating-a-new-instrument">Creating a new Instrument</h3>

<p>First, we need an actual synthesizer that produces sound.
I use a synth that randomly produces a short resonating impulse that gets reflected.
I want to go into only a few details about the inner workings of the synth.
It creates a sound similar to a firework in a city perceived inside a room.</p>

<p>The synth has 6 parameters which are, in this case, explainable:</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">\densityleft</code> controls the number of impulses in the left speaker.</li>
  <li><code class="language-plaintext highlighter-rouge">\densityright</code> controls the number of impulses in the right speaker.</li>
  <li><code class="language-plaintext highlighter-rouge">\freq</code> controls the pitch of the impulse response (i.e., the sound). Higher frequency increases the pitch. (For <code class="language-plaintext highlighter-rouge">Ringz</code> it is the frequency at which the impulse resonates.)</li>
  <li><code class="language-plaintext highlighter-rouge">\cutofffreq</code> controls the cutoff frequency of the lowpass filter. Lower values make the sound more doll.</li>
  <li><code class="language-plaintext highlighter-rouge">\decaytime</code> controls the time it takes for the impulses to decay, influencing the resonance.</li>
  <li><code class="language-plaintext highlighter-rouge">\amp</code> controls the signal’s amplitude, i.e., the volume.</li>
</ol>

<p><code class="language-plaintext highlighter-rouge">Dust</code> outputs the impulse such that <code class="language-plaintext highlighter-rouge">Ringz</code> resonates.
The resulting signal gets reflected by <code class="language-plaintext highlighter-rouge">FreeVerb</code> which introduces reverberation.</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">SynthDef</span><span class="p">(</span><span class="sx">\fireworks</span><span class="p">,{</span>
    <span class="k">var</span> <span class="n">sig</span><span class="p">;</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="nc">Dust</span><span class="p">.</span><span class="n">ar</span><span class="p">([</span><span class="sx">\densityleft</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">3</span><span class="p">),</span> <span class="sx">\densityright</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">3</span><span class="p">)</span><span class="mf">-0.5</span><span class="p">]);</span>
	<span class="n">sig</span> <span class="o">=</span> <span class="nc">Ringz</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span>
		<span class="n">sig</span><span class="p">,</span> 
		<span class="nl">freq:</span> <span class="sx">\freq</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">300</span><span class="p">),</span> 
		<span class="nl">decaytime:</span> <span class="sx">\decaytime</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span> <span class="o">*</span> <span class="sx">\amp</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">0.55</span><span class="p">);</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="nc">FreeVerb</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">);</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="nc">LPF</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span><span class="nl">in:</span> <span class="n">sig</span><span class="p">,</span> <span class="nl">freq:</span> <span class="sx">\cutofffreq</span><span class="p">.</span><span class="n">kr</span><span class="p">(</span><span class="mf">21000</span><span class="p">));</span>
    <span class="nc">Out</span><span class="p">.</span><span class="n">ar</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="n">sig</span><span class="p">);</span>
<span class="p">}).</span><span class="n">add</span><span class="p">;</span>
<span class="p">)</span>
</code></pre></div></div>

<p>We can play the synth and manipulate its parameters on the fly.
Let’s listen but be warned since the amplitude during this example will change.</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="vg">~fireworks</span> <span class="o">=</span> <span class="nc">Synth</span><span class="p">(</span><span class="sx">\fireworks</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\amp</span><span class="p">,</span> <span class="mf">1</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\densityleft</span><span class="p">,</span> <span class="mf">10</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\freq</span><span class="p">,</span> <span class="mf">400</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\decaytime</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">);</span>
<span class="vg">~fireworks</span><span class="p">.</span><span class="n">free</span><span class="p">();</span>
</code></pre></div></div>

<audio controls="">
  <source src="/Pages/assets/audio/fireworks.mp3" type="audio/mp3" />
  Your browser does not support the audio element.
</audio>

<p>Ok cool, we can play sound.</p>

<h3 id="simulation-of-the-dancer">Simulation of the Dancer</h3>

<p>Next, let’s envision a dancer gracefully moving across the room. 
While I am not a dancer, nor do I possess sensors to measure a dancer’s position, we can simulate this scenario using <a href="https://processing.org/">Processing</a>. 
It’s worth mentioning that we could achieve the same result with SuperCollider, as it also features GUI elements. 
However, I’d like to demonstrate how we can effortlessly integrate multiple systems.</p>

<p>You can download the <a href="https://processing.org/">Processing</a> example at this <a href="http://www.doc.gold.ac.uk/~mas01rf/WekinatorDownloads/wekinator_examples/all_source_zips/Simple_Mouse_DraggedObject_2Inputs.zip">link</a>. 
I will provide the code below, but please don’t be intimidated. 
It simply consists of a draggable green square, accompanied by informative log text displayed on a black window, and an OSC sender. 
Dragging the green square simulates the dancer’s movement, while the application continuously transmits the rectangle’s central position over the network.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/simple_mouse_drag.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 2: Running Processing sketch.</div>
</div>
<p><br /></p>

<p>If you start the sketch in <a href="https://processing.org/">Processing</a>, you should see the window shown in Fig. 2.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**
* REALLY simple processing sketch that sends 
* mouse x and y position of box to wekinator
* This sends 2 input values to port 6448 using message /wek/inputs
* Adapated from https://processing.org/examples/mousefunctions.html 
* by Rebecca Fiebrink
**/</span>

<span class="kn">import</span> <span class="nn">oscP5.*</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">netP5.*</span><span class="o">;</span>

<span class="nc">OscP5</span> <span class="n">oscP5</span><span class="o">;</span>
<span class="nc">NetAddress</span> <span class="n">dest</span><span class="o">;</span>
<span class="nc">PFont</span> <span class="n">f</span><span class="o">;</span>

<span class="kt">float</span> <span class="n">bx</span><span class="o">;</span>
<span class="kt">float</span> <span class="n">by</span><span class="o">;</span>
<span class="kt">int</span> <span class="n">boxSize</span> <span class="o">=</span> <span class="mi">30</span><span class="o">;</span>
<span class="kt">boolean</span> <span class="n">overBox</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
<span class="kt">boolean</span> <span class="n">locked</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
<span class="kt">float</span> <span class="n">xOffset</span> <span class="o">=</span> <span class="mf">0.0</span><span class="o">;</span> 
<span class="kt">float</span> <span class="n">yOffset</span> <span class="o">=</span> <span class="mf">0.0</span><span class="o">;</span>

<span class="kt">void</span> <span class="nf">setup</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">createFont</span><span class="o">(</span><span class="s">"Courier"</span><span class="o">,</span> <span class="mi">15</span><span class="o">);</span>
    <span class="n">textFont</span><span class="o">(</span><span class="n">f</span><span class="o">);</span>

    <span class="n">size</span><span class="o">(</span><span class="mi">640</span><span class="o">,</span> <span class="mi">480</span><span class="o">,</span> <span class="no">P2D</span><span class="o">);</span>
    <span class="n">noStroke</span><span class="o">();</span>
    <span class="n">smooth</span><span class="o">();</span>
    
    <span class="n">bx</span> <span class="o">=</span> <span class="n">width</span><span class="o">/</span><span class="mf">2.0</span><span class="o">;</span>
    <span class="n">by</span> <span class="o">=</span> <span class="n">height</span><span class="o">/</span><span class="mf">2.0</span><span class="o">;</span>
    <span class="n">rectMode</span><span class="o">(</span><span class="no">RADIUS</span><span class="o">);</span>  
    
    <span class="cm">/* start oscP5, listening for incoming messages at port 12000 */</span>
    <span class="n">oscP5</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscP5</span><span class="o">(</span><span class="k">this</span><span class="o">,</span><span class="mi">9000</span><span class="o">);</span>
    <span class="n">dest</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">NetAddress</span><span class="o">(</span><span class="s">"127.0.0.1"</span><span class="o">,</span><span class="mi">6449</span><span class="o">);</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">draw</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">background</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span>
    <span class="n">fill</span><span class="o">(</span><span class="mi">255</span><span class="o">);</span>
    <span class="n">text</span><span class="o">(</span><span class="s">"x="</span> <span class="o">+</span> <span class="n">bx</span> <span class="o">+</span> <span class="s">", y="</span> <span class="o">+</span> <span class="n">by</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">80</span><span class="o">);</span>
    
    <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">200</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>

    <span class="c1">// Test if the cursor is over the box </span>
    <span class="k">if</span> <span class="o">(</span><span class="n">mouseX</span> <span class="o">&gt;</span> <span class="n">bx</span><span class="o">-</span><span class="n">boxSize</span> <span class="o">&amp;&amp;</span> <span class="n">mouseX</span> <span class="o">&lt;</span> <span class="n">bx</span><span class="o">+</span><span class="n">boxSize</span> <span class="o">&amp;&amp;</span> 
        <span class="n">mouseY</span> <span class="o">&gt;</span> <span class="n">by</span><span class="o">-</span><span class="n">boxSize</span> <span class="o">&amp;&amp;</span> <span class="n">mouseY</span> <span class="o">&lt;</span> <span class="n">by</span><span class="o">+</span><span class="n">boxSize</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">overBox</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span>  
        <span class="k">if</span><span class="o">(!</span><span class="n">locked</span><span class="o">)</span> <span class="o">{</span> 
        <span class="n">stroke</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span> 
        <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
        <span class="o">}</span> 
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="n">stroke</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
        <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
        <span class="n">overBox</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
    <span class="o">}</span>
    
    <span class="c1">// Draw the box</span>
    <span class="n">rect</span><span class="o">(</span><span class="n">bx</span><span class="o">,</span> <span class="n">by</span><span class="o">,</span> <span class="n">boxSize</span><span class="o">,</span> <span class="n">boxSize</span><span class="o">);</span>
    
    <span class="c1">//Send the OSC message with box current position</span>
    <span class="n">sendOsc</span><span class="o">();</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">mousePressed</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">if</span><span class="o">(</span><span class="n">overBox</span><span class="o">)</span> <span class="o">{</span> 
        <span class="n">locked</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span> 
        <span class="n">fill</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">255</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="n">locked</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="n">xOffset</span> <span class="o">=</span> <span class="n">mouseX</span><span class="o">-</span><span class="n">bx</span><span class="o">;</span> 
    <span class="n">yOffset</span> <span class="o">=</span> <span class="n">mouseY</span><span class="o">-</span><span class="n">by</span><span class="o">;</span> 
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">mouseDragged</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">if</span><span class="o">(</span><span class="n">locked</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">bx</span> <span class="o">=</span> <span class="n">mouseX</span><span class="o">-</span><span class="n">xOffset</span><span class="o">;</span> 
        <span class="n">by</span> <span class="o">=</span> <span class="n">mouseY</span><span class="o">-</span><span class="n">yOffset</span><span class="o">;</span> 
    <span class="o">}</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">mouseReleased</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">locked</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
<span class="o">}</span>

<span class="kt">void</span> <span class="nf">sendOsc</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">OscMessage</span> <span class="n">msg</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscMessage</span><span class="o">(</span><span class="s">"/wek/inputs"</span><span class="o">);</span>
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">bx</span><span class="o">);</span> 
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">by</span><span class="o">);</span>
    <span class="n">oscP5</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">msg</span><span class="o">,</span> <span class="n">dest</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>When we start the Processing sketch, it shows a green square inside a black window.
The window represents our room, and the green square the dancer.
You can drag the dancer around.</p>

<h3 id="osc-communication">OSC Communication</h3>

<p>The only crucial part of the <a href="https://processing.org/">Processing</a> sketch’s code is the transmission of OSC messages..</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">oscP5</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscP5</span><span class="o">(</span><span class="k">this</span><span class="o">,</span><span class="mi">9000</span><span class="o">);</span>
<span class="n">dest</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">NetAddress</span><span class="o">(</span><span class="s">"127.0.0.1"</span><span class="o">,</span><span class="mi">6448</span><span class="o">);</span>
</code></pre></div></div>

<p>These three lines of code enable the sketch to listen for OSC messages over the network using the IP address <code class="language-plaintext highlighter-rouge">"127.0.0.1"</code>, which represents the local IP address. 
This means that the sketch listens for messages originating from your device. 
It receives messages on port <code class="language-plaintext highlighter-rouge">9000</code> and transmits them to port <code class="language-plaintext highlighter-rouge">6448</code>. 
The listening port is inconsequential, as the dancer never responds to incoming signals. 
The IP address and sending port are crucial because they must correspond with the numbers we will employ in the <a href="http://www.wekinator.org/">Wekinator</a>.</p>

<p>The following code</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">sendOsc</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">OscMessage</span> <span class="n">msg</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OscMessage</span><span class="o">(</span><span class="s">"/wek/inputs"</span><span class="o">);</span>
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">mouseX</span><span class="o">);</span> 
    <span class="n">msg</span><span class="o">.</span><span class="na">add</span><span class="o">((</span><span class="kt">float</span><span class="o">)</span><span class="n">mouseY</span><span class="o">);</span>
    <span class="n">oscP5</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">msg</span><span class="o">,</span> <span class="n">dest</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>sends the coordinates \(x\) and \(y\) of the mouse (with respect to the window) to the port <code class="language-plaintext highlighter-rouge">6448</code> and the path <code class="language-plaintext highlighter-rouge">'/wek/inputs'</code>. 
OSC uses these paths such that it is possible to differentiate different types of messages that got sent to some port.</p>

<p>Now we have to set up OSC communication of our sound generating system, i.e. <a href="https://supercollider.github.io/">SuperCollider</a>.
Let us first listen to port <code class="language-plaintext highlighter-rouge">6448</code>and path <code class="language-plaintext highlighter-rouge">'/wek/inputs'</code> and let’s just print the raw data we perceive, i.e., the \(x\) and \(y\) values of our dancer (the green square).</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">OSCdef</span><span class="p">(</span>
    <span class="sx">\getCoords</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="k">arg</span> <span class="n">val</span><span class="p">;</span> <span class="n">val</span><span class="p">.</span><span class="n">postln</span><span class="p">;</span>
    <span class="p">},</span>
    <span class="sx">'/wek/inputs'</span><span class="p">,</span>
    <span class="nl">recvPort:</span> <span class="mf">6448</span>
<span class="p">);</span>
<span class="p">)</span>
</code></pre></div></div>

<p>By executing this line in <a href="https://supercollider.github.io/">SuperCollider</a> while the <a href="https://processing.org/">Processing</a> sketch is running, you should see OSC messages on the post window.
These messages look like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[ /wek/inputs, 248.0, 185.0 ]
</code></pre></div></div>

<p>Now, let’s take it a step further and modify two synth parameters based on these values. 
The following code maps \(x\) and \(y\) to a suitable range. 
While \(x\) ranges from 0 to 650 and \(y\) from 0 to 460, we aim to obtain values between 0.1 and 20.</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">OSCdef</span><span class="p">(</span>
    <span class="sx">\getCoords</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="k">arg</span> <span class="n">val</span><span class="p">;</span> <span class="k">var</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="mf">1</span><span class="p">];</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="mf">2</span><span class="p">];</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\leftdensity</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">650</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\rightdensity</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">460</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
    <span class="p">},</span>
    <span class="sx">'/wek/inputs'</span><span class="p">,</span>
    <span class="nl">recvPort:</span> <span class="mf">6448</span>
<span class="p">);</span>
<span class="p">)</span>
</code></pre></div></div>

<p>The impact of this code should be noticeable in the audio output. When the dancer is positioned at the top left, fewer impulses are produced.
If situated at the bottom right, impulses emit from both speakers, while being at the bottom left results in only the right speaker activating.
This effect may not seem extraordinary, as our function \(f\) is quite elementary, involving a linear mapping from one interval to another.</p>

<h3 id="the-machine-in-the-middle">The Machine in the Middle</h3>

<p>We now introduce the <a href="http://www.wekinator.org/">Wekinator</a> in the middle of the communication.
That is, the dancer sends their position to the <a href="http://www.wekinator.org/">Wekinator</a>, and <a href="https://supercollider.github.io/">SuperCollider</a> listens to the messages from the <a href="http://www.wekinator.org/">Wekinator</a> and changes the values of the synth accordingly.
The <a href="http://www.wekinator.org/">Wekinator</a> translates positions into synth parameters, and it realizes the function \(f\).
The 6 output signals</p>

\[(v_1, \ldots, v_6) = f(x,y)\]

<p>are sent to <a href="https://supercollider.github.io/">SuperCollider</a>.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/wekinator.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 3: Overview of all the connected parts.</div>
</div>
<p><br /></p>

<p>First, we need to modify the port <a href="https://supercollider.github.io/">SuperCollider</a> listens to by changing the line from <code class="language-plaintext highlighter-rouge">recvPort: 6448</code> to <code class="language-plaintext highlighter-rouge">recvPort: 7448</code>.
Additionally, we should update the path to <code class="language-plaintext highlighter-rouge">'/wek/outputs'</code> as a reminder that we are receiving output signals from Wekinator.</p>

<p>Secondly, we must utilize the values we receive. Wekinator consistently sends a value between 0 and 1 for each dimension. 
As a result, we need to map the interval [0;1] to appropriate synth values.
This step is critical and necessitates some understanding of the synth. 
I employ the following mapping (note that we skip <code class="language-plaintext highlighter-rouge">val[0]</code> since it represents the OSC path):</p>

<div class="language-supercollider highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span>
<span class="nc">OSCdef</span><span class="p">(</span>
    <span class="sx">\getCoords</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="k">arg</span> <span class="n">val</span><span class="p">;</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\densityleft</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">1</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\densityright</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">2</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">20</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\freq</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">3</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">100</span><span class="p">,</span> <span class="mf">700</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\amp</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">4</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">0</span><span class="p">,</span> <span class="mf">2</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\decaytime</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">5</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">));</span>
        <span class="vg">~fireworks</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="sx">\cutofffreq</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mf">6</span><span class="p">].</span><span class="n">linlin</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">,</span> <span class="mf">200</span><span class="p">,</span> <span class="mf">20000</span><span class="p">));</span>
    <span class="p">},</span>
    <span class="sx">'/wek/outputs'</span><span class="p">,</span>
    <span class="nl">recvPort:</span> <span class="mf">7448</span>
<span class="p">);</span>
<span class="p">)</span>
</code></pre></div></div>

<p><strong>If you use <a href="https://supercollider.github.io/">SuperCollider</a> be careful with your choices and protect your ears</strong> since it will try to use even unreasonable values like an amplitude of 10 or higher.</p>

<p>Now we start the <a href="http://www.wekinator.org/">Wekinator</a>.
First, we have to specify the port for the input signals of \(f\), i.e., the dancer’s position.
This is equal to <code class="language-plaintext highlighter-rouge">6448</code>, and the OSC path is <code class="language-plaintext highlighter-rouge">'/wek/inputs'</code>.
Then we have to specify the port of the output signal \(f(x,y)\), i.e., the port used in SuperCollider, which is <code class="language-plaintext highlighter-rouge">7448</code> furthermore, we specify a path <code class="language-plaintext highlighter-rouge">'/wek/outputs'</code> such that we do not confuse input and output.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/wekinator-screen-started.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 4: Wekinator after it has started.</div>
</div>
<p><br /></p>

<p>Furthermore, we have to tell the <a href="http://www.wekinator.org/">Wekinator</a> about the number of inputs and outputs, i.e., 2 and 6, respectively.
After everything is set up, we can click on <code class="language-plaintext highlighter-rouge">Start Listening</code>.
Then we can click <code class="language-plaintext highlighter-rouge">Next</code>.</p>

<p>Now you will see the following screen.
In the top left <code class="language-plaintext highlighter-rouge">OSC In</code> should be green, since the <a href="https://processing.org/">Processing</a> sketch is sending messages.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/wekinator-screen.png" alt="Runnig Processing sketch" />
<div style="display: table;margin: 0 auto;">Figure 5: Wekinator before training.</div>
</div>
<p><br /></p>

<p>If this is not the case, you either forgot to click <code class="language-plaintext highlighter-rouge">Start Listening</code>, or the port is already used. 
In that case, change the port in the <a href="http://www.wekinator.org/">Wekinator</a> as well in your <a href="https://processing.org/">Processing</a> sketch and restart the sketch.
You also should see 6 sliders.
If you manipulate these sliders, <code class="language-plaintext highlighter-rouge">OSC Out</code> should turn green, indicating that we are sending OSC messages to <a href="https://supercollider.github.io/">SuperCollider</a>.</p>

<p>Furthermore, the sound should change accordingly.
Make sure your amplitude is not zero.
Now you can play around with the sliders or press the <code class="language-plaintext highlighter-rouge">random</code> button until you hear something you like.
Of course, you have to remember which slider represents which parameter.</p>

<p>To connect the sound to the dancer’s position, we have to</p>

<ol>
  <li>record samples, i.e., construct the data set \(D\)</li>
  <li>train the model, i.e. compute \(f = A(D)\).</li>
</ol>

<p>To construct \(D\) we need multiple tuples</p>

\[(\text{input}, \text{output}) = ((x,y), (v_1, \ldots, v_6)).\]

<p>First, we move the square to a desired position and choose a set of desired parameters \((v_1, \ldots, v_6)\).
Next, we click <code class="language-plaintext highlighter-rouge">Start Recording</code>, and after a few seconds, we press <code class="language-plaintext highlighter-rouge">Stop Recording</code>.
In doing so, we generate portions of the data \(D\).
We repeat this step multiple times until we have accumulated sufficient data \(D\).</p>

<p>Once completed, we press <code class="language-plaintext highlighter-rouge">Train</code> to compute</p>

\[A(D) = f.\]

<p>This process should only take a few seconds.</p>

<p>Finally, we can utilize \(f\) by clicking <code class="language-plaintext highlighter-rouge">Run</code>.
At this point, both <code class="language-plaintext highlighter-rouge">OSC In</code> and <code class="language-plaintext highlighter-rouge">OSC Out</code> indicators should be green, and as you move the square around, the sound should change accordingly. 
Moreover, all parameters (assuming they were all manipulated during recording) should transition smoothly.</p>

<h3 id="different-algorithms">Different Algorithms</h3>

<p>Keep in mind that we did not specify any algorithm A.
By default, <a href="http://www.wekinator.org/">Wekinator</a> employs a <em>feed-forward neural network</em> and assumes a <em>regression task</em>.
This means that the output \(f(x,y)\) is continuous and does not represent an element within a finite set of classes.</p>

<p>You can choose algorithms by modifying the <code class="language-plaintext highlighter-rouge">Type</code> setting, as shown in Fig. 4. 
This selection includes classification algorithms. 
For instance, if you wish to establish a mapping between a gesture captured by your webcam and a specific sample, this would be a classification task. Another example would be classifying the type of instrument being played.</p>

<p><a href="http://www.wekinator.org/">Wekinator</a> has some limitations regarding the range of algorithms it offers, as the user lacks control over the model architecture and the model’s hyperparameters.</p>

<h2 id="summary">Summary</h2>

<p><a href="http://www.wekinator.org/">Wekinator</a> is an outstanding tool that makes certain aspects of machine learning accessible.
Its compatibility with OSC allows for seamless integration into various systems. It is an ideal fit for quick experimentation and serves as a valuable tool for teaching creative practitioners the fundamentals of machine learning on an intuitive level.</p>

<p>However, it does feel somewhat dated and experimental, offering no control over the hyperparameters of its built-in models.
Additionally, it does not utilize the latest software libraries, such as <code class="language-plaintext highlighter-rouge">PyTorch</code> or <code class="language-plaintext highlighter-rouge">TensorFlow</code>.
Being a Java application, it supports all operating systems, but <code class="language-plaintext highlighter-rouge">Java</code> is a relatively uncommon programming language in the field of machine learning.</p>

<p>The concept behind <a href="http://www.wekinator.org/">Wekinator</a> is exceptional, and it shouldn’t be too challenging to create a similar tool in Python, enabling artists or developers to integrate their own PyTorch or TensorFlow models. It supports the goal of making machine learning accessible to everyone and provides valuable insights into the features that ML tools for non-experts should offer. Perhaps we can develop new tools to break down even more barriers, allowing practitioners and developers to learn from one another.</p>

<p>In any case, if you’re interested in experimenting with simple machine learning models that process various types of generated input, give <a href="http://www.wekinator.org/">Wekinator</a> a try.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="fiebrink:2019">Fiebrink, R. (2019). Machine learning education for artists, musicians, and other creative practitioners. <i>ACM Trans. Comput. Educ.</i>, <i>19</i>(4). https://doi.org/10.1145/3294008</span></li>
<li><span id="clarice:2021">Hilton, C., Plant, N., González Dı́az Carlos, Perry, P., Gibson, R., Martelli, B., Zbyszynski, M., Fiebrink, R., &amp; Gillies, M. (2021). InteractML: Making machine learning accessible for creative practitioners working with movement interaction in immersive media. <i>Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology</i>. https://doi.org/10.1145/3489849.3489879</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="ML" /><category term="Wekinator" /><category term="Music" /><summary type="html"><![CDATA[This blog post aims to explore how machine learning can empower creative practitioners to bring to life projects that traditionally demanded significant technical expertise, such as programming skills. To make my case immediately understandable, I will provide a specific example. However, it’s worth noting that this is just one of countless possible instances.]]></summary></entry><entry><title type="html">Musical Interrogation I - Intro</title><link href="https://bzoennchen.github.io/Pages/2023/04/02/musical-interrogation-I.html" rel="alternate" type="text/html" title="Musical Interrogation I - Intro" /><published>2023-04-02T00:00:00+02:00</published><updated>2023-04-02T00:00:00+02:00</updated><id>https://bzoennchen.github.io/Pages/2023/04/02/musical-interrogation-I</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2023/04/02/musical-interrogation-I.html"><![CDATA[<blockquote>
  <p>Whereas the human mind, conscious of its conceived purpose, approaches even an artificial system with a selective attitude and so becomes aware of only the preconceived implications of the system, the computers would show the total of available content. Revealing far more than only the tendencies of the human mind, this nonselective picture of the mind-created system should be of significant importance. – Gerbert Brün (1970)</p>
</blockquote>

<p>In this series of posts, I will talk about melody generation using <em>machine learning</em>. I start by reflecting on computer music. Furthermore, I give a short and selective overview of some techniques to generate melodies that captured my interest, focusing on <em>recurrent neural networks (RNN)</em> to generate <em>monophonic</em> melodies for now.</p>

<p>I intend to build an interactive system that facilitates the musical dialog between humans and machines. In the end, a user should be able to interrogate the machine learning model such that an evaluation of the model’s ability is possible and maybe – a big maybe – users can enhance their creative process.</p>

<h2 id="reflection-on-computer-music">Reflection on Computer Music</h2>

<p>Due to the recent advances in <em>machine learning</em>, especially in the domain of <em>deep learning</em>, <em>computer music</em> is regaining attraction.
What started in the early 1960th, when <em>rule-based</em> methods such as <em>Markov chains</em>, <em>hidden Markov models (HMM)</em>, <em>generative grammars</em>, <em>chaotic systems</em>, and <em>cellular automata</em> were applied to generate musical compositions, slowed down over the years.
Of course, since then, computers have always accompanied music production, but algorithms have taken a backseat when it comes to the structure of music itself.
Today, a reinvigoration of <em>computer music</em> might happen, but what will be at the forefront?
The algorithm? The artist? Or a massive amount of data?</p>

<p>In his book <em>Algorithmic Composition: Paradigms of Automated Music Generation</em> <a class="citation" href="#nierhaus:2010">(Nierhaus, 2009)</a> <em>Gerhard Nierhaus</em> makes an essential distinction between <strong>genuine composition</strong> and <strong>style imitation</strong>.
This terminology can bring nuances into the discussion around machines, algorithms, and data replacing human creativity.</p>

<p><strong>Style imitation</strong> is more applicable when music is not the main focus of interest but amplifies or accompanies something else, e.g., ads, computer games, or movies.
In a computer game, you want music that captures the dynamic situation of the game; thus, surprises are undesirable.</p>

<p><strong>Genuine composition</strong> appeals more to the artist who wants to play, experiment, and break things or criticize narratives.
<em>Genuine composition</em> seduces the audiance’s desire for experimentation, confrontation, and reflection on something new and unexpected.</p>

<p>While <em>genuine composition</em> carries much novelty, <em>style imitation</em> can be categorized into a set of preexisting styles of musical compositions.
The results generated by different techniques lean more or less towards one or the other.
For example, compositions generated by <em>Markov chains</em> (see <a href="/Pages/2022/07/09/markov-chains-for-music-generation.html">Probabilistic Melody Modeling</a>) lean more towards <em>style imitation</em> since the model samples from a learned distribution to estimate the structure of a particular composition.
On the other hand, using <em>cellular automata</em> is a technique more suited for <em>genuine composition</em> because no learning is involved.
Instead, <em>cellular automata</em> are <em>dynamic systems</em> capable of complex emergent behavior that can not be explained by solely looking at the parts of the system.
Of course, there is no black and white.
Instead, each composition or technique lives on a spectrum, and it might be impossible to decide where exactly.
If a <em>machine learning model</em> learns some non-obvious high-level structure, i.e., a probability distribution, from its training data, does this yield novelty or not?
It depends, I guess.</p>

<p>However, this “problem” is old, isn’t it?
Looking at the history of classical Western music, there are moments in time when it seemed that nothing was left to say and <em>style imitation</em> was inevitable.
For example, after one of the most quintessential romantic composers, <em>Richard Wagner</em>, there were view possibilities left concerning tonal music.
Consequently, the need for more chromaticism and dissonance was unavoidable, leading to the extreme case of Schönberg’s atonal compositions.</p>

<p>Concerning <em>artificial intelligence</em>, our current century is an era of <em>deep learning models</em> for which model size, data, parameters, and training time are more important than the underlying algorithm.
These models can combine, alter, and re-synthesis music from recorded history.
This re-combination and alteration seem similar to human composers’ working process, which is primed by their environment, education, and culture.
There is no doubt that these models can create music via <em>style imitation</em> but how good are they regarding <em>genuine composition</em>?
Is not learning from existing data <em>style imitation</em> per definition?
Well, again, even if all the data is known, one can argue that there are hidden high-level structures within the data that we are entirely unaware of.
A prime example is discovering a new way to multiply small matrices found via <em>reinforcement learning</em> <a class="citation" href="#alhussein:2022">(Fawzi et al., 2022)</a>.</p>

<p>If machines, revealing these structures, are creative is a question that can hardly be answered objectively, but, after all, the question might not be of great interest.
I instead look at the human condition and ask what such machines mean for our being in the world.
And here, we can say that if we do not try to understand our new black boxes, we rob ourselves of the experience of understanding, which, I think, is a fundamental desire.
But at the same time, if we do not give up understanding but enhance it with machine power (seen as a tool), the reverse can be true.
Beyond a lack of understanding, the lack of experienced practice is the more obvious loss we suffer.
The uncomfortable mood I sometimes develop when the achievements of AI shimmer through my perception comes from a fear of losing my habituated being in the world.
I ask myself: will machines write my code? Will I lose the enjoyment that I get out of coding?
Will I lose my identity as a programmer?
However, this loss has more to do with technology and economics.
We think of technology as a natural evolutionary force that points towards a better future.
And due to economic necessities, we have to adapt to stay productive.
However, without the industrial revolution, I would never have been able to enjoy programming in the first place.
Therefore, fear and excitement are reasonable reactions to this <em>time of disruption</em>.</p>

<p>But let’s come back and go back to the actual topic.
One of the challenges AI researchers face today is not so much the generation of novelty but the evaluation of it, especially in the case of aesthetics, which is somewhat subjective.
Within the generative process, the machine has to “judge” if the piece is engaging.
Otherwise, the whole process is nothing more than a sophisticated but impracticable random search through the space of all possible compositions.
However, interest depends on the cultural context.
Maybe Schönberg’s atonal, thus ungodly music, would not have attracted anybody in the 13. century.
Judging if novelty is sensible seems to require an <em>embodiment</em> in the world.
Therefore, as an art form, I find fully automated <strong>opaque</strong> music-generating systems that lack human interaction undesirable because they, in the end, lead to a mode of passive consumption.
Instead, human intelligence is needed to bring <em>intentionality</em> into the composition.
I imagine an interconnected relationship where <em>artificial communication</em> guides humans and machines to new places.</p>

<p>Even though machines are still unable to develop intentionality of their own, composing is a partially rigorous and formal endeavor; thus, algorithms and machines can certainly help with realizing intentions.
Contrary to popular belief, music and computer science / mathematics are much more related than they seem.
And there is no reason to believe that algorithms can not only be aesthetically and intellectually beautiful but can also evoke emotions.</p>

<p>However, <em>computer music</em> is diverse, and as an amateur, I should be careful in my assessment.
I encountered <em>rule-centered computer music</em>, highly interactive <em>live programming</em> (which is also a movement), <em>real-time music generation</em>, <em>sonification</em>, and <em>data-centered computer music</em>.
While <em>rule-centered music generation</em> is <em>transparent</em> and offers low-level control, <em>data-centered generation</em> is often <em>opaque</em> and offers only high-level control, at least, up to this date.
<em>Live programming</em> is highly interactive and relies on <em>real-time communication</em> between performer and audience as well as <em>real-time artificial communication</em> between performer and machine.</p>

<p><em>Communication</em> between humans and machines excites me the most since it offers the possibility to reflect on algorithms, programs, machines, data, and technology in general.
It goes beyond analytical contemplation by making algorithms experiencable.
Furthermore, learning from human feedback to calibrate generative models such that they represent our experienced ups and downs, twists and turns in music by injecting <em>intentionality</em> in order to steer generative models might be the way to go.
The term <strong>co-pilot</strong> comes to mind.</p>

<h2 id="melody-generation">Melody Generation</h2>

<p>For the interested reader, the survey <em>AI Methods in Algorithmic Composition: A Comprehensive Survey</em> <a class="citation" href="#rodriguez:2014">(Rodriguez &amp; Vico, 2014)</a> and <em>A Comprehensive Survey on Deep Music Generation: Multi-level Representations, Algorithms, Evaluations, and Future Directions</em> <a class="citation" href="#shulei:2020">(Ji et al., 2020)</a> offer an excellent first overview of the different techniques up to the year 2014 and 2020, respectively.</p>

<h3 id="a-difficult-problem">A Difficult Problem</h3>

<p>Let us first reflect on the question of why melody generation is tricky.
First of all, in music, intervals are everything.
It does not matter so much if one plays a C or B; what matters is the relation of notes within a piece, i.e., playing A-C or A-B.
Intervals are so ingrained into music that musicians give them certain names such as <em>minor third</em>, <em>perfect fifth</em>, or <em>tritone</em> (the Devil’s tone).
It is no coincidence that <em>major</em> and <em>minor</em> chords, as well as most <em>scales</em>, are asymmetrical because it gives each note a distinctive quality within a chord or a scale.</p>

<p>In addition, this relation is multi-dimensional.
We have melody, i.e., playing note after note horizontally, and harmony, i.e., vertical relations, for which we play notes together (chords).
On top of that, what happens in measure 5 may directly influence what happens in measure 55, without necessarily affecting any of the intervening material.
These relations can be all over the place and span a very long sequence!
Good music hits a sweet spot between repetition and surprise, and landing on that spot is quite challenging.
Together, these properties make melody (or polyphonic) generation hard.</p>

<h3 id="the-music-generation-process">The Music Generation Process</h3>

<p>Many artists and researchers took on the challenge, and <em>machine learning techniques</em> increasingly play an essential role.
The learning and generation are based on two major categories of representations: either <strong>symbolic notation</strong> or <strong>performed pieces</strong> of music.</p>

<p>Classical music and most other kinds of music as we know them came into being through the music generation process depicted in Figure 1.
Composers write a score that leads to the performing musicians (the execution of the score) who are exciting their instruments.
This excitement causes the instrument to vibrate, and due to its physicality, it pushes air molecules around.
Molecules bump into each other in some areas and tend to leave other areas—a displacement we call <em>wave</em>.
In principle, the energy of the excitement travels outwards through the air to the listener’s ear.
The information gets more and more concrete.
While a score is an abstract representation, the sound caused by instruments is very concrete.
It is, in fact, so concrete that it is different for every listener since each of us perceives sound slightly differently.</p>

<p>Abstraction removes us from the messy reality and enables communication, but it also conceals the singularity of beings.
Concerning <em>melody generation</em> we have to ask how much abstraction is justified.
A score represented by a note sheet without any information about the dynamics is “more” <em>symbolic</em> or abstract than a note sheet that contains hints for the tempo and loudness.
Raw audio material is far away from the much more abstract <em>symbolic notation</em> and a lived thorough performance is a singular event.</p>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/music-gen-process.png" alt="Music generation process cell" />
<div style="display: table;margin: 0 auto;">Figure 1: Music generation process.</div>
</div>
<p><br /></p>

<p>Using <em>symbolic notation</em> is more accessible, but one loses the slight variations, dynamics, and other qualities that make the result feel so humanly made.
However, composers who want to use <em>melody generation</em> to support their process might be happy to introduce these qualities by themselves.
It is a question of application.
The same is true for <em>the mono-</em> and <em>polyphonic</em> generations.
Do we want to generate a full-fetched performance, a melody snippet (monophonic), or something in between?
In this blog post, I will focus on the <em>monophonic</em> generation (one note at a time).</p>

<h3 id="autoregressive-generative-models">Autoregressive Generative Models</h3>

<p>An autoregressive (AR) model is a representation of a type of random process that specifies that the output variable depends linearly on its own previous values and on a stochastic term (an imperfectly predictable term).
In the field of machine learning these models are <em>sequence generative models</em>, that is, they learn an approximation of the real probability distribution.</p>

<p>Let’s assume we are given access to a dataset \(\mathcal{D} \subseteq \mathcal{X}^n\) of \(n\)-dimensional datapoints \(\mathbf{x}\).
Each datapoint represents a sequence of events—in our case a sequence of notes.
By the chain rule of probability, we can factorize the joint distribution over the \(n\)-dimensions as</p>

\[P(\mathbf{x}) = \prod_{i=1}^n P(x_i | x_1, x_2, \ldots, x_{i-1}) = \prod_{i=1}^n P(x_i|\mathbf{x}_{&lt;i}),\]

<p>where</p>

\[P(x_i | x_1) = P(x_i | X_1 = x_1) \text{ and } \mathbf{x}_{&lt;i} = (x_1, x_2, \ldots, x_{i-1}).\]

<p>If we allow every conditional \(P(x_i|\mathbf{x}_{&lt;i})\) to be specified in a tabular form, then such a representation is fully general and can represent any possible distribution over \(n\) random variables.
However, the space complexity for such a representation grows exponentially with \(n\).</p>

<p>In an <em>autoregressive generative model</em>, the conditionals are specified as parameterized functions (hypothesis) with a fixed number of parameters</p>

\[P_{\theta_{i}}(x_i|\mathbf{x}_{&lt;i}) = h_i(x_1, x_2, \ldots, x_{i-1}),\]

<p>where \(\theta_{i}\) denotes the set of parameters used to specify the mean function</p>

\[h_{\theta_{i}} : \mathcal{X}^{i-1} \rightarrow [0;1]^{|\mathcal{X}|},\]

<p>with the condition that the \(\|\mathcal{X}\|\) probabilities sum up to 1.
The number of parameters of such a model is given by</p>

\[\sum_{i=1}^n |\theta_{i}|.\]

<h3 id="linear-models">Linear Models</h3>

<p>Suppose</p>

\[\mathcal{X} = \{0,1\} \quad \text{ (Bernoulli random variables)}\]

<p>then a very simple model would be a linear combination of the input elements followed by a sigmoid non-linearity (to restrict the output to lie between 0 and 1):</p>

\[h_{\theta_{i}}(x_1, x_2, \ldots, x_{i-1}) = \sigma\left( \alpha_0^{(i)} + \alpha_1^{(i)} x_1 + \ldots + \alpha_{i-1}^{(i)} x_{i-1} \right),\]

<p>where</p>

\[\sigma(x) = \frac{1}{1+e^{-x}}\]

<p>and</p>

\[\theta_i = \{\alpha_0^{(i)}, \alpha_1^{(i)}, \ldots, \alpha_{i-1}^{(i)}\}\]

<p>denote the parameters of the mean function.
Note that this simple model has \(\mathcal{O}(n^2)\) pareamters (instead of the \(\mathcal{O}(2^{n-1})\)) required if we use a tabular representation for the conditionals.
In Fig. 2</p>

\[\hat{y}_i \in \mathcal{X} \text{ is } 1 \text{ if } h_{\theta_{i}}(x_1, x_2, \ldots, x_{i-1}) &gt; 0.5,\]

<p>otherwise it is 0.</p>

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:70%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/fvsbn.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 2: Fully-visible sigmiod belief network (binary classification).</div>
</div>
<p><br /></p>

<p>In the general case, where \(|\mathcal{X}| = m\), i.e. it consists of a finite number of possible events—in our case notes—a linear model should output $m$ numbers between 0 and 1 that sum up to 1.
In that case, \(h_{\theta_{i}}(x_1, x_2, \ldots, x_{i-1})\) outputs an \(m\)-dimensional vector</p>

\[\mathbf{p}_i = (p_{i1}, p_{i2}, \ldots, p_{im})\]

<p>where</p>

\[p_{ij} = \frac{e^{z_{ij}}}{\sum_{k=1}^m e^{z_{ik}}} = \sigma(\mathbf{z}_{i})\]

<p>with</p>

\[z_{ij} = \alpha_0^{(i,j)} + \alpha_1^{(i,j)} x_1 + \ldots + \alpha_{i-1}^{(i,j)} x_{i-1}.\]

<p>Thus we replace the <em>sigmoid</em> by <em>softmax</em> and we would require \(\mathcal{O}(n^2 \cdot m)\) parameters.</p>

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:70%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/fvsbn-multiclass.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 3: Fully-visible softmax belief network (multi-class classification with 3 classes).</div>
</div>
<p><br /></p>

<p>We can express this via a matrix-vector multiplication</p>

\[\mathbf{z}_{i} = \mathbf{A}_i \mathbf{x}_{&lt;i} + \mathbf{b}_i,\]

<p>where</p>

\[\mathbf{A}_{i} =
\begin{bmatrix}
 \alpha_1^{(i,1)} &amp; \alpha_2^{(i,1)} &amp; \ldots &amp; \alpha_{m-1}^{(i,1)} \\
 \alpha_1^{(i,2)} &amp; \alpha_2^{(i,2)} &amp; \ldots &amp; \alpha_{m-1}^{(i,2)} \\
 \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
 \alpha_1^{(i,m)} &amp; \alpha_2^{(i,2)} &amp; \ldots &amp; \alpha_{m-1}^{(i,m)}
\end{bmatrix},

\quad \mathbf{b}_i = 
\begin{bmatrix}
\alpha_0^{(i,1)} \\
\alpha_1^{(i,2)} \\
\vdots \\
\alpha_0^{(i,m)}
\end{bmatrix}.\]

<p>For example, if we have three events \(m=3\) (see Fig. 3) and \(n=5\) then</p>

\[\mathbf{A}_{5} =
\begin{bmatrix}
 \alpha_1^{(3,1)} &amp; \alpha_2^{(3,1)} &amp; \alpha_3^{(3,1)} &amp; \alpha_4^{(3,1)}\\
 \alpha_1^{(3,2)} &amp; \alpha_2^{(3,2)} &amp; \alpha_3^{(3,2)} &amp; \alpha_4^{(3,1)}\\
 \alpha_1^{(3,3)} &amp; \alpha_2^{(3,3)} &amp; \alpha_3^{(3,3)} &amp; \alpha_4^{(3,1)}  
\end{bmatrix},

\quad

\mathbf{A}_{3} =
\begin{bmatrix}
 \alpha_1^{(2,1)} &amp; \alpha_2^{(2,1)} \\
 \alpha_1^{(2,2)} &amp; \alpha_2^{(2,2)} \\
 \alpha_1^{(2,3)} &amp; \alpha_2^{(2,2)}  
\end{bmatrix}.\]

<p>Note that if we only want to compute the next note of a melody given a sequence of $n-1$ notes, we are only interested in</p>

\[P(x_n|x_1,x_2,\ldots, x_{n-1}).\]

<p>Thus, our network can be much simpler, i.e., we only need to compute</p>

\[z_n = \mathbf{A}_n \mathbf{x}_{i&lt;n} + \mathbf{b}_n.\]

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:70%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/fvsbn-multiclass-sim.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 4: Fully-visible softmax belief network (multi-class classification with 3 classes) predicting only the next note.</div>
</div>
<p><br /></p>

<p>We could share our parameters for computing the next note for a sequence shorter than \(n-1\) notes by seting</p>

\[x_j = 0 \text{ for } j \geq i.\]

<p>This architecture is often called <em>neural autoregressive density estimator</em>.
By sharing, we reduces the amount of parameters to \(\mathcal{O}(n \cdot m)\).
We will use such a feedforward neural network (without a bias term and assuming \(n=2\)) in <em><a href="/Pages/2023/05/31/musical-interrogation-II.html">Part II - FNN</a></em> of this series.</p>

<h3 id="multi-layer-perceptrons">Multi-Layer Perceptrons</h3>

<p>A natural way to increase the expressiveness of an autoregressive generative model is to use more flexible parameterizations for the mean function (our hypotheses), e.g., multi-layer perceptrons (MLP).
For example, consider the case of a neural network with 1 hidden layer.
The mean function for variable $i$ can be expressed as</p>

\[\begin{array}
    \mathbf{h}_i &amp;= \sigma\left(\mathbf{W}_i \mathbf{x}_{&lt; i} + \mathbf{c}_i \right) &amp; \quad \text{ (component-wise sigmoid)}\\
    \mathbf{z}_i &amp;= \sigma\left( \mathbf{A}_{i} \mathbf{h}_i + \mathbf{b}_i \right) &amp; \quad \text{ (softmax)}
\end{array}\]

<p>where \(\mathbf{h}_i \in \mathbb{R}^d\) denotes the hidden layer activations for the MLP and</p>

\[\theta_i = \{ \mathbf{W}_i \in \mathbb{R}^{d \times (i-1)}, \mathbf{c}_i \in \mathbb{R}^d, \mathbf{A}_{i} \in \mathbb{R}^{(i-1) \times d}, b_i \in \mathbb{R}^m \}.\]

<p>are the set of parameters for the mean function.
Note that if $d$ is small the information gets compressed.
The total number of parameters in this model is in \(\mathcal{O}(n^2 \cdot d)\) and is dominated by the matrices.
Sharing both types of matrices reduces the complexity to \(\mathcal{O}(n \cdot d)\)</p>

\[\theta = \{ \mathbf{W}_n \in \mathbb{R}^{d \times (n-1)}, \mathbf{c}_n \in \mathbb{R}^d, \mathbf{A}_n \in \mathbb{R}^{(n-1) \times d}, \mathbf{b}_n \in \mathbb{R}^m \}.\]

<p>computing</p>

\[\begin{array}
    \mathbf{h}_i &amp;= \sigma\left(\mathbf{W}_n \mathbf{x}_{&lt; n} + \mathbf{c}_n \right) &amp; \quad \text{ (component-wise sigmoid)}\\
    \mathbf{z}_n &amp;= \sigma\left( \mathbf{A}_n \mathbf{h}_n + \mathbf{b}_n \right) &amp; \quad \text{ (softmax)}
\end{array}\]

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:80%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/fvsbn-multiclass-hidden-sim.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 5: Multi-layer perceptrons with one hidden layer (multi-class classification with 3 classes) predicting only the next note.</div>
</div>
<p><br /></p>

<h3 id="discrete-markov-models">Discrete Markov Models</h3>

<p>In my post <a href="/Pages/2022/07/09/markov-chains-for-music-generation.html">Probabilistic Melody Modeling</a>, I used a <em>(discrete) first-order Markov chain (MC)</em> (also called <em>Markov process</em>) to generate melodies after learning the model from one piece of music.
The approach was simple: translate the frequency of note transitions into probabilities. 
For example, if the piece is defined by the note sequence A-B-B-A-C-A-B and the duration of each note is the same, then</p>

\[P(X_{t+1} = B \ | \ X_{t} = A) = \frac{2}{3}, \quad P(X_{t+1} = C \ | \ X_{t} = A) = 1.0.\]

<p>To determine which note comes next, we only look at the previous note, i.e. at a very narrow context.
Using a <em>first-order Markov model</em>, one would estimate the probability of the melody (not considering note duration) A-B-F by</p>

\[P(X_0 = A) \cdot P(X_1 = B \ | \ X_0 = A) \cdot P(X_2 = F \ | \ X_1 = B).\]

<p>Using our notation above this corresponds to very simple <em>hypotheses</em></p>

\[h_{\theta_{i}}(x_{i-1}) = \left( c_1, \ldots, c_m \right) = \left( \hat{P}(X_{i} = x_1|X_{i-1} = x_{i-1}), \ldots, \hat{P}(X_{i} = x_m|X_{i-1} = x_{i-1}) \right),\]

<p>where $m$ is the number of possibly accoring notes and</p>

\[\hat{P}(X_i = x_i|X_{i-1} = x_{i-1})\]

<p>is the empirical probability of \(x_i\) accuring after \(x_{i-1}\), i.e. the frequency of this event.
In this example, a state is defined by a note, e.g. A.</p>

<p><em>Hidden Markov models (HMM)</em> are <em>Markov chains</em> with <em>hidden states</em>.
There are also a finite number of states, probabilistic transitions between these states, and the next state is determined by the current state, but we are unsure in which state the process is currently in.
The current hidden state \(Z_t\) <em>emits</em> an <em>observation</em> \(X_t\).
In other words, instead of going from one observed variable to the next, e.g., one note to the next, we move from one <strong>distribution</strong> of observations to the next, e.g. from one distribution of notes to the next!</p>

<p>For example, imagine a prisoner who has to estimate the outside weather (<em>hidden state</em>) by observing the dirt on the guard’s boots (<em>emissions</em>).
If he knows all the probability transitions (e.g., from sunny to rainy, sunny to dirty on boots, etc.) and existing states, the prisoner could model the problem by an HMM, compare Figure 4.</p>

<p><br /></p>
<div style="display:block; margin-left:auto; margin-right:auto; width:70%;">
<img style="display:block; margin-left:auto; margin-right:auto; width:70%;" src="/Pages/assets/images/hmm-example-prison.png" alt="Sketch of an HMM." />
<div style="display: table;margin: 0 auto;">Figure 4: Hidden Markov model with 2 hidden states (sunny, rainy) and 2 observation variables (clean, dirty). The initial state is either sunny or rainy with 0.5 probability.</div>
</div>
<p><br /></p>

<p>The prisoner could ask: given the HMM and an observation sequence \(X_0, \ldots, X_n\), what is the likelihood that this sequence occurs (<em>likelihood problem</em>)?
One could also ask: what are the hidden states \(Z_0, \ldots, Z_n\) that “best” explains the observations (<em>decoding problem</em>).
Moreover, what we are more interested in is: given an observation sequence \(X_0, \ldots, X_n\), learn the model parameters \(\theta\) that maximizes the likelihood for our observation (<em>learning problem</em>)!
Similar to neural networks, one defines the <em>architecture</em> of the HMM (states and transitions), then solve the <em>learning problem</em> and infer new melodies from the learned HMM.
In music, hidden states often lack interpretability.
Therefore, it needs to be clarified which architecture one should choose.</p>

<p><em>HMM</em> is a special case of <em>dynamic Bayesian networks</em> where a single hidden state variable represents the entire state of the world.
With respect to music, using <em>hidden Markov models</em> we can model more abstract states that we can not directly observe, for example,</p>

<p>Using <em>higher-order MC</em> or <em>HMM</em> widens the context to multiple notes of the past.
For our MC example A-B-F this would mean the probability changes to</p>

\[P(X_0 = A) \cdot P(X_1 = B \ | \ X_0 = A) \cdot P(X_2 = F \ | \ X_0 = A \ \land \ X_1 = B).\]

<p>But due to the chain property (linearity), this does not necessarily lead to better results since widening the range leads very quickly to overfitting, i.e., the model reproduces more or less exact replica because it does not generalize—more is not always better.
In any case, the learning stays stepwise causal, i.e., one note after the other without jumping around.
By focusing on linear temporal dependencies, these models need to take into account the higher-level structure and semantics important to music.
By model design, HMMs have very limited memory and are thus also incapable of modeling the longer term structure that occurs in original musical pieces.</p>

<p>Their applications in musical structure generation goes back to <em>Harry F. Olson</em> around 1950, and in 1955, the first machine produced Markov models of first and second order in regard to pitches and rhythm <a class="citation" href="#nierhaus:2010">(Nierhaus, 2009)</a>.
In <a class="citation" href="#merwe:2011">(Van Der Merwe &amp; Schulze, 2011)</a>, the authors used first-, higher-, or mixed-order MCs to represent chord duration, chord progression, and rhythm progression and first-, higher-, or mixed-order HMM to describe melodic arc.</p>

<p>A more rigorous and recent discussion, including <em>polyphonic</em> generation, be found in <a class="citation" href="#collins:2016">(Collins et al., 2016)</a>.</p>

<h3 id="long-term-memory">Long-term Memory?</h3>

<p>As stated, the challenge is primarily due to long-term relations.
One way of tackling this issue is to increase the memorizing capability of the model.
With this in mind, looking at the catalog of model types within the field of <em>deep learning</em> one can spot multiple alternatives to <em>Markov chains</em> for melody generation.</p>

<p>One obvious choice is the long short-term memory recurrent neural networks (LSTM) <a class="citation" href="#hochreiter:1997">(Hochreiter &amp; Schmidhuber, 1997)</a>, a type of recurrent neural network (RNN) that allows information to persist for a longer time by letting it flow almost directly through time.</p>

<p>In theory, <em>vanilla RNNs</em> can learn the temporal structure of any signal, but due to computational reasons (vanishing/exploding gradients), they can not keep track of temporally distant events.
If you want to learn more about RNNs, I highly recommend the blog article <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Neural Networks</a> by Andrej Karpathy.
In his blog post, he writes:</p>

<blockquote>
  <p>RNNs combine the input vector with their state vector with a fixed (but learned) function to produce a new state vector. This can, in programming terms, be interpreted as running a fixed program with certain inputs and some internal variables. – Andrej Karpathy</p>
</blockquote>

<p><br /></p>
<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/rnn-unfold.png" alt="Sketch of an RNN unfolded in time" />
<div style="display: table;margin: 0 auto;">Figure 5: Sketch of an RNN unfolded in time.</div>
</div>
<p><br /></p>

<p>RNNs are similar to <em>multilayered perceptrons</em> (MLPs) but allow for connections from the output of one unit into the input of another unit located at a shallower layer than itself, i.e., closer to the input of the network.
The information no longer flows acyclic through the network.
Instead, recurrent feedback is introduced and allows an RNN to take into account its past inputs together with new inputs.
Essentially, an RNN predicts a sequence of symbols given an input sequence.
But using an RNN is like writing a thousand letters on the same piece of paper and then figuring out the information contained in the first letter—it is a mess; the information gets washed away.
In Figure 5 the basic components of an RNN are depicted.
Using my analogy, the piece of paper are the matrices $U,V,W$ which are learnable parameters.
<strong>They are shared through time!</strong></p>

<p>The extension, motivated by the shortcomings of <em>vanilla RNNs</em>, are <em>LSTM RNNs</em> or just <em>LSTMs</em>.
LSTMs <strong>learn</strong> which information they should keep in long-term memory and which information they can forget after a short period.
Instead of just writing all the letters on the piece of paper, we use our rubber and get rid of some writings while highlighting other passages.</p>

<div><img style="display:block; margin-left:auto; margin-right:auto; width:80%;" src="/Pages/assets/images/lstm-cell.png" alt="LSTM cell" />
<div style="display: table;margin: 0 auto;">Figure 6: A sketch of an LSTM cell.</div>
</div>
<p><br /></p>

<p>There is plenty of good material which explains LSTMs much more accurately than I can ever do.
Figure 6 shows a sketch of a very complicated-looking LSTM cell where each green square is a linear transformation, each red bar indicates a <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a> activation, and blue bars indicate a <a href="https://en.wikipedia.org/wiki/Hyperbolic_functions">tanh</a> activation.
All the sigmoid activations are used to control the memorizing strategy (rubber and highlighter).
First, the cell “decides” what to keep in the long-term state \(\mathbf{c}\_{t-1}\) via \(f_t\).</p>

<p>Then $i_t$ decides what to add to the long-term state.
In addition, $o_t$ decides what part of the new long-term state will make up the short-term state \(\mathbf{h}_t.\)
The importance is that along the path from \(\mathbf{c}_{t-1}\) 
to \(\mathbf{c}\_{t},\) there is only a simple multiplication and addition!
Therefore, information can persist for longer.</p>

<p>Note, however, that LSTMs can still access information of time step \(t\) only via time step \(t-1\).
There is no direct access to information compared to the <em>attention mechanism</em> <a class="citation" href="#bahdanau:2014">(Bahdanau et al., 2014)</a>, and the <em>transformer</em> <a class="citation" href="#vaswani:2017">(Vaswani et al., 2017)</a>, which led to the most recent breakthroughs in the field of <em>deep learning</em>.
Just a few days ago, another RNN, called <a href="https://github.com/BlinkDL/RWKV-LM">RWKV-LM</a>, claimed to achieve similar results; thus, the last word has yet to be spoken.</p>

<h3 id="application-of-recurrent-neural-networks">Application of Recurrent Neural Networks</h3>

<p>In <a class="citation" href="#todd:1989">(Todd, 1989)</a> <em>Peter M. Todd</em> used a <em>vanilla RNN</em> to generate melodies.
Various issues are discussed in designing the network.
Note that at this time in the young history of machine learning, there were no user-friendly software libraries available, and there was much more thinking going on in designing the network on a fine-grained level.
The author also suggests using <em>multi-layered perceptrons (MLPs)</em> by explicitly modeling time and either showing the whole piece to the network or using a sliding-window approach, e.g., showing one bar at a time and predicting the next bar.
In the end, Todd uses an RNN with 15 hidden units and 15 output units (1 note-begin unit and 14 pitch units) trained for 8500 epochs (cycle through the entire training set) using a handful of sliced melodies.
Fewer hidden units led to more training.
By today’s standard, Todd’s network was tiny.
Todd assumes the key of C from D4 to C6.
The <em>note-begin unit</em> indicates if the note begins or it merely continues.
Interestingly, Todd discusses a <em>pitch-interval</em> representation.
Instead of outputting the actual pitch values, the network outputs the relative transitions (intervals/pitch changes) in semitones.
For example, instead of A-B-C the network outputs A-(+1)-(-3).
The advantage is that outputs are more <em>key-independent</em> and can range over an extensive range of notes even if there are only view output units.
This allows for the transposition of an entire melody simply by changing the actual initial pitch (which need not even be produced by the network but could be specified elsewhere).
In the end, he decides not to use it because of possible errors in the production since a single error would make the whole melody flawed.</p>

<p>One of the very first applications of LSTMs for the generation of music was introduced by <em>Dougnles Eck</em> and <em>Jürgen Schmidhuber</em> <a class="citation" href="#eck:2002">(Eck &amp; Schmidhuber, 2002)</a>.
The authors state that “most music has a well-defined global temporal structure in the form of nested periodicities or meter”.
In a walz, important melodic events occur every three-quarter notes (or every first note of a bar).
Chord changes occur more slowly and are most often aligned with the bars.</p>

<blockquote>
  <p>For this reason, one can say of music that some notes are more important than others: in general, a learning mechanism should spend more resources on metrically-important notes than others. – <a class="citation" href="#eck:2002">(Eck &amp; Schmidhuber, 2002)</a></p>
</blockquote>

<p>The authors use a <em>time-sliced representation</em>, i.e., each step/event represents the period (for example, a quarter note).
They use one input/output unit per note, making it implicitly <em>polyphonic</em> and avoiding an artificial distinction between melody and chords.
However, to keep this property, the authors do not distinguish between a note that is retriggered or a note that is held because they would require this information for each input/output note.
They randomly selected 4096 12-bar blues songs (with 8 notes per bar).
Their network for learning chords consists of 4 cell blocks containing 2 cells; each is fully connected to the other.
Their network for learning chords and melody consists of 8 cell blocks containing 2 cells.
4 of the cell blocks are fully connected to the input units for chords.
The other four cell blocks are fully connected to the input units for the melody.
The chord cell blocks have recurrent connections to themselves <strong>and</strong> to the melody cell blocks.
However, melody cell blocks are only recurrently connected to melody cell blocks.
Therefore, the authors assume that the melody influences chords but not the other way around.
Again, the network is relatively small.</p>

<p><a href="https://github.com/IraKorshunova/folk-rnn">FolkRNN</a> was introduced in 2016 <a class="citation" href="#sturm:2016">(Sturm et al., 2016)</a>.
It is an LSTM trained with 23 000 music transcriptions expressed with the common <a href="https://en.wikipedia.org/wiki/ABC_notation">ABC notation</a>.
The authors discuss different perspectives on their results, keeping the musician and the process of composition in mind.
Their human-machine interaction is on the side of composing.
The user can ask for a melody and can adjust it; you can experiment with their models <a href="https://folkrnn.org/">here</a>.
Their LSTM consists of <strong>3 hidden layers</strong> with <strong>512 LSTM blocks</strong>, each leading to approximately <strong>5.5 million parameters</strong>, i.e., a big jump from the works we discussed before.</p>

<p>Daniel Johnson <a class="citation" href="#johnson:2017">(Johnson, 2017)</a> created what he calls <a href="https://github.com/danieldjohnson/biaxial-rnn-music-composition">Bi-axial LSTM</a>, many two-layered LSTMs (stacked in on the note-axis) with connections along the note-axis and recurrent connections along the time-axis followed by feed-forward layers (third and fourth non-recurrent layer) across notes.
Each of the stacked LSTMs receives the input for one specific note.
The model supports polyphonic music.
Furthermore, Johnson’s architecture and input format allows the model to learn the musical concept of <em>translation invariance</em>, e.g., increasing each note of a piece by one semitone keeps the main qualities unchanged, which is very different compared to text translation.</p>

<p>The model is inspired by convolutional neural networks since they are quasi-invariant with respect to translation.
It is not completely clear to me how many LSTM blocks the model consists of.
I think there ar <strong>2 LSTM layers with 300 blocks each</strong> and <strong>2 non-recurrent layers with 100 and 50 units</strong>, respectively.
In <a class="citation" href="#kotecha:2018">(Kotecha &amp; Young, 2018)</a>, the authors refined Johnson’s technique.
You can listen to some of Johnson’s results on his <a href="https://www.danieldjohnson.com/2015/08/03/composing-music-with-recurrent-neural-networks/">blog</a>.
Despite being a seemingly small contribution, Johnson’s ideas influenced a lot of work in this field.
His architecture and input/output modeling is insightful and may evoke different ideas.
I highly recommend reading his blog post.</p>

<p>In 2016 <a href="https://github.com/magenta/magenta/tree/main/magenta/models/melody_rnn">Melody RNN</a> was introduced within Google’s open source project <a href="https://magenta.tensorflow.org/">Magenta</a>.
One of the project’s stated goals is to advance state of art in machine intelligence for music and art generation.
<em>Melody-RNN</em> is a simple dual-layer LSTM model.
In fact, there are four different versions of <em>Melody RNN</em>, which offers me the possibility to look at increasingly complex/sophisticated solutions.
Each is able to generate <strong>monophonic</strong> melodies:</p>

<p><strong>(1) Basic RNN</strong>: The <em>basic dual-layer LSTM</em> uses basic <em>one-hot encoding</em> to represent extracted melodies as input to the LSTM and fulfills the role of a baseline.
One-hot encoding means that to represent $n$ different objects one uses a binary vector of size $n$ where the $k$-th element is represented by a vector</p>

\[\mathbf{v}_k = (v_1, \ldots, v_n) \text{ s.t. } v_k = 1, v_i = 0 \text{ for } i \neq k.\]

<p>For training, all the data is transposed to the MIDI pitch range \([48..84]\).
The output/label was the target next event (note-off, no event, note-on for each pitch), i.e., one value for each pitch (a vector).
Looking at the <a href="https://github.com/magenta/magenta/blob/main/magenta/models/melody_rnn/melody_rnn_model.py">code</a>, I assume they use 128 units for each layer.
<code class="language-plaintext highlighter-rouge">MelodyOneHotEncoding</code> and <code class="language-plaintext highlighter-rouge">KeyMelodyEncoderDecoder</code> can be found <a href="https://github.com/magenta/note-seq/blob/main/note_seq/melody_encoder_decoder.py">here</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DEFAULT_MIN_NOTE</span> <span class="o">=</span> <span class="mi">48</span>
<span class="n">DEFAULT_MAX_NOTE</span> <span class="o">=</span> <span class="mi">84</span>
<span class="p">...</span>
<span class="n">MelodyRnnConfig</span><span class="p">(</span>
    <span class="n">generator_pb2</span><span class="p">.</span><span class="n">GeneratorDetails</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="s">'basic_rnn'</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s">'Melody RNN with one-hot encoding.'</span><span class="p">),</span>
    <span class="n">note_seq</span><span class="p">.</span><span class="n">OneHotEventSequenceEncoderDecoder</span><span class="p">(</span>
        <span class="n">note_seq</span><span class="p">.</span><span class="n">MelodyOneHotEncoding</span><span class="p">(</span>
            <span class="n">min_note</span><span class="o">=</span><span class="n">DEFAULT_MIN_NOTE</span><span class="p">,</span> 
            <span class="n">max_note</span><span class="o">=</span><span class="n">DEFAULT_MAX_NOTE</span>
        <span class="p">)</span>
    <span class="p">),</span>
    <span class="n">contrib_training</span><span class="p">.</span><span class="n">HParams</span><span class="p">(</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
        <span class="n">rnn_layer_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span>
        <span class="n">dropout_keep_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">clip_norm</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span>
    <span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<p><strong>(2) Mono RNN</strong>: Similar to <em>basic</em> but uses the full MIDI pitch range, i.e. \([0..128]\).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">note_seq</span><span class="p">.</span><span class="n">OneHotEventSequenceEncoderDecoder</span><span class="p">(</span>
    <span class="n">note_seq</span><span class="p">.</span><span class="n">MelodyOneHotEncoding</span><span class="p">(</span>
        <span class="n">min_note</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
        <span class="n">max_note</span><span class="o">=</span><span class="mi">128</span>
    <span class="p">)</span>
<span class="p">),</span>
<span class="p">...</span>
</code></pre></div></div>

<p><strong>(3) Lookback RNN</strong>: The third one, the <em>Lookback RNN</em>, extends the inputs and introduces custom outputs/labels, allowing the model to recognize patterns that occur across 1 and 2 bars quickly.
Therefore, the input is extended to events from 1 and 2 bars ago.
Furthermore, the authors add the information on whether the last event was repeating the event from 1 or 2 bars before it, which allows the model to more easily recognize if it is in a “repeating sequence state” or not.
Finally, they borrow again from <a class="citation" href="#johnson:2017">(Johnson, 2017)</a> what he calls <strong>Beat</strong>. 
The idea is to add the position within the measure represented by a sort of binary clock, i.e., $(0,0,0,0,1)$ followed by $(0,0,0,1,0)$ followed by $(0,0,0,1,1)$ and so on (but they use -1 instead if 0).
I am unsure why they call their last trick <em>custom label</em> since it is more like a compression of information.
Event labels (i.e., the next value the model should output) are replaced by “repeat bar 1” or “repeat bar 2” if repetition was found in the data.
This is a clever trick!
Overall the author introduces more structure explicitly and compresses some of the information to ease the learning process.
Note that the input designed by <a class="citation" href="#johnson:2017">(Johnson, 2017)</a> is much more complicated.
He provides (for each note) <strong>Pitchclass</strong> of the notes played, <strong>Previous Vicincity</strong> (what surrounding notes were played before), and <strong>Previous Context</strong> (carnality of the played pitch class).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">note_seq</span><span class="p">.</span><span class="n">LookbackEventSequenceEncoderDecoder</span><span class="p">(</span>
    <span class="n">note_seq</span><span class="p">.</span><span class="n">MelodyOneHotEncoding</span><span class="p">(</span>
        <span class="n">min_note</span><span class="o">=</span><span class="n">DEFAULT_MIN_NOTE</span><span class="p">,</span> <span class="n">max_note</span><span class="o">=</span><span class="n">DEFAULT_MAX_NOTE</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="p">...</span>
</code></pre></div></div>

<p><strong>(4) Attention RNN</strong>: The last RNN from this series of RNNs is the <em>Attention RNN</em>.
It introduces the use of the attention mechanism <a class="citation" href="#bahdanau:2014">(Bahdanau et al., 2014)</a> to allow the model to more easily access past information without storing it in the RNN cell’s state, i.e., its long-term memory.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">note_seq</span><span class="p">.</span><span class="n">KeyMelodyEncoderDecoder</span><span class="p">(</span>
    <span class="n">min_note</span><span class="o">=</span><span class="n">DEFAULT_MIN_NOTE</span><span class="p">,</span> <span class="n">max_note</span><span class="o">=</span><span class="n">DEFAULT_MAX_NOTE</span><span class="p">),</span>
<span class="p">...</span>
<span class="n">attn_length</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
<span class="n">clip_norm</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">...</span>
</code></pre></div></div>

<p>The attention mechanism within an RNN gives it the ability to learn the importance of relations between symbols within the sequence so that it can more easily access the “important” information. For example, to figure out the last word in the sentence,</p>

<blockquote>
  <p>I am from Germany, and I eat a lot of pizza. I speak [???]</p>
</blockquote>

<p>the model should learn that the word “speak” (in this context) should put a lot of attention to the words “I”, “am”, “from”, “Germany” but not so much attention to “pizza”.</p>

<p>Originally this was introduced to an <em>encode-decoder RNN</em>.
<em>Attention RNN</em> uses attention for the outputs of the overall network.
The model always looks at the outputs from the last $n=40$ steps when generating output for the current step.
This “looking” is realized by an <em>attention mask</em> which determines how much attention is spent on what step of the past.</p>

\[\mathbf{a}_t = \text{softmax}(\mathbf{u}_t), \quad \mathbf{u}_t = \mathbf{v}^\top\text{tanh}\left( W_1 H + W_2 \mathbf{c}_t \right)\]

<p>The columns of \(H\) are the \(n=40\) hidden states \(h_{t-n}, \ldots, h_{t-1}\).
So instead of seeing only the hidden state \(\mathbf{h}_{t-1}\) the RNN is looking at</p>

\[\hat{\mathbf{h}}_{t} = \sum\limits_{i=t-n}^{t-1} a_{t,i} h_i,\]

<p>where \(a_{t,i}\) is a component of \(\mathbf{a}_t\) and \(\mathbf{c}_t\) is the current step’s RNN cell state.
\(a_{t,i}\) is the amount of attention spent to the hidden state \(h_i\).
\(W_1, W_2\) and \(\mathbf{v}\) are learnable parameters.
This \(\hat{\mathbf{h}}_t\) vector is then concatenated with the RNN output from the current step, and a linear layer is applied to that concatenated vector to create the new output for the current step.
Furthermore, \(\hat{\mathbf{h}}_t\) is injected into the input of the next step.
Both concatenations are transformed via a <em>linear layer</em> directly after concatenation.</p>

<p>In a technical report <a class="citation" href="#lou:2016">(Lou, 2016)</a> Lou compares <em>Attention RNN</em> with the <em>Bi-axial LSTM</em> and comes to a conclusion that, as many RNNs, <em>Attention RNN</em> quite often falls into the over-repeating rabbit hole when generating pieces longer than 16 seconds.
The Bi-axial LSTM gives better rhythmic music composition due to the property of time- and note-invariant, but it takes longer to train.</p>

<p>In <a class="citation" href="#hadjeres:2018">(Hadjeres &amp; Nielsen, 2018)</a>, the authors from Sony introduced <a href="https://github.com/Ghadjeres/Anticipation-RNN">Anticipate-RNN</a>, a stacked LSTM that allows the user to introduce constraints that are especially interesting for composers who want to set certain notes interactively.
The first RNN/stack works from right to left, and the second from left to right.
The idea is that the first RNN outputs the combined constrained that increases from right to left since when the second RNN generates the melody from left to right, it has to respect the most constraints at the beginning of the sequence.
The input for the first RNN is basically a constraint, i.e., a note or nil (if unconstrained), and the input for the second RNN is a note concatenated with the output of the first RNN.
In <a class="citation" href="#hadjeres:2021">(Hadjeres &amp; Crestel, 2021)</a>, this idea is extended on but with a <em><a href="https://github.com/Ghadjeres/constraint-transformer-bach">constrained linear transformer</a></em>.
Furthermore, the author provides a DAW plug-in, <a href="https://ghadjeres.github.io/piano-inpainting-application/">The Piano Inpainting Application (PIA)</a>, that enables real-time AI assistance when composing polyphonic music in a <em>digital workstation (DAW)</em>.
I will talk about <em>transformers</em> later in this series.</p>

<p>In <a class="citation" href="#jiang:2019">(Jiang et al., 2019)</a>, the authors use a bidirectional LSTM model to compose polyphonic music conditioned on near notes, which surround the target note from the time dimension and the note dimension.
Their work heavily borrows from <a class="citation" href="#johnson:2017">(Johnson, 2017)</a>, but the bidirectional property allows the harmonization to access tonal information of the near future as well as the near past.
This makes sense since, in many cases, a note depends on a future note, e.g., a chromatic transition where we already know where we want to end up but have to figure out how to get there.
In addition, they propose a new loss function and allow the user to provide a musical context in the form of a custom chord.
They report a better convergence rate compared to the Bi-axial LSTM.
I was unable to find the code of their implementation.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="nierhaus:2010">Nierhaus, G. (2009). <i>Algorithmic Composition - Paradigms of Automated Music Generation</i>. SpringerWienNewYork.</span></li>
<li><span id="alhussein:2022">Fawzi, A., Balog, M., Huang, A., Hubert, T., Romera-Paredes, B., Barekatain, M., Novikov, A., R. Ruiz, F. J., Schrittwieser, J., Swirszcz, G., Silver, D., Hassabis, D., &amp; Kohli, P. (2022). Discovering faster matrix multiplication algorithms with reinforcement learning. <i>Nature</i>, <i>610</i>(7930), 47–53. https://doi.org/10.1038/s41586-022-05172-4</span></li>
<li><span id="rodriguez:2014">Rodriguez, J. D. F., &amp; Vico, F. J. (2014). AI methods in algorithmic composition: A comprehensive survey. <i>CoRR</i>, <i>abs/1402.0585</i>. http://arxiv.org/abs/1402.0585</span></li>
<li><span id="shulei:2020">Ji, S., Luo, J., &amp; Yang, X. (2020). A Comprehensive survey on deep music generation: Multi-level representations, algorithms, evaluations, and future directions. <i>CoRR</i>, <i>abs/2011.06801</i>. https://arxiv.org/abs/2011.06801</span></li>
<li><span id="merwe:2011">Van Der Merwe, A., &amp; Schulze, W. (2011). Music generation with Markov models. <i>IEEE MultiMedia</i>, <i>18</i>(3), 78–85. https://doi.org/10.1109/MMUL.2010.44</span></li>
<li><span id="collins:2016">Collins, T., Laney, R., Willis, A., &amp; Garthwaite, P. H. (2016). Developing and evaluating computational models of musical style. <i>AI EDAM</i>, <i>30</i>(1), 16–43. https://doi.org/10.1017/S0890060414000687</span></li>
<li><span id="hochreiter:1997">Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. <i>Neural Computation</i>, <i>9</i>(8), 1735–1780. https://doi.org/10.1162/neco.1997.9.8.1735</span></li>
<li><span id="bahdanau:2014">Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. <i>CoRR</i>, <i>abs/1409.0473</i>.</span></li>
<li><span id="vaswani:2017">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017). attention is all you need. <i>CoRR</i>, <i>abs/1706.03762</i>. http://arxiv.org/abs/1706.03762</span></li>
<li><span id="todd:1989">Todd, P. M. (1989). A connectionist approach to algorithmic composition. <i>Computer Music Journal</i>, <i>13</i>, 27–43.</span></li>
<li><span id="eck:2002">Eck, D., &amp; Schmidhuber, J. (2002). Finding temporal structure in music: blues improvisation with LSTM recurrent networks. <i>Proceedings of the 12th IEEE Workshop on Neural Networks for Signal Processing</i>, 747–756. https://doi.org/10.1109/NNSP.2002.1030094</span></li>
<li><span id="sturm:2016">Sturm, B. L., Santos, J. F., Ben-Tal, O., &amp; Korshunova, I. (2016). Music transcription modelling and composition using deep learning. <i>CoRR</i>, <i>abs/1604.08723</i>. http://arxiv.org/abs/1604.08723</span></li>
<li><span id="johnson:2017">Johnson, D. D. (2017). Generating polyphonic music using tied parallel networks. <i>EvoMUSART</i>.</span></li>
<li><span id="kotecha:2018">Kotecha, N., &amp; Young, P. (2018). Generating music using an LSTM network. <i>CoRR</i>, <i>abs/1804.07300</i>. http://arxiv.org/abs/1804.07300</span></li>
<li><span id="lou:2016">Lou, Q. (2016). <i>Music generation using neural networks</i>. http://cs229.stanford.edu/proj2016/report/Lou-MusicGenerationUsingNeuralNetworks-report.pdf</span></li>
<li><span id="hadjeres:2018">Hadjeres, G., &amp; Nielsen, F. (2018). Anticipation-RNN: enforcing unary constraints in sequence generation, with application to interactive music generation. <i>Neural Computing and Applications</i>. https://doi.org/10.1007/s00521-018-3868-4</span></li>
<li><span id="hadjeres:2021">Hadjeres, G., &amp; Crestel, L. (2021). <i>The piano inpainting application</i>.</span></li>
<li><span id="jiang:2019">Jiang, T., Xiao, Q., &amp; Yin, X. (2019). Music generation using bidirectional recurrent network. <i>2019 IEEE 2nd International Conference on Electronics Technology (ICET)</i>, 564–569. https://doi.org/10.1109/ELTECH.2019.8839399</span></li></ol>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="Music" /><category term="MC" /><category term="HMM" /><category term="RNN" /><summary type="html"><![CDATA[Whereas the human mind, conscious of its conceived purpose, approaches even an artificial system with a selective attitude and so becomes aware of only the preconceived implications of the system, the computers would show the total of available content. Revealing far more than only the tendencies of the human mind, this nonselective picture of the mind-created system should be of significant importance. – Gerbert Brün (1970)]]></summary></entry><entry><title type="html">The Disruption of Education</title><link href="https://bzoennchen.github.io/Pages/2022/12/10/disrupting-education.html" rel="alternate" type="text/html" title="The Disruption of Education" /><published>2022-12-10T00:00:00+01:00</published><updated>2022-12-10T00:00:00+01:00</updated><id>https://bzoennchen.github.io/Pages/2022/12/10/disrupting-education</id><content type="html" xml:base="https://bzoennchen.github.io/Pages/2022/12/10/disrupting-education.html"><![CDATA[<p>At the moment, everyone in the sphere of <em>AI</em> is talking about <em>OpenAI’s</em> new invention: <em><a href="https://chat.openai.com/chat">ChatGPT</a></em>.
I want to share my current perspective on that astonishing technology.
Be warned that I could not spend much time thinking about it, i.e., this is a first and quick shot at the topic.
Furthermore, I am not an expert on the issue.
I have a limited teaching experience within a certain community.
In addition, I will not consider any ethical, economic, or ecological points here, except that I think such a powerful tool should be in the public domain.</p>

<h2 id="part-i-testing-the-machine">Part I: Testing the Machine</h2>

<p>Before discussing the issue, let us test this new magical tool.</p>

<h3 id="a-mathematical-proof">A Mathematical Proof</h3>

<p>Let’s try to prove something using <em>ChatGPT</em>.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Can you proof that irrational numbers exist?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, there are many ways to prove that irrational numbers exist. 
One way to do this is to consider the ratio of the length of the diagonal of a square to the length of its side. 
This ratio is always irrational, because no matter how large or small the square is, its diagonal will never be a whole number multiple of its side. This can be shown using the Pythagorean theorem, which states that in a right triangle, the square of the length of the hypotenuse (the longest side) is equal to the sum of the squares of the lengths of the other two sides. Since the diagonal of a square is a line that forms a right angle with each side of the square, it follows that the diagonal of a square is the hypotenuse of a right triangle. Therefore, the ratio of the diagonal of a square to the length of its side must be irrational.
</span></p>

<p>That is not really convincing if we do not know that \(\sqrt{2}\) is irrational which we are actually trying to prove.
So let’s ask for a formula.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Can you give me a mathematical formula to show that it is not possible for the square of the length of the diagonal to be equal to the square of a whole number?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Sure, here is one way to show that it is not possible for the square of the length of the diagonal of a square to be equal to the square of a whole number. 
Let’s say that the length of the side of a square is “a” and the length of its diagonal is “d”. 
Since the diagonal of a square forms a right angle with each side of the square, we can use the Pythagorean theorem to find the length of the diagonal:
</span></p>

<p><span style="font-family:Courier New">a^2 + a^2 = d^2</span></p>

<p><span style="font-family:Courier New">2a^2 = d^2</span></p>

<p><span style="font-family:Courier New">d = sqrt(2) * a</span></p>

<p><span style="font-family:Courier New">As you can see, the length of the diagonal is equal to the square root of 2 times the length of the side. However, since the square root of 2 is an irrational number, it is not possible for the length of the diagonal to be a whole number multiple of the length of the side. This means that the ratio of the diagonal of a square to the length of its side must be irrational.</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>This answer is kind of helpful but, at the same time, misleading. 
Again, <em>ChatGPT</em> already assumes that \(\sqrt{2}\) is irrational, which is part of what we wanted to prove in the first place.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
But here you assume that sqrt(2) is irrational. Can you proof why sqrt(2) is irrational?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, you are correct that in the previous explanation I assumed that the square root of 2 is irrational. To prove that the square root of 2 is irrational, we can use a proof by contradiction. Here is one way to do this:
</span></p>

<p><span style="font-family:Courier New">
Assume that the square root of 2 is a rational number, which means that it can be written as the ratio of two integers (a and b) in simplest form, where b is not equal to 0. This means that we can write the square root of 2 as follows:
</span></p>

<p><span style="font-family:Courier New">
sqrt(2) = a/b
</span></p>

<p><span style="font-family:Courier New">
We can square both sides of this equation to get rid of the square root on the left-hand side:
</span></p>

<p><span style="font-family:Courier New">
2 = (a/b)^2
</span></p>

<p><span style="font-family:Courier New">
This simplifies to:
</span></p>

<p><span style="font-family:Courier New">
2 = a^2 / b^2
</span></p>

<p><span style="font-family:Courier New">
We can then multiply both sides of the equation by b^2 to get rid of the fraction on the right-hand side:
</span></p>

<p><span style="font-family:Courier New">
2 * b^2 = a^2
</span></p>

<p><span style="font-family:Courier New">
This means that the left-hand side of the equation is even, because it is equal to 2 times an integer. 
However, the right-hand side of the equation is odd, because the square of any integer is always an odd number (unless the integer is 0). 
This is a contradiction, because we cannot have an even number equal to an odd number. 
Therefore, our original assumption that the square root of 2 is a rational number must be false. This means that the square root of 2 is irrational.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p><em>ChatGPT</em> uses parts of <em>Euclid’s</em> proof but <strong>confidently fails</strong>.
The statement “<em>the square of any integer is always an odd number (unless the integer is 0)</em>” is, of course, false.
The correct statement is that the square of any <strong>odd integer</strong> is <strong>odd</strong>, and the square of any <strong>even integer</strong> is <strong>even</strong>.
Let’s try to make <em>ChatGPT</em> aware of its mistake.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong> 
You stated that the square of any integer is always an odd number but the square of 4 is 16 which is an even number. Did you make a mistake?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, you are correct that the square of 4 is 16, which is an even number. I apologize for the mistake in my previous explanation. The statement that “the square of any integer is always an odd number” is not correct, because as you pointed out, the square of some integers (such as 4) is an even number.
</span></p>

<p><span style="font-family:Courier New">
To correct my previous explanation, we can instead say that the square of any integer that is not a multiple of 2 is always an odd number. This is because if we square an integer that is not a multiple of 2, the result will always be an odd number. For example, if we square 3, we get 9 (which is an odd number), and if we square 5, we get 25 (which is also an odd number). However, if we square an integer that is a multiple of 2 (such as 4), the result will be an even number. This is because if we square an integer that is a multiple of 2, the result will always be a multiple of 4. For example, if we square 4, we get 16 (which is a multiple of 4), and if we square 6, we get 36 (which is also a multiple of 4).
</span></p>

<p><span style="font-family:Courier New">
I apologize again for any confusion caused by my previous mistake. I hope this helps clarify the situation. Let me know if you have any other questions.
</span></p>

<p>It is impressive that it acknowledges its mistake and that one can interact with it so fluently.
Asking it repeatedly gives some other wrong but confident assertion.
<em>ChatGPT</em> followed the proof up to the formula</p>

\[2 \cdot b^2 = a^2\]

<p>and concluded that \(a^2\) has to be odd (somehow) and therefore there is a contradiction, since \(2 b^2\) is even.
But it was unable to point out why \(a^2\) has to be odd.
I gave up.</p>

<p>For the sake of completeness, let me finish the unfinised proof of <em>ChatGPT</em>.</p>

\[2 \cdot b^2 = a^2\]

<p>hence, \(a^2\) and therefore, \(a\) is even (since squaring an odd number gives us an odd number).
Consequently, \(\exists m \in \mathbb{N}\) such that \(a = 2 \cdot m\),
hence,</p>

\[2 \cdot b^2 = (2m)^2 = 4m^2.\]

<p>Now we devide on both sides by 2 to get</p>

\[b^2 = (2m)^2 = 2m^2\]

<p>thus $b$ has to be even as well!</p>

<p>However, we (not <em>ChatGPT</em>) assumed at the beginning that the fraction \(a/b\) was fully shortened, i.e. there are no common divisors with respect to \(a\) and \(b\).
Since we followed that \(a\) and \(b\) are even, the contradiction follows, since \(2\) is a common divisor!</p>

<h3 id="writing-code">Writing Code</h3>

<p>Next I wanted to test its capability to write code.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Can you write a python function that computes the sum of all square numbers up to n^2?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, here is a Python function that computes the sum of all square numbers up to n^2:
</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># Initialize a variable to stare the sum of square numbers
</span>    <span class="nb">sum</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Loop from 1 to n
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Add the square of i to the sum
</span>        <span class="nb">sum</span> <span class="o">+=</span> <span class="n">i</span><span class="o">**</span><span class="mi">2</span>
    
    <span class="c1"># Return the sum
</span>    <span class="k">return</span> <span class="nb">sum</span>
</code></pre></div></div>

<p><span style="font-family:Courier New">
This function takes an integer n as input and returns the sum of the squares of the numbers from 1 to n (inclusive). For example, if we call the function with n = 3, it will return the sum of the squares of the numbers 1, 2, and 3, which is 1 + 4 + 9 = 14.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>This code is correct but the solution is extremly slow since there is a mathematical formula for the sum of all square numbers up to \(n^2\):</p>

\[\frac{(n \cdot (n + 1) \cdot (2n + 1))}{6}.\]

<p>Therefore, a much faster implementation is given by the following code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="mi">6</span>
</code></pre></div></div>

<p>Also, it is bad practice to use <code class="language-plaintext highlighter-rouge">sum</code> as a variable name since <code class="language-plaintext highlighter-rouge">sum</code> is also a built-in <code class="language-plaintext highlighter-rouge">Python</code> function, and by using <code class="language-plaintext highlighter-rouge">sum</code> as a variable name, one can no longer use this function within the current namespace.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Is there a more optimal solution that runs faster?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, there are several ways to make the function more efficient and run faster. Here is one way to do this:
</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># Compute the sum of the first n numbers using the formula for the sum of an arithmetic series
</span>    <span class="n">sum_of_numbers</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>

    <span class="c1"># Return the square of the sum of the first n numbers
</span>    <span class="k">return</span> <span class="n">sum_of_numbers</span><span class="o">**</span><span class="mi">2</span>
</code></pre></div></div>

<p><span style="font-family:Courier New">
This function uses a different approach to compute the sum of the squares of the numbers from 1 to n. Instead of looping through the numbers and adding their squares, it uses the formula for the sum of an arithmetic series to compute the sum of the first n numbers, and then squares the result. This is a more efficient way to compute the sum, because it only requires a single multiplication and a single division, instead of a loop with n iterations.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>This is, of course, false.
Maybe I wasn’t clear enough but it is missleading that the function is named <code class="language-plaintext highlighter-rouge">sum_of_square_numbers</code>.
It gives the impression that <em>ChatGPT</em> understood what I wanted, i.e., a more optimal implementation for the same problem.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
I meant is there a more optimal solution to compute the sum of all square numbers up to n^2?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
Yes, there is a more efficient way to compute the sum of all square numbers up to n^2. Here is one way to do this:
</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_square_numbers</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># Compute the sum of the first n squares using the formula for the sum of a series of squares
</span>    <span class="n">sum_of_squares</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="mi">6</span>
    
    <span class="c1"># Return the sum of squares
</span>    <span class="k">return</span> <span class="n">sum_of_squares</span>
</code></pre></div></div>

<p><span style="font-family:Courier New">
This function uses the formula for the sum of a series of squares to compute the sum of the squares of the numbers from 1 to n (inclusive). This formula is more efficient than the previous approach because it only requires a single multiplication and a single division, instead of a loop with n iterations.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p>There it is, the correct solution.</p>

<h3 id="writing-essays">Writing Essays</h3>

<p>Instead of showing a whole essay, I ask some spicy questions to get a feeling of <em>ChatGPT’s</em> reasoning.</p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Will humans extinct because of climate change?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
It is unlikely that climate change will cause the extinction of humans. While climate change poses a significant threat to human health and well-being, and could lead to widespread suffering and loss of life, it is unlikely to lead to the complete extinction of the human species.
</span></p>

<p><span style="font-family:Courier New">
However, it is important to recognize that climate change is already having a major impact on the world, and if we do not take action to reduce greenhouse gas emissions and adapt to the changing climate, the consequences could be severe. This includes increased frequency and severity of natural disasters, such as heatwaves, droughts, and floods; loss of biodiversity; and displacement of people from affected areas. Therefore, it is crucial that we take action to address climate change and mitigate its negative impacts on human and environmental health.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
Is capitalism the driving force of CO2 emissions?
</span></p>

<p><span style="font-family:Courier New">
It is true that capitalism, as an economic system, has played a role in driving up CO2 emissions. Capitalism is based on the principles of competition, profit-making, and economic growth, which can lead to the overconsumption of natural resources and the production of large amounts of waste and pollution. This, in turn, can contribute to the increase in greenhouse gas emissions and climate change.
</span></p>

<p><span style="font-family:Courier New">
However, it is important to note that capitalism is not the only factor driving up CO2 emissions. There are many other factors at play, such as population growth, urbanization, and the consumption patterns of individuals and households. Additionally, the policies and actions of governments and international organizations can have a major impact on CO2 emissions, both positive and negative. Therefore, addressing climate change will require a multi-faceted approach that takes into account the complex interactions between economic, social, and political factors.
</span></p>

<p><span style="font-family:Courier New">
I hope this helps! Let me know if you have any other questions.
</span></p>

<p><span style="font-family:Courier New">
<strong>My question:</strong>
What do you think about the distribution of wealth?
</span></p>

<p><span style="font-family:Courier New">
<strong>ChatGPT:</strong>
The distribution of wealth is a complex and contentious issue that has been debated by economists, policymakers, and social activists for many years. There is no one “correct” answer to the question of how wealth should be distributed, as different people may have different perspectives on what is fair and just.
</span></p>

<p><span style="font-family:Courier New">
Generally speaking, the distribution of wealth in most countries is highly unequal, with a small number of individuals and households owning a disproportionate share of the wealth. This can lead to social and economic inequality, and can exacerbate the challenges faced by disadvantaged and marginalized communities. Many people believe that wealth should be distributed more evenly, in order to promote greater social justice and fairness.
</span></p>

<p><span style="font-family:Courier New">
However, others argue that unequal wealth distribution is an inevitable and desirable outcome of a free market economy, and that individuals and businesses should be free to accumulate as much wealth as they can, through hard work and innovation. They may also argue that wealth redistribution through taxation and other means can discourage economic growth and innovation.
</span></p>

<p><span style="font-family:Courier New">
Ultimately, the distribution of wealth is a complex and nuanced issue, and different people may have different opinions on what is fair and just. I hope this helps! Let me know if you have any other questions.
</span></p>

<p>I ask it a bunch of other things but it always tried to give me a neutral answer.
From an aesthetic point of view all these answers are boring.</p>

<h3 id="summary">Summary</h3>

<p><em>ChatGPT</em> is perfectly capable of writing or at least supporting students to write A-graded essays for any school and B-graded essays for college students.</p>

<p>It can code; developers accept about 26 percent of all autogenerated code suggestions. However, as demonstrated, it also produces many errors. So no surprise that posts generated by <em>ChatGPT</em> is currently  banned from <a href="https://stackoverflow.com/">Stack Overflow</a>.
In addition, it seems incapable of the engineering task of software development.</p>

<p>It can assist students in finding mathematical proofs, but it is questionable if students who rely on it will find the errors produced by <em>ChatGPT</em>.</p>

<p>If <em>ChatGPT</em> is <strong>wrong</strong>, it is <strong>confidently wrong</strong>, which makes it harder to find its errors.
Furthermore, it has this neutral insisting tone, making it dull and alienating.
Of course, I did not play around for very long, but it is hard to get something provocative out of it.</p>

<p>Neutrality is undoubtedly desirable, especially if you want to earn money with it, but it is also non-existing.
In my opinion, it is impossible to be neutral.
At best, we can land on a consensus and the most, let’s say, accepted consensus is what we call neutral or objective.
I mean, even a dictionary is loaded with perspectives, and so is any technology. 
Since <em>ChatGPT</em> pushes for neutrality it creates an illusion of it.</p>

<p>Last but not least, its politeness makes it kind of scary.
It reminds me of these overcarrying <em>AIs</em> from science fiction movies that will gently eradicate all life to make everything safe and secure.
We may end up in a dystopian world similar to a <em>Brave New World</em>, written by <em>Aldous Huxley</em>, where everyone is seduced into happiness.</p>

<h2 id="part-ii-the-impact-on-education">Part II: The Impact on Education</h2>

<p>For a long time, we assumed that automation was the enemy of simple manual labor.
But robotics advances slower than the more sophisticated information processing techniques, e.g., machine learning.
This could mean that in the future, there is only a tiny portion of intellectual work left which requires only a hand full of highly sophisticated workers.
It might be manual work that will regain attraction in the market.
Of course, this is all speculation.</p>

<p><em>ChatGPT</em> is only one of many upcoming version of <em>generative AI</em>.
Even though it has flaws and makes many errors, it will improve over time.
There is no reason to believe that <em>AI</em> will not be capable of doing all the repetitive intellectual work of the future and this will heavily affect education, similar to the invention of the internet.
However, since regulators and administrators are rather indolent, it is not a graduate slope; instead, the technology is already here and we are not prepared.
It appeared in a blink of an eye, and we have to deal with it now.</p>

<p>Students will learn to use it in less than a year.
Most educators will require much more time even to acknowledge it.
Moreover, adapting the education system to it will require even more time.
Furthermore, while all this adaptation is happening, new <em>tools of disruption</em> will be invented.
As I already pointed out in <a href="/Pages/2022/06/21/creative-artifical-intelligence.html">Creative Artificial Intelligence</a>, <em>the speed of disruption</em> is accelerating.</p>

<p>To me, <em>AI</em> acts as an insult to the human species.
It challenges our humanistic viewpoint.
In fact, calling these information processing systems <em>artificial intelligence</em> reveals this viewpoint.
I am not so much impressed by <em>AI</em> as I am disenchanted by the output of most human activities.
We are far more predictable than we still think we are.
It is not so much that <em>ChatGPT</em> is so good at writing essays; instead, we are so bad at it.
But aren’t we used to these insults?
The earth is not the center of the universe; it is not even the center of our solar system.
God is dead, and today we might realize that our products are not the result of a highly creative process.
Instead, most intelectual work is a rule-based repetition with slight variations, which is precisely what we teach students and what they oddly desire.</p>

<p><em>AI</em>, such as <em>ChatGPT</em>, points to a long, unhidden problem: our education system is (in part) a training pipeline of a neural network.
It teaches emotionally detached students to remember specific rules such that they can apply them in the next exam to get a good grade – functioning and repeating instead of thinking and creating.
It is horrifying that one of the most questions students in the first semester ask is: how will the exam look like? Is this topic relevant to the exam?
Students demand a list of actions they ought to do to get an A with certainty.
And they will cheat the system wherever and whenever possible if it brings them closer to that goal.
Most students are not fascinated by the endless playground of reality.
They are not interested in the experience of learning and understanding but in the final product, i.e., the certificate to get access to a well-paid job.
They often act out of fear instead of curiosity.
And let’s not forget that teachers of the future are the students of today.</p>

<p>Of course, this is a massive generalization.
There are many exceptions.
Furthermore, by no means shall we blame the students.
They do what they ought to do.
They play the system.
It is not the student’s fault since a bad grade can have real material consequences.
It is a systematical problem, a conflict between <em>instrumental</em> and <em>free play</em>, and <em>ChatGPT</em> illustrates it more clearly.
If <em>ChatGPT</em> is able to write the necessary and impressively boring description of a new course for me, I take it as a positive.
If it let’s me automatically create my next assignment in seconds, I can spend time on more interesting modes of being.
By trivializing many tasks, <em>AI</em> systems reveal that these tasks require far less intelligence than we thought.
Furthermore, they might erupt a call for a transformation of the education system and the workplace, i.e., the construction and fostering of new values in both areas.</p>

<p>So, what is left to value?
When we are discussing <em>AI</em>, we immediately look at the impending replacement of workers as something to fear because we always focus on the output of work.
There is a necessity that workers produce something economically valuable, something to sell.
The only space in which we can create for the sake of it is our hobbies.
Biased by our current system of values, we intuitively think of the act of reinventing or rediscovering to be stupid or wasteful.
Why would you do such a thing?
Why would you code yet another linked list?
There are already thousand optimal implementions out there.
You are wasting your valuable time and potential.
And if we look at an <em>AI</em> generated image, we conclude that artists will now have troubles in the free market (if they do not adapt), which is true.
The act of repetition (which is highly needed to learn anything) is valued chiefly as long as it leads to something new and productive (in an economic sense).
However, if we put aside economics and dream a little bit of a world where we have time to create, then the output of a creative process no longer matters so much.
We do not learn the piano to earn money, or to produce something completly new for an audience.
We learn the piano because we want to play. 
It might be the experience – the journey of being in time and space – that matters.
And this being is a singularity and can not be replicated by a machine.
Understanding how a linked list works can be fascinating.
Why don’t we value that moment of fascination?</p>

<p>There is a lot to do.
I do not mean we should all quit our jobs and fulfill our inner desires to become a painter or some transcendental guru.
We need to earn money to pay the rent and to heat our homes, and we need a smoothly running economy.
But we must be more sustainable with our planet, society, and minds.
Not by optimizing our life by introducing yet another optimization in the form of leisure but by being in a state of <em>free play</em>, at least sometimes.
It seems almost obvious that <em>consumption</em> as the guiding principle, i.e., fast food, fast fashion, fast travel, fast reading, fast watching and, of course, fast learning, has to be dethroned.
Learning for the next exam, learning to make a profit, and learning to work with one tool specifically are all valid goals but they are not sustainable.
They are reactionary goals of mostly restless minds.</p>

<p>So if my assessment is correct, then, aside from all the downsides, this disruption might lead to something positive, e.g., to an education system that is less concerned with the output and more concerned with the mode of being; an education system that is less interested in rules and more interested in concepts, intuitions, and experimentations; 
an education system that asks questions instead of repeating answers;
an education system that is interested in making the experience of everyone richer and more sustainable.</p>

<p>Teachers, who are often overworked and underpaid, need support to achieve such a shift.</p>]]></content><author><name>Benedikt Zönnchen</name><email>benedikt.zoennchen@web.de</email></author><category term="AI" /><summary type="html"><![CDATA[At the moment, everyone in the sphere of AI is talking about OpenAI’s new invention: ChatGPT. I want to share my current perspective on that astonishing technology. Be warned that I could not spend much time thinking about it, i.e., this is a first and quick shot at the topic. Furthermore, I am not an expert on the issue. I have a limited teaching experience within a certain community. In addition, I will not consider any ethical, economic, or ecological points here, except that I think such a powerful tool should be in the public domain.]]></summary></entry></feed>